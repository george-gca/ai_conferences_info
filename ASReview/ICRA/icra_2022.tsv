title	abstract	url	authors
1D-LRF Aided Visual-Inertial Odometry for High-Altitude MAV Flight.	This paper addresses the problem of visual-inertial odometry (VIO) with a downward facing monocular camera when a micro aerial vehicle (MAV) flying at high altitude (over 100 meters). It is important to note that large scene depth causes visual motion constraints significantly less informative than that in near-sighted scenarios as considered in most existing VIO methods. To cope with this challenge, we develop an efficient MSCKF-based VIO algorithm aided by a single 1D laser range finder (LRF), termed LRF-VIO, which runs in real time on an embedded system. The key idea of the proposed LRF-VIO is to fully exploit the limited metric distance information provided by the 1D LRF to disambiguate the scale during visual feature tracking, thus improving the VIO performance at high altitude. Specifically, during the MSCKF visual measurement update, we deliberately constrain the depth of those SLAM features co-planar with the single LRF measuring point. Additionally, delayed initialization of features utilizes the LRF measurements whenever possible, and online extrinsic calibration between the LRF and monocular camera is performed to further improve estimation accuracy and robustness. The proposed LRF-VIO is extensively validated in both indoor and outdoor real-world experiments, outperforming the state-of-the-art methods.	https://doi.org/10.1109/ICRA46639.2022.9811757	Jiaxin Hu, Jun Hu, Yunjun Shen, Xiaoming Lang, Bo Zang, Guoquan Huang, Yinian Mao
360VO: Visual Odometry Using A Single 360 Camera.	In this paper, we propose a novel direct visual odometry algorithm to take the advantage of a 360-degree camera for robust localization and mapping. Our system extends direct sparse odometry by using a spherical camera model to process equirectangular images without rectification to attain omnidirectional perception. After adapting mapping and optimization algorithms to the new model, camera parameters, including intrinsic and extrinsic parameters, and 3D mapping can be jointly optimized within the local sliding window. In addition, we evaluate the proposed algorithm using both real world and large-scale simulated scenes for qualitative and quantitative validations. The extensive experiments indicate that our system achieves start of the art results.	https://doi.org/10.1109/ICRA46639.2022.9812203	Huajian Huang, Sai-Kit Yeung
3D Perception based Imitation Learning under Limited Demonstration for Laparoscope Control in Robotic Surgery.	Automatic laparoscope motion control is fundamentally important for surgeons to efficiently perform operations. However, its traditional control methods based on tool tracking without considering information hidden in surgical scenes are not intelligent enough, while the latest supervised imitation learning (IL)-based methods require expensive sensor data and suffer from distribution mismatch issues caused by limited demonstrations. In this paper, we propose a novel Imitation Learning framework for Laparoscope Control (ILLC) with reinforcement learning (RL), which can efficiently learn the control policy from limited surgical video clips. Specially, we first extract surgical laparoscope trajectories from unlabeled videos as the demonstrations and reconstruct the corresponding surgical scenes. To fully learn from limited motion trajectory demonstrations, we propose Shape Preserving Trajectory Augmentation (SPTA) to augment these data, and build a simulation environment that supports parallel RGB-D rendering to reinforce the RL policy for interacting with the environment efficiently. With adversarial training for IL, we obtain the laparoscope control policy based on the generated rollouts and surgical demonstrations. Extensive experiments are conducted in unseen reconstructed surgical scenes, and our method outperforms the previous IL methods, which proves the feasibility of our unified learning-based framework for laparoscope control.	https://doi.org/10.1109/ICRA46639.2022.9812010	Bin Li, Ruofeng Wei, Jiaqi Xu, Bo Lu, Chi Hang Yee, Chi-Fai Ng, Pheng-Ann Heng, Qi Dou, Yun-Hui Liu
3D Printing of Concrete with a Continuum Robot Hose Using Variable Curvature Kinematics.	We present a novel application of continuum robots acting as concrete hoses to support 3D printing of cementitious materials. An industrial concrete hose was fitted with a cable harness and remotely actuated via tendons. The resulting continuum hose robot exhibited non constant curvature. In order to account for this, a new geometric approach to modeling variable curvature inverse kinematics using Euler curves is introduced herein. The new closed form model does not impose any additional computational cost compared to the constant curvature model and results in a marked improvement in the observed performance. Experiments involving 3D printing with cementitious mortar using a continuum hose robot were also conducted.	https://doi.org/10.1109/ICRA46639.2022.9812123	Manu Srivastava, Jake Ammons, Abdul B. Peerzada, Venkat N. Krovi, Prasad Rangaraju, Ian D. Walker
A Benchmark Comparison of Learned Control Policies for Agile Quadrotor Flight.	Quadrotors are highly nonlinear dynamical systems that require carefully tuned controllers to be pushed to their physical limits. Recently, learning-based control policies have been proposed for quadrotors, as they would potentially allow learning direct mappings from high-dimensional raw sensory observations to actions. Due to sample inefficiency, training such learned controllers on the real platform is impractical or even impossible. Training in simulation is attractive but requires to transfer policies between domains, which demands trained policies to be robust to such domain gap. In this work, we make two contributions: (i) we perform the first benchmark comparison of existing learned control policies for agile quadrotor flight and show that training a control policy that commands body-rates and thrust results in more robust sim-to-real transfer compared to a policy that directly specifies individual rotor thrusts, (ii) we demonstrate for the first time that such a control policy trained via deep reinforcement learning can control a quadrotor in real-world experiments at speeds over 45 km/h.	https://doi.org/10.1109/ICRA46639.2022.9811564	Elia Kaufmann, Leonard Bauersfeld, Davide Scaramuzza
A Collision-Free MPC for Whole-Body Dynamic Locomotion and Manipulation.	In this paper, we present a real-time whole-body planner for collision-free legged mobile manipulation. We enforce both self-collision and environment-collision avoidance as soft constraints within a Model Predictive Control (MPC) scheme that solves a multi-contact optimal control problem. By penalizing the signed distances among a set of representative primitive collision bodies, the robot is able to safely execute a variety of dynamic maneuvers while preventing any self-collisions. Moreover, collision-free navigation and manipulation in both static and dynamic environments are made viable through efficient queries of distances and their gradients via a euclidean signed distance field. We demonstrate through a comparative study that our approach only slightly increases the computational complexity of the MPC planning. Finally, we validate the effectiveness of our framework through a set of hardware experiments involving dynamic mobile manipulation tasks with potential collisions, such as locomotion balancing with the swinging arm, weight throwing, and autonomous door opening.	https://doi.org/10.1109/ICRA46639.2022.9812280	Jia-Ruei Chiu, Jean-Pierre Sleiman, Mayank Mittal, Farbod Farshidian, Marco Hutter
A Colored Petri Net Model for Control Problem of Border Crossing Under Constraints.	In this paper, we consider the European Rail Traffic Management System (ERTMS) as a System-of-Systems (SoS) and propose modeling it using colored Petri nets. We formally control the European rail transport, while guaranteeing a set of cross-border security properties. This becomes an essential and challenging task since each of them have mainly developed safety and trackside rules regardless of its neighbors. The feature of this work lies in the approach that considers ERTMS Level 2 as an SoS and addresses the cross-border railway as a mode management problem. In addition, the aspects of mode activation/deactivation, starting state and handling of resource states common to multiple operating modes are taken into account in the proposed model.	https://doi.org/10.1109/ICRA46639.2022.9811549	Hela Kadri, Simon Collart Dutilleul, Philippe Bon, Rochdi Merzouki
A Continuous Learning Approach for Probabilistic Human Motion Prediction.	Human Motion Prediction (HMP) plays a crucial role in safe Human-Robot-Interaction (HRI). Currently, the majority of HMP algorithms are trained by massive pre-collected data. As the training data only contains a few pre-defined motion patterns, these methods cannot handle the unfamiliar motion patterns. Moreover, the pre-collected data are usually non-interactive, which does not consider the real-time responses of collaborators. As a result, these methods usually perform unsatisfactorily in real HRI scenarios. To solve this problem, in this paper, we propose a novel Continual Learning (CL) approach for probabilistic HMP which makes the robot continually learns during its interaction with collaborators. The proposed approach consists of two steps. First, we leverage a Bayesian Neural Network to model diverse uncertainties of observed human motions for collecting online interactive data safely. Then we take Experience Replay and Knowledge Distillation to elevate the model with new experiences while maintaining the knowledge learned before. We first evaluate our approach on a large-scale benchmark dataset Human3.6m. The experimental results show that our approach achieves a lower prediction error compared with the baselines methods. Moreover, our approach could continually learn new motion patterns without forgetting the learned knowledge. We further conduct real-scene experiments using Kinect DK. The results show that our approach can learn the human kinematic model from scratch, which effectively secures the interaction.	https://doi.org/10.1109/ICRA46639.2022.9811906	Jie Xu, Shihong Wang, Xingyu Chen, Jiahao Zhang, Xuguang Lan, Nanning Zheng
A Continuum Robot Surface of Woven, McKibben Muscles Embedded in and Giving Shape to Rooms.	"Robots are typically designed as occupants of rooms, adapting to, and navigating within them. ""Robot surfaces,"" an emerging robot typology, are not occupants of but integral with rooms, physically shaping rooms to support human activity. We report on an advancement of robot surfaces formed by weaving McKibben Pneumatic Air Muscles that, when actuated, morph a 2D planar surface to generate 3D geometries including a ""spherical cap."" Following our foundational study at different scales with different materials, we developed a full-scale prototype that offers an intimate and private space for people meeting in open plan environments. We report on our research, focusing on a design case, and validate the full-scale prototype as compared to our Non-Uniform Rational B-Splines (NURBS) model for three useful configurations. Our quantitative and qualitative results suggest that our robot surface can support human activity as envisioned. This research contributes foundational understanding of an emerging category of robotics from which our team and peers can build."	https://doi.org/10.1109/ICRA46639.2022.9811987	Grace Tan, Harrison Hidalgo, Hsin-Liu Cindy Kao, Ian D. Walker, Keith E. Green
A Data-Driven Multiple Model Framework for Intention Estimation.	This paper presents a data-driven multiple model framework for estimating the intention of a target from observations. Multiple model (MM) state estimation methods have been extensively used for intention estimation by mapping one intention to one dynamic model assuming one-to-one relations. However, intentions are subjective to humans and it is difficult to establish the one-to-one relations explicitly. The proposed framework infers the multiple-to-multiple relations between intentions and models directly from observations that are labeled with intentions. For intention estimation, both the relations and model probabilities of an Interacting Multiple Model (IMM) state estimation approach are integrated into a recursive Bayesian framework. Taking advantage of the inferred multiple-to-multiple relations, the framework incorpo-rates more accurate relations and avoids following the strict one-to-one relations. Numerical and real experiments were performed to investigate the framework through the intention estimation of a maneuvered quadrotor. Results show higher estimation accuracy and superior flexibility in designing mod-els over the conventional approach that assumes one-to-one relations.	https://doi.org/10.1109/ICRA46639.2022.9812432	Yongming Qin, Makoto Kumon, Tomonari Furukawa
A Deep Concept Graph Network for Interaction-Aware Trajectory Prediction.	Temporal patterns (how vehicles behave in our observed past) underline our reasoning of how people drive on the road, and can explain why we make certain predictions about interactions among road agents. In this paper we propose the ConceptNet trajectory predictor - a novel prediction framework that is able to incorporate agent interactions as explicit edges in a temporal knowledge graph. We demonstrate the sample efficiency and the overall accuracy of the proposed approach, and show that using the graphical structure to explicitly model interactions enables better detection of agent interactions and improved trajectory predictions on a large real-world driving dataset.	https://doi.org/10.1109/ICRA46639.2022.9811567	Yutong Ban, Xiao Li, Guy Rosman, Igor Gilitschenski, Ozanan R. Meireles, Sertac Karaman, Daniela Rus
A Deep Reinforcement Learning Environment for Particle Robot Navigation and Object Manipulation.	Particle robots are novel biologically-inspired robotic systems where locomotion can be achieved collectively and robustly, but not independently. While its control is currently limited to a hand-crafted policy for basic locomotion tasks, such a multi-robot system could be potentially controlled via Deep Reinforcement Learning (DRL) for different tasks more efficiently. However, the particle robot system presents a new set of challenges for DRL differing from existing swarm robotics systems: the low degrees of freedom of each robot and the increased necessity of coordination between robots. We present a 2D particle robot simulator using the OpenAI Gym interface and Pymunk as the physics engine, and introduce new tasks and challenges to research the underexplored applications of DRL in the particle robot system. Moreover, we use Stable-baselines3 to provide a set of benchmarks for the tasks. Current baseline DRL algorithms show signs of achieving the tasks but are yet unable to reach the performance of the hand-crafted policy. Further development of DRL algorithms is necessary in order to accomplish the proposed tasks.	https://doi.org/10.1109/ICRA46639.2022.9811965	Jeremy Shen, Erdong Xiao, Yuchen Liu, Chen Feng
A Detumbling Strategy for an Orbital Manipulator in the Post-Grasp Phase.	In this paper, we propose a detumbling strategy that stabilizes the motion of a tumbling client satellite using an orbital servicing manipulator, which is the goal of the post-grasp phase. One of the critical aspects in this phase is ensuring that excessive contact forces are not generated at the grasp interface. In addition, space mission requirements might demand a nominal manipulator configuration that is suitable for further manipulation/servicing activities. The proposed strategy allows the detumbling of the client motion while ensuring that the contact forces developed at the grasp interface do not violate a safety threshold. Further, it allows the reconfiguration of the manipulator arm by exploiting the full actuation capability of the manipulator-equipped servicing spacecraft. The controller guarantees joint task convergence in the nullspace of the manipulator's end-effector, and is also valid for kinematically singular configurations of the manipulator. It is further augmented using a quadratic programming based approach to optimally constrain the contact forces. Finally, simulation results for a post-grasp detumbling scenario are shown to validate the effectiveness of the proposed method.	https://doi.org/10.1109/ICRA46639.2022.9812067	Ria Vijayan, Marco De Stefano, Christian Ott
A Divide-and-Merge Point Cloud Clustering Algorithm for LiDAR Panoptic Segmentation.	Clustering objects from the LiDAR point cloud is an important research problem with many applications such as autonomous driving. To meet the real-time requirement, existing research proposed to apply the connected-component-labeling (CCL) technique on LiDAR spherical range image with a heuristic condition to check if two neighbor points are connected. However, LiDAR range image is different from a binary image which has a deterministic condition to tell if two pixels belong to the same component. The heuristic condition used on the LiDAR range image only works empirically, which suggests the LiDAR clustering algorithm should be robust to potential failures of the empirical heuristic condition. To overcome this challenge, this paper proposes a divide-and-merge LiDAR clustering algorithm. This algorithm firstly conducts clustering in each evenly divided local region, then merges the local clustered small components by voting on edge point pairs. Assuming there are N LiDAR points of objects in total with m divided local regions, the time complexity of the proposed algorithm is O(N)+O(m^{2}). A smaller m means the voting will involve more neighbor points, but the time complexity will become larger. So the m controls the trade-off between the time complexity and the clustering accuracy. A proper m helps the proposed algorithm work in real-time as well as maintain good performance. We evaluate the divide-and-merge clustering algorithm on the SemanticKITTI panoptic segmentation benchmark by cascading it with a state-of-the-art semantic segmentation model. The final performance evaluated through the leaderboard achieves the best among all published methods. The proposed algorithm is implemented with C++ and wrapped as a python function. It can be easily used with the modern deep learning framework in python. We released the code under the following link 11https://github.com/placeforyiming/Divide-and-Merge-LiDAR-Panoptic-Cluster.	https://doi.org/10.1109/ICRA46639.2022.9812058	Yiming Zhao, Xiao Zhang, Xinming Huang
A Double Branch Next-Best-View Network and Novel Robot System for Active Object Reconstruction.	Next best view (NBV) is a technology that finds the best view sequence for sensor to perform scanning based on partial information, which is the core part for robot active reconstruction. Traditional works are mostly based on the evaluation of candidate views through time-consuming volu-metric transformation and ray casting, which heavily limits the applications of NBV. Recent deep learning based NBV methods aim to approximately learn the evaluation function by large-scale training, and improve both the effectiveness and efficiency of NBV. However, these methods force the network to regress the exact groundtruth value of each candidate view, which is much harder than simply ranking all the candidate views. Besides, most previous NBV works assume perfect sensing and perform in simulation environments, lacking real application abilities. In this paper, we propose a novel double branch NBV network, DB-NBV, to utilize the ranking process together with the evaluation process. We further design a real NBV robot and a pipeline to conduct real active reconstruction. Experiments on both simulation and real robot show that our method achieves the best performance and can be applied to real application with high accuracy and speed.	https://doi.org/10.1109/ICRA46639.2022.9811769	Yiheng Han, Irvin Haozhe Zhan, Wang Zhao, Yong-Jin Liu
A Dual-Stream Architecture for Real-Time Morphological Analysis of Aneurysm in Robot-Assisted Minimally Invasive Surgery.	Real-time and precise morphological analysis of intraoperative AAA is a significant pre-imperative for robot-assisted minimally invasive surgery (RMIS). However, this task is frequently accompanied by the difficulties of ambiguous boundaries and obscured surfaces of aneurysms. To remedy these problems, we propose a Light-Weight Dual-Stream Boundary-Aware Network (DSB-Net) and a novel diagnosis algorithm for real-time morphological analysis of AAA. In the network, the features at the boundaries are preserved by incorporating a boundary localization stream, while the interior segmentation accuracy is guaranteed with a mask prediction stream. Moreover, the diagnosis algorithm is developed to measure the exact size of AAA. Quantitative and qualitative assessments on two different types of datasets illustrate that (1) The presented DSB-Net remarkably outperforms the other previously proposed medical networks with the inference rate of 10.8 FPS, which meets the real-time clinical necessities. (2) The developed algorithm provides accurate size measurements for AAA, which indicates the proposed approach can be integrated into the robotic navigation framework for RMIS.	https://doi.org/10.1109/ICRA46639.2022.9812075	Yan-Jie Zhou, Shi-Qi Liu, Xiao-Liang Xie, Xiao-Hu Zhou, Zeng-Guang Hou, Rui-Qi Li, Zhen-Liang Ni, Chen-Chen Fan
A Force-Sensitive Grasping Controller Using Tactile Gripper Fingers and an Industrial Position-Controlled Robot.	Grasping fragile objects in the presence of un-certainty is a crucial task for robots, that becomes inherently challenging if the manipulator in use is an industrial robot platform that does not provide compliant control inputs. This requires not only to estimate the alignment error during object contact but also to alter the robot configuration to decrease this error while taking interaction constraints into account. Thus, this work proposes a novel grasping controller tailored to industrial robots by exploiting tactile sensor feedback on the robot gripper fingers in order to estimate and compensate for the alignment error when touching the object. Specifically, we propose two grasping strategies, that allow to either directly compensate for interaction wrenches or to solve a model predictive control-problem to minimize the estimated alignment error. Eventually, we outline how these modalities can be realized as a hybrid Cartesian force-velocity-controller on an industrial manipulator. We evaluate the proposed grasping strategies on a WSG 50 parallel two-finger gripper, that is equipped with a digital sensor array (DSA) per finger, for which we also provide an extended ROS-driver that allows to obtain DSA-data at a communication rate above 5 Hz. Given the collected empirical evidence, the presented grasping controller increases the skill-set of industrial robots in the presence of uncertainty and thus allows to apply stiff robots to handle fragile objects autonomously.	https://doi.org/10.1109/ICRA46639.2022.9812278	Volker Gabler, Gerold Huber, Dirk Wollherr
A Framework for Real-World Multi-Robot Systems Running Decentralized GNN-Based Policies.	Graph Neural Networks (GNNs) are a paradigm-shifting neural architecture to facilitate the learning of complex multi-agent behaviors. Recent work has demonstrated remarkable performance in tasks such as flocking, multi-agent path planning and cooperative coverage. However, the policies derived through GNN-based learning schemes have not yet been deployed to the real-world on physical multi-robot systems. In this work, we present the design of a system that allows for fully decentralized execution of GNN-based policies. We create a framework based on ROS2 and elaborate its details in this paper. We demonstrate our framework on a case-study that requires tight coordination between robots, and present first-of-a-kind results that show successful real-world deployment of GNN-based policies on a decentralized multi-robot system relying on Adhoc communication. A video demonstration of this case-study can be found online11youtube.com/watch?v=COh-WLn4i04.	https://doi.org/10.1109/ICRA46639.2022.9811744	Jan Blumenkamp, Steven D. Morad, Jennifer Gielis, Qingbiao Li, Amanda Prorok
A Hierarchical Control Framework for Drift Maneuvering of Autonomous Vehicles.	Maneuvering an autonomous vehicle under drift condition is critical to the safety of autonomous vehicles when there is a sudden loss of traction due to external conditions such as rain or snow, which is a challenging control problem due to the presence of significant sideslip and nearly full saturation of the tires. In this paper, we focus on the control of drift maneuvers of autonomous vehicle to track circular paths with either fixed or moving centers, subject to change in the tire-ground interaction. In order to achieve the above tasks, we propose a hierarchical control architecture which decouples the curvature and center control of the trajectory. In particular, an outer control loop is proposed to stabilize the center by tuning the target curvature, and an inner control loop tracks the curvature using a feedforward/feedback controller enhanced by an \mathcal{L}_{1} adaptive component. The hierarchical architecture is flexible because the inner loop is task-agnostic and adaptive to changes in tire-ground interaction, which allows the outer loop to be designed independent of low-level dynamics, opening up the possibility of incorporating sophisticated planning algorithms. We implement our control strategy on a simulation platform as well as on a 1/10 scale RC car, and both the simulation and experiment results illustrate the effectiveness of our strategy in achieving the above described set of drift maneuvering tasks.	https://doi.org/10.1109/ICRA46639.2022.9812110	Bo Yang, Yiwen Lu, Xu Yang, Yilin Mo
A Hierarchical Deliberative-Reactive System Architecture for Task and Motion Planning in Partially Known Environments.	We describe a task and motion planning architecture for highly dynamic systems that combines a domain-independent sampling-based deliberative planning algorithm with a global reactive planner. We leverage the recent development of a reactive, vector field planner that provides guarantees of reachability to large regions of the environment even in the face of unknown or unforeseen obstacles. The reachability guarantees can be formalized using contracts that allow a deliberative planner to reason purely in terms of those contracts and synthesize a plan by choosing a sequence of reactive behaviors and their target configurations, without evaluating specific motion plans between targets. This reduces both the search depth at which plans will be found, and the number of samples required to ensure a plan exists, while crucially preserving correctness guarantees. The result is reduced computational cost of synthesizing plans, and increased robustness of generated plans to actuator noise, model misspecification, or unknown obstacles. Simulation studies show that our hierarchical planning and execution architecture can solve complex navigation and rearrangement tasks, even when faced with narrow passageways or incomplete world information.	https://doi.org/10.1109/ICRA46639.2022.9811936	Vasileios Vasilopoulos, Sebastian Castro, William Vega-Brown, Daniel E. Koditschek, Nicholas Roy
A Hybrid Approach for Learning to Shift and Grasp with Elaborate Motion Primitives.	Many possible fields of application of robots in real world settings hinge on the ability of robots to grasp objects. As a result, robot grasping has been an active field of research for many years. With our publication we contribute to the endeavor of enabling robots to grasp, with a particular focus on bin picking applications. Bin picking is especially challenging due to the often cluttered and unstructured arrangement of objects and the often limited graspability of objects by simple top down grasps. To tackle these challenges, we propose a fully self-supervised reinforcement learning approach based on a hybrid discrete-continuous adaptation of soft actor-critic (SAC). We employ parametrized motion primitives for pushing and grasping movements in order to enable a flexibly adaptable behavior to the difficult setups we consider. Furthermore, we use data augmentation to increase sample efficiency. We demonstrate our proposed method on challenging picking scenarios in which planar grasp learning or action discretization methods would face a lot of difficulties.	https://doi.org/10.1109/ICRA46639.2022.9811735	Zohar Feldman, Hanna Ziesche, Ngo Anh Vien, Dotan Di Castro
A Hybrid, Soft Robotic Exoskeleton Glove with Inflatable, Telescopic Structures and a Shared Control Operation Scheme.	Grasping and manipulation are two of the most important hand functions that allow people to efficiently execute activities of daily living. Over the last years, many robotic devices have been proposed to assist people who suffer from neurological conditions by enhancing their grasping capabilities. In this work, we focus on the development of a robotic exoskeleton glove that can increase the grasp stability and the force exertion capabilities of the user by employing soft, telescopic, inflatable structures on the palmar side of the hand. Also, the proposed design employs a camera and an object identification system to facilitate the development of a shared control scheme that simplifies the operation of the device. The experiments demonstrate that the soft robotic exoskeleton glove can successfully execute semi-autonomous grasps and that the soft telescopic structures can increase the total exerted grasping forces by more than 40% when inflated.	https://doi.org/10.1109/ICRA46639.2022.9812426	Lucas Gerez, Gal Gorjup, Yuran Zhou, Minas V. Liarokapis
A Lightweight, High-Extension, Planar 3-Degree-of-Freedom Manipulator Using Pinched Bistable Tapes.	To facilitate sensing and physical interaction in remote and/or constrained environments, high-extension, lightweight robot manipulators are easier to transport and reach substantially further than traditional serial chain manipulators. We propose a novel planar 3-degree-of-freedom manipulator that achieves low weight and high extension through the use of a pair of spooling bistable tapes, commonly used in self-retracting tape measures, which are pinched together to form a reconfigurable revolute joint. The pinching action flattens the tapes to produce a localized bending region, resulting in a revolute joint that can change its orientation by cable tension and its location on the tapes though friction-driven movement of the pinching mechanism. We present the design, implementation, kinematic modeling, stiffness behavior of the revolute joint, and quasi-static performance of this manipulator. In particular, we demonstrate the ability of the manipulator to reach specified targets in free space, reach a 2D target with various orientations, and maintain an end-effector angle or stationary bending point while changing the other. The long-term goal of this work is to integrate the manipulator with an aerial robot to enable more capable aerial manipulation.	https://doi.org/10.1109/ICRA46639.2022.9811976	O. Godson Osele, Allison M. Okamura, Brian H. Do
A Linear Comb Filter for Event Flicker Removal.	Event cameras are bio-inspired sensors that capture per-pixel asynchronous intensity change rather than the synchronous absolute intensity frames captured by a classical camera sensor. Such cameras are ideal for robotics applications since they have high temporal resolution, high dynamic range and low latency. However, due to their high temporal resolution, event cameras are particularly sensitive to flicker such as from fluorescent or LED lights. During every cycle from bright to dark, pixels that image a flickering light source generate many events that provide little or no useful information for a robot, swamping the useful data in the scene. In this paper, we propose a novel linear filter to preprocess event data to remove unwanted flicker events from an event stream. The proposed algorithm achieves over 4.6 times relative improvement in the signal-to-noise ratio when compared to the raw event stream due to the effective removal of flicker from fluorescent lighting. Thus, it is ideally suited to robotics applications that operate in indoor settings or scenes illuminated by flickering light sources. Code, Datasets and Video: https://github.com/ziweiWWANG/EFR	https://doi.org/10.1109/ICRA46639.2022.9812003	Ziwei Wang, Dingran Yuan, Yonhon Ng, Robert E. Mahony
A Linearization of Centroidal Dynamics for the Model-Predictive Control of Quadruped Robots.	Centroidal dynamics, which describes the overall linear and angular motion of a robot, is often used in locomotion generation and control of legged robots. However, the equation of centroidal dynamics contains nonlinear terms mainly caused by the robot's angular motion and needs to be linearized for deriving a linear model-predictive motion controller. This paper proposes a new linearization of the robot's centroidal dynamics. By expressing the angular motion with exponential coordinates, more linear terms are identified and retained than in the existing methods to reduce the loss from the model linearization. As a consequence, a model-predictive control (MPC) algorithm is derived and shows a good performance in tracking angular motions on a quadruped robot.	https://doi.org/10.1109/ICRA46639.2022.9812433	Wanchao Chi, Xinyang Jiang, Yu Zheng
A Low-Cost, Easy-to-Manufacture, Flexible, Multi-Taxel Tactile Sensor and its Application to In-Hand Object Recognition.	Soft robotics is an emerging field that yields promising results for tasks that require safe and robust interactions with the environment or with humans, such as grasping, manipulation, and human-robot interaction. Soft robots rely on intrinsically compliant components and are difficult to equip with traditional, rigid sensors which would interfere with their compliance. We propose a highly flexible tactile sensor that is low-cost and easy to manufacture while measuring contact pressures independently from 14 taxels. The sensor is built from piezoresistive fabric for highly sensitive, continuous responses and from a custom-designed flexible printed circuit board which provides a high taxel density. From these taxels, location and intensity of contact with the sensor can be inferred. In this paper, we explain the design and manufacturing of the proposed sensor, characterize its input-output relation, evaluate its effects on compliance when equipped to the silicone-based pneumatic actuators of the soft robotic RBO Hand 2, and demonstrate that the sensor provides rich and useful feedback for learning-based in-hand object recognition.	https://doi.org/10.1109/ICRA46639.2022.9811761	Tessa J. Pannen, Steffen Puhlmann, Oliver Brock
A Low-Profile Hip Exoskeleton for Pathological Gait Assistance: Design and Pilot Testing.	Hip exoskeletons may hold potential to augment walking performance and mobility in individuals with disabilities. The purpose of this study was to design and validate a novel autonomous hip exoskeleton with a user-adaptive control strategy capable of reducing the energy cost of level and incline walking in individuals with and without walking impairment. First, in a small cohort of three unimpaired individuals, we validated the ability of our control strategy to provide hip flexion-extension torque that was proportional to the biological hip moment and reduce the energy cost of level and incline walking (24 ± 5% and 13 ± 5% reductions, respectively). Next, in a clinical feasibility experiment with an individual with significant walking impairment from cerebral palsy, we demonstrated that our untethered device and adaptive control scheme improved hip extension by 14° across the gait cycle, reduced average rectus femoris and semitendinosus muscle activity by 23% and 46%, respectively, and resulted in a 15% improvement in metabolic cost relative to walking without wearing the device.	https://doi.org/10.1109/ICRA46639.2022.9812300	Safoura Sadegh Pour Aji Bishe, Leah Liebelt, Ying Fang, Zachary F. Lerner
A Magnetorheological Fluid-based Damper Towards Increased Biomimetism in Soft Robotic Actuators.	Damping properties in biological muscle are crit-ical for absorbing shock, maintaining posture, and positioning limbs and appendages. When creating biomimetic robots, the ability to replicate the dynamics of biological muscle is neces-sary to reproduce behaviors seen in an animal model. However, the damping properties of existing soft artificial muscles are difficult to predict and tune to match specific muscles as may be needed in biomimetic robots. Here, we present the design, manufacturing, and characterization of a novel soft damper to enable a greater degree of biomimetism in these soft actuators. The damper is composed of magnetorheological fluid contained within an elastomeric shell, which is cast using low-cost 3D printed parts and commercially available urethane rubber. We demonstrate that the force-velocity response over a velocity range of 0.1 to 10 mm/s is proportional to applied magnetic flux densities between 0.12 and 0.31 T. In the presence of a 0.31 T magnetic field from a small permanent magnet, the damper is capable of a maximum damping force increase of 13.2 N to 15.5 N relative to the 0 T control, at a compression depth of 7.9 mm, which is larger than that of several previously reported centimeter-scale dampers. As a proof-of-concept for integration with a Pneumatic Artificial Muscle (PAM), we use two parallel dampers to reduce the oscillations of a rapidly pressurized McKibben actuator. The ability to modulate the force-velocity performance of our elastomeric damper paves the way for custom damping profiles that can be used to improve biomimetism in soft robotic actuators.	https://doi.org/10.1109/ICRA46639.2022.9811787	Ravesh Sukhnandan, Kevin Dai, Victoria A. Webster-Wood
A Mathematical Design for a Novel Walking Support Device that Leverages Passive Dynamics and Coupling Effects.	This paper mathematically conceives a novel walking support device that leverages passive dynamics and coupling effects. In this model, a passive human walker is flexibly connected to an active humanoid, where the coupling effect induces a stable walking gait of the human. To understand the key mechanism of such indirect gait regulation, different actuation modes are designed for the humanoid and compared via phase-plane analysis of the steady-state gaits. Moreover, stability analysis is conducted via Poincaré map. The results show that it is difficult to enhance the human walker's stability when coupled to a humanoid robot using additional sensory information, compared to using a humanoid robot actuated with a predetermined force that employs no state feedback. The present mathematical model and our theoretical findings contribute to analysis and control design for locomotion systems with robot-human or inter-robots cooperation.	https://doi.org/10.1109/ICRA46639.2022.9811958	Longchuan Li, Shugen Ma, Isao T. Tokuda, Makoto Nokata, Yang Tian, Liang Du, Zhiqing Li
A Memory-based SO(3) Parameterization: Theory and Application to 6D Impedance Control with Radially Unbounded Potential Function.	This paper proposes a parameterization method to represent SO (3) over multiple turns. This method is called a memory-based parameterization, because the idea is to integrate the past trajectory of exponential coordinates. The parameterization is consistent in the sense that the true rotation matrix can be reconstructed by using the exponential map. As an application of the proposed method, a 6D impedance controller is designed with a radially unbounded potential function. Consequently, in contrast to the conventional methods, an arbitrarily large angular deflection can be accommodated, resulting in a more realistic impedance behavior. The proposed schemes are validated through simulations and experiments.	https://doi.org/10.1109/ICRA46639.2022.9812268	Jinyeong Jeong, Hrishik Mishra, Christian Ott, Min Jun Kim
A Method for Designing Autonomous Robots that Know Their Limits.	While the design of autonomous robots often emphasizes developing proficient robots, another important attribute of autonomous robot systems is their ability to evaluate their own proficiency and limitations. A robot should be able to assess how well it can perform a task before, during, and after it attempts the task. Thus, we consider the following question: How can we design autonomous robots that know their own limits? Toward this end, this paper presents an approach, called assumption-alignment tracking (AAT), for designing autonomous robots that can effectively evaluate their own limits. In AAT, the robot combines (a) measures of how well its decision-making algorithms align with its environment and hardware systems with (b) its past experiences to assess its ability to succeed at a given task. The effectiveness of AAT in assessing a robot's limits are illustrated in a robot navigation task.	https://doi.org/10.1109/ICRA46639.2022.9812030	Alvika Gautam, Tim Whiting, Xuan Cao, Michael A. Goodrich, Jacob W. Crandall
A Model Predictive-based Motion Planning Method for Safe and Agile Traversal of Unknown and Occluding Environments.	Agile navigation through uncertain and obstacle-rich environments remains a challenging task for autonomous mobile robots (AMR). For most AMR, obstacles are identified using onboard sensors, e.g., lidar or cameras. The effectiveness of these sensors may be severely limited, however, by occlusions introduced from the presence of other obstacles. The occluded area may contain obstacles, static or dynamic, not included into the motion planning of the robot and could cause potential collisions if they suddenly appear in the field of view of the robot. This paper proposes a general Model Predictive Control (MPC)-based framework for handling occlusions in structured or unstructured environments, that contain known or unknown static or dynamic obstacles. Safety is promoted by commanding velocities that consider surrounding obstacle uncertainty, while perception is promoted through a specially designed objective that can reduce the occluded area created by obstacles. The effectiveness of this framework is validated through simulations that show swift and safe motion in a variety of different environments. Similarly, experimental validation is achieved with a Boston Dynamics' Spot quadruped robot operating in an occluding environment.	https://doi.org/10.1109/ICRA46639.2022.9811717	Jacob Higgins, Nicola Bezzo
A Multi-VTOL Modular Aspect Ratio Reconfigurable Aerial Robot.	This work presents a novel Aspect Ratio-Modular Vertical Take-Off and Landing (ARM-VTOL) aerial robot, which is a meta-aircraft composed of two or more TiltRotor hybrid aircraft systems capable of magnetically being coupled during hovering flight, and of executing VTOL / Fixed-Wing hybrid missions once combined. The proposed meta-aircraft system carries the advantage of improved aerodynamic efficiency due its increased cumulative planform aspect ratio, which can be leveraged to achieve prolonged flight times in collaborative multi-vehicle flight. We propose an extendable methodology for its control which relies on the multi-body equivalent dynamics, and we present the coupling mechanism design that facilitates its experimental demonstration. We accompany these contributions with a field test-driven evaluation study conducted with a bi-vehicle ARM-VTOL prototype. The presented sequence includes vehicle-to-vehicle magnetic coupling during hovering flight, and is followed by a combined-vehicle mission comprising vertical climb, VTOL-forward transition, fixed-wing flight and maneuvering, and reverse-transition to VTOL and landing.	https://doi.org/10.1109/ICRA46639.2022.9811542	Stephen J. Carlson, Prateek Arora, Christos Papachristos
A New Bio-Inspired Hybrid Cable-Driven Robot (HCDR) to Design More Realistic Snakebots.	Bioinspired robots are useful tools to study complex biomechanical processes of animal locomotion. Key movements and kinematic parameters are under the control of experimenters, which is impossible to perform when experimenting with living animals. The primary challenge to test biological hypotheses is designing realistic robots taking inspiration from swimming snakes. Yet, underlying biomechanics of undulatory swimming i.e., anguilliform swimming, remains poorly understood. Many of underwater snakebots are made of rigid segments that form a broken-line system, unlike the skeleto-muscular systems of living snakes include more than 200 vertebrae, conferring an extreme fluidity. This paper introduces a novel design based on hybrid continuum cable driven robot (HCDR) developed through interaction with biologists and roboticists. This Biology-Push design significantly increases the fluidity and freedom of the robot's motion. Thus, improved mimic snake's locomotion is given using cable-driven to represent linkages between muscles and vertebrae providing good fluidity. In addition, the association of rigid and flexible parts allows a homogeneous distribution of actuators and masses to design autonomous swimming snake robot. Combining literature data and kinematic of swimming snakes' analyses, we implemented a kinematic model to control prototype' motion in both a plane and a volume. Finally, a comparative study between the device kinematics and the snake's movements is carried out.	https://doi.org/10.1109/ICRA46639.2022.9811550	Elie Gautreau, Juan Sandoval, Xavier Bonnet, Marc Arsicault, Saïd Zeghloul, Med Amine Laribi
A Novel Assistive Controller Based on Differential Geometry for Users of the Differential-Drive Wheeled Mobile Robots.	Certain wheeled mobile robots e.g., electric wheelchairs, can operate through indirect joystick controls from users. Correct steering angle becomes essential when the user should determine the vehicle direction and velocity, in particular for differential wheeled vehicles since the vehicle velocity and direction are controlled with only two actuating wheels. This problem gets more challenging when complex curves should be realized by the user. A novel assistive controller with safety constraints is needed to address these problems. Also, the classic control methods mostly require the desired states beforehand which completely contradicts human's spontaneous decisions on the desired location to go. In this work, we develop a novel assistive control strategy based on differential geometry relying on only joystick inputs and vehicle states where the controller does not require any desired states. We begin with explaining the vehicle kinematics and our designed Darboux frame kinematics on a contact point of a virtual wheel and plane. Next, the geometric controller using the Darboux frame kinematics is designed for having smooth trajectories under certain safety constraints. We experiment our approach with different participants and evaluate its performance in various routes.	https://doi.org/10.1109/ICRA46639.2022.9811593	Seyed Amir Tafrishi, Ankit A. Ravankar, Jose Victorio Salazar Luces, Yasuhisa Hirata
A Novel Convolutional Neural Network for Emotion Recognition Using Neurophysiological Signals.	Non-invasive brain-computer interfaces (BCIs) provide us with the unique ability to classify the psychological state of a person using only neurophysiological signals, such as those captured with an electroencephalogram (EEG). With this ability, new avenues for innovation in the field of healthcare arise, especially as it is used for robotics. EEGNet is a novel deep learning technique for the classification of EEG data with a limited training set that generalizes well to a variety of BCI paradigms, and the performance thereof can further be improved. We propose the use of Thomson Multitaper Power Spectral Density estimation in the EEG-BCI classification pipeline as well as a novel convolutional neural network (CNN), which extends EEGNet with sparse feature maps produced by efficient regularized separable convolutions. Further, we test the efficacy of interspersed Gaussian noise as a data augmentation technique. To show the improvements found with this new pipeline, we test on a widely used public EEG dataset related to emotion classification, then perform an ablation study to determine the most contributing factors. The accuracy on this public dataset was 77.16%. These results show that our pipeline improved the classification accuracy by 10.86% when compared with the state-of-the-art.	https://doi.org/10.1109/ICRA46639.2022.9811868	Marc A. Tunnell, Huijin Chung, Yuchou Chang
A Novel Full State Feedback Decoupling Controller For Elastic Robot Arm.	In this paper a novel full state feedback approach for control of compliant actuated robot with nonlinear spring characteristics is presented. A multi-DOF elastic robot arm is a multi-input multi-output (MIMO) under-actuated system. By the new novel controller, which is based on motor coordinate transformation and motor inertia shaping, the MIMO system can be converted into a set of decoupled single-input single-output (SISO) systems. Using full state feedback controller, we can configurate the poles of each SISO system. The controller is validated by an 3-DOF elastic robot with nonlinear spring characteristics in simulation of MATLAB/Simulink.	https://doi.org/10.1109/ICRA46639.2022.9812047	Hongxi Zhu, Ulrike Thomas
A Novel Limbs-Free Variable Structure Wheelchair based on Face-Computer Interface (FCI) with Shared Control.	"In order to meet the mobility and physical activity needs of people with impaired limbs function, a novel limbs-free variable structure wheelchair system controled by face-computer interface (FCI) was developed in this study. FCI used facial electromyography (fEMG) as a human intention recognition method from 6 facial movements, and the accuracy of intent recognition reached 97.6% under a series of offline optimization including channel optimization based on the Hilbert transform to obtain the envelope of fEMG, features optimization, and channel-independent model optimization. A collection of finite state machines (FSM) was used to control the movement and structural changes of the wheelchair. A shared control strategy called "" Keep Action after Take Over (KAaTO) "" that can reduce user fatigue while increasing safety was used in long-distance movement control of wheelchair. To test the performance of the system, in the braking distance test experiment, the result of 0.429m under KAaTO was better than the EMG-based discrete command control and speech command control method. Finally, an outdoor long-distance control pilot experiment proved the superior performance of the developed system."	https://doi.org/10.1109/ICRA46639.2022.9811571	Bo Zhu, Daohui Zhang, Yaqi Chu, Xingang Zhao
A Novel Model of Interaction Dynamics between Legged Robots and Deformable Terrain.	Navigating natural environments with deformable terrain is a difficult challenge in robotics. Understanding the interaction dynamics between robots and such terrain is an important first step in enabling them to explore these environments. Terramechanics models are largely developed and tested on wheeled and tracked platforms, but with the advent of readily available lightweight legged robots, developing an understanding of how robot feet interact with the terrain becomes increasingly important. Works on estimating terramechanical properties of deformable sands and soils use an underlying assumption that translation of the robot foot along the surface of the terrain is due to internal shear deformation of the soil. We show that for lightweight legged robots, this is not the case. Shear forces acting on the foot of a robot during a stride are not accurately predicted by the widely-used Janosi-Hanamoto formula. We propose a new model in which two forces acting on the foot dominate the foot-terrain interaction - gross sliding friction and bulldozing resistance - and propose a model of how these forces act on the foot. We test this model on multiple soil types with different foot materials. Experimental data, collected on a testbench equipped with actuators and sensors identical to those deployed on a robot in the field, is used to validate our proposed model.	https://doi.org/10.1109/ICRA46639.2022.9812351	Anthony Vanderkop, Navinda Kottege, Thierry Peynot, Peter Corke
A Novel Multimodal Human-Exoskeleton Interface Based on EEG and sEMG Activity for Rehabilitation Training.	Despite the advances in the field of human-robot interface (HRI) based on biological neural signal, the use of the sole electroencephalography (EEG) signal to help robotic exoskeleton predict the limb movement is currently no mature in rehabilitation training, due to its unreliability. Multimodal HRI represents a very recent solution to enhance the performance of single modal HRI. These HRI normally include the EEG signal with surface electromyography (sEMG) signal. However, their use for the lower limb movement prediction in hemiplegia is still limited, and the deep fusion feature of sEMG and EEG signal is ignored. This paper proposes a Dense co-attention mechanism-based Multimodal Enhance fusion Network (DMEFNet) for the lower limb movement prediction in hemiplegia. The DMEFNet can realize the mapping and deep fusion between the sEMG and EEG signal features and get a high accuracy movement prediction of the lower limbs. A sEMG and EEG data acquisition experiment and an incomplete asynchronous data collection paradigm are designed to verify the effectiveness of DMEFNet. The experimental results show that DMEFNet has a good movement prediction performance in both within-subject and cross-subject situations, reaching an accuracy of 82.96% and 88.44% respectively.	https://doi.org/10.1109/ICRA46639.2022.9812180	Kecheng Shi, Rui Huang, Fengjun Mu, Zhinan Peng, Ke Huang, Yizhe Qin, Xiao Yang, Hong Cheng
A Novel Passive Mechanism for Flying Robots to Perch onto Surfaces.	Perching onto objects can allow flying robots to stay at a desired height at low or no cost of energy. This paper presents a novel passive mechanism for aerial perching onto smooth surfaces. This mechanism is made from a bistable mechanism and a soft suction cup. Different from existing designs, it can be easily attached onto and detached from a surface, but it can also hold a large weight when attached to a surface. Further, the mechanism can still work when the suction cup is not precisely aligned with the surface, alleviating the requirement for precise motion control of flying robots. The attachment and detachment are facilitated by the bistable mechanism, while the strong holding is enabled by a locking mechanism that can disable the bistable mechanism. We conduct experiments to characterize the required forces for successful attachments and detachments. We also equip the perching mechanism onto a quadcopter to demonstrate it can be successfully used for perching onto smooth surfaces (e.g., glass).	https://doi.org/10.1109/ICRA46639.2022.9811671	HaoTse Hsiao, Feiyu Wu, Jiefeng Sun, Jianguo Zhao
A Novel Triad Twisted String Actuator for Controlling a Two Degrees of Freedom Joint: Design and Experimental Validation.	Actuated universal joints, or equivalent joint systems, are found in a number of robotic applications, in particular mobile snake robots, continuum robots and robotic tails. These joints have two degrees of freedom on two axes, each perpendicular to a third axis and to themselves. Such joints use a variety of actuation methods, including direct drive motors, linear screw drives, cable based systems, and hydraulics/pneumatics. In this paper the authors design and validate a mechanism that uses the Twisted String Actuator (TSA) in an antagonistic triad to actuate the universal joint, using orientation sensors and load cells to create a robust cascading closed loop control system. This results in a light, compact, high-performance actuation system that avoids the extra mass and hardware complexity that alternative actuation methods present, with the additional challenge of nonlinearity.	https://doi.org/10.1109/ICRA46639.2022.9812124	Damian Crosby, Joaquín Carrasco, William Paul Heath, Andrew Weightman
A Passively Adaptable Toroidal Continuously Variable Transmission Combined with Twisted String Actuator.	Robots performing close physical interaction with humans would require a continuously variable transmission to operate in the region around the peak efficiency or peak power of the driving system. Conventional continuously variable transmission (CVT) has shown advantages in energy-efficient driving systems. However, these CVT designs are heavy and large for robotic applications. This paper presents a passively adaptable toroidal-CVT (pat-CVT) that is coupled with a twisted string actuator (TSA). The proposed combination of pat-CVT with TSA expands the operation range of TSA and mimics the torque-speed characteristics of artificial muscles. The contributions of the proposed system are as follows: 1) It has a high transmission ratio (4.6:1) compared to the level of existing CVT, and compact design; 2) We propose a structure that increases the power transmission efficiency by reducing slip rate during rotation through the application of soft material on the input/output disk and roller surfaces of the CVT; 3) Relations between the external load and the transmission ratio can be determined by selecting the spring in the system to optimize the motor operating conditions over the entire range of loads. We show theoretical modeling of pat-CVT with TSA and characterization of the transmission ratio, energy efficiency, and force-velocity curve.	https://doi.org/10.1109/ICRA46639.2022.9811545	Wonseok Shin, Sungbin Park, GunHee Park, Jung Kim
A Proprioceptive Haptic Device Design for Teaching Bimanual Manipulation.	Manipulation involves a broad spectrum of skills, e.g., polishing, peeling, flipping, screwing, etc., requiring complex and delicate control over both force and position. This paper aims at designing an optimal haptic interface for providing a robot with direct demonstrations of human's innate intelligence in performing a wide range of force-based bimanual manipulation tasks. Based on the proprioceptive actuation mechanism, kinodynamic design parameters of the (dual) 7-DOF haptic arm are optimized so as to maximize the force transparency perceived by the operator over the full real-scale workspace of human arm while also ensuring other important constraints including robot-to-operator collision and singularity avoidance, payload, controlled stiffness, etc. 2.65 kg of average reflective mass and 1500 N/m of controlled stiffness is achieved over the entire workspace. We show the efficacy of our haptic interface by demonstrating various force-based manipulation tasks with a light-weight anthropomorphic bimanual manipulator, LIMS2-AMBIDEX [1].	https://doi.org/10.1109/ICRA46639.2022.9811694	Choongin Lee, Taeyoon Lee, Jae-Kyung Min, Albert Wang, SungPyo Lee, Jaesung Oh, Chang-Woo Park, Keunjun Choi
A Quantitative Analysis of Activities of Daily Living: Insights into Improving Functional Independence with Assistive Robotics.	Wheelchair-mounted robotic manipulators have the potential to help the elderly and individuals living with disabilities carry out their activities of daily living (ADLs) independently. Robotics researchers focus on assistive tasks from the perspective of various control schemes and motion types, whereas, health research focuses on clinical assessment and rehabilitation, arguably leaving important differences between the two domains. In particular, there have been many studies on which activities are relevant to functional independence, but little is known quantitatively about the frequencies of ADLs that are typically carried out in everyday life. Understanding what activities are frequently carried out during the day can help guide the development and prioritization of robotic technology for in-home assistive robotic deployment. Robotics and health care communities have differing terms and taxonomies for representing tasks and motions; we aim to ameliorate taxonomic differences by consolidating quantitative task data with prior results from subjective task priority surveys. This study targets lifelogging databases, where we compute (i) daily activity task frequency from long-term low sampling frequency video and Internet of Things sensor data, and (ii) short term arm and hand movement data from video data of domestic tasks. In this work, we aim to provide deeper insights and meaningful guidelines to focus research and future developments in the field of assistive robotic manipulation that support the needs and performance requirements of the target population.	https://doi.org/10.1109/ICRA46639.2022.9811960	Laura Petrich, Jun Jin, Masood Dehghan, Martin Jägersand
A Recurrent Differentiable Engine for Modeling Tensegrity Robots Trainable with Low-Frequency Data.	Tensegrity robots, composed of rigid rods and flexible cables, are difficult to accurately model and control given the presence of complex dynamics and high number of DoFs. Differentiable physics engines have been recently proposed as a data-driven approach for model identification of such complex robotic systems. These engines are often executed at a high-frequency to achieve accurate simulation. Ground truth trajectories for training differentiable engines, however, are not typically available at such high frequencies due to limitations of real-world sensors. The present work focuses on this frequency mismatch, which impacts the modeling accuracy. We proposed a recurrent structure for a differentiable physics engine of tensegrity robots, which can be trained effectively even with low-frequency trajectories. To train this new recurrent engine in a robust way, this work introduces relative to prior work: (i) a new implicit integration scheme, (ii) a progressive training pipeline, and (iii) a differentiable collision checker. A model of NASA's icosahedron SUPERballBot on MuJoCo is used as the ground truth system to collect training data. Simulated experiments show that once the recurrent differentiable engine has been trained given the low-frequency trajectories from MuJoCo, it is able to match the behavior of MuJoCo's system. The criterion for success is whether a locomotion strategy learned using the differentiable engine can be transferred back to the ground-truth system and result in a similar motion. Notably, the amount of ground truth data needed to train the differentiable engine, such that the policy is transferable to the ground truth system, is 1% of the data needed to train the policy directly on the ground-truth system.	https://doi.org/10.1109/ICRA46639.2022.9812135	Kun Wang, Mridul Aanjaneya, Kostas E. Bekris
A Robotic Lower Limb With Eight DoFs and Whole-Foot Tactile Perception for Anthropomorphic Behavior Performance.	Humanoid lower limbs with tactile cognition are crucial for future bipedal robots developing advanced bionic intelligence, such as owning autonomous reflexes and performing human-like actions. Most existing robotic lower limbs focus on providing physical support and mobility, with little work on more bionic DoFs or tactile sensing abilities that are more than significant for a fully humanoid system. This paper develops a robotic lower limb with whole-foot tactile sensing capability. An eight-DoF mechanism with humanoid joints is designed comprehensively, and a tactile sensor with electric double-layer capacitors principle wraps the special-shaped foot surface. An STM32-based circuit integrating perception and control with a real-time inverse kinematics algorithm is experimentally demonstrated. This work provides novel insight and methodology for humanoid robots and tactile-based bionic intelligence.	https://doi.org/10.1109/ICRA46639.2022.9811690	Funing Hou, Jixiao Liu, Kuo Liu, Dicai Chen, Shijie Guo
A Simple Formulation for Fast Prioritized Optimal Control of Robots using Weighted Exact Penalty Functions.	Prioritization of tasks is a common approach to resolve conflicts in instantaneous control of redundant robots. However, the idea of prioritization has not yet been satisfactorily extended to model predictive control (MPC) to allow for real-time robot control. The standard sequential approach for prioritization is unsuitable because of the computational burden involved in solving a nonlinear problem (NLP) at every priority level. We introduce an alternate promising approach of using weighted exact penalties for the MPC stage costs, where a correctly tuned set of weights can introduce strict prioritization. We prove the existence of a set of equivalent weights that provides the same solution as the sequential approach for a local convex approximation of the original NLP and use this insight to design an algorithm to adaptively tune the weights. The weighted method is validated on a dual arm robot task in simulations and also implemented on a physical robot. We report computational times that are fast enough for prioritized MPC of robot manipulators for the first time, to the best of our knowledge.	https://doi.org/10.1109/ICRA46639.2022.9812224	Ajay Suresha Sathya, Wilm Decré, Goele Pipeleers, Jan Swevers
A Single Correspondence Is Enough: Robust Global Registration to Avoid Degeneracy in Urban Environments.	Global registration using 3D point clouds is a crucial technology for mobile platforms to achieve localization or manage loop-closing situations. In recent years, numerous researchers have proposed global registration methods to address a large number of outlier correspondences. Unfortunately, the degeneracy problem, which represents the phenomenon in which the number of estimated inliers becomes lower than three, is still potentially inevitable. To tackle the problem, a degeneracy-robust decoupling-based global registration method is proposed, called Quatro. In particular, our method employs quasi-SO(3) estimation by leveraging the Atlanta world assumption in urban environments to avoid degeneracy in rotation estimation. Thus, the minimum degree of freedom (DoF) of our method is reduced from three to one. As verified in indoor and outdoor 3D LiDAR datasets, our proposed method yields robust global registration performance compared with other global registration methods, even for distant point cloud pairs. Furthermore, the experimental results confirm the applicability of our method as a coarse alignment. Our code is available: https://github.com/url-kaist/quatro	https://doi.org/10.1109/ICRA46639.2022.9812018	Hyungtae Lim, Suyong Yeon, Soo-Hyun Ryu, Yonghan Lee, Youngji Kim, Jaeseong Yun, Euigon Jung, Donghwan Lee, Hyun Myung
A Switchable Rigid-Continuum Robot Arm: Design and Testing.	This paper presents a novel robot arm that is capable of switching between a rigid robot arm and a continuum robot arm. Therefore, the novel robot arm can perform adaptive physical interaction and manipulation against complex working environments and tasks. The switch-ability of the robot arm is achieved with two types of joints: knee-like flexible joints and continuum flexible joints, with which the continuum segment of the robot arm is capable of locking and losing, hence the degree of freedom of the robot arm is capable to be switched. In this work, kinematics is established for specifying the relationship between joints space and global coordinates in both rigid and continuum configurations. Then, the posture and workspace in rigid and continuum configurations are analyzed and illustrated with numerical simulations, and compared based on the established kinematic model. Finally, a series of preliminary experimental testing toward the joint motion and stiffness has been carried out to validate the design, the kinematic model, and the motion performance of the proposed robot arm. Both the numerical and experimental results show that the knee-like joints can guarantee favorable motion accuracy, and the motion of continuum segment from the testing is well aligned with the motion calculated from the theoretical model. Moreover, the stiffness of rigid configuration is larger than the continuum configuration based on the stiffness experiment results. Therefore, the proposed novel robot arm is capable to handle adaptive interaction and manipulation in a diverse environment through the switching between the rigid and continuum configurations.	https://doi.org/10.1109/ICRA46639.2022.9812074	Hao Wang, Zhengxue Zhou, Xingyu Yang, Xuping Zhang
A Universal Footstep Planning Methodology for Continuous Walking in Challenging Terrain Applicable to Different Types of Legged Robots.	In recent years, the capabilities of legged locomotion controllers have been significantly advanced enabling them to traverse basic types of uneven terrain without visual perception. However, safely and autonomously traversing longer distances over difficult uneven terrain requires appropriate motion planning using online collected environmental knowledge. In this paper, we present such a novel methodology for generic closed-loop preceding horizon footstep planning that enables legged robots equipped with capable locomotion controllers to autonomously traverse previously unknown terrain while continuously walking long distances. Hereby, our approach addresses the challenge of online terrain perception and soft real-time footstep planning. The proposed new formulation of the search-based planning problem makes no specific assumptions about the robot kinematics (e.g. number of legs) or the used locomotion control schemes. Therefore, it can be applied to a broad range of different types of legged robots. Unlike current methods, the proposed new framework can optionally consider the floating base as part of the state-space. It is possible to configure the complexity of the planner online, from efficiently solving tasks in flat terrain to using non-contiguous contacts in highly challenging terrain. Finally, the presented methodology is successfully applied and evaluated in virtual and real experiments on state of the art bipedal, quadrupedal, and a novel eight-legged robot.	https://doi.org/10.1109/ICRA46639.2022.9811711	Alexander Stumpf, Oskar von Stryk
A User-customized Automatic Music Composition System.	This paper introduces an intelligent system which composes music following the users' instructions. Current auto-matic music generation models are lack of stability. Meanwhile, they cannot satisfy the preference of different people. To overcome these challenges, we train a Transformer-based neural network to generate short music segments using a dataset. A user can compose music pieces by interacting with a well-trained generator. Our system collects the user's feedback during the interactions, and fine-tunes the neural network to optimize the generator. After a large number of interactions, our system can learn the musical taste of the user and customize a personal automatic music composer for him or her. Our work enhances the application value of generative models significantly, which enables people to compose music with the assistance of artificial intelligence.	https://doi.org/10.1109/ICRA46639.2022.9812396	Fan Mo, Xiaoqiang Ji, Huihuan Qian, Yangsheng Xu
A Wearable Fingertip Cutaneous Haptic Device with Continuous Omnidirectional Motion Feedback.	In both teleoperation in real space and exploration in virtual space, 'passive' and 'active' haptic feedback can help to improve the performance of the task, especially in object handover and exploring. However, the current wearable haptic devices are hard to display continuous omnidirectional motion feedback simultaneously, which makes it not yet achieved. In this study, we thus propose a cutaneous haptic device, which enables continuous omnidirectional motion feedback for exhibiting 'active' and 'passive' haptic feedback. By applying small smart actuators (i.e., piezo actuators), the device can obtain contact force and be wearable. By arranging the closed loop with a plain-woven structure, our device makes continuous omnidirectional motion feedback possible. Our 35 g device can generate 0.94 N contact force and 0.5 N shear force. The passive and active haptic evaluations also proved its haptic capability. In conclusion, our proposed device with 'active' and 'passive' haptic feedback can provide continuous omnidirectional motion making it possible to be used for precise teleoperation.	https://doi.org/10.1109/ICRA46639.2022.9812131	Peizhi Zhang, Mitsuhiro Kamezaki, Yutaro Hattori, Shigeki Sugano
A beetle-claw inspired miniature mesh climbing robot.	Beetles can walk smoothly on the meshed surface without slipping or getting stuck in the meshed surface due to its stiffness-variable tarsi and expandable hooks on the tip of tarsi. In this study, we find that beetles bend and open their claws proactively to walk freely. Inspired by the mechanism, we designed a centimeter-scale climbing robot, equipping an artificial claw to open and bend in the same cyclic manner as the natural beetles. The robot can climb freely on the mesh surface of 30° without being stuck at a speed of 26.18 mm/s (0.3 body length per second), and the speed was 37.5 mm/s on the 55-degree rough slop. This is the first demonstration of a centimeter-scale robot that can climb on the mesh surface.	https://doi.org/10.1109/ICRA46639.2022.9812229	Hong Wang, Yao Li, Bing Li
A hybrid model-based evolutionary optimization with passive boundaries for physical human-robot interaction.	The field of physical human-robot interaction has dramatically evolved in the last decades. As a result, the robotic system's requirements have become more challenging, including personalized behavior for different tasks and users. Various machine learning techniques have been proposed to give the robot such adaptability features. This paper proposes a model-based evolutionary optimization algorithm to tune the apparent impedance of a wrist rehabilitation device. We used passivity to define boundaries for the possible controller outcomes, limiting the shared autonomy of the robot and ensuring the coupled system stability. The experiment consists of a hardware-in-the-loop optimization and a one-degree-of-freedom robot used for wrist rehabilitation. Experimental results showed that the proposed technique could generate customized passive impedance controllers for three subjects. Furthermore, when compared with a constant impedance controller, the method suggested decreased in 20% the root mean square of interaction torques while maintaining stability during optimization.	https://doi.org/10.1109/ICRA46639.2022.9811606	Gustavo J. G. Lahr, Henrique Borges Garcia, Arash Ajoudani, Thiago Boaventura, Glauco A. P. Caurin
A model free robot control method for dragging an object on a planar surface by applying top contact forces.	In this work, a robot control method is proposed for dragging an object by applying top contact forces under unknown friction and object dynamics. This is a non-prehensile manipulation of an object that can enhance the grasping capabilities of a robotic manipulator in a plethora of grasping scenarios. In the proposed method, an initializing controller generates reference contact force trajectories until a desired contact motion status is achieved that enables dragging the object without slippage of the robot tip. Based on these forces, a sufficient Virtual Friction Cone (VFC) is calculated which allows proper position control of the object with no further slippage of the robotic tip. The proposed method is validated via simulations, where contact forces are simulated with the elasto-plastic friction model, and experiments with a KUKA robot dragging a variety of objects with different dynamics and surface friction.	https://doi.org/10.1109/ICRA46639.2022.9811686	Savvas Sampaziotis, Zoe Doulgeri
A novel hydrogel-based connection mechanism for soft modular robots.	Connection mechanisms are crucial in reconfigurable robots. In this work, we present a novel approach, based on the self-healing property of a hydrogel synthesized by our group, which allows us to easily attach and detach robotic modules using water as the only trigger element. Our connection mechanism does not need external energy to work and it is reversible and soft, being useful for soft modular robots. Tensile, fatigue and adhesion tests are presented to demonstrate the mechanical performance of our mechanism. Two modular soft robots, manipulator and snake, are featured to show the functionality of our approach.	https://doi.org/10.1109/ICRA46639.2022.9812164	Antonio López-Díaz, Jesús De La Morena, Francisco Ramos, Ester Vázquez, Andrés S. Vázquez
A physics-informed, vision-based method to reconstruct all deformation modes in slender bodies.	This paper is concerned with the problem of estimating (interpolating and smoothing) the shape (pose and the six modes of deformation) of a slender flexible body from multiple camera measurements. This problem is important in both biology, where slender, soft, and elastic structures are ubiquitously encountered across species, and in engineering, particularly in the area of soft robotics. The proposed mathematical formulation for shape estimation is physics-informed, based on the use of the special Cosserat rod theory whose equations encode slender body mechanics in the presence of bending, shearing, twisting and stretching. The approach is used to derive numerical algorithms which are experimentally demonstrated for fiber reinforced and cable-driven soft robot arms. These experimental demonstrations show that the methodology is accurate (<5 mm error, three times less than the arm diameter) and robust to noise and uncertainties.	https://doi.org/10.1109/ICRA46639.2022.9811909	Seung Hyun Kim, Heng-Sheng Chang, Chia-Hsien Shih, Naveen Kumar Uppalapati, Udit Halder, Girish Krishnan, Prashant G. Mehta, Mattia Gazzola
A2DIO: Attention-Driven Deep Inertial Odometry for Pedestrian Localization based on 6D IMU.	In this work, we propose A2DIO, a novel hybrid neural network model with a set of carefully designed attention mechanisms for pose invariant inertial odometry. The key idea is to extract both local and global features from the window of IMU measurements for velocity prediction. A2DIO leverages the convolutional neural network (CNN) to capture the sectional features and long-short term memory (LSTM) recurrent neural network to extract long-range dependencies. In both CNN and LSTM modules, attention mechanisms are designed and embedded for better model representation. Specifically, in the CNN attention block, the convolved features are refined along both channel and spatial dimensions, respectively. For the LSTM module, softmax scoring is applied to update the weights of the hidden states along the temporal axis. We evaluate A2DIO on the benchmark with the largest and most natural IMU data, RoNIN. Extensive ablation experiments demonstrate the effectiveness of our A2DIO model. Compared with the state of the art, the 50th percentile accuracy of A2DIO is 18.21 % higher and the 90th percentile accuracy is 21.15 % higher for all the phone holders not appeared in the training set.	https://doi.org/10.1109/ICRA46639.2022.9811714	Yingying Wang, Hu Cheng, Max Q.-H. Meng
AMI: Adaptive Motion Imitation Algorithm Based on Deep Reinforcement Learning.	In this paper, we develop a novel adaptive motion imitation algorithm (AMI) for robotic systems. Although AMI can be used in a variety of human-robot interaction scenarios, we are particularly interested in robotic rehabilitation where the robot plays the role of demonstrating and practicing challenging motion physiotherapy. During therapy, the robot first demonstrates a reference trajectory to the patient that needs to be repeated during practice and then adapts its motion to a cyclic speed and amplitude based on the patient's abilities. Using this algorithm, the robotic system learns an upper-body motion of the human user and performs a unique, similar, and easier motion based on the learned trajectory from the user. Adaptation in the AMI is based on deep reinforcement learning with deep deterministic policy gradient implemented in the Robot Operating System (ROS) environment. Experimental data collected from 11 users during upper body human-robot imitation sessions with social robot Zeno was used to show that the algorithm can learn reference elbow joint trajectories of the user in an off-line manner after just a few cycles. Finally, we also implemented the algorithm online using the Baxter robot to demonstrate its learning and playback performance.	https://doi.org/10.1109/ICRA46639.2022.9812121	Nazita Taghavi, Moath H. A. Alqatamin, Dan O. Popa
AMRA*: Anytime Multi-Resolution Multi-Heuristic A.	Heuristic search-based motion planning algorithms typically discretise the search space in order to solve the shortest path problem. Their performance is closely related to this discretisation. A fine discretisation allows for better approximations of the continuous search space, but makes the search for a solution more computationally costly. A coarser resolution might allow the algorithms to find solutions quickly at the expense of quality. For large state spaces, it can be beneficial to search for solutions across multiple resolutions even though defining the discretisations is challenging. The recently proposed algorithm Multi-Resolution A* (MRA*) searches over multiple resolutions. It traverses large areas of obstacle-free space and escapes local minima at a coarse resolution. It can also navigate so-called narrow passageways at a finer resolution. In this work, we develop AMRA*, an anytime version of MRA*, AMRA* tries to find a solution quickly using the coarse resolution as much as possible. It then refines the solution by relying on the fine resolution to discover better paths that may not have been available at the coarse resolution. In addition to being anytime, AMRA* can also leverage information sharing between multiple heuristics. We prove that AMRA* is complete and optimal (in-the-limit of time) with respect to the finest resolution. We show its performance on 2D grid navigation and 4D kinodynamic planning problems.	https://doi.org/10.1109/ICRA46639.2022.9812359	Dhruv Mauria Saxena, Tushar Kusnur, Maxim Likhachev
APF-RL: Safe Mapless Navigation in Unknown Environments.	This paper is focused on safe mapless navigation of mobile robots in unknown and possibly complex environments containing both internal and dynamic obstacles. We present a novel modular approach that combines the strengths of artificial potential functions (APF) with deep reinforcement learning. Differing from related work, the robot learns how to adjust the two input parameters of the APF controller as necessary through soft actor-critic algorithm. Environmental complexity measures are introduced in order to ensure that the robot's training covers a range of learning scenarios that vary in regard to maneuvering difficulty. Our experimental results show that differing from the classical navigation methods and end-to-end models, the robot can navigate successfully on its own even in complex scenarios with moving entities without requiring any maps.	https://doi.org/10.1109/ICRA46639.2022.9811537	Kemal Bektas, H. Isil Bozma
ARChemist: Autonomous Robotic Chemistry System Architecture.	Automated laboratory experiments have the potential to propel new discoveries, while increasing reproducibility and improving scientists' safety when handling dangerous materials. However, many automated laboratory workflows have not fully leveraged the remarkable advancements in robotics and digital lab equipment. As a result, most robotic systems used in the labs are programmed specifically for a single experiment, often relying on proprietary architectures or using unconventional hardware. In this work, we tackle this problem by proposing a novel robotic system architecture specifically designed with and for chemists, which allows the scientist to easily reconfigure their setup for new experiments. Specifically, the system's strength is its ability to combine together heterogeneous robotic platforms with standard laboratory equipment to create different experimental setups. Finally, we show how the architecture can be used for specific laboratory experiments through case studies such as solubility screening and crystallisation.	https://doi.org/10.1109/ICRA46639.2022.9811996	Hatem Fakhruldeen, Gabriella Pizzuto, Jakub Glowacki, Andrew Ian Cooper
ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement Learning.	Building assistive interfaces for controlling robots through arbitrary, high-dimensional, noisy inputs (e.g., webcam images of eye gaze) can be challenging, especially when it involves inferring the user's desired action in the absence of a natural 'default' interface. Reinforcement learning from online user feedback on the system's performance presents a natural solution to this problem, and enables the interface to adapt to individual users. However, this approach tends to require a large amount of human-in-the-loop training data, especially when feedback is sparse. We propose a hierarchical solution that learns efficiently from sparse user feedback: we use offline pre-training to acquire a latent embedding space of useful, high-level robot behaviors, which, in turn, enables the system to focus on using online user feedback to learn a mapping from user inputs to desired high-level behaviors. The key insight is that access to a pre-trained policy enables the system to learn more from sparse rewards than a naïve RL algorithm: using the pre-trained policy, the system can make use of successful task executions to relabel, in hindsight, what the user actually meant to do during unsuccessful executions. We evaluate our method primarily through a user study with 12 participants who perform tasks in three simulated robotic manipulation domains using a webcam and their eye gaze: flipping light switches, opening a shelf door to reach objects inside, and rotating a valve. The results show that our method successfully learns to map 128-dimensional gaze features to 7-dimensional joint torques from sparse rewards in under 10 minutes of online training, and seamlessly helps users who employ different gaze strategies, while adapting to distributional shift in webcam inputs, tasks, and environments	https://doi.org/10.1109/ICRA46639.2022.9812442	Sean Chen, Jensen Gao, Siddharth Reddy, Glen Berseth, Anca D. Dragan, Sergey Levine
Abnormal Occupancy Grid Map Recognition using Attention Network.	The occupancy grid map is a critical component of autonomous positioning and navigation in the mobile robotic system, as many other systems' performance depends heavily on it. To guarantee the quality of the occupancy grid maps, researchers previously had to perform tedious manual recognition for a long time. This work focuses on automatic abnormal occupancy grid map recognition using the residual neural network with novel attention mechanism modules. We propose an effective channel and spatial Residual Squeeze-and-Excitation (csRSE) attention module, which contains a residual block for producing hierarchical features, followed by both channel SE (cSE) block and spatial SE (sSE) block for the sufficient information extraction along the channel and spatial pathways. To further summarize the occupancy grid map characteristics and experiments with our csRSE attention modules, we constructed a dataset called occupancy grid map dataset (OGMD) for our experiments. On this OGMD test dataset, we tested a few variants of our proposed structure and compared them with other attention mechanisms. Our experimental results show that the proposed attention network can infer the abnormal map with state-of-the-art (SOTA) accuracy of 96.23% for abnormal occupancy grid map recognition.	https://doi.org/10.1109/ICRA46639.2022.9812106	Fuqin Deng, Hua Feng, Mingjian Liang, Qi Feng, Ningbo Yi, Yong Yang, Yuan Gao, Junfeng Chen, Tin Lun Lam
Abstract Flow for Temporal Semantic Segmentation on the Permutohedral Lattice.	Semantic segmentation is a core ability required by autonomous agents, as being able to distinguish which parts of the scene belong to which object class is crucial for navigation and interaction with the environment. Approaches which use only one time-step of data cannot distinguish between moving objects nor can they benefit from temporal integration. In this work, we extend a backbone LatticeNet to process temporal point cloud data. Additionally, we take inspiration from optical flow methods and propose a new module called Abstract Flow which allows the network to match parts of the scene with similar abstract features and gather the information temporally. We obtain state-of-the-art results on the SemanticKITTI dataset that contains LiDAR scans from real urban environments. We share the PyTorch implementation of TemporalLatticeNet at https://github.com/AIS-Bonn/temporal_latticenet.	https://doi.org/10.1109/ICRA46639.2022.9811818	Peer Schütt, Radu Alexandru Rosu, Sven Behnke
Accessibility-Based Clustering for Efficient Learning of Locomotion Skills.	For model-free deep reinforcement learning of quadruped locomotion, the initialization of robot configurations is crucial for data efficiency and robustness. This work focuses on algorithmic improvements of data efficiency and robustness simultaneously through automatic discovery of initial states, which is achieved by our proposed K-Access algorithm based on accessibility metrics. Specifically, we formulated accessibility metrics to measure the difficulty of transitions between two arbitrary states, and proposed a novel K-Access algorithm for state-space clustering that automatically discovers the centroids of the static-pose clusters based on the accessibility metrics. By using the discovered centroidal static poses as the initial states, we can improve data efficiency by reducing redundant explorations, and enhance the robustness by more effective explorations from the centroids to sampled poses. Focusing on fall recovery as a very hard set of locomotion skills, we validated our method extensively using an 8-DoF quadrupedal robot Bittle. Compared to the baselines, the learning curve of our method converges much faster, requiring only 60% of training episodes. With our method, the robot can successfully recover to standing poses within 3 seconds in 99.4% of the test cases. Moreover, the method can generalize to other difficult skills successfully, such as backflipping.	https://doi.org/10.1109/ICRA46639.2022.9812113	Chong Zhang, Wanming Yu, Zhibin Li
Accurate Calibration of Multi-Perspective Cameras from a Generalization of the Hand-Eye Constraint.	Multi-perspective cameras are quickly gaining importance in many applications such as smart vehicles and virtual or augmented reality. However, a large system size or absence of overlap in neighbouring fields-of-view often complicate their calibration. We present a novel solution which relies on the availability of an external motion capture system. Our core contribution consists of an extension to the hand-eye calibration problem which jointly solves multi-eye-to-base problems in closed form. We furthermore demonstrate its equivalence to the multi-eye-in-hand problem. The practical validity of our approach is supported by our experiments, indicating that the method is highly efficient and accurate, and outperforms existing closed-form alternatives.	https://doi.org/10.1109/ICRA46639.2022.9811577	Yifu Wang, Wenqing Jiang, Kun Huang, Sören Schwertfeger, Laurent Kneip
Acoustic and magnetic hybrid actuated immune cell robot for target and kill cancer cells.	"Macrophage immunotherapy is a promising clinical approach to treat cancer. However, low targeting efficiency severely limits the immunotherapeutic effect of macrophages. Here, we report a unique macrophage robot that can target and kill cancer cells using a combination of external acoustic and magnetic fields. First, the inactive macrophages (Mø) are magnetized by endocytosis of the \gamma
-Fe2O3 nanoparticles (FeNPs). Then, the magnetized M⊘can be moved towards the capillary wall under the influence of an acoustic radiation force generated from a lead zirconate titanate piezoelectric (PZT) transducer. Finally, the magnetized cells rotate forward under the action of alternating magnetic fields (AMF). During the process of magnetizing macrophages, FeNPs activate the anti-tumor immune activity of macrophages (M1) to induce cancer cell death. Overall, the present study highlights a novel cell robot that can target and kill cancer cells. Considering that the nanoparticles, macrophages, magnetic fields, and ultrasound technology have all been FDA approved for clinical settings, our targeted delivery system has tremendous clinical translational potential."	https://doi.org/10.1109/ICRA46639.2022.9812071	Xue Bai, Wei Zhang, Yuguo Dai, Yueying Wang, Hongyan Sun, Lin Feng
Active Autorotation of Micro Aerial Vehicle with Foldable Winged Shell for Impact Mitigation during Free Fall.	Drop mitigation is an important function of micro aerial vehicles (MAVs) that are used for internal inspections of enclosed and cluttered structures (height: 5–10 m). The mechanism also allows continuous operation of drones, prevents the downtime required for maintenance and repair and also provides a safer environment for workers who are working below the drones. Some solutions include parachutes, auto-rotors, and active auto-rotors. However, these are inapplicable to MAV s with a protector shell because of their size and payload. We herein propose a new rapid response drop mitigation method for MA V s involving active autorotation with bendable wings and shells. Active autorotation enables faster deceleration during dropping motion as compared to parachutes or passive autorotation. Bendable wings can ensure optimal flight performance and enable sufficient deceleration during falling motion. This newly proposed fixture was shown to reduce the impact impulse by 32.2 % and horizontal oscillation by 34.4 %. From our flight tests conducted at heights of 5 m and 10m in both outdoor and indoor environments, the measured impact impulse for both profiles were attained at 0.93 N s. The minimum impact impulse that can cause harm to the human eye, which is the most vulnerable part, is 2 N s. Thus, this mechanism was successfully proven to provide a greater safety buffer based on the drop test conducted. We envision this mechanism to provide greater safety to drone operating environments in relevant fields involving indoor and urban drone flights. Furthermore, it can reduce damage to drones and structures and avoid injuries arising from drone crashes.	https://doi.org/10.1109/ICRA46639.2022.9812294	Quek Ching Alvin, Kazunori Ohno, Yoshito Okada, Daiki Fujikura, Satoshi Abe, Masaki Takahashi, Zitong Han, Satoshi Tadokoro
Active Extrinsic Contact Sensing: Application to General Peg-in-Hole Insertion.	We propose a method that actively estimates contact location between a grasped rigid object and its environment and uses this as input to a peg-in-hole insertion policy. An estimation model and an active tactile feedback controller work collaboratively to estimate the external contacts accurately. The controller helps the estimation model get a better estimate by regulating a consistent contact mode. The better estimation makes it easier for the controller to regulate the contact. We then train an object-agnostic insertion policy that learns to use the series of contact estimates to guide the insertion of an unseen peg into a hole. In contrast with previous works that learn a policy directly from tactile signals, since this policy is in contact configuration space, it can be learned directly in simulation. Lastly, we demonstrate and evaluate the active extrinsic contact line estimation and the trained insertion policy together in a real experiment. We show that the proposed method inserts various-shaped test objects with higher success rates and fewer insertion attempts than previous work with end-to-end approaches. See supplementary video and results at https://sites.google.com/view/active-extrinsic-contact.	https://doi.org/10.1109/ICRA46639.2022.9812017	Sangwoon Kim, Alberto Rodriguez
Active Learning for Testing and Evaluation in Field Robotics: A Case Study in Autonomous, Off-Road Navigation.	Testing and evaluation of field robotic systems requires both experimentation in representative conditions and human supervision to effectively assess components, manage risk, and interpret results. Due to the complexity of robotic sys-tems, we argue this experimentation should be done adaptively by using insights gained from previous trials. Furthermore, we envision an advisory system that could assist experimenters with selecting trial configurations by learning and accounting for human preferences and risk tolerances; however, formal methods for human decision making in the context of field robotic experimentation remains an open question. In this work, we present and analyze a case study for how decisions were made during the testing and evaluation of an off-road, autonomous navigation system. From the perspective of active learning, we find that Bayesian Optimization is a promising mathematical framework for modeling human decision making in adaptive experimental design of field robotics and that a combination of the EI, KG, and PES acquisition functions would likely be useful for realizing an advisory system.	https://doi.org/10.1109/ICRA46639.2022.9812453	Jason M. Gregory, Daniel M. Sahu, Eli Lancaster, Felix A. Sanchez, Trevor Rocks, Brian Kaukeinen, Jonathan Fink, Satyandra K. Gupta
Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking.	Visual tracking is adopted to extensive unmanned aerial vehicle (UAV)-related applications, which leads to a highly demanding requirement on the robustness of UAV trackers. However, adding imperceptible perturbations can easily fool the tracker and cause tracking failures. This risk is often overlooked and rarely researched at present. Therefore, to help increase awareness of the potential risk and the robustness of UAV tracking, this work proposes a novel adaptive adversarial attack approach, i.e., Ad2 Attack, against UAV object tracking. Specifically, adversarial examples are generated online during the resampling of the search patch image, which leads trackers to lose the target in the following frames. Ad2 Attack is composed of a direct downsampling module and a super-resolution upsampling module with adaptive stages. A novel optimization function is proposed for balancing the imperceptibility and efficiency of the attack. Comprehensive experiments on several well-known benchmarks and real-world conditions show the effectiveness of our attack method, which dramatically reduces the performance of the most advanced Siamese trackers.	https://doi.org/10.1109/ICRA46639.2022.9812056	Changhong Fu, Sihang Li, Xinnan Yuan, Junjie Ye, Ziang Cao, Fangqiang Ding
Ada-Detector: Adaptive Frontier Detector for Rapid Exploration.	In this paper, we propose an efficient frontier detector method based on adaptive Rapidly-exploring Random Tree (RRT) for autonomous robot exploration. Robots can achieve real-time incremental frontier detection when they are exploring unknown environments. First, our detector adaptively adjusts the sampling space of RRT by sensing the surrounding environment structure. The adaptive sampling space can greatly improve the successful sampling rate of RRT (the ratio of the number of samples successfully added to the RRT tree to the number of sampling attempts) according to the environment structure and control the expansion bias of the RRT. Second, by generating non-uniform distributed samples, our method also solves the over-sampling problem of RRT in the sliding windows, where uniform random sampling causes over-sampling in the overlap area between two adjacent sliding windows. In this way, our detector is more inclined to sample in the latest explored area, which improves the efficiency of frontier detection and achieves incremental detection. We validated our method in three simulated benchmark scenarios. The experimental comparison shows that we reduce the frontier detection runtime by about 40% compared with the SOTA method, DSV Planner.	https://doi.org/10.1109/ICRA46639.2022.9811614	Zezhou Sun, Banghe Wu, Chengzhong Xu, Hui Kong
Adaptable Action-Aware Vital Models for Personalized Intelligent Patient Monitoring.	Vital signs such as heart rate, oxygen saturation, and blood pressure are crucial information for healthcare workers to identify clinical deterioration of ward patients. Currently, medical devices monitor these vital signs and trigger alarms when the vital signs are not in the normal ranges based on predefined thresholds, which suggests the presence of clinical deterioration. However, such threshold-based approach is not robust for patient monitoring. This is because vital signs differ among patients due to human physiology and change across time based on the action performed by a patient. In this work, we want to tackle these problems by building adaptable action-aware vital models. These models can understand the changes in vital signs caused by patient's actions and can be adapted to the normal vital sign ranges of individual patients. Our experimental results show that general vital sign patterns for different actions exist and can be personalized to new patients. Additionally, we investigate the possibility of estimating the initial vital model for an unobserved action using models of observed actions for model personalization. The resulting adaptable action-aware vital models have the potential to improve patient monitoring by reducing false clinical alarms.	https://doi.org/10.1109/ICRA46639.2022.9812176	Kai Wu, Ee Heng Chen, Hao Xing, Felix Wirth, Keti Vitanova, Rüdiger Lange, Darius Burschka
Adaptive Dynamic Sliding Mode Control of Soft Continuum Manipulators.	Soft robots are made of compliant materials and perform tasks that are challenging for rigid robots. However, their continuum nature makes it difficult to develop model-based control strategies. This work presents a robust model-based control scheme for soft continuum robots. Our dynamic model is based on the Euler-Lagrange approach, but it uses a more accurate description of the robot's inertia and does not include oversimplified assumptions. Based on this model, we introduce an adaptive sliding mode control scheme, which is robust against model parameter uncertainties and unknown input disturbances. We perform a series of experiments with a physical soft continuum arm to evaluate the effectiveness of our controller at tracking task-space trajectory under different payloads. The tracking performance of the controller is around 38 % more accurate than that of a state-of-the-art controller, i.e., the inverse dynamics method. Moreover, the proposed model-based control design is flexible and can be generalized to any continuum robotic arm with an arbitrary number of segments. With this control strategy, soft robotic object manipulation can become more accurate while remaining robust to disturbances.	https://doi.org/10.1109/ICRA46639.2022.9811715	Amirhossein Kazemipour, Oliver Fischer, Yasunori Toshimitsu, Ki Wan Wong, Robert K. Katzschmann
Adaptive Impedance Controller for Human-Robot Arbitration based on Cooperative Differential Game Theory.	The problem addressed in this work is the arbitration of the role between a robot and a human during physical Human-Robot Interaction, sharing a common task. The system is modeled as a Cartesian impedance, with two separate external forces provided by the human and the robot. The problem is then reformulated as a Cooperative Differential Game, which possibly has multiple solutions on the Pareto frontier. Finally, the bargaining problem is addressed by proposing a solution depending on the interaction force, interpreted as the human will to lead or follow. This defines the arbitration law and assigns the role of leader or follower to the robot. Experiments show the feasibility and capabilities of the proposed control in managing the human-robot arbitration during a shared- trajectory following task.	https://doi.org/10.1109/ICRA46639.2022.9811853	Paolo Franceschi, Nicola Pedrocchi, Manuel Beschi
Adaptive Informative Path Planning Using Deep Reinforcement Learning for UAV-based Active Sensing.	Aerial robots are increasingly being utilized for environmental monitoring and exploration. However, a key challenge is efficiently planning paths to maximize the information value of acquired data as an initially unknown environment is explored. To address this, we propose a new approach for informative path planning based on deep reinforcement learning (RL). Combining recent advances in RL and robotic applications, our method combines tree search with an offline-learned neural network predicting informative sensing actions. We introduce several components making our approach applicable for robotic tasks with high-dimensional state and large action spaces. By deploying the trained network during a mission, our method enables sample-efficient online replanning on platforms with limited computational resources. Simulations show that our approach performs on par with existing methods while reducing runtime by 8-10×. We validate its performance using real-world surface temperature data.	https://doi.org/10.1109/ICRA46639.2022.9812025	Julius Rückin, Liren Jin, Marija Popovic
Adaptive Semi-Supervised Intent Inferral to Control a Powered Hand Orthosis for Stroke.	In order to provide therapy in a functional context, controls for wearable robotic orthoses need to be robust and intuitive. We have previously introduced an intuitive, user-driven, EMG-based method to operate a robotic hand orthosis, but the process of training a control that is robust to concept drift (changes in the input signal) places a substantial burden on the user. In this paper, we explore semi-supervised learning as a paradigm for controlling a powered hand orthosis for stroke subjects. To the best of our knowledge, this is the first use of semi-supervised learning for an orthotic application. Specifically, we propose a disagreement-based semi-supervision algorithm for handling intrasession concept drift based on multimodal ipsilateral sensing. We evaluate the performance of our algorithm on data collected from five stroke subjects. Our results show that the proposed algorithm helps the device adapt to intrasession drift using unlabeled data and reduces the training burden placed on the user. We also validate the feasibility of our proposed algorithm with a functional task; in these experiments, two subjects successfully completed multiple instances of a pick-and-handover task.	https://doi.org/10.1109/ICRA46639.2022.9811932	Jingxi Xu, Cassie Meeker, Ava Chen, Lauren Winterbottom, Michaela Fraser, Sangwoo Park, Lynne M. Weber, Mitchell Miya, Dawn Nilsen, Joel Stein, Matei T. Ciocarlie
Adaptive Tracking Control for Industrial Robot Manipulators with Unknown Inner loop Architecture.	The task space control of robot manipulators requires solving the thorny problem of stabilizing the compound system {outer controller - inner controller - robot manipulator}. To stabilize this compound system, both controllers must be designed by the user to achieve convergence of the tracking error. This problem is tricky to solve in the case of the control of an industrial robot manipulator because its internal controller is not accessible to users. In this work, we propose an adaptive neural network outer controller. The neural networks approximate the dynamics of the inner controller, the kinematic and dynamic parameters of the robot. Besides, the adaptive part finds parameters that achieve the stability of the global system. Since an adaptive approach is sensitive to errors in initial values, we have integrated into the controller a term that constrains the closed-loop system to maintain the prescribed performances. The effectiveness of the approach is demonstrated through Lyapunov's theory, simulation comparisons, and experimental studies.	https://doi.org/10.1109/ICRA46639.2022.9811748	Joseph Jean-Baptiste Mvogo Ahanda, Achille Melingui, Othman Lakhal, Bernard Essimbi Zobo, Hela Kadri, Rochdi Merzouki
Adaptive Vision-Based Control of Redundant Robots with Null-Space Interaction for Human-Robot Collaboration.	Human-robot collaboration aims to extend human ability through cooperation with robots. This technology is currently helping people with physical disabilities, has transformed the manufacturing process of companies, improved surgical performance, and will likely revolutionize the daily lives of everyone in the future. Being able to enhance the performance of both sides, such that human-robot collaboration outperforms a single robot/human, remains an open issue. For safer and more effective collaboration, a new control scheme has been proposed for redundant robots in this paper, consisting of an adaptive vision-based control term in task space and an interactive control term in null space. Such a formulation allows the robot to autonomously carry out tasks in an unknown environment without prior calibration while also interacting with humans to deal with unforeseen changes (e.g., potential collision, temporary needs) under the redundant configuration. The decoupling between task space and null space helps to explore the collaboration safely and effectively without affecting the main task of the robot end-effector. The stability of the closed-loop system has been rigorously proved with Lyapunov methods, and both the convergence of the position error in task space and that of the damping model in null space are guaranteed. The experimental results of a robot manipulator guided with the technology of augmented reality (AR) are presented to illustrate the performance of the control scheme.	https://doi.org/10.1109/ICRA46639.2022.9812218	Xiangjie Yan, Chen Chen, Xiang Li
Admittance Control Based Human-in-the-Loop Optimization for Hip Exoskeleton Reduces Human Exertion during Walking.	Human-in-the-loop (HIL) optimization usually optimizes assistive torque of exoskeletons to minimize the human's energetic expenditure in walking, quantified by metabolic cost. This formulation can, however, result in altered gait pattern of the human joint from the natural pattern, which is undesired. In this paper, we proposed a novel concept of HIL optimization of a hip exoskeleton. The optimization goal was to maintain the hip kinematics while providing optimal mechanical energy from the exoskeleton by modulating the admittance control. Policy iteration was used to optimize the switching time within the gait phase, at which a single parameter of the admittance controller was altered to provide assistance. The stiffness and equilibrium angle were considered as the two parameters for altering at the switching time, resulting in three possible modes of operation for the algorithm: (i) switching the equilibrium point, (ii) switching stiffness while equilibrium point is set at maximum extension and, (iii) maximum flexion. The optimization algorithm was found to converge for all three modes, with the equilibrium mode resulting in multiple solutions. Further analysis of power injected by the exoskeleton in the three modes showed that the first and third mode reduced human energetic exertion while the second mode increased human exertion. Implications of the results as well as the observed muscle activation patterns in response to assistance are discussed.	https://doi.org/10.1109/ICRA46639.2022.9811553	Varun Nalam, Xikai Tu, Minhan Li, Jennie Si, He Helen Huang
Admittance Model Optimization for Gait Balance Assistance of a Robotic Walker: Passive Model-based Mechanical Assessment.	This paper presents an optimization of an admittance control model for gait balance assistance offered by a walker-type assistive robot. We previously introduced the notion of quasi-passive physical Human-Robot Interaction (pHRI) where a non-wearable assistive device adaptively achieves supportability for providing physical assistance and operability to follow the user's intuitive operation. Aiming to mitigate the falling risk of elderly people with reduced mobility with our pHRI approach, we propose a hierarchical algorithm to optimize an admittance control model for a walker robot. By employing dynamic trajectories such as Zero Moment Point (ZMP) and Divergent Component of Motion (DCM) with optimization, our controller provides appropriate physical interaction to improve the gait stability while considering intrinsic body dynamics. In the current implementation, based on a model predictive control (MPC) framework, we formulate the optimization problems in the form of quadratic programming (QP), making the optimization suitable for real-time interaction. Through mechanical assessments with passive walking models of compass gait, we demonstrate the feasibility of our proposed optimization framework in stabilizing the limit cycle gait with minimized assistance.	https://doi.org/10.1109/ICRA46639.2022.9811594	Shunki Itadera, Gordon Cheng
Adversarial Imitation Learning from Video Using a State Observer.	The imitation learning research community has recently made significant progress towards the goal of enabling artificial agents to imitate behaviors from video demonstrations alone. However, current state-of-the-art approaches developed for this problem exhibit high sample complexity due, in part, to the high-dimensional nature of video observations. Towards addressing this issue, we introduce here a new algorithm called Visual Generative Adversarial Imitation from Observation using a State Observer (VGAIfO-SO). At its core, VGAIfO-SO seeks to address sample inefficiency using a novel, self-supervised state observer, which provides estimates of lower-dimensional proprioceptive state representations from high-dimensional images. We show experimentally in several continuous control environments that VGAIfO-SO is more sample efficient than other IfO algorithms at learning from video-only demonstrations and can sometimes even achieve performance close to the Generative Adversarial Imitation from Observation (GAIfO) algorithm that has privileged access to the demonstrator's proprioceptive state information.	https://doi.org/10.1109/ICRA46639.2022.9811570	Haresh Karnan, Faraz Torabi, Garrett Warnell, Peter Stone
Aerial Manipulation Using Contact with the Environment by Thrust Vectorable Multilinked Aerial Robot.	In recent years, an increasing number of research works have been focusing on the manipulation by aerial robots. Previous works using aerial robots with robotic arms have two problems: underactuation and external disturbances. We propose the fully-actuated control method and motion strategy using contact with the environment to solve these problems, along with the mechanical approach required. First, each propeller's 1 degree-of-freedom (DoF) thrust vectoring units are applied to enable fully-actuated flight control. In order to obtain the desired thrust and vectoring angle inputs for aerial manipulation satisfying hardware limits, we developed a fully-actuated control method using non-linear optimization. Second, we propose a manipulation motion strategy that treats the multilink robot body as a fixed manipulator by making contact with the environment. The contact mechanism attached to the link end is developed to maintain contact and resist external disturbances. In a real machine experiment, the robot successfully opened the door while in contact with the wall, demonstrating the feasibility of the proposed methods.	https://doi.org/10.1109/ICRA46639.2022.9811948	Nobuki Sugito, Moju Zhao, Tomoki Anzai, Takuzumi Nishio, Kei Okada, Masayuki Inaba
Aerial-Ground Robots Collaborative 3D Mapping in GNSS-Denied Environments.	Collaborative heterogeneous robots are expected to perform comprehensive perception, mapping and coordination in search and rescue scenarios. The challenge of collaboration between heterogeneous robots lies in their huge differences in perception, mobility and processing capabilities. In this paper, a novel collaborative UAV-UGV mapping framework is proposed in GNSS-denied and unknown environments. The key novelty of this work is the proposing of a unified framework to formulate the UAV-UGV collaborative mapping problem with a continuous-discrete model, as well as its realization in real robotic systems. In order to project continuous space into discrete space, a novel information gain trigger scheme is pro-posed. The continuous space allows each robot to perform high frequency local map estimation, while discrete space describes the problem of multi-resolution hybrid map fusion. Considering the nature of data heterogeneity, a flexible probabilistic fusion algorithm is proposed that addresses the multi-resolution hybrid map fusion problem, where the local maps generated by UAV and UGV are fused based on Bayesian rule. The proposed UAV-UGV hybrid system is validated in various challenging scenarios, demonstrating its accuracy and utility in practical tasks.	https://doi.org/10.1109/ICRA46639.2022.9812319	Yufeng Yue, Chunyang Zhao, Yuanzhe Wang, Yi Yang, Danwei Wang
Affordance Learning from Play for Sample-Efficient Policy Learning.	Robots operating in human-centered environments should have the ability to understand how objects function: what can be done with each object, where this interaction may occur, and how the object is used to achieve a goal. To this end, we propose a novel approach that extracts a self-supervised visual affordance model from human teleoperated play data and leverages it to enable efficient policy learning and motion planning. We combine model-based planning with model-free deep reinforcement learning (RL) to learn policies that favor the same object regions favored by people, while requiring minimal robot interactions with the environment. We evaluate our algorithm, Visual Affordance-guided Policy Optimization (VAPO), with both diverse simulation manipulation tasks and real world robot tidy-up experiments to demonstrate the effectiveness of our affordance-guided policies. We find that our policies train 4 × faster than the baselines and generalize better to novel objects because our visual affordance model can anticipate their affordance regions.	https://doi.org/10.1109/ICRA46639.2022.9811889	Jessica Borja-Diaz, Oier Mees, Gabriel Kalweit, Lukás Hermann, Joschka Boedecker, Wolfram Burgard
AirDOS: Dynamic SLAM benefits from Articulated Objects.	Dynamic Object-aware SLAM (DOS) exploits object-level information to enable robust motion estimation in dynamic environments. Existing methods mainly focus on identifying and excluding dynamic objects from the optimization. In this paper, we show that feature-based visual SLAM systems can also benefit from the presence of dynamic articulated objects by taking advantage of two observations: (1) The 3D structure of each rigid part of articulated object remains consistent over time; (2) The points on the same rigid part follow the same motion. In particular, we present AirDOS, a dynamic object-aware system that introduces rigidity and motion constraints to model articulated objects. By jointly optimizing the camera pose, object motion, and the object 3D structure, we can rectify the camera pose estimation, preventing tracking loss, and generate 4D spatio-temporal maps for both dynamic objects and static scenes. Experiments show that our algorithm improves the robustness of visual SLAM algorithms in challenging crowded urban environments. To the best of our knowledge, AirDOS is the first dynamic object-aware SLAM system demonstrating that camera pose estimation can be improved by incorporating dynamic articulated objects.	https://doi.org/10.1109/ICRA46639.2022.9811667	Yuheng Qiu, Chen Wang, Wenshan Wang, Mina Henein, Sebastian A. Scherer
AirLoop: Lifelong Loop Closure Detection.	Loop closure detection is an important building block that ensures the accuracy and robustness of simultaneous localization and mapping (SLAM) systems. Due to their generalization ability, CNN-based approaches have received increasing attention. Although they normally benefit from training on datasets that are diverse and reflective of the environments, new environments often emerge after the model is deployed. It is therefore desirable to incorporate the data newly collected during operation for incremental learning. Nevertheless, simply finetuning the model on new data is infeasible since it may cause the model's performance on previously learned data to degrade over time, which is also known as the problem of catastrophic forgetting. In this paper, we present AirLoop, a method that leverages techniques from lifelong learning to minimize forgetting when training loop closure detection models incrementally. We experimentally demonstrate the effectiveness of AirLoop on TartanAir, Nordland, and RobotCar datasets. To the best of our knowledge, AirLoop is one of the first works to achieve lifelong learning of deep loop closure detectors.	https://doi.org/10.1109/ICRA46639.2022.9811658	Dasong Gao, Chen Wang, Sebastian A. Scherer
All-in-One: A DRL-based Control Switch Combining State-of-the-art Navigation Planners.	Autonomous navigation of mobile robots is an es-sential aspect in use cases such as delivery, assistance or logistics. Although traditional planning methods are well integrated into existing navigation systems, they struggle in highly dynamic en-vironments. On the other hand, Deep-Reinforcement-Learning-based methods show superior performance in dynamic obstacle avoidance but are not suitable for long-range navigation and struggle with local minima. In this paper, we propose a Deep-Reinforcement-Learning-based control switch, which has the ability to select between different planning paradigms based solely on sensor data observations. Therefore, we develop an interface to efficiently operate multiple model-based, as well as learning-based local planners and integrate a variety of state-of-the-art planners to be selected by the control switch. Subsequently, we evaluate our approach against each planner individually and found improvements in navigation performance especially for highly dynamic scenarios. Our planner was able to prefer learning-based approaches in situations with a high number of obstacles while relying on the traditional model-based planners in long corridors or empty spaces.	https://doi.org/10.1109/ICRA46639.2022.9811797	Linh Kästner, Johannes Cox, Teham Buiyan, Jens Lambrecht
Amplitude Control for Parallel Lattices of Docked Modboats.	The Modboat is a low-cost, underactuated, modular robot capable of surface swimming. It is able to swim individually, dock to other Modboats, and undock from them using only a single motor and two passive flippers. Undocking without additional actuation is achieved by causing intentional self-collision between the tails of neighboring modules; this becomes a challenge when group swimming as one connected component is desirable. In this work, we develop a control strategy to allow parallel lattices of Modboats to swim as a single unit, which conventionally requires holonomic modules. We show that the control strategy is guaranteed to avoid unintentional undocking and minimizes internal forces within the lattice. Experimental verification shows that the controller performs well and is consistent for lattices of various sizes. Controllability is maintained while swimming, but pure yaw control causes lateral movement that cannot be counteracted by the presented framework.	https://doi.org/10.1109/ICRA46639.2022.9812381	Gedaliah Knizhnik, Mark Yim
An Adaptable Approach to Learn Realistic Legged Locomotion without Examples.	Learning controllers that reproduce legged locomotion in nature has been a longtime goal in robotics and computer graphics. While yielding promising results, recent approaches are not yet flexible enough to be applicable to legged systems of different morphologies. This is partly because they often rely on precise motion capture references or elaborate learning environments that ensure the naturality of the emergent locomotion gaits but prevent generalization. This work proposes a generic approach for ensuring realism in locomotion by guiding the learning process with the spring-loaded inverted pendulum model as a reference. Leveraging on the exploration capacities of Reinforcement Learning (RL), we learn a control policy that fills in the information gap between the template model and full-body dynamics required to maintain stable and periodic locomotion. The proposed approach can be applied to robots of different sizes and morphologies and adapted to any RL technique and control architecture. We present experimental results showing that even in a model-free setup and with a simple reactive control architecture, the learned policies can generate realistic and energy-efficient locomotion gaits for a bipedal and a quadrupedal robot. And most importantly, this is achieved without using motion capture, strong constraints in the dynamics or kinematics of the robot, nor prescribing limb coordination. We provide supplemental videos for qualitative analysis of the naturality of the learned gaits4.	https://doi.org/10.1109/ICRA46639.2022.9812441	Daniel Felipe Ordoñez Apraez, Antonio Agudo, Francesc Moreno-Noguer, Mario Martín
An Adaptive PID Autotuner for Multicopters with Experimental Results.	This paper develops an adaptive PID autotuner for multicopters, and presents simulation and experimental results. The autotuner consists of adaptive digital control laws based on retrospective cost adaptive control implemented in the PX4 flight stack. A learning trajectory is used to optimize the autopilot during a single flight. The autotuned autopilot is then compared with the default PX4 autopilot by flying a test trajectory constructed using the second-order Hilbert curve. In order to investigate the sensitivity of the autotuner to the quadcopter dynamics, the mass of the quadcopter is varied, and the performance of the autotuned and default autopilot is compared. It is observed that the autotuned autopilot outperforms the default autopilot.	https://doi.org/10.1109/ICRA46639.2022.9812065	John Spencer, Joonghyun Lee, Juan Augusto Paredes, Ankit Goel, Dennis S. Bernstein
An Agile Bicycle-like Robot for Complex Steel Structure Inspection.	This paper presents a simple but compact design of a bicycle-like robot for inspecting complex-shaped ferromagnetic structures. The design concept for versatile locomotion relies on two independently steered magnetic wheels formed in a bicycle-like configuration, allowing the robot to possess multi-directional mobility. The key feature of a reciprocating mechanism enables the robot to change its shape when passing obstacles. A dynamic joint of the robot configuration makes it naturally adapt to uneven and complex surfaces of steel structures. We demonstrate the usability and practical deployment of the robot for steel thickness measurement using an ultrasonic sensor.	https://doi.org/10.1109/ICRA46639.2022.9812153	Son Thanh Nguyen, Hai Nguyen, Son Tien Bui, Van Anh Ho, Trung Dung Ngo, Hung Manh La
An Assembly Sequence Planning Framework for Complex Data using General Voronoi Diagram.	We present the first realization of an assembly sequence planning framework for large-scale and complex 3D real-world CAD scenarios. Other than in academic benchmark data sets, in our scenario each assembled part is allowed to contain flexible fastening elements and the number of assembled parts is quite high. With our framework we are able to derive a meaningful assembly priority graph for the parts. Our framework divides the disassembly motion of each part into a NEAR- and a subsequent FAR planning phase and uses existing specialized motion planners for each phase. To reduce the number of unsuccessful motion planning requests we use a general Voronoi diagram graph and a novel collision perceiving method which significantly speed up our framework. At the end, we create an assembly priority graph to indicate which parts must be disassembled before others. In our experiments, we show that our framework is the first one which is able to generate a priority graph for a representative data set from the automotive industry. Moreover, the reported disassembly motions for the individual parts are shorter and can be computed faster than with other state-of-the-art frameworks.	https://doi.org/10.1109/ICRA46639.2022.9811867	Sebastian Dorn, Nicola Wolpert, Elmar Schömer
An Experimental Study of Wind Resistance and Power Consumption in MAVs with a Low-Speed Multi-Fan Wind System.	"This paper discusses a low-cost, open-source and open-hardware design and performance evaluation of a low-speed, multi-fan wind system dedicated to micro air vehicle (MAV) testing. In addition, a set of experiments with a flapping wing MAV and rotorcraft is presented, demonstrating the capabilities of the system and the properties of these different types of drones in response to various types of wind. We performed two sets of experiments where a MAV is flying into the wake of the fan system, gathering data about states, battery voltage and current. Firstly, we focus on steady wind conditions with wind speeds ranging from 0.5 m S-1 to 3.4 m S-1. During the second set of experiments, we introduce wind gusts, by periodically modulating the wind speed from 1.3 m S−1 to 3.4 m S−1 with wind gust oscillations of 0.5 Hz, 0.25 Hz and 0.125 Hz. The ""Flapper"" flapping wing MAV requires much larger pitch angles to counter wind than the ""CrazyFlie"" quadrotor. This is due to the Flapper's larger wing surface. In forward flight, its wings do provide extra lift, considerably reducing the power consumption. In contrast, the CrazyFlie's power consumption stays more constant for different wind speeds. The experiments with the varying wind show a quicker gust response by the CrazyFlie compared with the Flapper drone, but both their responses could be further improved. We expect that the proposed wind gust system will provide a useful tool to the community to achieve such improvements."	https://doi.org/10.1109/ICRA46639.2022.9811834	Diana A. Olejnik, Sunyi Wang, Julien Dupeyroux, Stein Stroobants, Matej Karásek, Christophe De Wagter, Guido de Croon
An Indeterministic Vision-Based State Observer for Growing Magnetic Microrobot Motion Status Estimation.	To date, untethered micro/nanorobots have attracted considerable attention in various aspects due to their unique potential for in-vivo applications such as the targeted therapy. One of the most promising types of micro/nanorobots is the class of ferromagnetic microrobots which can be efficiently actuated via gradient/rotational magnetic field generated by less costly electromagnetic coil systems. For performing successful operations, locomotion control of the magnetic microrobots is non-trivial. Modern controllers commonly require motion status-based feedback. To fully utilize those advanced approaches, motion state of one microrobot should be supplied, however it is still challenging in cases. It is noted that, during locomotion, one ferromagnetic microrobot can combine with others to form an unstructured larger one, namely growing magnetic microrobot (GMM), whose dynamic behavior keeps changing, and thus the model-based observers are never applicable. Besides, tracking and estimating states of those unstructured time-varying GMMs in complex surroundings are always challenging, especially for an uneven sampling scenario. In order to accurately estimate the GMM motion status in a complex environment via micro-vision, this study develops an indeterministic observer leveraging on the approach of discriminative correlation filter with channel/spatial reliability (CSR-DCF) and the variable-step finite-time sliding mode (FSM-V) state estimation theory. Experimental study verifies that the proposed observation scheme can effectively estimate motion states of one GMM moving in obstacle surroundings throughout.	https://doi.org/10.1109/ICRA46639.2022.9811375	Zhiyong Sun, Yu Cheng, Chao Zhou, Erkang Cheng, Gengliang Chen, Lixin Dong, Bo Song
An Integrated Design Pipeline for Tactile Sensing Robotic Manipulators.	Traditional robotic manipulator design methods require extensive, time-consuming, and manual trial and error to produce a viable design. During this process, engineers often spend their time redesigning or reshaping components as they discover better topologies for the robotic manipula-tor. Tactile sensors, while useful, often complicate the design due to their bulky form factor. We propose an integrated design pipeline to streamline the design and manufacturing of robotic manipulators with knitted, glove-like tactile sensors. The proposed pipeline allows a designer to assemble a collection of modular, open-source components by applying predefined graph grammar rules. The end result is an intuitive design paradigm that allows the creation of new virtual designs of manipulators in a matter of minutes. Our framework allows the designer to fine-tune the manipulator's shape through cage-based geometry deformation. Finally, the designer can select surfaces for adding tactile sensing. Once the manipulator design is finished, the program will automatically generate 3D printing and knitting files for manufacturing. We demonstrate the utility of this pipeline by creating four custom manipulators tested on real-world tasks: screwing in a wing nut, pouring water from a bottle, picking up an egg, and cutting paper with scissors.	https://doi.org/10.1109/ICRA46639.2022.9812335	Lara Zlokapa, Yiyue Luo, Jie Xu, Michael Foshey, Kui Wu, Pulkit Agrawal, Wojciech Matusik
An MPC Framework For Planning Safe & Trustworthy Robot Motions.	Strategies for safe human-robot interaction (HRI), such as the well-established Safe Motion Unit, provide a velocity scaling for biomechanically safe robot motion. In addition, psychologically-based safety approaches are required for trustworthy HRI. Such schemes can be very conservative and robot motion complying with such safety approaches should be time efficient within the robot motion planning. In this study, we improve the efficiency of a previously introduced approach for psychologically-based safety in HRI via a Model Predictive Control robot motion planner that simultaneously adjusts Cartesian path and speed to minimise the distance to the target pose as fast as possible. A subordinate real-time motion generator ensures human physical safety by integrating the Safe Motion Unit. Our motion planner is validated by two experiments. The simultaneous adjustment of path and velocity accomplishes highly time efficient robot motion, while considering the human physical and psychological safety. Compared to direct path velocity scaling approaches our planner enables 28 % faster motion execution.	https://doi.org/10.1109/ICRA46639.2022.9812160	Moritz Eckhoff, Robin Jeanne Kirschner, Elena Kern, Saeed Abdolshah, Sami Haddadin
An Over-Actuated Bionic Knee Prosthesis: Modeling, Design and Preliminary Experimental Characterization.	A pressing challenge in the design of actuated knee prostheses is the ability to address the high variation of speed and torque requirements for the different types and phases of locomotion. This manuscript presents a novel over-actuated knee prosthesis which makes use of a dual motor actuation architecture to address this issue. It utilizes a high speed/low torque motor to enable natural and highly dynamical motion, as required for swing phases of walking, which is permanently engaged. In addition to this motor, a clutchable uni-directional low dynamics high torque motor is present to assist during the execution of tasks which demand active torque. Preliminary experimental validations have been performed on a healthy subject provided with an able-bodied adapter to demonstrate natural walk patterns and power-assisted sit-to-stand activities.	https://doi.org/10.1109/ICRA46639.2022.9812197	Lorenzo Guercini, Federico Tessari, Josephus Driessen, Stefano Buccelli, Anna Pace, Samuele De Giuseppe, Simone Traverso, Lorenzo De Michieli, Matteo Laffranchi
An in-depth experimental study of sensor usage and visual reasoning of robots navigating in real environments.	Visual navigation by mobile robots is classically tackled through SLAM plus optimal planning, and more recently through end-to-end training of policies implemented as deep networks. While the former are often limited to waypoint planning, but have proven their efficiency even on real physical environments, the latter solutions are most frequently employed in simulation, but have been shown to be able learn more complex visual reasoning, involving complex semantic regularities. Navigation by real robots in physical environments is still an open problem. End-to-end training approaches have been thoroughly tested in simulation only, with experiments involving real robots being restricted to rare performance evaluations in simplified laboratory conditions. In this work we present an in-depth study of the performance and reasoning capacities of real physical agents, trained in simulation and deployed to two different physical environments. Beyond benchmarking, we provide insights into the generalization capabilities of different agents training in different conditions. We visualize sensor usage and the importance of the different types of signals. We show, that for the PointGoal task, an agent pre-trained on wide variety of tasks and fine-tuned on a simulated version of the target environment can reach competitive performance without modelling any sim2real transfer, i.e. by deploying the trained agent directly from simulation to a real physical robot.	https://doi.org/10.1109/ICRA46639.2022.9811833	Assem Sadek, Guillaume Bono, Boris Chidlovskii, Christian Wolf
An observer cascade for velocity and multiple line estimation.	Previous incremental estimation methods consider estimating a single line, requiring as many observers as the number of lines to be mapped. This leads to the need for having at least 4N state variables, with N being the number of lines. This paper presents the first approach for multi-line incremental estimation. Since lines are common in structured environments, we aim to exploit that structure to reduce the state space. The modeling of structured environments proposed in this paper reduces the state space to 3N + 3 and is also less susceptible to singular configurations. An assumption the previous methods make is that the camera velocity is available at all times. However, the velocity is usually retrieved from odometry, which is noisy. With this in mind, we propose coupling the camera with an Inertial Measurement Unit (IMU) and an observer cascade. A first observer retrieves the scale of the linear velocity and a second observer for the lines mapping. The stability of the entire system is analyzed. The cascade is shown to be asymptotically stable and shown to converge in experiments with simulated data.	https://doi.org/10.1109/ICRA46639.2022.9812292	André Mateus, Pedro U. Lima, Pedro Miraldo
Analyzing Multiagent Interactions in Traffic Scenes via Topological Braids.	We focus on the problem of analyzing multiagent interactions in traffic domains. Understanding the space of behavior of real-world traffic may offer significant advantages for algorithmic design, data-driven methodologies, and bench-marking. However, the high dimensionality of the space and the stochasticity of human behavior may hinder the identification of important interaction patterns. Our key insight is that traffic environments feature significant geometric and temporal structure, leading to highly organized collective behaviors, often drawn from a small set of dominant modes. In this work, we propose a representation based on the formalism of topological braids that can summarize arbitrarily complex multiagent behavior into a compact object of dual geometric and symbolic nature, capturing critical events of interaction. This representation allows us to formally enumerate the space of outcomes in a traffic scene and characterize their complexity. We illustrate the value of the proposed representation in summarizing critical aspects of real-world traffic behavior through a case study on recent driving datasets. We show that despite the density of real-world traffic, observed behavior tends to follow highly organized patterns of low interaction. Our framework may be a valuable tool for evaluating the richness of driving datasets, but also for synthetically designing balanced training datasets or benchmarks.	https://doi.org/10.1109/ICRA46639.2022.9812118	Christoforos I. Mavrogiannis, Jonathan A. DeCastro, Siddhartha S. Srinivasa
Anti-collision Static Rotation Local Planner for Four Independent Steering Drive Self-reconfigurable Robot.	Pavement cleaning is a labor-intensive, repetitive task and can be automated. Several autonomous pavement cleaning robots have been developed, pushing research towards their design and autonomous capabilities. Advances in design have been reported in earlier works on a self-reconfigurable robot with four independent steering drive (4ISD) capabilities, Panthera, for pavement cleaning and maintenance. Moreover, autonomous navigation requires sharp turns, heading angle adjustments, sideways movement, and locomotion without col-lision through constrained pavement conditions. The present work proposes an algorithm to ingeniously select the instan-taneous center of rotation (ICR) within the self-reconfigurable robot footprint and perform static rotation to adjust its heading angle during the waypoint navigation while avoiding collision with the constrained environment. Finally, the proposed algorithm is implemented, and experiments are conducted in real-world pavement scenarios. The experimental outcome success-fully demonstrates the self-reconfigurable robot's capability to navigate constrained pavement scenarios using the proposed algorithm during autonomous cleaning and maintenance tasks.	https://doi.org/10.1109/ICRA46639.2022.9812445	Lim Yi, Anh Vu Le, Abdullah Aamir Hayat, Karthikeyan Elangovan, K. Leong, A. P. Povendhan, Mohan Rajesh Elara
Approximating the Polynomial System for Effective Relative Pose Estimation.	Finding relative pose for cameras is of vital importance in computer vision and robotics. We investigate the problem of relative motion estimation between successive frames from a minimal number of correspondences. Existing approximated methods use a first-order approximation to relative pose in order to simplify the problem and produce an estimate quickly. Our solution uses Cayley parameterization to represent rotation and simplifies the high-degree polynomials only at the very end of the formulation, resulting in more accurate models. Furthermore, our method can be more effective if the camera rotates mainly around one coordinate axis. By treating the main rotation component as the hidden variable in the solution, we can retain more high-degree terms for the main rotation part, considerably widening the effective approximation range. Our experiments show that our method is more accurate than existing approximated solver, and that it is still effective for relatively large motions. Besides, our method produces far fewer solutions than essential matrix parameterized solvers.	https://doi.org/10.1109/ICRA46639.2022.9811709	Deshun Hu
Assisting Operators of Articulated Machinery with Optimal Planning and Goal Inference.	Operating an articulated machine is a complex and hierarchical task, involving several levels of decision making. Motivated by the timber-harvesting applications of these machines, we are interested in developing a collaborative framework for operating an articulated machine/robot in order to increase its level of autonomy. In this paper, we consider two problems in the context of collaborative operation of a feller-buncher: first, the problem of planning a sequence of cut/grasp/bunch tasks for the trees in the vicinity of the machine. Here we propose a human-inspired planning algorithm based on our observations of the operators in the field. Then, a Markov Decision Process (MDP) framework is provided, which enables us to obtain an optimal sequence of tasks. We provide numerical illustrations of how our MDP framework works. Second is the problem of inferring the operator's goal from the motions of the machine. The goal inference algorithm presented here enables the robot equipped with the planning intelligence to perceive the human's intent in real-time. We evaluate the performance of our goal inference algorithm through a user-study with a feller-buncher simulator. The results show the benefits of our algorithm over a robot that assumes the human is moving to the closest target.	https://doi.org/10.1109/ICRA46639.2022.9811864	Ehsan Yousefi, Dylan P. Losey, Inna Sharf
AstroLoc: An Efficient and Robust Localizer for a Free-flying Robot.	We present AstroLoc, an efficient and robust monocular visual-inertial graph-based localization system used by the Astrobee free-flying robots onboard the International Space Station (ISS). We provide a novel localization system that limits the traditionally higher computation times for graph-based localization systems and enables the resource constrained Astrobee robots to benefit from their increased accuracy. We also introduce methods for handling cheirality issues for visual odometry and localization factors that further increase localization robustness. We evaluate the performance of AstroLoc on a dataset of ISS activities and show that it greatly improves pose, velocity, and IMU bias estimation accuracy while efficiently running in a limited computation environment. AstroLoc has improved the localization accuracy for the Astrobee robots on the ISS and has led to more successful and longer duration activities. While the AstroLoc system is tuned for the Astrobee robots, it can be configured for any resource constrained platform. The source code for AstroLoc is released to the public.	https://doi.org/10.1109/ICRA46639.2022.9811919	Ryan Soussan, Varsha Kumar, Brian Coltin, Trey Smith
Asynchronous Collaborative Localization by Integrating Spatiotemporal Graph Learning with Model-Based Estimation.	Collaborative localization is an essential capability for a team of robots such as connected vehicles to collaboratively estimate object locations from multiple perspectives with reliant cooperation. To enable collaborative localization, four key challenges must be addressed, including modeling complex relationships between observed objects, fusing observations from an arbitrary number of collaborating robots, quantifying localization uncertainty, and addressing latency of robot communications. In this paper, we introduce a novel approach that integrates uncertainty-aware spatiotemporal graph learning and model-based state estimation for a team of robots to collaboratively localize objects. Specifically, we introduce a new uncertainty-aware graph learning model that learns spatiotemporal graphs to represent historical motions of the objects observed by each robot over time and provides uncertainties in object localization. Moreover, we propose a novel method for integrated learning and model-based state estimation, which fuses asynchronous observations obtained from an arbitrary number of robots for collaborative localization. We evaluate our approach in two collaborative object localization scenarios in simulations and on real robots. Experimental results show that our approach outperforms previous methods and achieves state-of-the-art performance on asynchronous collaborative localization.	https://doi.org/10.1109/ICRA46639.2022.9811613	Peng Gao, Brian Reily, Rui Guo, Hongsheng Lu, Qingzhao Zhu, Hao Zhang
Asynchronous Optimisation for Event-based Visual Odometry.	Event cameras open up new possibilities for robotic perception due to their low latency and high dynamic range. On the other hand, developing effective event-based vision algorithms that fully exploit the beneficial properties of event cameras remains work in progress. In this paper, we focus on event-based visual odometry (VO). While existing event-driven VO pipelines have adopted continuous-time representations to asynchronously process event data, they either assume a known map, restrict the camera to planar trajectories, or integrate other sensors into the system. Towards map-free event-only monocular VO in SE(3), we propose an asynchronous structure-from-motion optimisation back-end. Our formulation is underpinned by a principled joint optimisation problem involving non-parametric Gaussian Process motion modelling and incremental maximum a posteriori inference. A high-performance incremental computation engine is employed to reason about the camera trajectory with every incoming event. We demonstrate the robustness of our asynchronous back-end in comparison to frame-based methods which depend on accurate temporal accumulation of measurements.	https://doi.org/10.1109/ICRA46639.2022.9811943	Daqi Liu, Álvaro Parra, Yasir Latif, Bo Chen, Tat-Jun Chin, Ian D. Reid
Asynchronous Reinforcement Learning for Real-Time Control of Physical Robots.	An oft-ignored challenge of real-world reinforcement learning is that the real world does not pause when agents make learning updates. As standard simulated environments do not address this real-time aspect of learning, most available implementations of RL algorithms process environment interactions and learning updates sequentially. As a consequence, when such implementations are deployed in the real world, they may make decisions based on significantly delayed observations and not act responsively. Asynchronous learning has been proposed to solve this issue, but no systematic comparison between sequential and asynchronous reinforcement learning was conducted using real-world environments. In this work, we set up two vision-based tasks with a robotic arm, implement an asynchronous learning system that extends a previous architecture, and compare sequential and asynchronous reinforcement learning across different action cycle times, sensory data dimensions, and mini-batch sizes. Our experiments show that when the time cost of learning updates increases, the action cycle time in sequential implementation could grow excessively long, while the asynchronous implementation can always maintain an appropriate action cycle time. Consequently, when learning updates are expensive, the performance of sequential learning diminishes and is outperformed by asynchronous learning by a substantial margin. Our system learns in real-time to reach and track visual targets from pixels within two hours of experience and does so directly using real robots, learning completely from scratch. Our code is available at: https://github.com/YufengYuan/ur5_async_r1.	https://doi.org/10.1109/ICRA46639.2022.9811771	Yufeng Yuan, A. Rupam Mahmood
Attentive One-Shot Meta-Imitation Learning From Visual Demonstration.	The ability to apply a previously-learned skill (e.g., pushing) to a new task (context or object) is an important requirement for new-age robots. An attempt is made to solve this problem in this paper by proposing a deep meta-imitation learning framework comprising of an attentive-embedding net-work and a control network, capable of learning a new task in an end-to-end manner while requiring only one or a few visual demonstrations. The feature embeddings learnt by incorporating spatial attention is shown to provide higher embedding and control accuracy compared to other state-of-the-art methods such as TecNet [7] and MIL [4]. The interaction between the embedding and the control networks is improved by using multiplicative skip-connections and is shown to overcome the overfitting of the trained model. The superiority of the proposed model is established through rigorous experimentation using a publicly available dataset and a new dataset created using PyBullet [36]. Several ablation studies have been carried out to justify the design choices.	https://doi.org/10.1109/ICRA46639.2022.9812281	Vishal Bhutani, Anima Majumder, Madhu Babu Vankadari, Samrat Dutta, Aaditya Asati, Swagat Kumar
Audio-Visual Grounding Referring Expression for Robotic Manipulation.	Referring expressions are commonly used when referring to a specific target in people's daily dialogue. In this paper, we develop a novel task of audio-visual grounding referring expression for robotic manipulation. The robot leverages both the audio and visual information to understand the referring expression in the given manipulation instruction and the corresponding manipulations are implemented. To solve the proposed task, an audio-visual framework is proposed for visual localization and sound recognition. We have also established a dataset which contains visual data, auditory data and manipulation instructions for evaluation. Finally, extensive experiments are conducted both offline and online to verify the effectiveness of the proposed audio-visual framework. And it is demonstrated that the robot performs better with the audio-visual data than with only the visual data.	https://doi.org/10.1109/ICRA46639.2022.9811895	Yefei Wang, Kaili Wang, Yi Wang, Di Guo, Huaping Liu, Fuchun Sun
Augmented Pointing Gesture Estimation for Human-Robot Interaction.	With recent advancements in CV (computer vision) and AI (Artificial Intelligence) technologies, pointing gesture is becoming an emerging trend for human-robot interaction. Its intuitive and deictic nature makes it an ideal way for giving commands, especially referring spatial information to the robots. In this paper, we propose an augmented pointing gesture estimation method to enable richer and programmable instructions to be given to the robots. We propose five pointing gestures and demonstrate the idea using a collaborative robot with a multi-finger robotic gripper. Experiments are designed and conducted to test the pointing accuracy in space and in gesture estimation. The results show that our proposed method can achieve a mean drift of 8.3 cm and an estimation accuracy of 94.08%.	https://doi.org/10.1109/ICRA46639.2022.9811617	Zhixian Hu, Yingtian Xu, Waner Lin, Ziya Wang, Zhenglong Sun
Augmenting Imitation Experience via Equivariant Representations.	The robustness of visual navigation policies trained through imitation often hinges on the augmentation of the training image-action pairs. Traditionally, this has been done by collecting data from multiple cameras, by using standard data augmentations from computer vision, such as adding random noise to each image, or by synthesizing training images. In this paper we show that there is another practical alternative for data augmentation for visual navigation based on extrapolating viewpoint embeddings and actions nearby the ones observed in the training data. Our method makes use of the geometry of the visual navigation problem in 2D and 3D and relies on policies that are functions of equivariant embeddings, as opposed to images. Given an image-action pair from a training navigation dataset, our neural network model predicts the latent representations of images at nearby viewpoints, using the equivariance property, and augments the dataset. We then train a policy on the augmented dataset. Our simulation results indicate that policies trained in this way exhibit reduced cross-track error, and require fewer interventions compared to policies trained using standard augmentation methods. We also show similar results in autonomous visual navigation by a real ground robot along a path of over 500m.	https://doi.org/10.1109/ICRA46639.2022.9811885	Dhruv Sharma, Alihusein Kuwajerwala, Florian Shkurti
Augmenting Reinforcement Learning with Behavior Primitives for Diverse Manipulation Tasks.	Realistic manipulation tasks require a robot to interact with an environment with a prolonged sequence of motor actions. While deep reinforcement learning methods have recently emerged as a promising paradigm for automating manipulation behaviors, they usually fall short in long-horizon tasks due to the exploration burden. This work introduces Manipulation Primitive-augmented reinforcement Learning (MAPLE), a learning framework that augments standard reinforcement learning algorithms with a pre-defined library of behavior primitives. These behavior primitives are robust functional modules specialized in achieving manipulation goals, such as grasping and pushing. To use these heterogeneous primitives, we develop a hierarchical policy that involves the primitives and instantiates their executions with input parameters. We demonstrate that MAPLE out-performs baseline approaches by a significant margin on a suite of simulated manipulation tasks. We also quantify the compositional structure of the learned behaviors and highlight our method's ability to transfer policies to new task variants and to physical hardware. Videos and code are available at https://ut-austin-rpl.github.io/maple	https://doi.org/10.1109/ICRA46639.2022.9812140	Soroush Nasiriany, Huihan Liu, Yuke Zhu
AutoPlace: Robust Place Recognition with Single-chip Automotive Radar.	This paper presents a novel place recognition approach to autonomous vehicles by using low-cost, single-chip automotive radar. Aimed at improving recognition robustness and fully exploiting the rich information provided by this emerging automotive radar, our approach follows a principled pipeline that comprises (1) dynamic points removal from instant Doppler measurement, (2) spatial-temporal feature embedding on radar point clouds, and (3) retrieved candidates refinement from Radar Cross Section measurement. Extensive experimental results on the public nuScenes dataset demonstrate that existing visual/LiDAR/spinning radar place recognition approaches are less suitable for single-chip automotive radar. In contrast, our purpose-built approach for automotive radar consistently outperforms a variety of baseline methods via a comprehensive set of metrics, providing insights into the efficacy when used in a realistic system.	https://doi.org/10.1109/ICRA46639.2022.9811869	Kaiwen Cai, Bing Wang, Chris Xiaoxuan Lu
Automated Linear and Non-Linear Path Planning for Neurosurgical Interventions.	Recent advances in medical technology have produced a number of flexible instruments that are capable of traversing non-linear paths. This is of special interest in the field of neurosurgery. However, the non-rigid instruments have the disadvantage that path planning becomes increasingly difficult. In addition to anatomical risk factors, the mechanical properties and constraints of the specific instrument must also be considered. To support surgeons to deal with the increase in planning complexity, we present a novel method for both linear and arbitrary follow-the-leader flexible path planning. Our method is utilizing patient-specific image data, which is then used to generate a multi-objective problem consisting of conventional risk metrics for path planning in high-risk regions like the accumulated path cost or the distance to risk structures. Simultaneously, the path-problem is also constraint to mechanical properties of the instrument such as curvature or maximum operational length. Optimal paths can then be generated by solving a multi-objective problem by approximating the Pareto front. We show that our method can automatically generate linear and non-linear paths for neurosurgical interventions in the human brain in less than 2 minutes. Furthermore, we show that the proposed automated method generates paths with 87% reduced risk compared to standard of care plannings.	https://doi.org/10.1109/ICRA46639.2022.9811679	Steffen Peikert, Christian Kunz, Nikola Fischer, Michal Hlavác, Andrej Pala, Max Schneider, Franziska Mathis-Ullrich
Automated Task Updates of Temporal Logic Specifications for Heterogeneous Robots.	Given a heterogeneous group of robots executing a complex task represented in Linear Temporal Logic, and a new set of tasks for the group, we define the task update problem and propose a framework for automatically updating individual robot tasks given their respective existing tasks and capabilities. Our heuristic, token-based, conflict resolution task allocation algorithm generates a near-optimal assignment for the new task. We demonstrate the scalability of our approach through simulations of multi-robot tasks.	https://doi.org/10.1109/ICRA46639.2022.9812045	Amy Fang, Hadas Kress-Gazit
Automated Testing With Temporal Logic Specifications for Robotic Controllers Using Adaptive Experiment Design.	"Many robot control scenarios involve assessing system robustness against a task specification. If either the controller or environment are composed of ""black-box"" components with unknown dynamics, we cannot rely on formal verification to assess our system. Assessing robustness via exhaustive testing is also often infeasible if the number of possible environments is large compared to experiment cost. Given limited budget, we provide a method to choose experiment inputs which accurately reflect how robustly a system satisfies a given specification across the domain. By combining signal temporal logic metrics with adaptive experiment design, our method chooses each experiment by incrementally constructing a surrogate model of the specification robustness. This model then chooses experiments in areas of either high prediction error or high uncertainty. Our evaluation shows how this adaptive experiment design results in sample-efficient descriptions of system robustness. Further, we show how to use the constructed surrogate model to assess the behaviour of a data-driven control system under domain shift."	https://doi.org/10.1109/ICRA46639.2022.9811579	Craig Innes, Subramanian Ramamoorthy
Automatic Acquisition of a Repertoire of Diverse Grasping Trajectories through Behavior Shaping and Novelty Search.	Grasping a particular object may require a dedicated grasping movement that may also be specific to the robot end-effector. No generic and autonomous method does exist to generate these movements without making hypotheses on the robot or on the object. Learning methods could help to autonomously discover relevant grasping movements, but they face an important issue: grasping movements are so rare that a learning method based on exploration has little chance to ever observe an interesting movement, thus creating a bootstrap issue. We introduce an approach to generate diverse grasping movements in order to solve this problem. The movements are generated in simulation, for particular object positions. We test it on several simulated robots: Baxter, Pepper and a Kuka Iiwa arm. Although we show that generated movements actually work on a real Baxter robot, the aim is to use this method to create a large dataset to bootstrap deep learning methods.	https://doi.org/10.1109/ICRA46639.2022.9811837	Aurélien Morel, Yakumo Kunimoto, Alexandre Coninx, Stéphane Doncieux
Automatic Biopsy Tool Presence and Episode Recognition in Robotic Bronchoscopy Using a Multi-Task Vision Transformer Network.	Automatic recognition of surgical workflow is a growing area of interest with significant potential to become part of context-aware decision-support systems in future enhanced ORs and clinical suites. Applications range from post-operative analysis to intra-operative monitoring to providing automated assistance to the clinical staff. This work proposes, for the first time, automatic tool presence and episodes recognition in bronchoscopy images, using a newly annotated video dataset obtained from robotic bronchoscopy procedures. A novel multi-task architecture that utilizes Vision Transformers for the episode recognition task is used to achieve improved accuracy while reducing the computational burden during the training stage. The method is thoroughly validated on clinical procedure video data obtained across 135 procedures, displaying improved performance and training times compared to various state-of-the-art methods.	https://doi.org/10.1109/ICRA46639.2022.9811982	Mingyi Zheng, Menglong Ye, Hedyeh Rafii-Tari
Automatic Classification and Disassembly of Fasteners in Industrial 3D CAD-Scenarios.	The automatic generation of (dis)assembly sequences for complex technical products is a challenging field. Complex products like vehicles consist of numerous different components. Determining the sequence using a brute-force-approach by testing all components for disassembly one after another in a loop until all components are disassembled is laborious and costly. In industrial scenarios, a large proportion of the components are fasteners. In this paper, we propose a new framework which improves the disassembly sequencing generation by prioritizing fasteners during planning. Our proposed framework comprises a preprocessing in which fasteners are identified with a convolutional neural network within a dataset and a procedure that preferentially and automatically checks fasteners for disassembly. The algorithm takes initial and unavoidable collisions of the fasteners into account. We show the effectiveness of our approach on real-world data from the automotive industry. A new synthetic dataset of fasteners for training neural networks is available.	https://doi.org/10.1109/ICRA46639.2022.9811539	Michele Franco Adesso, Robert Hegewald, Nicola Wolpert, Elmar Schömer, Bianca Maier, Benjamin A. Epple
Autonomous Actuation of Flapping Wing Robots Inspired by Asynchronous Insect Muscle.	"In most instances, flapping wing robots have emulated the ""synchronous"" actuation of insects in which the wingbeat timing is generated from a time-dependent, rhythmic signal. The internal dynamics of asynchronous insect flight muscle enable high-frequency, adaptive wingbeats with minimal direct neural control. In this paper, we investigate how the delayed stretch-activation (dSA) response of asynchronous insect flight muscle can be transformed into a feedback control law for flapping wing robots that results in stable limit cycle wingbeats. We first demonstrate - in theory and simulation - the mechanism by which asynchronous wingbeats self-excite. Then, we implement the feedback law on a dynamically-scaled robophysical model as well as on an insect-scale robotic flapping wing. Experiments on large- and small-scale robots demonstrate good agreement with the theory results and highlight how dSA parameters govern wingbeat amplitude and frequency. Lastly, we demonstrate that asynchronous actuation has several advantages over synchronous actuation schemes, including the ability to rapidly adapt or halt wingbeats in response to external loads or collisions through low-level feedback control."	https://doi.org/10.1109/ICRA46639.2022.9812028	James Lynch, Jeff Gau, Simon Sponberg, Nick Gravish
Autonomous Exploration Development Environment and the Planning Algorithms.	Autonomous Exploration Development Environment is an open-source repository released to facilitate development of high-level planning algorithms and integration of com-plete autonomous navigation systems. The repository contains representative simulation environment models, fundamental navigation modules, e.g., local planner, terrain traversability analysis, waypoint following, and visualization tools. Together with two of our high-level planner releases - TARE planner for exploration and FAR planner for route planning, we detail usage of the three open-source repositories and share experiences in integration of autonomous navigation systems. We use DARPA Subterranean Challenge as a use case where the repositories together form the main navigation system of the CMU-OSU Team. In the end, we discuss a few potential use cases in extended applications.	https://doi.org/10.1109/ICRA46639.2022.9812330	Chao Cao, Hongbiao Zhu, Fan Yang, Yukun Xia, Howie Choset, Jean Oh, Ji Zhang
Autonomous Racing with Multiple Vehicles using a Parallelized Optimization with Safety Guarantee using Control Barrier Functions.	This paper presents a novel planning and control strategy for competing with multiple vehicles in a car racing scenario. The proposed racing strategy switches between two modes. When there are no surrounding vehicles, a learning-based model predictive control (MPC) trajectory planner is used to guarantee that the ego vehicle achieves better lap timing performance. When the ego vehicle is competing with other surrounding vehicles to overtake, an optimization-based planner generates multiple dynamically-feasible trajectories through parallel computation. Each trajectory is optimized under a MPC formulation with different homotopic Bezier-curve reference paths lying laterally between surrounding vehicles. The time-optimal trajectory among these different homotopic trajectories is selected and a low-level MPC controller with control barrier function constraints for obstacle avoidance is used to guarantee the system's safety-critical performance. The proposed algorithm has the capability to generate collision-free trajectories and track them while enhancing the lap timing performance with steady low computational complexity, outper-forming existing approaches in both timing and performance for an autonomous racing environment. To demonstrate the performance of our racing strategy, we simulate with multiple randomly generated moving vehicles on the track and test the ego vehicle's overtaking maneuvers.	https://doi.org/10.1109/ICRA46639.2022.9811969	Suiyi He, Jun Zeng, Koushil Sreenath
Autonomous Teamed Exploration of Subterranean Environments using Legged and Aerial Robots.	This paper presents a novel strategy for autonomous teamed exploration of subterranean environments using legged and aerial robots. Tailored to the fact that subterranean settings, such as cave networks and underground mines, often involve complex, large-scale and multi-branched topologies, while wireless communication within them can be particularly challenging, this work is structured around the synergy of an onboard exploration path planner that allows for resilient long-term autonomy, and a multi-robot coordination framework. The onboard path planner is unified across legged and flying robots and enables navigation in environments with steep slopes, and diverse geometries. When a communication link is available, each robot of the team shares submaps to a centralized location where a multi-robot coordination framework identifies global frontiers of the exploration space to inform each system about where it should re-position to best continue its mission. The strategy is verified through a field deployment inside an underground mine in Switzerland using a legged and a flying robot collectively exploring for 45 min, as well as a longer simulation study with three systems.	https://doi.org/10.1109/ICRA46639.2022.9812401	Mihir Kulkarni, Mihir Dharmadhikari, Marco Tranzatto, Samuel Zimmermann, Victor Reijgwart, Paolo De Petris, Huan Nguyen, Nikhil Khedekar, Christos Papachristos, Lionel Ott, Roland Siegwart, Marco Hutter, Kostas Alexis
Autonomous Ultrasound Scanning using Bayesian Optimization and Hybrid Force Control.	Ultrasound scanning is an imaging technique that aids medical professionals in diagnostics and interventional procedures. However, a trained human-in-the-loop (HITL) with a radiologist is required to perform the scanning procedure. We seek to create a novel ultrasound system that can provide imaging in the absence of a trained radiologist, say for patients in the field who suffered injuries after a natural disaster. One challenge of automating ultrasound scanning involves finding the optimal area to scan and then performing the actual scan. This task requires simultaneously maintaining contact with the surface while moving along it to capture high quality images. In this work, we present an automated Robotic Ultrasound System (RUS) to tackle these challenges. Our approach introduces a Bayesian Optimization framework to guide the probe to multiple points on the unknown surface. Our proposed framework collects the ultrasound images as well as the pose information at every probed point to estimate regions with high vessel density (information map) and the surface contour. Based on the information map and the surface contour, an area of interest is selected for scanning. Furthermore, to scan the proposed region, a novel 6-axis hybrid force-position controller is presented to ensure acoustic coupling. Lastly, we provide experimental results on two different phantom models to corroborate our approach.	https://doi.org/10.1109/ICRA46639.2022.9812410	Raghavv Goel, Abhimanyu, Kirtan Patel, John M. Galeotti, Howie Choset
Autonomous Vehicle Parking in Dynamic Environments: An Integrated System with Prediction and Motion Planning.	This paper presents an integrated motion planning system for autonomous vehicle (AV) parking in the presence of other moving vehicles. The proposed system includes 1) a hybrid environment predictor that predicts the motions of the surrounding vehicles and 2) a strategic motion planner that reacts to the predictions. The hybrid environment predictor performs short-term predictions via an extended Kalman filter and an adaptive observer. It also combines short-term predictions with a driver behavior cost-map to make long-term predictions. The strategic motion planner comprises 1) a model predictive control-based safety controller for trajectory tracking; 2) a search-based retreating planner for finding an evasion path in an emergency; 3) an optimization-based repairing planner for planning a new path when the original path is invalidated. Simulation validation demonstrates the effectiveness of the proposed method in terms of initial planning, motion prediction, safe tracking, retreating in an emergency, and trajectory repairing.	https://doi.org/10.1109/ICRA46639.2022.9812309	Jessica EnShiuan Leu, Yebin Wang, Masayoshi Tomizuka, Stefano Di Cairano
Autonomy and Perception for Space Mining.	Future Moon bases will likely be constructed using resources mined from the surface of the Moon. The difficulty of maintaining a human workforce on the Moon and communications lag with Earth means that mining will need to be conducted using collaborative robots with a high degree of autonomy. In this paper, we describe our solution for Phase 2 of the NASA Space Robotics Challenge, which provided a simulated lunar environment in which teams were tasked to develop software systems to achieve autonomous collaborative robots for mining on the Moon. Our 3rd place and innovation award winning solution shows how machine learning-enabled vision could alleviate major challenges posed by the lunar environment towards autonomous space mining, chiefly the lack of satellite positioning systems, hazardous terrain, and delicate robot interactions. A robust multi-robot coordinator was also developed to achieve long-term operation and effective collaboration between robots11A recording of our robots in action is available at [1]..	https://doi.org/10.1109/ICRA46639.2022.9811661	Ragav Sachdeva, Ravi Hammond, James Bockman, Alec Arthur, Brandon Smart, Dustin Craggs, Anh-Dzung Doan, Thomas Rowntree, Elijah Schutz, Adrian Orenstein, Andy Yu, Tat-Jun Chin, Ian D. Reid
BAANet: Learning Bi-directional Adaptive Attention Gates for Multispectral Pedestrian Detection.	Thermal infrared (TIR) image has proven effectiveness in providing temperature cues to the RGB features for multispectral pedestrian detection. Most existing methods directly inject the TIR modality into the RGB-based framework or simply ensemble the results of two modalities. This, however, could lead to inferior detection performance, as the RGB and TIR features generally have modality-specific noise, which might worsen the features along with the propagation of the network. Therefore, this work proposes an effective and efficient cross-modality fusion module called Bi-directional Adaptive Attention Gate (BAA-Gate). Based on the attention mechanism, the BAA-Gate is devised to distill the informative features and recalibrate the representations asymptotically. Concretely, a bi-direction multi-stage fusion strategy is adopted to progressively optimize features of two modalities and retain their specificity during the propagation. Moreover, an adaptive interaction of BAA-Gate is introduced by the illumination-based weighting strategy to adaptively adjust the recalibrating and aggregating strength in the BAA-Gate and enhance the robustness towards illumination changes. Considerable experiments on the challenging KAIST dataset demonstrate the superior performance of our method with satisfactory speed.	https://doi.org/10.1109/ICRA46639.2022.9811999	Xiaoxiao Yang, Yeqiang Qian, Huijie Zhu, Chunxiang Wang, Ming Yang
Back to the Future: Efficient, Time-Consistent Solutions in Reach-Avoid Games.	We study the class of reach-avoid dynamic games in which multiple agents interact noncooperatively, and each wishes to satisfy a distinct target criterion while avoiding a failure criterion. Reach-avoid games are commonly used to express safety-critical optimal control problems found in mobile robot motion planning. Here, we focus on finding time-consistent solutions, in which future motion plans remain optimal even when a robot diverges from the plan early on due to, e.g., intrinsic dynamic uncertainty or extrinsic environment disturbances. Our main contribution is a computationally-efficient algorithm for multi-agent reach-avoid games which renders time-consistent solutions for all players. We demonstrate our approach in two- and three-player simulated driving scenarios, in which our method provides safe control strategies for all agents.	https://doi.org/10.1109/ICRA46639.2022.9812243	Dennis R. Anthony, Duy Phuong Nguyen, David Fridovich-Keil, Jaime F. Fisac
Balancing Efficiency and Comfort in Robot-Assisted Bite Transfer.	Robot-assisted feeding in household environments is challenging because it requires robots to generate trajectories that effectively bring food items of varying shapes and sizes into the mouth while making sure the user is comfortable. Our key insight is that in order to solve this challenge, robots must balance the efficiency of feeding a food item with the comfort of each individual bite. We formalize comfort and efficiency as heuristics to incorporate in motion planning. We present an approach based on heuristics-guided bi-directional Rapidly-exploring Random Trees (h-BiRRT) that selects bite transfer trajectories of arbitrary food item geometries and shapes using our developed bite efficiency and comfort heuristics and a learned constraint model. Real-robot evaluations show that op-timizing both comfort and efficiency significantly outperforms a fixed-pose based method, and users preferred our method significantly more than that of a method that maximizes only user comfort. Videos and Appendices are found on our website: https://tinyurl.com/bticra22.	https://doi.org/10.1109/ICRA46639.2022.9812332	Suneel Belkhale, Ethan K. Gordon, Yuxiao Chen, Siddhartha S. Srinivasa, Tapomayukh Bhattacharjee, Dorsa Sadigh
Bang-bang Control with Constant Thrust of a Spherical Blimp Propelled by Ultrasound Beam.	Ultrasound beam propulsion, a propulsion system that uses airborne ultrasound phased arrays (AUPAs) to propel a blimp in an indoor environment to propel a blimp, has advantages for operations near humans such as no audible noises and no risk of propeller strike. To achieve the high mobility with limited actuation force of AUPAs, the dynamics should be fully exploited. In this paper, we propose a two-degree-of-freedom controller specifically tailored for ultrasound beam propulsion. We investigate the trajectory of bang-bang control with constant thrust (BBCT control), where a blimp accelerates and then decelerates with constant thrust reaching the terminal point at rest, as one of the most basic trajectories. First, we analytically derive the trajectory of a blimp under aerodynamic drag. Then, we provide a trajectory generator that derives the maximum constant thrust for an arrangement of AUPAs and the constraints on the control input. Finally, we integrate the trajectory generator and a PID-based feedback controller in a physical setup. We evaluated the proposed controller in physical and numerical experiments. The results showed that the proposed method allows a blimp to reach the terminal point almost in expected time. We also showed that the flight time is shorter than a PID-based one-degree-of-freedom controller, which was typically used in previous studies, by 19.0 − 43.2 %.	https://doi.org/10.1109/ICRA46639.2022.9812012	Takuro Furumoto, Masahiro Fujiwara, Yasutoshi Makino, Hiroyuki Shinoda
Barrier Forming: Separating Polygonal Sets with Minimum Number of Lines.	In this work, we carry out structural and al-gorithmic studies of a problem of barrier forming: selecting the minimum number of straight line segments (barriers) that separate several sets of mutually disjoint objects in the plane. The problem models the optimal placement of line sensors (e.g., infrared laser beams) for isolating many types of regions in a pair- wise manner for practical purposes (e.g., guarding against intrusions). The problem is NP-hard even if we want to find the minimum number of lines to separate two sets of points in the plane. Under the umbrella problem of barrier forming with minimum number of line segments, three settings are examined: barrier forming for point sets, point sets with polygonal obstacles, polygonal sets with polygonal obstacles. We describe methods for computing the optimal solution for the first two settings with the assistance of mathematical programming, and provide a 2-OPT solution for the third. We demonstrate the effectiveness of our methods through extensive simulations.	https://doi.org/10.1109/ICRA46639.2022.9812256	Si Wei Feng, Jingjin Yu
Barrier Function-based Safe Reinforcement Learning for Formation Control of Mobile Robots.	Distributed model predictive control (DMPC) concerns how to online control multiple robotic systems with constraints effectively. However, the nonlinearity, nonconvexity, and strong interconnections of dynamic system models and constraints can make the real-time and real-world DMPC implementations nontrivial. Reinforcement learning (RL) algorithms are promising for control policy design. However, how to ensure safety in terms of state constraints in RL remains a significant issue. This paper proposes a barrier function-based safe reinforcement learning algorithm for DMPC of nonlinear multi-robot systems under state constraints. The proposed approach is composed of several local learning-based MPC regulators. Each regulator, associated with a local system, learns and deploys the local control policy using a safe reinforcement learning algorithm in a distributed manner, i.e., with state information only among the neighbor agents. As a prominent feature of the proposed algorithm, we present a novel barrier-based policy structure to ensure safety, which has a clear mechanistic interpretation. Both simulated and real-world experiments on the formation control of mobile robots with collision avoidance show the effectiveness of the proposed safe reinforcement learning algorithm for DMPC.	https://doi.org/10.1109/ICRA46639.2022.9811604	Xinglong Zhang, Yaoqian Peng, Wei Pan, Xin Xu, Haibin Xie
Bayesian Optimisation for Robust Model Predictive Control under Model Parameter Uncertainty.	We propose an adaptive optimisation approach for tuning stochastic model predictive control (MPC) hyper-parameters while jointly estimating probability distributions of the transition model parameters based on performance rewards. In particular, we develop a Bayesian optimisation (BO) algorithm with a heteroscedastic noise model to deal with varying noise across the MPC hyper-parameter and dynamics model parameter spaces. Typical homoscedastic noise models are unrealistic for tuning MPC since stochastic controllers are inherently noisy, and the level of noise is affected by their hyper-parameter settings. We evaluate the proposed optimisation algorithm in simulated control and robotics tasks where we jointly infer control and dynamics parameters. Experimental results demonstrate that our approach leads to higher cumulative rewards and more stable controllers.	https://doi.org/10.1109/ICRA46639.2022.9812406	Rel Guzman Apaza, Rafael Oliveira, Fabio Ramos
Bayesian Optimization Meets Hybrid Zero Dynamics: Safe Parameter Learning for Bipedal Locomotion Control.	In this paper, we propose a multi-domain control parameter learning framework that combines Bayesian Optimization (BO) and Hybrid Zero Dynamics (HZD) for locomotion control of bipedal robots. We leverage BO to learn the control parameters used in the HZD-based controller. The learning process is firstly deployed in simulation to optimize different control parameters for a large repertoire of gaits. Next, to tackle the discrepancy between the simulation and the real world, the learning process is applied on the physical robot to learn for corrections to the control parameters learned in simulation while also respecting a safety constraint for gait stability. This method empowers an efficient sim-to-real transition with a small number of samples in the real world, and does not require a valid controller to initialize the training in simulation. Our proposed learning framework is experimentally deployed and validated on a bipedal robot Cassie to perform versatile locomotion skills with improved performance on smoothness of walking gaits and reduction of steady-state tracking errors.	https://doi.org/10.1109/ICRA46639.2022.9812154	Lizhi Yang, Zhongyu Li, Jun Zeng, Koushil Sreenath
Belief Space Planning: a Covariance Steering Approach.	A new belief space planning algorithm, called covariance steering Belief RoadMap (CS-BRM), is introduced, which is a multi-query algorithm for motion planning of dynamical systems under simultaneous motion and observation uncertainties. CS-BRM extends the probabilistic roadmap (PRM) approach to belief spaces and is based on the recently developed theory of covariance steering (CS) that enables guaranteed satisfaction of terminal belief constraints in finitetime. The CS-BRM algorithm allows the sampling of non-stationary belief nodes, and thus is able to explore the velocity space and find efficient motion plans. We evaluate CS-BRM in different planning problems and demonstrate the benefits of the proposed approach.	https://doi.org/10.1109/ICRA46639.2022.9811560	Dongliang Zheng, Jack Ridderhof, Panagiotis Tsiotras, Ali-akbar Agha-mohammadi
Bidirectional Communication Control for Human-Robot Collaboration.	A fruitful collaboration is based on the mutual knowledge of each other skills and on the possibility of communicating their own limits and proposing alternatives to adapt the execution of a task to the capabilities of the collaborators. This paper aims at reproducing such a scenario in a human-robot collaboration setting by proposing a novel communication control architecture. Exploiting control barrier functions, the robot is made aware of its (dynamic) skills and limits and, thanks to a local predictor, it is able to assess if it is possible to execute a requested task and, if not, to propose alternative by relaxing some constraints. The controller is interfaced with a communication infrastructure that enables human and robot to set up a bidirectional communication about the task to execute and the human to take an informed decision on the behavior of the robot. A comparative experimental validation is proposed.	https://doi.org/10.1109/ICRA46639.2022.9811665	Davide Ferrari, Federico Benzi, Cristian Secchi
Bidirectional Soft Robotic Catheter for Arrhythmia Treatment.	Heart rhythm disorders are becoming increasingly prevalent with population aging. Atrial fibrillation ablation (AFA) is a procedure used to treat an irregular heart rhythm (arrhythmia) that starts in the heart's upper chambers. The AFA works by scarring or destroying heart tissue to disrupt aberrant conduction pathways causing the arrhythmia. In hospital cardiac units, a flexible catheter with integrated metal electrode is currently used for the AFA procedure. Despite advances, existing cardiac catheter tips are driven by cable mechanisms which are associated with high nonlinear hysteresis and force loss. In addition, they are also limited to rigid components which require multiple actuators to control the bending tip to reach the complex anatomical corners of the heart. This paper introduces a new soft hydraulic catheter that can achieve bidirectional bending motion via a single soft artificial muscle. The new catheter is also equipped with a portable handle as an ergonomic control interface. To validate the design concept, various prototypes are fabricated and tested including bending angles and generated force capability. Mathematical models for the bending arm are also developed and experimentally validated. The new soft catheter will enable rapid and precise manipulation to reach any target within the cardiac chambers, offering more rapid and focused ablation therapy to improve patient outcomes.	https://doi.org/10.1109/ICRA46639.2022.9811988	Chi Cong Nguyen, Timotius Teh, Mai Thanh Thai, Phuoc Thien Phan, Trung Thien Hoang, Harrison Low, James Davies, Emanuele Nicotra, Nigel H. Lovell, Thanh Nho Do
Bipedal Walking on Constrained Footholds: Momentum Regulation via Vertical COM Control.	This paper presents an online walking synthesis methodology to enable dynamic and stable walking on constrained footholds for underactuated bipedal robots. Our approach modulates the change of angular momentum about the foot-ground contact pivot at discrete impact using pre-impact vertical center of mass (COM) velocity. To this end, we utilize the underactuated Linear Inverted Pendulum (LIP) model for approximating the underactuated walking dynamics to provide the desired post-impact angular momentum for each step. Desired outputs are constructed via online optimization combined with closed-form polynomials and tracked via a quadratic program (QP) based controller. This method is demonstrated on two robots, AMBER and 3D Cassie, for which stable walking behaviors with constrained footholds are realized on flat ground, stairs, and randomly located stepping stones.	https://doi.org/10.1109/ICRA46639.2022.9812247	Min Dai, Xiaobin Xiong, Aaron D. Ames
Blending Primitive Policies in Shared Control for Assisted Teleoperation.	Movement primitives have the property to accom-modate changes in the robot state while maintaining attraction to the original policy. As such, we investigate the use of primitives as a blending mechanism by considering that state deviations from the original policy are caused by user inputs. As the primitive recovers from the user input, it implicitly blends human and robot policies without requiring their weightings-referred to as arbitration. In this paper, we adopt Dynamical Movement Primitives (DMPs), which allow us to avoid the need for multiple demonstrations, and are fast enough to enable numerous instantiations, one for each hypothesis of the human intent. User studies are presented on assisted teleoperation tasks of reaching multiple goals and dynamic obstacle avoidance. Comparable performance to conventional teleoperation was achieved while significantly decreasing human intervention, often by more than 60%.	https://doi.org/10.1109/ICRA46639.2022.9812414	Guilherme Maeda
Brick Yourself within 3 Minutes.	This paper presents an intelligent machine which can automatically convert the captured portrait into a physical gadget made up of LEGO bricks. On the contrary to synthesising a 2D image or a virtual 3D object, generating physical 3D assembly object needs to take physical properties and assembly process into consideration, leading to more challenges. To generate brick models for arbitrary portraits, we formulate the transformation between the attribute space (extracted from 2D images) and the brick model space as a constraint integer programming problem which can be solved with a heuristic search method. Furthermore, as the bricks are physically scattered, we propose an algorithm to generate corresponding assembly instructions for customized figure-featured-bricks to facilitate users' assembly. Meanwhile, we deploy the proposed algorithms on an automatic machine which integrates a camera, a printer, a laptop, and a brick operation unit. Finally, the generated brick models and assembly instructions are evaluated by a large number of users. It is worth noting that the whole system works as an intelligent vending machine, producing a 150-brick-model within 3 minutes.	https://doi.org/10.1109/ICRA46639.2022.9812161	Guyue Zhou, Liyi Luo, Hao Xu, Xinliang Zhang, Haole Guo, Hao Zhao
CATs: Task Planning for Shared Control of Assistive Robots with Variable Autonomy.	From robotic space assistance to healthcare robotics, there is increasing interest in robots that offer adaptable levels of autonomy. In this paper, we propose an action representation and planning framework that is able to generate plans that can be executed with both shared control and supervised autonomy, even switching between them during task execution. The action representation - Constraint Action Templates (CATs) - combine the advantages of Action Templates [1] and Shared Control Templates [2]. We demonstrate that CATs enable our planning framework to generate goal-directed plans for variations of a typical task of daily living, and that users can execute them on the wheelchair-robot EDAN in shared control or in autonomous mode.	https://doi.org/10.1109/ICRA46639.2022.9811360	Samuel Bustamante, Gabriel Quere, Daniel Leidner, Jörn Vogel, Freek Stulp
CCO-VOXEL: Chance Constrained Optimization over Uncertain Voxel-Grid Representation for Safe Trajectory Planning.	We present CCO-VOXEL: the very first chance-constrained optimization (CCO) algorithm that can compute trajectory plans with probabilistic safety guarantees in real-time directly on the voxel-grid representation of the world. CCO-VOXEL maps the distribution over the distance to the closest obstacle to a distribution over collision-constraint violation and computes an optimal trajectory that minimizes the violation probability. Importantly, unlike existing works, we never assume the nature of the sensor uncertainty or the probability distribution of the resulting collision-constraint violations. We leverage the notion of Hilbert Space embedding of distributions and Maximum Mean Discrepancy (MMD) to compute a tractable surrogate for the original chance-constrained optimization problem and employ a combination of A* based graph-search and Cross-Entropy Method for obtaining its minimum. We show tangible performance gain in terms of collision avoidance and trajectory smoothness as a consequence of our probabilistic formulation vis a vis state-of-the-art planning methods that do not account for such non-parametric noise. Finally, we also show how a combination of low-dimensional feature embedding and pre-caching of Kernel Matrices of MMD allow us to achieve real-time performance in simulations as well as in implementations on on-board commodity hardware that controls the quadrotor flight.	https://doi.org/10.1109/ICRA46639.2022.9812250	Sudarshan S. Harithas, Rishabh Dev Yadav, Deepak Singh, Arun Kumar Singh, K. Madhava Krishna
CCRobot-V: A Silkworm-Like Cooperative Cable-Climbing Robotic System for Cable Inspection and Maintenance.	"This paper presents CCRobot-V, the fifth version of CCRobot, a cooperative serial multi-robot system for bridge cable inspection and maintenance that uses silkworm-like locomotion to climb the entire length of super-long stay cable at high speeds while carrying heavy inspection/maintenance equipment. CCRobot-V consists of one climbing precursor robot, one inspection/maintenance robot, several cable-carrying robots, and a power-tethered cable guiding system. The pre-cursor robot is the ""head,"" which leads the affiliated sub-robots along the bridge cable. Every sub-robot possesses a pair of self-locking palms. When a sub-robot grips on the bridge cable with its palms, it becomes a fixed anchor point that allows the adjacent sub-robots in front and back to use winches and steel wires to pull themselves upward. With this cooperative multi-robot system, cable inspection/maintenance tasks can be divided into several functional units, with each inspection/maintenance equipment installed separately on a customized sub-robot. Thus, CCRobot-V provides a complete mobile inspection/maintenance work line for a bridge cable. The experimental and field tests demonstrate CCRobot-V's high climbing speed, high payload capacity, and full-length cable moving capability. It has the potential application value for the actual bridge cable inspection/maintenance."	https://doi.org/10.1109/ICRA46639.2022.9811603	Zhenliang Zheng, Ning Ding, Huaping Chen, Xiaoli Hu, Zhihao Zhu, Xueqi Fu, Wenchao Zhang, Lin Zhang, Sarsenbek Hazken, Ziya Wang, Min Zhao
CLA-NeRF: Category-Level Articulated Neural Radiance Field.	We propose CLA-NeRF - a Category-Level Articulated Neural Radiance Field that can perform view synthesis, part segmentation, and articulated pose estimation. CLA-NeRF is trained at the object category level using no CAD models and no depth, but a set of RGB images with ground truth camera poses and part segments. During inference, it only takes a few RGB views (i.e., few-shot) of an unseen 3D object instance within the known category to infer the object part segmentation and the neural radiance field. Given an articulated pose as input, CLA-NeRF can perform articulation-aware volume rendering to generate the corresponding RGB image at any camera pose. Moreover, the articulated pose of an object can be estimated via inverse rendering. In our experiments, we evaluate the framework across five categories on both synthetic and real-world data. In all cases, our method shows realistic deformation results and accurate articulated pose estimation. We believe that both few-shot articulated object rendering and articulated pose estimation open doors for robots to perceive and interact with unseen articulated objects.	https://doi.org/10.1109/ICRA46639.2022.9812272	Wei-Cheng Tseng, Hung-Ju Liao, Yen-Chen Lin, Min Sun
COP: Control & Observability-aware Planning.	In this research, we aim to answer the question: How to combine Closed-Loop State and Input Sensitivity-based with Observability-aware trajectory planning? These possibly op-posite optimization objectives can be used to improve trajectory control tracking and, at the same time, estimation performance. Our proposed novel Control & Observability-aware Planning (COP) framework is the first that uses these possibly opposing objectives in a Single-Objective Optimization Problem (SOOP) based on the Augmented Weighted Tchebycheff method to perform the balancing of them and generation of Bézier curve-based trajectories. Statistically relevant simulations for a 3D quadrotor unmanned aerial vehicle (UAV) case study produce results that support our claims and show the negative correlation between both objectives. We were able to reduce the positional mean integral error norm as well as the estimation uncertainty with the same trajectory to comparable levels of the trajectories optimized with individual objectives.	https://doi.org/10.1109/ICRA46639.2022.9812373	Christoph Böhm, Pascal Brault, Quentin Delamare, Paolo Robuffo Giordano, Stephan Weiss
CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation.	LiDAR semantic segmentation essential for advanced autonomous driving is required to be accurate, fast, and easy-deployed on mobile platforms. Previous point-based or sparse voxel-based methods are far away from real-time applications since time-consuming neighbor searching or sparse 3D convolution are employed. Recent 2D projection-based methods, including range view and multi-view fusion, can run in real time, but suffer from lower accuracy due to information loss during the 2 D projection. Besides, to improve the performance, previous methods usually adopt test time augmentation (TTA), which further slows down the inference process. To achieve a better speed-accuracy trade-off, we propose Cascade Point-Grid Fusion Network (CPGNet), which ensures both effectiveness and efficiency mainly by the following two techniques: 1) the novel Point-Grid (PG) fusion block extracts semantic features mainly on the 2D projected grid for efficiency, while summarizes both 2D and 3D features on 3D point for minimal information loss; 2) the proposed transformation consistency loss narrows the gap between the single-time model inference and TTA. The experiments on the SemanticKITTI and nuScenes benchmarks demonstrate that the CPGNet without ensemble models or TTA is comparable with the state-of-the-art RPVNet, while it runs 4.7 times faster.	https://doi.org/10.1109/ICRA46639.2022.9811767	Xiaoyan Li, Gang Zhang, Hongyu Pan, Zhenhua Wang
CRANE: a 10 Degree-of-Freedom, Tele-surgical System for Dexterous Manipulation within Imaging Bores.	Physicians perform minimally invasive percuta-neous procedures under Computed Tomography (CT) image guidance both for the diagnosis and treatment of numerous diseases. For these procedures performed within Computed Tomography Scanners, robots can enable physicians to more accurately target sub-dermal lesions while increasing safety. However, existing robots for this application have limited dexterity, workspace, or accuracy. This paper describes the design, manufacture, and performance of a highly dexterous, low-profile, 8+2 Degree-of-Freedom (DoF) robotic arm for CT guided percutaneous needle biopsy. In this article, we propose CRANE: CT Robot and Needle Emplacer. The design focuses on system dexterity with high accuracy: extending physicians' ability to manipulate and insert needles within the scanner bore while providing the high accuracy possible with a robot. We also propose and validate a system architecture and control scheme for low profile and highly accurate image-guided robotics, that meets the clinical requirements for target accuracy during an in-situ evaluation. The accuracy is additionally evaluated through a trajectory tracking evaluation resulting in < \\boldsymbol{0.2}\\mathbf{mm}\nand <\\boldsymbol{ 0.71}^{\\circ}\ntracking error. Finally, we present a novel needle driving and grasping mechanism with controlling electronics that provides simple manufacturing, sterilization, and adaptability to accom-modate different sizes and types of needles.	https://doi.org/10.1109/ICRA46639.2022.9811732	Dimitri A. Schreiber, Zhaowei Yu, Hanpeng Jiang, Taylor Henderson, Guosong Li, Julie Yu, Renjie Zhu, Alexander M. Norbash, Michael C. Yip
CRAT-Pred: Vehicle Trajectory Prediction with Crystal Graph Convolutional Neural Networks and Multi-Head Self-Attention.	Predicting the motion of surrounding vehicles is essential for autonomous vehicles, as it governs their own motion plan. Current state-of-the-art vehicle prediction models heavily rely on map information. In reality, however, this information is not always available. We therefore propose CRAT-Pred, a multi-modal and non-rasterization-based trajectory prediction model, specifically designed to effectively model social interactions between vehicles, without relying on map information. CRAT-Pred applies a graph convolution method originating from the field of material science to vehicle prediction, allowing to efficiently leverage edge features, and combines it with multi-head self-attention. Compared to other map-free approaches, the model achieves state-of-the-art performance with a significantly lower number of model parameters. In addition to that, we quantitatively show that the self-attention mechanism is able to learn social interactions between vehicles, with the weights representing a measurable interaction score. The source code is publicly available33Source code: https://github.com/schmidt-ju/crat-pred.	https://doi.org/10.1109/ICRA46639.2022.9811637	Julian Schmidt, Julian Jordan, Franz Gritschneder, Klaus Dietmayer
CT-ICP: Real-time Elastic LiDAR Odometry with Loop Closure.	Multi-beam LiDAR sensors are increasingly used in robotics, particularly with autonomous cars for localization and perception tasks, both relying on the ability to build a precise map of the environment. For this, we propose a new real-time LiDAR-only odometry method called CT-ICP (for Continuous-Time ICP), completed into a full SLAM with a novel loop detection procedure. The core of this method, is the introduction of the combined continuity in the scan matching, and discontinuity between scans. It allows both the elastic distortion of the scan during the registration for increased precision, and the increased robustness to high frequency motions from the discontinuity. We build a complete SLAM on top of this odometry, using a fast pure LiDAR loop detection based on elevation image 2D matching, providing a pose graph with loop constraints. To show the robustness of the method, we tested it on seven datasets: KITTI, KITTI-raw, KITTI-360, KITTICARLA, ParisLuco, Newer College, and NCLT in driving and high-frequency motion scenarios. Both the CT-ICP odometry and the loop detection are made available online. CT-ICP is currently first, among those giving access to a public code, on the KITTI odometry leaderboard, with an average Relative Translation Error (RTE) of 0.59% and an average time per scan of 60ms on a CPU with a single thread.	https://doi.org/10.1109/ICRA46639.2022.9811849	Pierre Dellenbach, Jean-Emmanuel Deschaud, Bastien Jacquet, François Goulette
CaTGrasp: Learning Category-Level Task-Relevant Grasping in Clutter from Simulation.	Task-relevant grasping is critical for industrial assembly, where downstream manipulation tasks constrain the set of valid grasps. Learning how to perform this task, however, is challenging, since task-relevant grasp labels are hard to define and annotate. There is also yet no consensus on proper representations for modeling or off-the-shelf tools for performing task-relevant grasps. This work proposes a framework to learn task-relevant grasping for industrial objects without the need of time-consuming real-world data collection or manual annotation. To achieve this, the entire framework is trained solely in simulation, including supervised training with synthetic label generation and self-supervised, hand-object interaction. In the context of this framework, this paper proposes a novel, object-centric canonical representation at the category level, which allows establishing dense correspondence across object instances and transferring task-relevant grasps to novel instances. Extensive experiments on task-relevant grasping of densely-cluttered industrial objects are conducted in both simulation and real-world setups, demonstrating the effectiveness of the proposed framework. Code and data are available at https://sites.google.com/view/catgrasp.	https://doi.org/10.1109/ICRA46639.2022.9811568	Bowen Wen, Wenzhao Lian, Kostas E. Bekris, Stefan Schaal
Camera-Tracklet-Aware Contrastive Learning for Unsupervised Vehicle Re-Identification.	Recently, vehicle re-identification methods based on deep learning constitute remarkable achievement. However, this achievement requires large-scale and well-annotated datasets. In constructing the dataset, assigning globally available identities (Ids) to vehicles captured from a great number of cameras is labour-intensive, because it needs to consider their subtle appearance differences or viewpoint variations. In this paper, we propose camera-tracklet-aware contrastive learning (CTACL) using the multi-camera tracklet information without vehicle identity labels. The proposed CTACL divides an unlabelled domain, i.e., entire vehicle images, into multiple camera-level subdomains and conducts contrastive learning within and beyond the subdomains. The positive and negative samples for contrastive learning are defined using tracklet Ids of each camera. Additionally, the domain adaptation across camera networks is introduced to improve the generalisation performance of learnt representations and alleviate the performance degradation resulted from the domain gap between the subdomains. We demonstrate the effectiveness of our approach on video-based and image-based vehicle Re-ID datasets. Experimental results show that the proposed method outperforms the recent state-of-the-art unsupervised vehicle Re-ID methods. The source code for this paper is publicly available on https://github.com/andreYoo/CTAM-CTACL-VVReID.git.	https://doi.org/10.1109/ICRA46639.2022.9812007	Jongmin Yu, Junsik Kim, Minkyung Kim, Hyeontaek Oh
Can your drone touch? Exploring the boundaries of consumer-grade multirotors for physical interaction.	Aerial robots have been widely used as sensor carrying platforms in a wide range of application, mainly because using this type of systems for physical interaction seems to be an unsuitable operation. This is not only due to the risk of collision and damage of the platform, but also because it is unclear whether a consumer-grade UAV can withstand physical contact with the environment. In this paper, we address the issue of performing physical interaction with the environment by a multirotor UAV implementing a basic cascaded position-attitude controller, typical of most of consumer-grade multirotor systems. Precisely, we identify mathematically the boundaries where the system can safely be used to perform physical interaction with the environment. The theoretical approach is finally validated through experiments showing that physical contact can only be achieved within a predefined region of control inputs.	https://doi.org/10.1109/ICRA46639.2022.9812187	Paul Lassen, Matteo Fumagalli
Capacitive Proximity Sensor for Non-Contact Endoscope Localization.	The promising automation of flexible surgical instruments and robots is impeded by the lack of sensory means, which allow for sensing of an instrument's position to the surrounding tissue. This work presents a novel sensory method utilizing capacitive proximity sensing to derive a relative localization of a flexible instrument inside a hollow organ. The method is evaluated by exemplary integration of a sensor in a commercial gastroendoscope and accuracy analysis using a high precision robot. The results show an accuracy of distance sensing from a medical phantom's center of 2%. The method is also evaluated for the irregularly shaped surrounding of ex-vivo tissue in a dynamic scenario. This promising approach holds potential for transfer to clinical scenarios and for further development towards pose estimation of flexible surgical robots and shape sensing of a minimally invasive environment.	https://doi.org/10.1109/ICRA46639.2022.9811734	Christian Marzi, Hosam Alagi, Olivia Rau, Jochen Hampe, Jan G. Korvink, Björn Hein, Franziska Mathis-Ullrich
Capacitive Tactile Sensor Using Mutual Capacitance Sensing Method for Increased Resolution.	As robots move toward more complex environments, imbuing them with a sense of touch similar to humans becomes increasingly important. To fulfill that goal, there has been significant research conducted in the past few decades to develop a tactile sensor that matches human level touch capabilities. Recently, the progress in capacitive touch screens has made capacitive sensing a very appealing option for such a sensor, and therefore many research groups have proposed novel designs of tactile sensors based on capacitive technologies. This technology has the advantage of generating a predictable sensor response with a high degree of sensitivity, but has the drawback of a limited spatial resolution. This paper shows how using mutual capacitance in combination with a microstructured dielectric can lead to a very sensitive sensor that also possesses a high spatial resolution. The response of the sensor in relation to its various components is explored in order to fully comprehend the physical principles of the sensing mechanism and generate a predictable output.	https://doi.org/10.1109/ICRA46639.2022.9811696	Jean-Christophe Sicotte-Brisson, Alexandre Bernier, Jennifer Kwiatkowski, Vincent Duchaine
Causal-based Time Series Domain Generalization for Vehicle Intention Prediction.	Accurately predicting the possible behaviors of traffic participants is an essential capability for autonomous vehicles. Since autonomous vehicles need to navigate in dynamically changing environments, they are expected to make accurate predictions regardless of where they are and what driving circumstances they encountered. Therefore, generalization capability to unseen domains is crucial for prediction models when autonomous vehicles are deployed in the real world. In this paper, we aim to address the domain generalization problem for vehicle intention prediction tasks and a causal-based time series domain generalization (CTSDG) model is proposed. We construct a structural causal model for vehicle intention prediction tasks to learn an invariant representation of input driving data for domain generalization. We further integrate a recurrent latent variable model into our structural causal model to better capture temporal latent dependencies from time-series input data. The effectiveness of our approach is evaluated via real-world driving data. We demonstrate that our proposed method has consistent improvement on prediction accuracy compared to other state-of-the-art domain generalization and behavior prediction methods.	https://doi.org/10.1109/ICRA46639.2022.9812188	Yeping Hu, Xiaogang Jia, Masayoshi Tomizuka, Wei Zhan
CenterSnap: Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation.	This paper studies the complex task of simultaneous multi-object 3D reconstruction, 6D pose and size estimation from a single-view RGB-D observation. In contrast to instance- level pose estimation, we focus on a more challenging problem where CAD models are not available at inference time. Existing approaches mainly follow a complex multi-stage pipeline which first localizes and detects each object instance in the image and then regresses to either their 3D meshes or 6D poses. These approaches suffer from high-computational cost and low performance in complex multi-object scenarios, where occlusions can be present. Hence, we present a simple one- stage approach to predict both the 3D shape and estimate the 6D pose and size jointly in a bounding-box free manner. In particular, our method treats object instances as spatial centers where each center denotes the complete shape of an object along with its 6D pose and size. Through this per- pixel representation, our approach can reconstruct in real- time (40 FPS) multiple novel object instances and predict their 6D pose and sizes in a single-forward pass. Through extensive experiments, we demonstrate that our approach significantly outperforms all shape completion and categorical 6D pose and size estimation baselines on multi-object ShapeNet and NOCS datasets respectively with a 12.6% absolute improvement in mAP for 6D pose for novel real-world object instances.	https://doi.org/10.1109/ICRA46639.2022.9811799	Muhammad Zubair Irshad, Thomas Kollar, Michael Laskey, Kevin Stone, Zsolt Kira
Centroidal Aerodynamic Modeling and Control of Flying Multibody Robots.	This paper presents a modeling and control frame-work for multibody flying robots subject to non-negligible aero-dynamic forces acting on the centroidal dynamics. First, aero-dynamic forces are calculated during robot flight in different operating conditions by means of Computational Fluid Dynamics (CFD) analysis. Then, analytical models of the aerodynamics coefficients are generated from the dataset collected with CFD analysis. The obtained simplified aerodynamic model is also used to improve the flying robot control design. We present two control strategies: compensating for the aerodynamic effects via feedback linearization and enforcing the controller robustness with gain-scheduling. Simulation results on the jet-powered humanoid robot iRonCub validate the proposed approach.	https://doi.org/10.1109/ICRA46639.2022.9812147	Tong Hui, Antonello Paolino, Gabriele Nava, Giuseppe L'Erario, Fabio Di Natale, Fabio Bergonti, Francesco Braghin, Daniele Pucci
Characterizing Error in Noncommutative Geometric Gait Analysis.	A key problem in robotic locomotion is in finding optimal shape changes to effectively displace systems through the world. Variational techniques for gait optimization require estimates of body displacement per gait cycle; however, these estimates introduce error due to unincluded high order terms. In this paper, we formulate existing estimates for displacement, and describe the contribution of low order terms to these estimates. We additionally describe the magnitude of higher (third) order effects, and identify that choice of body coordinate, gait diameter, and starting phase influence these effects. We demonstrate that variation of such parameters on two example systems (the differential drive car and Purcell swimmer) effectively manages third order contributions.	https://doi.org/10.1109/ICRA46639.2022.9812130	Capprin Bass, Suresh Ramasamy, Ross L. Hatton
Charting the trade-off between design complexity and plan execution under probabilistic actions.	Practical robot designs must strike a compromise between fabrication/manufacture cost and anticipated execution performance. Compared to parsimonious designs, more capable (and hence more expensive) robots generally achieve their ends with greater efficiency. This paper examines how the roboticist might explore the space of designs to gain an understanding of such trade-offs. We focus, specifically, on design choices that alter the set of actions available to the robot, and model those actions as involving uncertainty. We consider planning problems under the Markov Decision Process (MDP) model, which leads us to examine how to relate the cost of some design to the expected cost of an execution for the optimal policies feasible with that design. The complexity of this problem ─expressed via hardness in the fixed parameter tractability sense─depends on the number of actions to choose from. When that number is not negligible, we give a novel representation and an algorithm utilizing that structure that allows useful savings over naïve enumeration.	https://doi.org/10.1109/ICRA46639.2022.9811751	Fatemeh Zahra Saberifar, Dylan A. Shell, Jason M. O'Kane
CineMPC: Controlling Camera Intrinsics and Extrinsics for Autonomous Cinematography.	We present CineMPC, an algorithm to autonomously control a UAV-borne video camera in a nonlinear Model Predicted Control (MPC) loop. CineMPC controls both the position and orientation of the camera-the camera extrinsics-as well as the lens focal length, focal distance, and aperture-the camera intrinsics. While some existing solutions autonomously control the position and orientation of the camera, no existing solutions also control the intrinsic parameters, which are essential tools for rich cinematographic expression. The intrinsic parameters control the parts of the scene that are focused or blurred, the viewers' perception of depth in the scene and the position of the targets in the image. CineMPC closes the loop from camera images to UAV trajectory and lens parameters in order to follow the desired relative trajectory and image composition as the targets move through the scene. Experiments using a photo-realistic environment demon-strate the capabilities of the proposed control framework to successfully achieve a full array of cinematographic effects not possible without full camera control.	https://doi.org/10.1109/ICRA46639.2022.9811827	Pablo Pueyo, Eduardo Montijano, Ana C. Murillo, Mac Schwager
Cityscapes TL++: Semantic Traffic Light Annotations for the Cityscapes Dataset.	There is a gap in holistic urban scene understanding between multi-modal datasets for segmentation and object detection on the one hand and traffic light datasets on the other hand. The role of traffic lights in the former is not labelled, making it difficult to use them for higher-level tasks and leave critical information of an intersection scene blank. Including traffic lights from traffic light specific datasets into the comprehensive semantic data introduces a penalty from the domain shift. We close this gap by providing semantically annotated traffic lights for the Cityscapes dataset. We demonstrate the domain shift penalty by using a traffic light dataset from a similar domain and show superior performance on data labelled in the original domain. We demonstrate an application by training a real-time capable network for semantic segmentation and object detection which can now additionally make sense of traffic lights, delivering an F1- Score of 66.4% on the important class of traffic lights relevant to the ego vehicle. The network is made publicly available at https://github.com/joeda/NNAD and the data at https://github.com/KIT-MRT/cityscapes-t1.	https://doi.org/10.1109/ICRA46639.2022.9812144	Johannes Janosovits
Cluttered Food Grasping with Adaptive Fingers and Synthetic-Data Trained Object Detection.	The food packaging industry handles an immense variety of food products with wide-ranging shapes and sizes, even within one kind of food. Menus are also diverse and change frequently, making automation of pick-and-place difficult. A popular approach to bin-picking is to first identify each piece of food in the tray by using an instance segmentation method. However, human annotations to train these methods are unreli-able and error-prone since foods are packed close together with unclear boundaries and visual similarity making separation of pieces difficult. To address this problem, we propose a method that trains purely on synthetic data and successfully transfers to the real world using sim2real methods by creating datasets of filled food trays using high-quality 3d models of real pieces of food for the training instance segmentation models. Another concern is that foods are easily damaged during grasping. We address this by introducing two additional methods- a novel adaptive finger mechanism to passively retract when a collision occurs, and a method to filter grasps that are likely to cause damage to neighbouring pieces of food during a grasp. We demonstrate the effectiveness of the proposed method on several kinds of real foods.	https://doi.org/10.1109/ICRA46639.2022.9812448	Avinash Ummadisingu, Kuniyuki Takahashi, Naoki Fukaya
ColibriDoc: an Eye-in-Hand Autonomous Trocar Docking System.	Retinal surgery is a complex medical procedure that requires exceptional expertise and dexterity. For this purpose, several robotic platforms are currently under development to enable or improve the outcome of microsurgical tasks. Since the control of such robots is often designed for navigation inside the eye in proximity to the retina, successful trocar docking and insertion of the instrument into the eye represents an additional cognitive effort, and is therefore one of the open challenges in robotic retinal surgery. For this purpose, we present a platform for autonomous trocar docking that combines computer vision and a robotic setup. Inspired by the Cuban Colibri (hummingbird) aligning its beak to a flower using only vision, we mount a camera onto the endeffector of a robotic system. By estimating the position and pose of the trocar, the robot is able to autonomously align and navigate the instrument towards the Trocar Entry Point (TEP) and finally perform the insertion. Our experiments show that the proposed method is able to accurately estimate the position and pose of the trocar and achieve repeatable autonomous docking. The aim of this work is to reduce the complexity of the robotic setup prior to the surgical task and therefore, increase the intuitiveness of the system integration into clinical workflow.	https://doi.org/10.1109/ICRA46639.2022.9811364	Shervin Dehghani, Michael Sommersperger, Junjie Yang, Mehrdad Salehi, Benjamin Busam, Kai Huang, Peter Gehlbach, Iulian Iordachita, Nassir Navab, M. Ali Nasseri
Collaborative Robot Mapping using Spectral Graph Analysis.	In this paper, we deal with the problem of creating globally consistent pose graphs in a centralized multi-robot SLAM framework. For each robot to act autonomously, individual onboard pose estimates and maps are maintained, which are then communicated to a central server to build an optimized global map. However, inconsistencies between onboard and server estimates can occur due to onboard odometry drift or failure. Furthermore, robots do not benefit from the collaborative map if the server provides no feedback in a computationally tractable and bandwidth-efficient manner. Motivated by this challenge, this paper proposes a novel collaborative mapping framework to enable accurate global mapping among robots and server. In particular, structural differences between robot and server graphs are exploited at different spatial scales using graph spectral analysis to generate necessary constraints for the individual robot pose graphs. The proposed approach is thoroughly analyzed and validated using several real-world multi-robot field deployments where we show improvements of the onboard system up to 90%.	https://doi.org/10.1109/ICRA46639.2022.9812102	Lukas Bernreiter, Shehryar Khattak, Lionel Ott, Roland Siegwart, Marco Hutter, César Cadena
Collision Avoidance for Multiple Quadrotors Using Elastic Safety Clearance Based Model Predictive Control.	When multiple quadrotors fly in a cluttered environment, collision-free flight must be assured. In this paper, we propose a novel elastic safety clearance based model predictive control (ESC-MPC) for multiple maneuverable quadrotors to avoid collisions in the presence of disturbance. This is accomplished through leveraging tube based model predictive control to maintain the quadrotor in a tube of trajectories. Exponential control barrier function (ECBF) is integrated to realize the elastic safety clearance mechanism which offers a dynamic safety margin in maneuverable flight. We validate the superiority of our approach with laboratory experiments.	https://doi.org/10.1109/ICRA46639.2022.9811659	Tao Jin, Xinghu Wang, Haibo Ji, Jian Di, Han Yan
ComOpT: Combination and Optimization for Testing Autonomous Driving Systems.	ComOpT is an open-source research tool for coverage-driven testing of autonomous driving systems, focusing on planning and control. Starting with (i) a meta-model characterizing discrete conditions to be considered and (ii) constraints specifying the impossibility of certain combinations, ComOpT first generates constraint-feasible abstract scenarios while maximally increasing the coverage of k-way combinatorial testing. Each abstract scenario can be viewed as a conceptual equivalence class, which is then instantiated into multiple concrete scenarios by (1) randomly picking one local map that fulfills the specified geographical condition, and (2) assigning all actors accordingly with parameters within the range. Finally, ComOpT evaluates each concrete scenario against a set of KPIs and performs local scenario variation via spawning a new agent that might lead to a collision at designated points. We use ComOpT to test the Apollo 6 autonomous driving software stack. ComOpT can generate highly diversified scenarios with limited test budgets while uncovering problematic situations such as inabilities to make simple right turns, uncomfortable accelerations, and dangerous driving patterns. ComOpT participated in the 2021 IEEE AI Autonomous Vehicle Testing Challenge and won first place among more than 110 contending teams.	https://doi.org/10.1109/ICRA46639.2022.9811794	Changwen Li, Chih-Hong Cheng, Tiantian Sun, Yuhang Chen, Rongjie Yan
Combined Grid and Feature-based Mapping of Metal Structures with Ultrasonic Guided Waves.	The ultrasonic mapping of plate-based facilities is an essential step towards the robotic inspection of large metal structures such as storage tanks or ship hulls. This work proposes a novel framework that exploits ultrasonic echoes to recover grid-based and feature-based spatial representations jointly. We aim to improve on a previous mapping method [1] subject to errors due to interference, and which provides plate geometry estimates without uncertainty assessment. The grid can represent, all along the mapping process, both areas identified as inside or outside the current plate and areas whose state is still unknown, making it is suitable e.g. for detecting a change of plate, or for use in a later active-sensing strategy. We also leverage the resulting spatial information to filter out candidate plate edges that are no longer relevant, mitigating the detrimental effect of interference. We test the approach in simulation, with acoustic data acquired manually and with a real robot. Results show that it is effective for building combined map representations and robust to echo misdetection, contrary to a more standard mapping approach.	https://doi.org/10.1109/ICRA46639.2022.9811581	Othmane-Latif Ouabi, Ayoub Ridani, Pascal Pomarede, Neil Zeghidour, Nico F. Declercq, Matthieu Geist, Cédric Pradalier
Combining Planning and Learning of Behavior Trees for Robotic Assembly.	Industrial robots can solve tasks in controlled environments, but modern applications require robots able to operate also in unpredictable surroundings. An increasingly popular reactive policy architecture in robotics is Behavior Trees (BTs) but as other architectures, programming time drives cost and limits flexibility. The two main branches of algorithms to generate policies automatically, automated planning and machine learning, both have their own drawbacks and have not previously been combined for generation of BTs. We propose a method for creating BTs by combining these branches, inserting the result of an automated planner into the population of a Genetic Programming algorithm. Experiments confirm that the proposed method performs well on a variety of robotic assembly problems and outperforms the base methods used separately. We also show that this high level learning of Behavior Trees can be transferred to a real system without further training.	https://doi.org/10.1109/ICRA46639.2022.9812086	Jonathan Styrud, Matteo Iovino, Mikael Norrlöf, Mårten Björkman, Christian Smith
Communicating Robot Conventions through Shared Autonomy.	When humans control robot arms these robots often need to infer the human's desired task. Prior research on assistive teleoperation and shared autonomy explores how robots can determine the desired task based on the human's joystick inputs. In order to perform this inference the robot relies on an internal mapping between joystick inputs and discrete tasks: e.g., pressing the joystick left indicates that the human wants a plate, while pressing the joystick right indicates a cup. This approach works well after the human understands how the robot interprets their inputs - but inexperienced users still have to learn these mappings through trial and error! Here we recognize that the robot's mapping between tasks and inputs is a convention. There are multiple, equally efficient conventions that the robot could use: rather than passively waiting for the human, we introduce a shared autonomy approach where the robot actively reveals its chosen convention. Across repeated interactions the robot intervenes and exaggerates the arm's motion to demonstrate more efficient inputs while also assisting for the current task. We compare this approach to a state-of-the-art baseline - where users must identify the convention by themselves - as well as written instructions. Our user study results indicate that modifying the robot's behavior to reveal its convention outperforms the baselines and reduces the amount of time that humans spend controlling the robot. See videos of our user study here: https://youtu.be/jROTVOp469I	https://doi.org/10.1109/ICRA46639.2022.9811674	Ananth Jonnavittula, Dylan P. Losey
Comparison of Haptic and Augmented Reality Visual Cues for Assisting Tele- manipulation.	Robot teleoperation via human motion tracking has been proven to be easy to learn, intuitive to operate, and facilitate faster task execution than existing baselines. However, precise control while performing the dexterous telemanipulation tasks is still a challenge. In this paper, we implement sensory augmentation in terms of haptic and augmented reality visual cues to represent four types of information critical to the precision and performance of a telemanipulation task, namely: (1) target location; (2) constraint alert; (3) grasping affordance; and (4) grasp confirmation. We further conduct two user studies to investigate the effectiveness and preferred modality of the sensory feedback against no sensory support, and how the preference will be influenced by the different types of simulated real-world additional workload. We asked 8 participants to perform a general manipulation task using a KINOVA robotic arm. Our results indicate that: (1) the haptic and AR visual cues can significantly reduce the task completion time, occurrences of errors, the total length traversed by the robot end-effector, the operational effort while increasing the interface usability; (2) the haptic feedback trended in the direction of presenting the information that needs a prompt response, while the AR visual cues are suitable to monitor the system status; (3) the participants chose their preferred feedback with the purpose of reducing the cognitive workload despite increased extra effort.	https://doi.org/10.1109/ICRA46639.2022.9811669	Tsung-Chi Lin, Achyuthan Unni Krishnan, Zhi Li
Compensating for Material Deformation in Foldable Robots via Deep Learning - A Case Study.	Foldable, origami-inspired, and laminate mechanisms are highly susceptible to deformation under external loading, which can lead to position or orientation errors if idealized kinematic models are used. According to dimensional scaling laws, laminate devices can often be treated as rigid bodies at millimeter and smaller scale deformations. However, foldable mechanisms enter the territory of soft robots at larger scales. In this paper, we show the effect of external loads applied to a laminate, 2-DOF parallel robot and the corresponding errors during a pointing task. We then present two control methods, based on deep learning, that compensates for errors caused by the material deformation in foldable robots. For each proposed control method, a Deep Neural Network (DeepNN) is trained to learn the end-effector's deformation model in no-load and loaded conditions. A DeepNN called an updating network is trained and applied in real-time using measured sensor data, in order to transfer updated weights into another DeepNN called the target network. The target network generates control signals with the aim of compensating for the end-effector's error in tracking a desired trajectory. We evaluate our proposed control methods when applied to a laminate robotic end-effector under different external loading conditions in tracking spiral paths. The experimental results show the effectiveness of our proposed control methods in compensating for material deformation in foldable robots.	https://doi.org/10.1109/ICRA46639.2022.9811752	Mohammad Sharifzadeh, Yuhao Jiang, Amir Salimi Lafmejani, Daniel M. Aukes
Complex Terrain Navigation via Model Error Prediction.	Robot navigation traditionally relies on building an explicit map that is used to plan collision-free trajectories to a desired target. In deformable, complex terrain, using geometric-based approaches can fail to find a path due to mischaracterizing deformable objects as rigid and impassable. Instead, we learn to predict an estimate of traversability of terrain regions and to prefer regions that are easier to navigate (e.g., short grass over small shrubs). Rather than predicting collisions, we instead regress on realized error compared to a canonical system model. We train with an on-policy approach, resulting in successful navigation policies using as little as 50 minutes of training data split across simulation and real world. Our learning-based navigation system is a sample efficient short-term planner that we demonstrate on a Clearpath Husky navigating through a variety of terrain including grassland and forest.	https://doi.org/10.1109/ICRA46639.2022.9811644	Adam Polevoy, Craig Knuth, Katie M. Popek, Kapil D. Katyal
Composable Causality in Semantic Robot Programming.	Assembly tasks are challenging for robot manipulation because the robot must reason over the composed effects of actions and execute multi-objective behaviors. Robots typically use predefined priorities provided by users to determine how to compose controller behaviors, but we want the robot to autonomously select these compositions based on their composed effects within the task. We present Composable Causality in Semantic Robot Programming to allow robots to reason over the composed effects of controllers when executing multi-objective actions and autonomously compose controllers without predefined priorities. Our proposed causal control basis combines controller behaviors with causal information about how the behaviors can be used to execute high-level symbolic actions. The robot uses the causal control basis to predict the transition probability of achieving the composed effects of a multi-objective action. The composed causality estimates are used to select which action to execute within the context of a furniture assembly task. We evaluate the robot's transition probability estimates in different furniture assembly trials in simulation on the Baxter robot. The robot's ability to assemble furniture using different multi-objective connection actions demonstrates the usefulness of the composed causality estimates from our causal control basis.	https://doi.org/10.1109/ICRA46639.2022.9811365	Emily Sheetz, Xiaotong Chen, Zhen Zeng, Kaizhi Zheng, Qiuyu Shi, Odest Chadwicke Jenkins
Comprehensive Swing Leg Motion Predictor for Steady and Transient Walking Conditions.	Data-driven methods based on neural networks are becoming more widespread for predicting human lower-limb motion. Until now, however, actual examples have focused on only a handful, steady locomotion behaviors. Here we explore if neural network predictors can simultaneously cover many more behaviors including transient ones. Training four common types of predictor networks on a large data set of human gait, we find that they all accommodate these behaviors similarly well, maintaining prediction errors of a few centimeters (lower-limb joint positions) and degrees (joint angles) when tested on data of previously seen subjects. We further observe that although the prediction quality drops for data of unseen subjects, overall, the predicted and actual lower-limb motions remain well aligned. While the predictors demonstrated here cover the largest range of locomotion behaviors reported to date, we achieve this improvement not by better network design but simply by training on more data. This outcome clearly supports the notion that the fastest route to obtain truly general network predictors of lower-limb motion is by focusing time and effort on the rapid growth and sharing of data sets of locomotion behaviors encountered in daily life.	https://doi.org/10.1109/ICRA46639.2022.9811835	Haosen Xing, Saurav Kumar, Hartmut Geyer
Computation of Dynamic Joint Reaction Forces of PKM and its Use for Load-Minimizing Trajectory Planning.	Parallel kinematics machines (PKM) operate with maximal acceleration being designed for highly dynamic manipulation tasks. This leads to extreme loads of the joints, which is usually not accounted for in the motion planning. In this paper an extended inverse dynamics method is introduced, which allows computing the joint reaction forces along with the actuation torques, and provides a basis for time optimal motion planning and control minimizing wear of the components. To this end, PKM are modeled using absolute coordinates. The joint constraints are complemented with servo constraints so that the motion can be described by the actuator motion or by the end-effector motion. The presented method is particularly advantageous when certain model parameters are unknown and allows for model simplification, which would not be possible for the relative coordinate formulation. The sparsity of the obtained velocity constraint Jacobian matrix, due to the use of absolute coordinates, can be efficiently exploited to minimize computation time. The method is demonstrated and numerical results are reported for a time-optimal pick and place movement of a 4-DOF Delta robot.	https://doi.org/10.1109/ICRA46639.2022.9812095	Daniel Gnad, Hubert Gattringer, Andreas Müller, Wolfgang Höbarth, Roland Riepl, Lukas Messner
Computing Funnels Using Numerical Optimization Based Falsifiers.	In this paper, we present an algorithm that computes funnels along trajectories of systems of ordinary differential equations. A funnel is a time-varying set of states containing the given trajectory, for which the evolution from within the set at any given time stays in the funnel. Hence it generalizes the behavior of single trajectories to sets around them, which is an important task, for example, in robot motion planning. In contrast to approaches based on sum-of-squares programming, which poorly scale to high dimensions, our approach is based on falsification and tackles the funnel computation task directly, through numerical optimization. This approach computes accurate funnel estimates far more efficiently and leaves formal verification to the end, outside all funnel size optimization loops.	https://doi.org/10.1109/ICRA46639.2022.9811730	Jirí Fejlek, Stefan Ratschan
Concurrent Policy Blending and System Identification for Generalized Assistive Control.	In this work, we address the problem of solving complex collaborative robotic tasks subject to multiple varying parameters. Our approach combines simultaneous policy blending with system identification to create generalized policies that are robust to changes in system parameters. We employ a blending network whose state space relies solely on parameter estimates from a system identification technique. As a result, this blending network learns how to handle parameter changes instead of trying to learn how to solve the task for a generalized parameter set simultaneously. We demonstrate our scheme's ability on a collaborative robot and human itching task in which the human has motor impairments. We then showcase our approach's efficiency with a variety of system identification techniques when compared to standard domain randomization. The code is available on Luke Bhan's Github.	https://doi.org/10.1109/ICRA46639.2022.9811672	Luke Bhan, Marcos Quiñones-Grueiro, Gautam Biswas
Conditioned Human Trajectory Prediction using Iterative Attention Blocks.	Human motion prediction is key to understand social environments, with direct applications in robotics, surveil-lance, etc. We present a simple yet effective pedestrian trajectory prediction model aimed at pedestrians' positions prediction in urban-like environments conditioned by the environment: map and surround agents. Our model is a neural-based architecture that can run several layers of attention blocks and transformers in an iterative sequential fashion, allowing to capture the important features in the environment that improve prediction. We show that without explicit introduction of social masks, dynamical models, social pooling layers, or complicated graph-like structures, it is possible to produce on par results with SoTA models, which makes our approach easily extendable and configurable, depending on the data available. We report results performing similarly with SoTA models on publicly available and extensible-used datasets with uni-modal prediction metrics ADE and FDE.	https://doi.org/10.1109/ICRA46639.2022.9812404	Aleksey Postnikov, Aleksander Gamayunov, Gonzalo Ferrer
Confidence-Based Robot Navigation Under Sensor Occlusion with Deep Reinforcement Learning.	This paper considers the problem of prolonged occlusions on navigation sensors due to dust, smudges, soils, etc. Such uncontrollable occlusions often cause lower visibility as well as higher uncertainty that require considerably sophisticated behavior. To secure visibility (i.e., confidence about the world), we propose a confidence-based navigation method that encourages the robot to explore the uncertain region around the robot maximizing its local confidence. To effectively extract features from the variable size of sensor occlusions, we adopt a point-cloud based representation network. Our method returns a resilient navigation policy via deep reinforcement learning, autonomously avoiding collisions under sensor occlusions while reaching a goal. We evaluate our method in simulated and real-world environments with either static or dynamic obstacles under various sensor-occlusion scenarios. The experimental result shows that our method outperforms baseline methods under the highly occurring sensor occlusion, and achieves maximum 90% and 80% success rates in the tested static and dynamic environments, respectively.	https://doi.org/10.1109/ICRA46639.2022.9812090	Hyeongyeol Ryu, Minsung Yoon, Daehyung Park, Sung-Eui Yoon
Configuration Control for Physical Coupling of Heterogeneous Robot Swarms.	In this paper, we present a heterogeneous robot swarm system that can physically couple with each other to form functional structures and dynamically decouple to perform individual tasks. The connection between robots can be formed with a passive coupling mechanism, ensuring minimum energy consumption during coupling and decoupling behavior. The heterogeneity of the system enables the robots to perform structural enhancement configurations based on specific environmental requirements. We propose a connection-pair oriented configuration control algorithm to form different assemblies. We show experiments of up to nine robots performing the coupling, gap-crossing, and decoupling behaviors.	https://doi.org/10.1109/ICRA46639.2022.9812115	Sha Yi, Fatma Zeynep Temel, Katia P. Sycara
Consensus in Operational Space for Robotic Manipulators with Task and Input Constraints.	This paper presents a real-time control framework for consensus in operational space for robotic manipulators while satisfying task and input constraints. Consensus in operational space, as compared to joint space, enables heterogeneous robotic manipulators to achieve consensus. However, traditional frameworks tend to ignore task and input constraints while achieving consensus in operational space. We address this problem by defining safe sets in operational space and then ensure task constraint by designing Control Barrier Functions (CBF) in operational space. Control barrier functions guarantees to provide collision-free behavior for the robotic manipulator by modifying the nominal controller in a minimally invasive manner such that the trajectory of the manipulator remains in the safe set. The Quadratic Programming (QP) formulation also ensures that the nominal controller is only modified when the constraints are active, and the resulting controller is optimal in a min-norm setting. Our approach contrasts the traditional potential field method, which continues to influence the nominal controller because of its attractive and repulsive field design, and is therefore unsuitable for consensus problems. We also incorporate the input constraint in our QP formulation to ensure that the resulting controller complies with the task and input constraints. We show the efficacy of the proposed approach on 7 Degree of Freedom (DoF) KUKA LBR iiwa, 6 DoF KUKA KR5 R650 and 7 DoF Flexiv Rizon robotic manipulators, each with different dynamical and kinematic models using Dynamic Animation and Robotics Toolkit (DART) physics engine.	https://doi.org/10.1109/ICRA46639.2022.9811846	Muhammad Ali Murtaza, Seth Hutchinson
Constrained Variable Impedance Control using Quadratic Programming.	This paper proposes a quadratic programming (QP)-based variable impedance control (VIC) algorithm to solve contact-rich trajectory tracking problems with impedance, position and velocity constraints. To the best of our knowledge, the impedance constraints which are significant to ensure the worst contact compliance have never been considered in other previous works. To handle the impedance constraints of the VIC algorithm, a novel impedance model where the impedance parameters are directly served as the control input is established. The impedance-constrained VIC design problem is then formulated as a QP problem which can be efficiently solved. To handle the position and velocity constraints, a complementary force is introduced into the novel impedance model. The complementary force will appear to prevent the constraints violation when the robot approaches the constrained area. The design problem of the complementary force is also transformed into a QP problem. Combing these two QP solutions, the VIC algorithm with both impedance, position and velocity constraints can be obtained. Finally, various experiments are conducted to show the effectiveness of the proposed QP-based constrained VIC algorithm.	https://doi.org/10.1109/ICRA46639.2022.9812210	Zhehao Jin, Dongdong Qin, Andong Liu, Wen-An Zhang, Li Yu
Constrained Visual-Inertial Localization With Application And Benchmark in Laparoscopic Surgery.	We propose a novel method to tackle the visual-inertial localization problem for constrained camera movements. We use residuals from the different modalities to jointly optimize a global cost function. The residuals emerge from IMU measurements, stereoscopic feature points, and constraints on possible solutions in SE(3). In settings where dynamic disturbances are frequent, the residuals reduce the complexity of the problem and make localization feasible. We verify the advantages of our method in a suitable medical use case and produce a dataset capturing a minimally invasive surgery in the abdomen. Our novel clinical dataset MITI is comparable to state-of-the-art evaluation datasets, contains calibration and synchronization and is available at [1].	https://doi.org/10.1109/ICRA46639.2022.9812105	Regine Hartwig, Daniel Ostler, Jean-Claude Rosenthal, Hubertus Feußner, Dirk Wilhelm, Dirk Wollherr
Contact Mode Guided Motion Planning for Quasidynamic Dexterous Manipulation in 3D.	This paper presents Contact Mode Guided Manipulation Planning (CMGMP) for 3D quasistatic and quasi-dynamic rigid body motion planning in dexterous manipulation. The CMGMP algorithm generates hybrid motion plans including both continuous state transitions and discrete contact mode switches, without the need for pre-specified contact sequences or pre-designed motion primitives. The key idea is to use automatically enumerated contact modes of environment-object contacts to guide the tree expansions during the search. Contact modes automatically synthesize manipulation primitives, while the sampling-based planning framework sequences those primitives into a coherent plan. We test our algorithm on fourteen 3D manipulation tasks, and validate our models by executing some plans open-loop on a real robot-manipulator system11The video is available at https://youtu.be/JuLlliG3vGc.	https://doi.org/10.1109/ICRA46639.2022.9811872	Xianyi Cheng, Eric Huang, Yifan Hou, Matthew T. Mason
Contact Transfer: A Direct, User-Driven Method for Human to Robot Transfer of Grasps and Manipulations.	We present a novel method for the direct transfer of grasps and manipulations between objects and hands through utilization of contact areas. Our method fully preserves contact shapes, and in contrast to existing techniques, is not dependent on grasp families, requires no model training or grasp sampling, makes no assumptions about manipulator morphology or kinematics, and allows user control over both transfer parameters and solution optimization. Despite these accommodations, we show that our method is capable of synthesizing kinematically-feasible whole hand poses in seconds even for poor initializations or hard-to-reach contacts. We additionally highlight the method's benefits in both response to design alterations as well as fast approximation over in-hand manipulation sequences. Finally, we demonstrate a solution generated by our method on a physical, custom-designed prosthetic hand.	https://doi.org/10.1109/ICRA46639.2022.9811739	Arjun Lakshmipathy, Dominik Bauer, Cornelia Bauer, Nancy S. Pollard
Contact-Rich Manipulation of a Flexible Object based on Deep Predictive Learning using Vision and Tactility.	We achieved contact-rich flexible object manipulation, which was difficult to control with vision alone. In the unzipping task we chose as a validation task, the gripper grasps the puller, which hides the bag state such as the direction and amount of deformation behind it, making it difficult to obtain information to perform the task by vision alone. Additionally, the flexible fabric bag state constantly changes during operation, so the robot needs to dynamically respond to the change. However, the appropriate robot behavior for all bag states is difficult to prepare in advance. To solve this problem, we developed a model that can perform contact-rich flexible object manipulation by real-time prediction of vision with tactility. We introduced a point-based attention mechanism for extracting image features, softmax transformation for predicting motions, and convolutional neural network for extracting tactile features. The results of experiments using a real robot arm revealed that our method can realize motions responding to the deformation of the bag while reducing the load on the zipper. Furthermore, using tactility improved the success rate from 56.7% to 93.3% compared with vision alone, demonstrating the effectiveness and high performance of our method.	https://doi.org/10.1109/ICRA46639.2022.9811940	Hideyuki Ichiwara, Hiroshi Ito, Kenjiro Yamamoto, Hiroki Mori, Tetsuya Ogata
Context is Everything: Implicit Identification for Dynamics Adaptation.	Understanding environment dynamics is necessary for robots to act safely and optimally in the world. In realistic scenarios, dynamics are non-stationary and the causal variables such as environment parameters cannot necessarily be precisely measured or inferred, even during training. We propose Implicit Identification for Dynamics Adaptation (IIDA), a simple method to allow predictive models to adapt to changing environment dynamics. IIDA assumes no access to the true variations in the world and instead implicitly infers properties of the environment from a small amount of contextual data. We demonstrate IIDA's ability to perform well in unseen environments through a suite of simulated experiments on MuJoCo environments and a real robot dynamic sliding task. In general, IIDA significantly reduces model error and results in higher task performance over commonly used methods. Our code, video of the method, and latest paper is available here https://bennevans.github.io/icra-iida/	https://doi.org/10.1109/ICRA46639.2022.9812119	Ben Evans, Abitha Thankaraj, Lerrel Pinto
Context-Aware Grasp Generation in Cluttered Scenes.	Conventional methods to autonomous grasping rely on a pre-computed database with known objects to synthesize grasps, which is not possible for novel objects. On the other hand, recently proposed deep learning-based approaches have demonstrated the ability to generalize grasp for unknown objects. However, grasp generation still remains a challenging problem, especially in cluttered environments under partial occlusion. In this work, we propose an end-to-end deep learning approach for generating 6-DOF collision-free grasps given a 3D scene point cloud. To build robustness to occlusion, the proposed model generates candidates by casting votes and accumulating evidence for feasible grasp configurations. We exploit contextual information by encoding the dependency of objects in the scene into features to boost the performance of grasp generation. The contextual information enables our model to increase the likelihood that the generated grasps are collision-free. Our experimental results confirm that the proposed system performs favorably in terms of predicting object grasps in cluttered environments in comparison to the current state of the art methods.	https://doi.org/10.1109/ICRA46639.2022.9811371	Dinh-Cuong Hoang, Johannes A. Stork, Todor Stoyanov
Continuous-Time Spline Visual-Inertial Odometry.	We propose a continuous-time spline-based formulation for visual-inertial odometry (VIO). Specifically, we model the poses as a cubic spline, whose temporal derivatives are used to synthesize linear acceleration and angular velocity, which are compared to the measurements from the inertial measurement unit (IMU) for optimal state estimation. The spline boundary conditions create constraints between the camera and the IMU, with which we formulate VIO as a constrained nonlinear optimization problem. Continuous-time pose representation makes it possible to address many VIO challenges, e.g., rolling shutter distortion and sensors that may lack synchronization. We conduct experiments on two publicly available datasets that demonstrate the state-of-the-art accuracy and real-time computational efficiency of our method.	https://doi.org/10.1109/ICRA46639.2022.9811586	Jiawei Mo, Junaed Sattar
Control Scheme for Sideways Walking on a User-driven Treadmill.	For immersive interaction in a virtual reality (VR) environment, an omnidirectional treadmill (ODT) can support performance of various locomotive motions (curved walk, side walk, moving with shooting stance) in any direction. When a user performs lateral locomotive motions on an ODT, a control scheme to achieve immersive and safe interaction with the ODT should satisfy robustness in terms of position error of a user to keep a reference position of the ODT by accurately estimating intentional walking speed (IWS) of the user, and it should guarantee postural stability of the user during the control actions. Existing locomotion interface (LI) control focuses on the reference position tracking performance regarding the position of the user's center of mass (COM) in order to respond to forward locomotion that can move at high speed. However, in sideways walking, the movement of the lower extremities is different from that of forward walking, and when the conventional LI control was directly applied to sideways walking, it was observed that excessive acceleration commands caused postural instability. For appropriate interface of sideways walking, we propose an estimation scheme based on an accurate walking model including the movement of the ankle joint. The proposed observer estimates the acting torque generated by the force of both lower extremities through the position information of COM and ankle joint to more accurately predict the user's intentional walking speed (IWS). In the sideways walking experiment conducted using a 1-dimensional user-driven treadmill (UDT), the proposed method allowed more natural interface of the lateral-side locomotion with better postural stability compared to the conventional estimation method that uses only the COM position information.	https://doi.org/10.1109/ICRA46639.2022.9812403	Sanghun Pyo, Hoyoung Kim, Jungwon Yoon
Control-Aware Prediction Objectives for Autonomous Driving.	Autonomous vehicle software is typically structured as a modular pipeline of individual components (e.g., perception, prediction, and planning) to help separate concerns into interpretable sub-tasks. Even when end-to-end training is possible, each module has its own set of objectives used for safety assurance, sample efficiency, regularization, or interpretability. However, intermediate objectives do not always align with overall system performance. For example, optimizing the likelihood of a trajectory prediction module might focus more on easy-to-predict agents than safety-critical or rare behaviors (e.g., jaywalking). In this paper, we present control-aware prediction objectives (CAPOs), to evaluate the down-stream effect of predictions on control without requiring the planner be differentiable. We propose two types of importance weights that weight the predictive likelihood: one using an attention model between agents, and another based on control variation when exchanging predicted trajectories for ground truth trajectories. Experimentally, we show our objectives improve overall system performance in suburban driving scenarios using the CARLA simulator.	https://doi.org/10.1109/ICRA46639.2022.9811884	Rowan McAllister, Blake Wulfe, Jean Mercat, Logan Ellis, Sergey Levine, Adrien Gaidon
Convex Model Predictive Control of Single Rigid Body Model on SO(3) for Versatile Dynamic Legged Motions.	This paper presents a convex model predictive control framework for versatile dynamic legged motions with negligible leg dynamics. The framework utilizes the single rigid body model linearly approximated around the operating point. With ground reaction forces as direct control inputs to the system, no reference control trajectory needs to be specified in advance. By using the rotation matrix for the evolution of rotational dynamics, issues arising from other representations can be avoided. Moreover, the rotation matrix is parametrized using the history of angular velocity without introducing additional variables. The effect is that we can still take the orientation into consideration efficaciously without directly working on it. The framework tackles the robot reference tracking problem via trajectory optimization, which is formulated into a standard quadratic program and can be solved efficiently in real time with guaranteed optimality. It was verified on various legged robots with different numbers of legs for performing different types of dynamic motions in the simulation environment. We thus envision a promising future of the proposed convex model predictive control framework in legged robots and potentially in other applications as well.	https://doi.org/10.1109/ICRA46639.2022.9811926	Junjie Shen, Dennis W. Hong
Convex strategies for trajectory optimisation: application to the Polytope Traversal Problem.	Non-linear trajectory optimisation methods require good initial guesses to converge to a locally optimal solution. A feasible guess can often be obtained by allocating a large amount of time for the trajectory to be complete. However for unstable dynamical systems such as humanoid robots, this quasi-static assumption does not always hold. We propose a conservative formulation of the trajectory problem that simultaneously computes a feasible path and its time allocation. The problem is solved as a convex optimisation problem guaranteed to converge to a feasible local optimum. The approach is evaluated with the computation of feasible trajectories that traverse sequentially a sequence of polytopes. We demonstrate that on instances of the problem where quasi static solutions are not admissible, our approach is able to find a feasible solution with a success rate above 80% in all the scenarios considered, in less than 10ms for problems involving traversing less than 5 polytopes and less than 1s for problems involving 20 polytopes, thus demonstrating its ability to reliably provide initial guesses to advanced non linear solvers.	https://doi.org/10.1109/ICRA46639.2022.9811719	Steve Tonneau
Cooperative Modular Single Actuator Monocopters Capable of Controlled Passive Separation.	In this paper, we introduce a Modular Single Actuator Monocopter (M-SAM), which is capable of flying in both singular configuration and cooperative configuration. From singular mode, M-SAMs can be manually assembled into cooperative mode, using magnetic connectors built into the body of each M-SAM unit. The design of the connectors allow for passive separation of the units without the need for a dedicated separating actuator, by harnessing the variable centrifugal force from controlled adjustment of the rotating speed of the craft. To achieve control in both configurations, we firstly studied and analyzed their full dynamic models by introducing equilibrium state and relaxed hovering condition. Next, we derived a reduced model to approximate the dynamical behavior of both singular and cooperative configuration in flight to design a generalized cyclic-based cascaded flight controller. Finally, we validated the proposed controller and separation mechanism by conducting several flight experiments for two M-SAMs in singular mode, cooperative mode as well as mid-air separating under motion capture system.	https://doi.org/10.1109/ICRA46639.2022.9812182	Xinyu Cai, Shane Kyi Hla Win, Luke Soe Thura Win, Danial Sufiyan, Shaohui Foong
Cooperative Transportation using Multiple Single-Rotor Robots and Decentralized Control for Unknown Payloads.	Cooperative transportation via multiple aerial robots has the potential to support various payloads and reduce the chances of them being dropped. Furthermore, autonomously controlled robots render the system scalable with respect to the payload. In this study, a cooperative transportation system was developed using rigidly attached single-rotor robots, and a decentralized controller was proposed to guarantee asymptotic stability of the error dynamics for unknown strictly positive real systems. A feedback controller was used to transform unstable systems into strictly positive real ones considering the shared attachment positions. First, the cooperative transportation of unknown payloads with different shapes larger than the carrier robots was investigated via numerical simulations. Second, cooperative transportation of an unknown payload (with a weight of approximately 2.7 kg and maximum length of 1.6 m) was demonstrated using eight robots, even under robot failure. Finally, the proposed system was shown to be capable of carrying an unknown payload, even if the attachment positions were not shared, that is, even if asymptotic stability was not strictly guaranteed.	https://doi.org/10.1109/ICRA46639.2022.9811768	Koshi Oishi, Yasushi Amano, Tomohiko Jimbo
Coordinate Invariant User-Guided Constrained Path Planning with Reactive Rapidly Expanding Plane-Oriented Escaping Trees.	As collaborative robots move closer to human environments, motion generation and reactive planning strategies that allow for elaborate task execution with minimal easy-to-implement guidance whilst coping with changes in the environment is of paramount importance. In this paper, we present a novel approach for generating real-time motion plans for point-to-point tasks using a single successful human demonstration. Our approach is based on screw linear interpolation, which allows us to respect the underlying geometric constraints that characterize the task and are implicitly present in the demonstration. We also integrate an original reactive collision avoidance approach with our planner. We present extensive experimental results to demonstrate that with our approach, by using a single demonstration of moving one block, we can generate motion plans for complex tasks like stacking multiple blocks (in a dynamic environment). Analogous generalization abilities are also shown for tasks like pouring and loading shelves. For the pouring task, we also show that a demonstration given for one-armed pouring can be used for planning pouring with a dual-armed manipulator of different kinematic structure.	https://doi.org/10.1109/ICRA46639.2022.9812014	Riddhiman Laha, Ruiai Sun, Wenxi Wu, Dasharadhan Mahalingam, Nilanjan Chakraborty, Luis F. C. Figueredo, Sami Haddadin
Coordination of two robotic manipulators for object retrieval in clutter.	We consider the problem of retrieving a target object from a confined space by two robotic manipulators where overhand grasps are not allowed. If other movable obstacles occlude the target, more than one object should be relocated to clear the path to reach the target object. With two robots, the relocation could be done efficiently by simultaneously performing relocation tasks. However, the precedence constraint between the tasks (e.g, some objects at the front should be removed to manipulate the objects in the back) makes the simultaneous task execution difficult. We propose a coordination method that determines which robot relocates which object so as to perform tasks simultaneously. Given a set of objects to be relocated, the objective is to maximize the number of switches between the robots in performing relocation tasks. Thus, one robot can pick an object in the clutter while the other robot places an object in hand to the outside of the clutter. However, the object to be relocated may not be accessible to all robots, so switching could not always be achieved. Our method is based on the uniform-cost search so the number of switches can be maximized. We also propose a greedy variant whose computation time is shorter. From experiments, we show that our method reduces the completion time of the mission by at least 22.9% (at most 27.3%) compared to the methods with no consideration of switching.	https://doi.org/10.1109/ICRA46639.2022.9811978	Jeeho Ahn, Chang-Hwan Kim, Changjoo Nam
Cost-Effective Sensing for Goal Inference: A Model Predictive Approach.	Goal inference is of great importance for a variety of applications that involve interaction, coordination, and/or competition with goal-oriented agents. Typical goal inference approaches use as many pointwise measurements of the agent's trajectory as possible to pursue a most accurate a-posteriori estimate of the goal. However, taking frequent measurements may not be preferred in situations where sensing is associated with high cost (e.g., sensing + perception may involve high computational/bandwidth cost and sensing may raise security concerns in privacy-critical/data-sensitive applications). In such situations, a sensible tradeoff between the information gained from measurements and the cost associated with sensing actions is highly desirable. This paper introduces a cost-effective sensing strategy for goal inference tasks based on hybrid Kalman filtering and model predictive control. Our key insights include: 1) a model predictive approach can be used to predict the amount of information gained from new measurements over a horizon and thus to optimize the tradeoff between information gain and sensing action cost, and 2) the high computational efficiency of hybrid Kalman filtering can ensure real-time feasibility of such a model predictive approach. We evaluate the proposed cost-effective sensing approach in a goal-oriented task, where we show that compared to standard goal inference approaches, our approach takes a considerably reduced number of measurements while not impairing the speed, accuracy, and reliability of goal inference by taking measurements smartly.	https://doi.org/10.1109/ICRA46639.2022.9811974	Ran Tian, Nan Li, Anouck Girard, Ilya V. Kolmanovsky, Masayoshi Tomizuka
Coverage Control in Multi-Robot Systems via Graph Neural Networks.	This paper develops a decentralized approach to mobile sensor coverage by a multi-robot system. We consider a scenario where a team of robots with limited sensing range must position itself to effectively detect events of interest in a region characterized by areas of varying importance. Towards this end, we develop a decentralized control policy for the robots-realized via a Graph Neural Network-which uses inter-robot communication to leverage non-local information for control decisions. By explicitly sharing information between multi-hop neighbors, the decentralized controller achieves a higher quality of coverage when compared to classical approaches that do not communicate and leverage only local information available to each robot. Simulated experiments demonstrate the efficacy of multi-hop communication for multi-robot coverage and evaluate the scalability and transferability of the learning-based controllers.	https://doi.org/10.1109/ICRA46639.2022.9811854	Walker Gosrich, Siddharth Mayya, Rebecca Li, James Paulos, Mark Yim, Alejandro Ribeiro, Vijay Kumar
Coverage Path Planning in Large-scale Multi-floor Urban Environments with Applications to Autonomous Road Sweeping.	Coverage Path Planning is the work horse of contemporary service task automation, powering autonomous floor cleaning robots and lawn mowers in households and office sites. While steady progress has been made on indoor cleaning and outdoor mowing, these environments are small and with simple geometry compared to general urban environments such as city parking garages, highway bridges or city crossings. To pave the way for autonomous road sweeping robots to operate in such difficult and complex environments, a benchmark suite with three large-scale 3D environments representative of this task is presented. On this benchmark we evaluate a new Coverage Path Planning method in comparison with previous well performing algorithms, and demonstrate state-of-the-art performance of the proposed method. Part of the success, for all evaluated algorithms, is the usage of automated domain adaptation by in-the-loop parameter optimization using Bayesian Optimization. Apart from improving the performance, tedious and bias-prone manual tuning is made obsolete, which makes the evaluation more robust and the results even stronger.	https://doi.org/10.1109/ICRA46639.2022.9811941	Daniel Engelsons, Mattias Tiger, Fredrik Heintz
Crawling Locomotion Enabled by a Novel Actuated Rover Chassis.	"Traversing soft soils represents a major concern of planetary rover missions. In this paper, we present a new chassis mechanism capable of a crawling gait that enhances trafficability on soft soil while relying on as few actuators as possible. Articulated by two actuated joints, MARCEL is a four-wheeled rover chassis which name stands for Mobile Active Rover Chassis for Enhanced Locomotion. MARCEL's crawling leverages a continuous adjustment of the load distribution on the four wheels using an internal torque applied between two halves of the chassis by series elastic actuation. This allows the pressure on two wheels to be minimized while they are moving forward with the assistance of the chassis's articulated motion. As a result, the wheels can be propelled forward one pair after another while avoiding the bulldozing resistance of the sand. This crawling motion is tested experimentally and is shown to generate more drawbar pull than both rolling or using a mere ""push-pull"" locomotion. Its ability to extricate the rover from deep sand entrapment is also tested successfully. This will allow future missions to deal with unforeseen terrain properties or to venture in more challenging areas while minimizing design complexity."	https://doi.org/10.1109/ICRA46639.2022.9811836	Arthur Bouton, Yang Gao
Cross Domain Robot Imitation with Invariant Representation.	Animals are able to imitate each others' behavior, despite their difference in biomechanics. In contrast, imitating other similar robots is a much more challenging task in robotics. This problem is called cross domain imitation learning (CDIL). In this paper, we consider CDIL on a class of similar robots. We tackle this problem by introducing an imitation learning algorithm based on invariant representation. We propose to learn invariant state and action representations, which align the behavior of multiple robots so that CDIL becomes possible. Compared with previous invariant representation learning methods for similar purposes, our method does not require human-labeled pairwise data for training. Instead, we use cycle-consistency and domain confusion to align the representation and increase its robustness. We test the algorithm on multiple robots in the simulator and show that unseen new robot instances can be trained with existing expert demonstrations successfully. Qualitative results also demonstrate that the proposed method is able to learn similar representations for different robots with similar behaviors, which is essential for successful CDIL.	https://doi.org/10.1109/ICRA46639.2022.9811668	Zhao-Heng Yin, Lingfeng Sun, Hengbo Ma, Masayoshi Tomizuka, Wu-Jun Li
Crossmodal Transformer Based Generative Framework for Pedestrian Trajectory Prediction.	Providing guidance about collision avoidance, pedestrian trajectory prediction is an important task for autonomous driving. In this paper, to produce plausible trajectory predictions in the first-person view circumstance, we propose a crossmodal transformer based generative framework which could leverage sequences of cues from multiple modalities as well as pedestrian attributes. For the encoder, crossmodal transformers are exploited during the past stage to explore the cross-relation features of four modality-modality pairs, which are then fused with the help of a branch assigning operation and a modality attention module. For the decoder, we employ a bézier curve interpolation based method to project encoder features into trajectory results. Our training process not only considers the pedestrian's intention of crossing road but also optimizes our model to achieve more accurate predictions at the terminal time steps. Experimental results demonstrate that our framework outperforms state-of-the-art methods on both JAAD and PIE datasets. Especially, compared with the best baseline, our method could achieve 15.1%/14.3% and 14.3%/22.2% improvement for deterministic/multimodal prediction in the metric of box center final displacement error on JAAD and PIE, respectively.	https://doi.org/10.1109/ICRA46639.2022.9812226	Zhaoxin Su, Gang Huang, Sanyuan Zhang, Wei Hua
Crossview Mapping with Graph-based Geolocalization on City-Scale Street Maps.	3D environment mapping has been actively stud-ied recently with the development of autonomous driving and augmented reality. Although many image-based methods are proposed due to their convenience and flexibility compared to other complex sensors, few works focus on fixing the inherent scale ambiguity of image-based methods and registering the reconstructed structure to the real-world 3D map, which is very important for autonomous driving. This paper presents a low-cost mapping solution that is able to refine and align the monocular reconstructed point cloud given a public street map. Specifically, we first find the association between the street map and the reconstructed point cloud structure by a novel graph-based geolocalization method. Then, optimized with the corresponding relationship, the map accuracy is significantly improved. The rich environment information can also be associated with the point cloud by the geographical location. Experiments show that our geolocalization algorithm can locate the scene on a gigantic city-scale map (173.46 km2) in two minutes and support 3D map reconstruction with absolute scale and rich environmental information from Internet videos.	https://doi.org/10.1109/ICRA46639.2022.9811743	Zhichao Ye, Chong Bao, Xinyang Liu, Hujun Bao, Zhaopeng Cui, Guofeng Zhang
Cyclops: Open Platform for Scale Truck Platooning.	Cyclops, introduced in this paper, is an open research platform for everyone who wants to validate novel ideas and approaches in self-driving heavy-duty vehicle platooning. The platform consists of multiple 1/14 scale semi-trailer trucks equipped with associated computing, communication and control modules that enable self-driving on our scale proving ground. The perception system for each vehicle is composed of a lidar-based object tracking system and a lane detection/control system. The former maintains the gap to the leading vehicle, and the latter maintains the vehicle within the lane by steering control. The lane detection system is optimized for truck platooning, where the field of view of the front-facing camera is severely limited due to a small gap to the leading vehicle. This platform is particularly amenable to validating mitigation strategies for safety-critical situations. Indeed, the simplex architecture is adopted in the computing modules, enabling various fail-safe operations. In particular, we illustrate a scenario where the camera sensor fails in the perception system, but the vehicle is able to operate at a reduced capacity to a graceful stop. Details of Cyclops, including 3D CAD designs and algorithm source codes, are released for those who want to build similar testbeds.	https://doi.org/10.1109/ICRA46639.2022.9812174	Hyeongyu Lee, Jaegeun Park, Changjin Koo, Jong-Chan Kim, Yongsoon Eun
D2A-BSP: Distilled Data Association Belief Space Planning with Performance Guarantees Under Budget Constraints.	Unresolved data association in ambiguous and perceptually aliased environments leads to multi-modal hypotheses on both the robot's and the environment state. To avoid catastrophic results, when operating in such ambiguous environments, it is crucial to reason about data association within Belief Space Planning (BSP). However, explicitly considering all possible data associations, the number of hypotheses grows exponentially with the planning horizon and determining the optimal action sequence quickly becomes intractable. Moreover, with hard budget constraints where some non-negligible hypotheses must be pruned, achieving performance guarantees is crucial. In this work we present a computationally efficient novel approach that utilizes only a distilled subset of hypotheses to solve BSP problems while reasoning about data association. Furthermore, to provide performance guarantees, we derive error bounds with respect to the optimal solution. We then demonstrate our approach in an extremely aliased environment, where we manage to significantly reduce computation time without compromising on the quality of the solution.	https://doi.org/10.1109/ICRA46639.2022.9811984	Moshe Shienman, Vadim Indelman
DA-LMR: A Robust Lane Marking Representation for Data Association.	While complete localization approaches are widely studied in the literature, their data association and data representation subprocesses usually go unnoticed. However, both are a key part of the final pose estimation. In this work, we present DA-LMR (Delta-Angle Lane Marking Representation), a robust data representation in the context of localization approaches. We propose a representation of lane markings that encodes how a curve changes in each point and includes this information in an additional dimension, thus providing a more detailed geometric structure description of the data. We also propose DC-SAC (Distance-Compatible Sample Consensus), a data association method. This is a heuristic version of RANSAC that dramatically reduces the hypothesis space by distance compatibility restrictions. We compare the presented methods with some state-of-the-art data representation and data association approaches in different noisy scenarios. The DA-LMR and DC-SAC produce the most promising combination among those compared, reaching 98.1 % in precision and 99.7% in recall for noisy data with 0.5 m of standard deviation.	https://doi.org/10.1109/ICRA46639.2022.9812271	Miguel Ángel Muñoz-Bañón, Jan-Hendrik Pauls, Haohao Hu, Christoph Stiller
DC-Loc: Accurate Automotive Radar Based Metric Localization with Explicit Doppler Compensation.	Automotive mmWave radar has been widely used in the automotive industry due to its small size, low cost, and complementary advantages to optical sensors (e.g., cameras, LiDAR, etc.) in adverse weathers, e.g., fog, raining, and snowing. On the other side, its large wavelength also poses fundamental challenges to perceive the environment. Recent advances have made breakthroughs on its inherent drawbacks, i.e., the multipath reflection and the sparsity of mmWave radar's point clouds. However, the frequency-modulated continuous wave modulation of radar signals makes it more sensitive to vehicles' mobility than optical sensors. This work focuses on the problem of frequency shift, i.e., the Doppler effect distorts the radar ranging measurements and its knock-on effect on metric localization. We propose a new radar-based metric localization framework, termed DC-Loc, which can obtain more accurate location estimation by restoring the Doppler distortion. Specifically, we first design a new algorithm that explicitly compensates the Doppler distortion of radar scans and then model the measurement uncertainty of the Doppler-compensated point cloud to further optimize the metric localization. Extensive experiments using the public nuScenes dataset and CARLA simulator demonstrate that our method outperforms the state-of-the-art approach by 25.2% and 5.6% improvements in terms of translation and rotation errors, respectively.	https://doi.org/10.1109/ICRA46639.2022.9811561	Pengen Gao, Shengkai Zhang, Wei Wang, Chris Xiaoxuan Lu
DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions.	We present a novel real-time visual odometry framework for a stereo setup of a depth and high-resolution event camera. Our framework balances accuracy and robustness against computational efficiency towards strong performance in challenging scenarios. We extend conventional edge-based semi-dense visual odometry towards time-surface maps obtained from event streams. Semi-dense depth maps are generated by warping the corresponding depth values of the extrinsically calibrated depth camera. The tracking module updates the camera pose through efficient, geometric semi-dense 3D-2D edge alignment. Our approach is validated on both public and self-collected datasets captured under various conditions. We show that the proposed method performs comparable to state-of-the-art RGB-D camera-based alternatives in regular conditions, and eventually outperforms in challenging conditions such as high dynamics or low illumination.	https://doi.org/10.1109/ICRA46639.2022.9811805	Yi-Fan Zuo, Jiaqi Yang, Jiaben Chen, Xia Wang, Yifu Wang, Laurent Kneip
DKNAS: A Practical Deep Keypoint Extraction Framework Based on Neural Architecture Search.	Keypoint extraction including both keypoint detection and description is a fundamental step in a wide range of geometric multimedia applications. In recent years, many learning-based approaches for keypoint extraction emerge and achieve promising results. However, they usually design network architectures empirically and lack of considerations about the comprehensive performance, which leads to limited applications. In this paper, we propose a practical framework based on Neural Architecture Search (NAS) technology, DKNAS, which can search architectures automatically and maintain efficiency and effectiveness, simultaneously. To the best of our knowledge, the proposed framework is the first NAS framework for keypoint extraction. The evaluation on HPatches dataset shows that our method achieves state-of-the-art results in the metrics of repeatability, localization error, homography accuracy and matching scores. Besides, our model is applied to a traditional Simultaneous Localization and Mapping (SLAM) system, ORB-SLAM2, to replace the handcrafted keypoints. Experimental results demonstrate that the system adopting our model outperforms ORB-SLAM2 and some other deep keypoints enhanced systems.	https://doi.org/10.1109/ICRA46639.2022.9812101	Li Liu, Xing Cai, Ge Li, Thomas H. Li
DORA: Distributed Online Risk-Aware Explorer.	Exploration of unknown environments is an important challenge in the field of robotics. While a single robot can achieve this task alone, evidence suggests it could be accomplished more efficiently by groups of robots, with advantages in terms of terrain coverage as well as robustness to failures. Exploration can be guided through belief maps, which provide probabilistic information about which part of the terrain is interesting to explore (either based on risk management or reward). This process can be centrally coordinated by building a collective belief map on a common server. However, relying on a central processing station creates a communication bottleneck and single point of failure for the system. In this paper, we present Distributed Online Risk-Aware (DORA) Explorer, an exploration system that leverages decentralized information sharing to update a common risk belief map. DORA-Explorer allows a group of robots to explore an unknown environment discretized as a 2D grid with obstacles, with high coverage while minimizing exposure to risk, effectively reducing robot failures.	https://doi.org/10.1109/ICRA46639.2022.9812237	David Vielfaure, Samuel Arseneault, Pierre-Yves Lajoie, Giovanni Beltrame
DPMPC-Planner: A real-time UAV trajectory planning framework for complex static environments with dynamic obstacles.	Safe UAV navigation is challenging due to the complex environment structures, dynamic obstacles, and uncertainties from measurement noises and unpredictable moving obstacle behaviors. Although plenty of recent works achieve safe navigation in complex static environments with sophisticated mapping algorithms, such as occupancy map and ESDF map, these methods cannot reliably handle dynamic environments due to the mapping limitation from moving obstacles. To address the limitation, this paper proposes a trajectory planning framework to achieve safe navigation considering complex static environments with dynamic obstacles. To reliably handle dynamic obstacles, we divide the environment representation into static mapping and dynamic object representation, which can be obtained from computer vision methods. Our framework first generates a static trajectory based on the proposed iterative corridor shrinking algorithm. Then, reactive chance-constrained model predictive control with temporal goal tracking is applied to avoid dynamic obstacles with uncertainties. The simulation results in various environments demonstrate the ability of our algorithm to navigate safely in complex static environments with dynamic obstacles.	https://doi.org/10.1109/ICRA46639.2022.9811886	Zhefan Xu, Di Deng, Yiping Dong, Kenji Shimada
DRAGONFLY: a UAV Rapidly Deployed Micro-Profiler Array for Underwater Thermocline Observation.	Underwater thermocline, common in the lakes and ocean, plays a vital role in meteorological forecasting in the ocean and lakes dynamics research. This letter proposes a method for rapid and multipoint observation of thermocline variations with time and space using an airdropped micro-profiler array, named the DRAGONFLY system. It comprises specially designed disposable low-cost micro-profilers, a general unmanned aerial carrier platform, and a ground control system. This system can conduct periodic profile observations at a single point or quickly survey a large area. A series of experiments to characterize the micro-profiler and the DRAGONFLY system were conducted in Qiandao Lake, China. We demonstrate the developed system with data from field experiments, which show very high flexibility, and feasibility to observe the lake thermocline, implying potential applications in ocean transient phenomena observation.	https://doi.org/10.1109/ICRA46639.2022.9811369	Chenxin Lyu, Zhihao Fan, Yuanbo Bi, Zheng Zeng, Lian Lian
DRG: A Dynamic Relation Graph for Unified Prior-Online Environment Modeling in Urban Autonomous Driving.	Environment modeling is the backbone of how autonomous agents understand the world, and therefore has significant implications for decision-making and verification. Motivated by the success of relational mapping tools such as Lanelet2, we present the Dynamic Relation Graph (DRG). The DRG is a novel method for extending prior relational maps to include online observations, creating a unified en-vironment model which incorporates both prior and online data sources. Our prototype implementation models a finite set of heterogeneous features including road signage and pedestrian movement. However, the methodology behind the DRG can be expanded to a wider range of features in a fashion that does not increase the complexity of behavioral planning. Simulated stress tests indicate the DRG's effectiveness in decreasing decision-making complexity, and deployment on the University of Waterloo's WATonomous research vehicle demonstrates its practical utility. The prototype code will be released at github.com/WATonomous/DRG.	https://doi.org/10.1109/ICRA46639.2022.9812290	Rowan Dempster, Mohammad K. Al-Sharman, Yeshu Jain, Jeffery Li, Derek Rayside, William Melek
DURableVS: Data-efficient Unsupervised Recalibrating Visual Servoing via online learning in a structured generative model.	Visual servoing enables robotic systems to perform accurate closed-loop control, which is required in many applications. However, existing methods require either precise calibration of the robot kinematic model and cameras or use neural architectures that require large amounts of data to train. In this work, we present a method for unsupervised learning of visual servoing that does not require any prior calibration and is extremely data-efficient. Our key insight is that visual servoing does not depend on identifying the veridical kinematic and camera parameters, but instead only on an accurate generative model of image feature observations from the joint positions of the robot. We demonstrate that with our model architecture and learning algorithm, we can consistently learn accurate models from less than 50 training samples (which amounts to less than 1 min of unsupervised data collection), and that such data-efficient learning is not possible with standard neural architectures. Further, we show that by using the generative model in the loop and learning online, we can enable a robotic system to recover from calibration errors and to detect and quickly adapt to possibly unexpected changes in the robot-camera system (e.g. bumped camera, new objects).	https://doi.org/10.1109/ICRA46639.2022.9811607	Nishad Gothoskar, Miguel Lázaro-Gredilla, Yasemin Bekiroglu, Abhishek Agarwal, Joshua B. Tenenbaum, Vikash K. Mansinghka, Dileep George
DanceHAT: Generate Stable Dances for Humanoid Robots with Adversarial Training.	Music to dance for humanoid robots is an interesting task. Robot dance generation is challenging when considering music pieces, human dancer motions, and robot stability simultaneously. Previous methods rely on human-designed motion library or stability constraints for robot postures. Hence, dance generation for humanoid robots requires expert design, which can be time-consuming across different humanoid platforms. In this work, we propose a novel method called DanceHAT, which generates stable humanoid dances by imitating human dancers with self-learning. DanceHAT is an adversarial training framework, which incorporates similarity loss and stability loss simultaneously. Furthermore, DanceHAT does not require human-designed features or robot model information. Experiments in the simulation environment and on the real robot demonstrate that our model can generate stable, diverse, and human-like dances for humanoid robots automatically. In addition, DanceHAT is a general training approach for robot imitation tasks with stability constraints, thus can be utilized in other humanoid tasks and will be researched in future works.	https://doi.org/10.1109/ICRA46639.2022.9811649	Buqing Nie, Yue Gao
Data-Driven Control for a Milli-Scale Spiral-Type Magnetic Swimmer using MPC.	This paper presents four data-driven system models for a magnetically controlled swimmer. The models were derived directly from experimental data, and the accuracy of the models was experimentally demonstrated. Our previous study successfully implemented two non-model-based control algorithms for 3D path-following using PID and model reference adaptive controller (MRAC). This paper focuses on system identification using only experimental data and a model-based control strategy. Four system models were derived: (1) a physical estimation model, (2, 3) Sparse Identification of Nonlinear Dynamics (SINDY), linear system and nonlinear system, and (4) multilayer perceptron (MLP). All four system models were implemented as an estimator of a multi-step Kalman filter. The maximum required sensing interval was increased from 180 ms to 420 ms and the respective tracking error decreased from 9 mm to 4.6 mm. Finally, a Model Predictive Controller (MPC) implementing the linear SINDY model was tested for 3D path-following and shown to be computationally efficient and offers performances comparable to other control methods.	https://doi.org/10.1109/ICRA46639.2022.9812157	Haoran Zhao, Yitong Lu, Aaron T. Becker, Julien Leclerc
Data-efficient learning of object-centric grasp preferences.	Grasping made impressive progress during the last few years thanks to deep learning. However, there are many objects for which it is not possible to choose a grasp by only looking at an RGB-D image, might it be for physical reasons (e.g., a hammer with uneven mass distribution) or task constraints (e.g., food that should not be spoiled). In such situations, the preferences of experts need to be taken into account. In this paper, we introduce a data-efficient grasping pipeline (Latent Space GP Selector - LGPS) that learns grasp prefer-ences with only a few labels per object (typically 1 to 4) and generalizes to new views of this object. Our pipeline is based on learning a latent space of grasps with a dataset generated with any state-of-the-art grasp generator (e.g., Dex-Net). This latent space is then used as a low-dimensional input for a Gaussian process classifier that selects the preferred grasp among those proposed by the generator. The results show that our method outperforms both GR-ConvNet and GG-CNN (two state-of-the-art methods that are also based on labeled grasps) on the Cornell dataset, especially when only a few labels are used: only 80 labels are enough to correctly choose 80% of the grasps (885 scenes, 244 objects). Results are similar on our dataset (91 scenes, 28 objects).	https://doi.org/10.1109/ICRA46639.2022.9811760	Yoann Fleytoux, Anji Ma, Serena Ivaldi, Jean-Baptiste Mouret
De-snowing LiDAR Point Clouds With Intensity and Spatial-Temporal Features.	Point clouds from 3D light detection and ranging (LiDAR) are widely used. Noise caused by falling snow reduces the availability of point clouds. Due to the sparseness of LiDAR point clouds and the fact that the snow point clouds are easily affected by multi factors such as wind or snowfall conditions, it is difficult to accurately remove the snow while preserving the details of the point clouds. To solve the problem, this paper presents a de-snowing approach combining the intensity and spatial-temporal features. An intensity-based filter firstly removes the snow. Then a repairing method restores the non-snow points based on the spatial-temporal features. Experimental results demonstrate that our approach outperforms existing work in the literature and performs the least damage to the point clouds in different snowfall scenarios.	https://doi.org/10.1109/ICRA46639.2022.9812241	Boyang Li, Jieling Li, Gang Chen, Hejun Wu, Kai Huang
Decentralized Global Connectivity Maintenance for Multi-Robot Navigation: A Reinforcement Learning Approach.	The problem of multi-robot navigation of connectivity maintenance is challenging in multi-robot applications. This work investigates how to navigate a multi-robot team in unknown environments while maintaining connectivity. We propose a reinforcement learning (RL) approach to develop a decentralized policy, which is shared among multiple robots. Given range sensor measurements and the positions of other robots, the policy aims to generate control commands for navigation and preserve the global connectivity of the robot team. We incorporate connectivity concerns into the RL framework as constraints and introduce behavior cloning to reduce the exploration complexity of policy optimization. The policy is optimized with all transition data collected by multiple robots in random simulated scenarios. We validate the effectiveness of the proposed approach by comparing different combinations of connectivity constraints and behavior cloning. We also show that our policy can generalize to unseen scenarios in both simulation and holonomic robots experiments.	https://doi.org/10.1109/ICRA46639.2022.9812163	Minghao Li, Yingrui Jie, Yang Kong, Hui Cheng
Decentralized Model Predictive Control for Equilibrium-based Collaborative UAV Bar Transportation.	In this paper we analyze the equilibrium points of a collaborative transportation task, composed of two unmanned aerial vehicles and a payload - in this case, a bar. Moreover, centralized and decentralized linear model predictive controllers are designed, where the nonlinear dynamics are linearized around the equilibrium points previously analyzed. A comparison between the centralized and decentralized formulations is provided, based on experimental results for both setups, and considering the time to solution and performance of each controller. Our findings provide new operational equilibrium points that can be paired with predictive model-based controllers for efficient operation.	https://doi.org/10.1109/ICRA46639.2022.9811726	Roberto C. Sundin, Pedro Roque, Dimos V. Dimarogonas
Decentralized Ride-sharing of Shared Autonomous Vehicles Using Graph Neural Network-Based Reinforcement Learning.	Ride-sharing has important implications for improving the efficiency of mobility-on-demand systems. However, it remains a challenge due to the complex dynamics between vehicles and requests. This paper presents a decentralized ride-sharing algorithm suitable for shared autonomous vehicles (SAVs) deployment. The ride-sharing problem is formulated as a multi-agent reinforcement learning problem. We explore state representation with the request-vehicle graph to encode shareability and potential coordination information. We use a graph attention network to build a hierarchical structure that unifies ride-sharing assignments with rebalancing and handles real-world scenarios where hundreds of user requests can be associated with vehicles. We show results in both generic grid-world and SUMO simulation with real-world data from the Manhattan area. We empirically demonstrate that our proposed approach can achieve similar performance compared with a state-of-the-art centralized optimization method and higher computation efficiency.	https://doi.org/10.1109/ICRA46639.2022.9811596	Boqi Li, Nejib Ammar, Prashant Tiwari, Huei Peng
Decoupling of Inertia Effect in Angular Momentum of a Humanoid and its Application to Resolved Viscoelasticity Control.	As a basic part of the centroidal dynamics, an-gular momentum plays a critical role in humanoid motion control. Therefore, how to explicitly express and control an-gular momentum through whole-body motion is an important topic for researchers. This study discusses the selection of the generalized velocity corresponding to whole-body angular momentum. Based on the discussion, we present a method that decouples the inertia effect in centroidal angular momentum and applies it in resolved viscoelasticity control, which achieves the angular momentum control by whole-body compliance in an interpretable way without complicated calculation. At last, we validate the feasibility and effectiveness of proposed method in forward dynamics simulation of balancing control in the double and single support states and landing motion after hopping.	https://doi.org/10.1109/ICRA46639.2022.9811692	Zewen He, Ko Yamamoto
Deep Bayesian ICP Covariance Estimation.	Covariance estimation for the Iterative Closest Point (ICP) point cloud registration algorithm is essential for state estimation and sensor fusion purposes. We argue that a major source of error for ICP is in the input data itself, from the sensor noise to the scene geometry. Benefiting from recent developments in deep learning for point clouds, we propose a data-driven approach to learn an error model for ICP. We estimate covariances modeling data-dependent heteroscedastic aleatoric uncertainty, and epistemic uncertainty using a variational Bayesian approach. The system evaluation is performed on LiDAR odometry on different datasets, highlighting good results in comparison to the state of the art.	https://doi.org/10.1109/ICRA46639.2022.9811899	Andrea De Maio, Simon Lacroix
Deep Curiosity Driven Multicamera 3D Viewpoint Adjustment for Robot-Assisted Minimally Invasive Surgery.	Maneuverable multicamera systems offer potential benefits in abdominal minimally-invasive procedures, including multi-view scene reconstruction and optimal viewpoint capture. Effective autonomous movement and re-positioning of such systems, however, remains an open challenge due to dynamic motion constraints, deforming surgical scenes, and visual artifacts such as motion blur, specular reflections, and blood stains [1]. Despite these existing roadblocks, multicamera systems have been used both to provide surgeons with stable and analytically optimized viewpoints [2] and to enable 3D surgical scene reconstruction [3] that directly contributes towards the possibility of task autonomy [4] and AR-enhanced surgical procedures [5]. These methods, however, often require extensive, high-dimensional continuous data sets, and may not value scene discovery. To that end, this project presents a novel curiosity driven multicamera viewpoint adjustment framework, Ac, that aims to simultaneously (a) explore and maximize weighted 3D reconstructable coverage; (b) limit unnecessary camera motion; and (c) relieve data-intensiveness through dimension-reduced state representations. The developed algorithms are comparatively evaluated against three baseline methods on simulated surgical sequences, and results demonstrate performance enhancements with the presented methods.	https://doi.org/10.1109/ICRA46639.2022.9812413	Yun-Hsuan Su, Heidi Zhang, Wenfan Jiang, Khanh Ngo, Kevin Huang
Deep Drifting: Autonomous Drifting of Arbitrary Trajectories using Deep Reinforcement Learning.	In this paper, a Deep Neural Network is trained using Reinforcement Learning in order to drift on arbitrary trajectories which are defined by a sequence of waypoints. In a first step, a highly accurate vehicle simulation is used for the training process. Then, the obtained policy is refined and validated on a self-built model car. The chosen reward function is inspired by the scoring process of real life drifting competitions. It is kept simple and thus applicable to very general scenarios. The experimental results demonstrate that a relatively small network, given only a few measurements and control inputs, already achieves an outstanding performance. In simulation, the learned controller is able to reliably hold a steady state drift. Moreover, it is capable of generalizing to arbitrary, previously unknown trajectories and different driving conditions. After transferring the learned controller to the model car, it also performs surprisingly well given the physical constraints.	https://doi.org/10.1109/ICRA46639.2022.9812249	Fabian Domberg, Carlos Castelar Wembers, Hiren Patel, Georg Schildbach
Deep Learning-driven Front-Following within Close Proximity: a Hands-Free Control Model on a Smart Walker.	With the ever-increasing elderly population, elder walking assistance is in strong demand. Instead of receiving assistance from a human carer, a smart walker can bring an elder user a more convenient and autonomous walking experience. Towards intelligent and safe walking assistance, we propose a close-proximity front-following model for smart walkers, which analyzes the walking gait and detects the walking intention of the user, and intelligently follows the user in the front to provide walking support, without the user pushing the walker. We design a deep learning model named Front-Following Net (FFLNet), consisting of CNN and LSTM networks to extract spatial and temporal features of the elder walking gait, collected in time windows through a thermal camera and a 2D LiDAR, for effective walking intention detection. As compared to other walking intention detection approaches, our model can explore more effective information in the gait data within a short walking period, and achieve accurate hands-free tracking of the user. Experiments show that our FFLNet can achieve over 77% detection accuracy among six representative walking intentions and more than 90% accuracy for turning intentions. Combined with a carefully designed walker control policy, our smart walker can achieve high front-following correctness with the user.	https://doi.org/10.1109/ICRA46639.2022.9811910	Chongyu Zhao, Wenzhi Guo, Rongwei Wen, Wang Zheng, Wu Chuan
Deep Networks for Point Cloud Map Validation.	Modern SLAM engines typically rely on high-end sensor rigs and robust algorithms to guarantee the high-quality requirements that self-driving cars and other complex autonomous systems require from 3D point cloud maps. Nonetheless, multiple factors can impact the reconstruction quality and it is not uncommon to end up with generally consistent maps affected by local distortions and artifacts, especially when mapping increasingly larger environments. We tackle the problem of identifying these low-consistency areas in point cloud maps by analyzing the quality of pair-wise point cloud alignments. Rather than relying on geometric consistency analysis or visual inspection, we leverage on deep point networks and formulate the validation as a binary classification problem, allowing us to quickly and effectively identify areas of improvement.	https://doi.org/10.1109/ICRA46639.2022.9811595	Nicole Camous, Sergi Adipraja Widjaja, Venice Erin Liong, Taigo Maria Bonanni
Deep Reinforcement Learning for Next-Best-View Planning in Agricultural Applications.	Automated agricultural applications, i.e., fruit picking require spatial information about crops and, especially, their fruits. In this paper, we present a novel deep reinforcement learning (DRL) approach to determine the next best view for automatic exploration of 3D environments with a robotic arm equipped with an RGB-D camera. We process the obtained images into an octree with labeled regions of interest (ROIs), i.e., fruits. We use this octree to generate 3D observation maps that serve as encoded input to the DRL network. We hereby do not only rely on known information about the environment, but explicitly also represent information about the unknown space to force exploration. Our network takes as input the encoded 3D observation map and the temporal sequence of camera view pose changes, and outputs the most promising camera movement direction. Our experimental results show an improved ROI targeted exploration performance resulting from our learned network in comparison to a state-of-the-art method.	https://doi.org/10.1109/ICRA46639.2022.9811800	Xiangyu Zeng, Tobias Zaenker, Maren Bennewitz
Deep Surrogate Q-Learning for Autonomous Driving.	Open challenges for deep reinforcement learning systems are their adaptivity to changing environments and their efficiency w.r.t. computational resources and data. In the application of learning lane-change behavior for autonomous driving, the number of required transitions imposes a bottleneck, since test drivers cannot perform an arbitrary amount of lane changes in the real world. In the off-policy setting, additional information on solving the task can be gained by observing actions from others. While in the classical RL setup this knowledge remains unused, we use other drivers as surrogates to learn the agent's value function more efficiently. We propose Surrogate Q-learning that deals with the aforementioned problems and reduces the required driving time drastically. We further propose an efficient implementation based on a permutation equivariant deep neural network architecture of the Q-function to estimate action-values for a variable number of vehicles in sensor range. We evaluate our method in the open traffic simulator SUMO and learn well performing driving policies on the real highD dataset.	https://doi.org/10.1109/ICRA46639.2022.9811618	Maria Kalweit, Gabriel Kalweit, Moritz Werling, Joschka Boedecker
Deep Visual Navigation under Partial Observability.	How can a robot navigate successfully in rich and diverse environments, indoors or outdoors, along office corridors or trails on the grassland, on the flat ground or the staircase? To this end, this work aims to address three challenges: (i) complex visual observations, (ii) partial observability of local visual sensing, and (iii) multimodal robot behaviors conditioned on both the local environment and the global navigation objective. We propose to train a neural network (NN) controller for local navigation via imitation learning. To tackle complex visual observations, we extract multi-scale spatial representations through CNNs. To tackle partial observability, we aggregate multi-scale spatial information over time and encode it in LSTMs. To learn multimodal behaviors, we use a separate memory module for each behavior mode. Importantly, we integrate the multiple neural network modules into a unified controller that achieves robust performance for visual navigation in complex, partially observable environments. We implemented the controller on the quadrupedal Spot robot and evaluated it on three challenging tasks: adversarial pedestrian avoidance, blind-spot obstacle avoidance, and elevator riding. The experiments show that the proposed NN architecture significantly improves navigation performance.	https://doi.org/10.1109/ICRA46639.2022.9811598	Bo Ai, Wei Gao, Vinay, David Hsu
Deep-CNN based Robotic Multi-Class Under-Canopy Weed Control in Precision Farming.	Smart weeding systems to perform plant-specific operations can contribute to the sustainability of agriculture and the environment. Despite monumental advances in autonomous robotic technologies for precision weed management in recent years, work on under-canopy weeding in fields is yet to be realized. A prerequisite of such systems is reliable detection and classification of weeds to avoid mistakenly spraying and, thus, damaging the surrounding plants. Real-time multi-class weed identification enables species-specific treatment of weeds and significantly reduces the amount of herbicide use. Here, our first contribution is the first adequately large realistic image dataset AIWeeds (one/multiple kinds of weeds in one image), a library of about 10,000 annotated images of flax and the 14 most common weeds in fields and gardens taken from 20 different locations in North Dakota, California, and Central China. Second, we provide a full pipeline from model training with maximum efficiency to deploying the TensorRT-optimized model onto a single board computer. Based on AIWeeds and the pipeline, we present a baseline for classification performance using five benchmark CNN models. Among them, MobileNetV2, with both the shortest inference time and lowest memory consumption, is the qualified candidate for real-time applications. Finally, we deploy MobileNetV2 onto our own compact autonomous robot SAMBot for real-time weed detection. The 90% test accuracy realized in previously unseen scenes in flax fields (with a row spacing of 0.2-0.3 m), with crops and weeds, distortion, blur, and shadows, is a milestone towards precision weed control in the real world. We have publicly released the dataset and code to generate the results at https://github.com/StructuresComp/Multi-class-Weed-Classification.	https://doi.org/10.1109/ICRA46639.2022.9812240	Yayun Du, Guofeng Zhang, Darren Tsang, Mohammad Khalid Jawed
Deliberation in autonomous robotic surgery: a framework for handling anatomical uncertainty.	Autonomous robotic surgery requires deliberation, i.e. the ability to plan and execute a task adapting to uncer-tain and dynamic environments. Uncertainty in the surgical domain is mainly related to the partial pre-operative knowledge about patient-specific anatomical properties. In this paper, we introduce a logic-based framework for surgical tasks with deliberative functions of monitoring and learning. The DE-liberative Framework for Robot-Assisted Surgery (DEFRAS) estimates a pre-operative patient-specific plan, and executes it while continuously measuring the applied force obtained from a biomechanical pre-operative model. Monitoring module compares this model with the actual situation reconstructed from sensors. In case of significant mismatch, the learning module is invoked to update the model, thus improving the estimate of the exerted force. DEFRAS is validated both in simulated and real environment with da Vinci Research Kit executing soft tissue retraction. Compared with state-of-the-art related works, the success rate of the task is improved while minimizing the interaction with the tissue to prevent unintentional damage.	https://doi.org/10.1109/ICRA46639.2022.9811820	Eleonora Tagliabue, Daniele Meli, Diego Dall'Alba, Paolo Fiorini
Demonstration-Efficient Guided Policy Search via Imitation of Robust Tube MPC.	We propose a demonstration-efficient strategy to compress a computationally expensive Model Predictive Controller (MPC) into a more computationally efficient representation based on a deep neural network and Imitation Learning (IL). By generating a Robust Tube variant (RTMPC) of the MPC and leveraging properties from the tube, we introduce a data augmentation method that enables high demonstration-efficiency, capable of compensating the distribution shifts typically encountered in IL. Our approach opens the possibility of zero-shot transfer from a single demonstration collected in a nominal domain, such as a simulation or a robot in a lab/controlled environment, to a domain with bounded model errors/perturbations. Numerical and experimental evaluations performed on a trajectory tracking MPC for a multirotor show that our method outperforms strategies commonly employed in IL, such as DAgger and Domain Randomization, in terms of demonstration-efficiency and robustness to perturbations unseen during training.	https://doi.org/10.1109/ICRA46639.2022.9812122	Andrea Tagliabue, Dong-Ki Kim, Michael Everett, Jonathan P. How
DenseTact: Optical Tactile Sensor for Dense Shape Reconstruction.	Increasing the performance of tactile sensing in robots enables versatile, in-hand manipulation. Vision-based tactile sensors have been widely used as rich tactile feedback has been shown to be correlated with increased performance in manipulation tasks. Existing tactile sensor solutions with high resolution have limitations that include low accuracy, expensive components, or lack of scalability. In this paper, an inexpensive, scalable, and compact tactile sensor with high-resolution surface deformation modeling for surface reconstruction of the 3D sensor surface is presented. By observing the contact surface with a fisheye camera, it is shown that the surface deformation can be estimated in real-time (1.8 ms) using deep convolutional neural networks. This sensor in its design and sensing abilities represents a significant step toward better object in-hand localization, classification, and surface estimation all enabled by calibrated, high-resolution shape reconstruction.	https://doi.org/10.1109/ICRA46639.2022.9811966	Won Kyung Do, Monroe Kennedy III
Deploying Traffic Smoothing Cruise Controllers Learned from Trajectory Data.	Autonomous vehicle-based traffic smoothing con-trollers are often not transferred to real-world use due to challenges in calibrating many-agent traffic simulators. We show a pipeline to sidestep such calibration issues by collecting trajectory data and learning controllers directly from trajectory data that are then deployed zero-shot onto the highway. We construct a dataset of 772.3 kilometers of recorded drives on the I–24. We then construct a simple simulator using the recorded drives as the lead vehicle in front of a simulated platoon consisting of one autonomous vehicle and five human followers. Using policy-gradient methods with an asymmetric critic to learn the controller, we show that we are able to improve average MPG by 11% in simulation on congested trajectories. We deploy this controller to a mixed platoon of 4 autonomous Toyota RAV-4's and 7 human drivers in a validation experiment and demonstrate that the expected time-gap of the controller is maintained in the real world test. Finally, we release the driving dataset [1], the simulator, and the trained controller at https://github.com/nathanlct/trajectory-training-icra.	https://doi.org/10.1109/ICRA46639.2022.9811912	Nathan Lichtlé, Eugene Vinitsky, Matthew Nice, Benjamin Seibold, Dan Work, Alexandre M. Bayen
Depth Completion Using Geometry-Aware Embedding.	Exploiting internal spatial geometric constraints of sparse LiDARs is beneficial to depth completion, however, has been not explored well. This paper proposes an efficient method to learn geometry-aware embedding, which encodes the local and global geometric structure information from 3D points, e.g., scene layout, object's sizes and shapes, to guide dense depth estimation. Specifically, we utilize the dynamic graph representation to model generalized geometric relationship from irregular point clouds in a flexible and efficient manner. Further, we joint this embedding and corresponded RGB appearance information to infer missing depths of the scene with well structure-preserved details. The key to our method is to integrate implicit 3D geometric representation into a 2D learning architecture, which leads to a better trade-off between the performance and efficiency. Extensive experiments demonstrate that the proposed method outperforms previous works and could reconstruct fine depths with crisp boundaries in regions that are over-smoothed by them. The ablation study gives more insights into our method that could achieve significant gains with a simple design, while having better generalization capability and stability. The code is available at https://github.com/Wenchao-Du/GAENet.	https://doi.org/10.1109/ICRA46639.2022.9811556	Wenchao Du, Hu Chen, Hongyu Yang, Yi Zhang
Depth Distribution Split Labeling for Rubble Recognition of Crushing Machine.	This paper describes rubble recognition using a depth image sensor and an automatic rubble crushing system using a construction machine for automatic rubble crushing at a building demolition site. Depth Distribution Split Labeling (DDSL) is proposed to recognize irregularly shaped rubble using depth images and to identify the largest rubble in the workspace. In DDSL, we focused on the fact that the depth of the contact area of adjacent rubble is lower, and labeling by dividing the depth makes it possible to identify the rubble. The automatic rubble crushing system enables to avoid excessive pushing and to grasp objects based on the cylinder driving force calculated from the hydraulic cylinder internal pressure of the construction machine. Through evaluation experiments simulating the crushing environment, it was confirmed that the proposed system can identify and automatically crush rubble.	https://doi.org/10.1109/ICRA46639.2022.9811689	Takahiro Ikeda, Satoshi Ueki, Kazuma Shinkai, Hironao Yamada
Depth Estimation Matters Most: Improving Per-Object Depth Estimation for Monocular 3D Detection and Tracking.	Monocular image-based 3D perception has become an active research area in recent years owing to its applications in autonomous driving. Approaches to monocular 3D perception including detection and tracking, however, often yield inferior performance when compared to LiDAR-based techniques. Through systematic analysis, we identified that per-object depth estimation accuracy is a major factor bounding the performance. Motivated by this observation, we propose a multi-level fusion method that combines different representations (RGB and pseudo-LiDAR) and temporal information across multiple frames for objects (tracklets) to enhance per-object depth estimation. Our proposed fusion method achieves the state-of-the-art performance of per-object depth estimation on the Waymo Open Dataset, the KITTI detection dataset, and the KITTI MOT dataset. We further demonstrate that by simply replacing estimated depth with fusion-enhanced depth, we can achieve significant improvements in monocular 3D perception tasks, including detection and tracking.	https://doi.org/10.1109/ICRA46639.2022.9811749	Longlong Jing, Ruichi Yu, Henrik Kretzschmar, Kang Li, Charles R. Qi, Hang Zhao, Alper Ayvaci, Xu Chen, Dillon Cower, Yingwei Li, Yurong You, Han Deng, Congcong Li, Dragomir Anguelov
Depth-Aware Vision-and-Language Navigation using Scene Query Attention Network.	Vision-and-language navigation (VLN) has been an important task in the field of Robotics and Computer Vision. However, most existing vision-and-language navigation models only use features extracted from RGB observation as input, while robots can utilize depth sensors in the real world. Existing research has also shown that simply adding a depth stream to neural models could only provide a marginal improvement to the performance of the VLN task. Therefore, in our work, we develop a novel method for the VLN task using semantic map observations built from RGB-D input. We use vision-pretraining to efficiently encode the semantic map with CNN and scene query attention network by answering queries about semantic information of specific regions of a scene. The proposed method could be used with a simple model and does not require large-scale vision-language transformer pretraining, bringing a more than 10% increase in the success rate compared with a baseline model. When used together with the Speaker-Follower training technique, it achieves a success rate of 58 % on the test set for the R2R dataset in single-run setting, outperforming the previous RGB-D method and most existing RGB-only models that do not use large-scale vision-language transformers pretraining.	https://doi.org/10.1109/ICRA46639.2022.9811921	Sinan Tan, Mengmeng Ge, Di Guo, Huaping Liu, Fuchun Sun
Depth-SIMS: Semi-Parametric Image and Depth Synthesis.	In this paper we present a compositing image synthesis method that generates RGB canvases with well aligned segmentation maps and sparse depth maps, coupled with an in-painting network that transforms the RGB canvases into high quality RGB images and the sparse depth maps into pixel-wise dense depth maps. We benchmark our method in terms of structural alignment and image quality, showing an increase in mIoU over SOTA by 3.7 percentage points and a highly competitive FID. Furthermore, we analyse the quality of the generated data as training data for semantic segmentation and depth completion, and show that our approach is more suited for this purpose than other methods.	https://doi.org/10.1109/ICRA46639.2022.9811569	Valentina Musat, Daniele De Martini, Matthew Gadd, Paul Newman
Design Exploration and Experimental Characterization of a 6 Degrees-of-Freedom Robotic Manipulator Powered by Cable-Driven Semi-Delocalized Magnetorheological Actuators.	Collaborative robots need to work closely and safely with users while being fast and strong. Fulfilling both these needs simultaneously presents a significant challenge, if not a roadblock, for conventional geared motor technology. Magnetorheological (MR) actuation is an alternative technology that has the potential to exhibit both safety and speed at the same time in a compact and cost-effective envelope. MR actuation has demonstrated great potential for low-DOF mechatronic devices in close collaboration with humans such as exoskeletons and flight control systems but its potential for high-DOF collaborative robots remains widely unexplored. This paper presents the design and experimental validation of a 6 DOF manipulator prototype actuated by semi-delocalized MR clutches. The manipulator is designed with the objective of matching or exceeding the performance requirements of today's cobots in order to verify the potential of MR actuation for such applications. Experimental results show that the prototype has a mass in motion of 5.3 kg and can move a 4.5 kg payload at 1 m/s in a range of 0.885 m. Force bandwidth is above 50 Hz and backdriving forces less than 10% of the joints maximum torque, assuring excellent dynamic performance. Furthermore, the manipulator prototype is shown to be inherently safe and impact-tolerant. In all, results suggest that semi-delocalized MR actuation is a promising solution for high performance cobots although future work is needed for the MR technology to reach full-maturity in robotics.	https://doi.org/10.1109/ICRA46639.2022.9812275	Mathieu Gervais, Louis-Philippe Lebel, Jean-Sébastien Plante
Design and Analysis of a Long-range Magnetic Actuated and Guided Endoscope for Uniport VATS.	This paper presents a long-range magnetic actuated and guided endoscope for uniport video-assisted thoracic surgery (VATS). In VATS, the incision is quite narrow and part of the chest wall may be very thick. So, the magnetic endoscope system is required to produce sufficient attractive force at a considerable distance with a compact dimension. In this paper, a magnetic endoscope system is developed to meet the aforementioned clinical demands. In the system, both the internal and external units consist of two cylindrical magnets at both ends and a semi-cylindrical magnet in the middle. Coupled with the magnetic field from the external unit, the internal endoscope can achieve anchoring, tilting, panning, and translating to provide the desired view for the surgeon. The rotation of the endoscope is dynamically modeled by combining magnetic theory and coordinate transformation. The prototype is made with a boundary box of 10×14×56 mm, which can be inserted through the narrow incision in VATS. In the experiment, the developed models of anchoring, tilting, and panning were verified. The magnet configuration in the system can achieve a static anchoring distance of 95 mm and exhibits enhancement in attractive force compared with other designs.	https://doi.org/10.1109/ICRA46639.2022.9811731	Jixiu Li, Tao Zhang, Truman Cheng, Yehui Li, Heng Zhang, Yisen Huang, Calvin Sze Hang Ng, Philip Wai Yan Chiu, Zheng Li
Design and Control of a Miniature Bipedal Robot with Proprioceptive Actuation for Dynamic Behaviors.	As the study of humanoid robots becomes a world-wide interdisciplinary research field, the demand for a cost-effective bipedal robot system capable of dynamic behaviors is growing exponentially. This paper presents a miniature bipedal robot named Bipedal Robot Unit with Compliance Enhanced (BRUCE). Each leg of BRUCE has five degrees of freedom (DoFs), which includes a spherical hip joint, a knee joint, and an ankle joint. To lower the leg inertia, a cable-driven differential pulley system and a linkage mechanism are applied to the hip and ankle joints, respectively. With the proposed design, BRUCE is able to achieve a similar range of motion to a human's lower body. The proprioceptive actuation and contact sensing further prepare BRUCE for interactions with unstructured environments. For real-time control of dynamic motions, a convex formulation for model hierarchy predictive control (MHPC) is introduced. MHPC plans with whole-body dynamics in the near horizon and simplified dynamics in the long horizon to benefit from both model accuracy and computational efficiency. A series of experiments were conducted to evaluate the overall system performance including hip joint analysis, walking, push recovery, and vertical jumping.	https://doi.org/10.1109/ICRA46639.2022.9811790	Yeting Liu, Junjie Shen, Jingwen Zhang, Xiaoguang Zhang, Taoyuanmin Zhu, Dennis W. Hong
Design and Development for Humanoid-Vehicle Transformer Platform with Plastic Resin Structure and Distributed Redundant Sensors.	The humanoid robot that can transform itself into a form according to its purpose requires whole-body motions with complex contact state transitions such as recovery from a fall and transition to the target form. To make the robot behavior in simulations closer to that in the real world for planning complex target trajectories, we need a platform that can measure the body stiffness during the motion and verify its application without being damaged by repeated motions that are prone to tipping over. In this study, we propose a small, inexpensive, and robust humanoid-vehicle transformer platform with redundant sensors and a low rigidity multi degree-of-freedom body and observe the effects of body deflection and internal forces during whole-body posture transition. By comparing the results obtained from experiments in several environments with different friction and from the simulator using a rigid body model, we were able to verify the influence of body flexibility on whole-body motion and the relationship between deflection and wrench observed by redundant sensors and movement failure.	https://doi.org/10.1109/ICRA46639.2022.9811683	Tasuku Makabe, Naoki Hiraoka, Shintaro Noda, Tomoki Anzai, Kohei Kimura, Mirai Hattori, Hiroya Sato, Fumihito Sugai, Yohei Kakiuchi, Kei Okada, Masayuki Inaba
Design and Evaluation of Object Classifiers for Probabilistic Decision-Making in Autonomous Systems.	Object classification is a key element that enables effective decision-making in many autonomous systems. A more sophisticated system may also utilize the probability distribution over the classes instead of basing its decision only on the most likely class. This paper introduces new performance metrics: the absolute class error (ACE), expectation of absolute class error (EACE) and variance of absolute class error (VACE) for evaluating the accuracy of such probabilities. We test this metric using different neural network architectures and datasets. Furthermore, we present a new task-based neural network for object classification and compare its performance with a typical probabilistic classification model to show the improvement with threshold-based probabilistic decision-making.	https://doi.org/10.1109/ICRA46639.2022.9812171	Hamad Ullah, Weisi Fan, Tichakorn Wongpiromsarn
Design and Modeling of a Compact Advancement Mechanism for a Modified COAST Guidewire Robot.	Peripheral vascular intervention remains a challenging procedure mainly due to the tortuosity of the vessels needing to be traversed by guidewires and catheters. In addition, handling long guidewires while navigating tortuous vasculature requires extensive time and skill from the surgeon. In this work, a compact guidewire advancement mechanism is proposed that is able to dispense guidewires up to 150 cm in length. The mechanism is adapted to actuate a prototype of the modified COaxially Aligned STeerable (COAST) guidewire robot to perform follow-the-leader (FTL) motion. The design of this mechanism consists of a spool, with actuation components nested inside to vary the bending length, actuate the tendon, and deflect the tip of the guidewire. The spool is mounted onto a lead screw that dispenses the guidewire with a tolerance of ±2mm. A modified bending joint kinematics and statics model is developed to characterize and validate the relationship between the tendon stroke and the desired curvature. The model is further used in a control system to navigate the distal tip through an ex vivo porcine aorta.	https://doi.org/10.1109/ICRA46639.2022.9811907	Patrick Lis, Achraj Sarma, Grace Trimpe, Timothy A. Brumfiel, Ronghuai Qi, Jaydev P. Desai
Design and Modeling of a Spherical Robot Actuated by a Cylindrical Drive.	Rolling spherical robots have been studied in the past few years as an alternative to legged and wheeled robots in unstructured environments. These systems are of uttermost interest for space exploration: fast, robust to collision and able to handle various terrain topologies. This paper introduces a novel barycentric spherical robot, dubbed the Autonomous Robotic Intelligent Explorer Sphere (ARIES). Equipped with an actuated cylindrical joint acting as a pendulum with two degrees-of-freedom (DoF), the ARIES has a continuous differential transmission to allow simultaneous rolling and steering. This mechanism allows an unprecedented mass allocation optimization, notably to provide a low center of mass. Kinematics and dynamics of this novel system are detailed. An analysis of the steering mechanism proves that it is more efficient than a more conventional 2-DoF tilting mechanism, while also retaining more space for a payload, for instance to host sensors for simultaneous localization and mapping, in the upper part of the sphere. Moreover, the kinematic input/output equations obtained significantly simplify the device's control. Finally, we present a first complete prototype with preliminary experimental tests.	https://doi.org/10.1109/ICRA46639.2022.9812148	Bruno Belzile, David St-Onge
Design and Optimization of a Magnetic Catcher for UAV Landing on Disturbed Aquatic Surface Platforms.	In this paper, a new capture system for UAV precision landing in a disturbed environment is proposed. Compared with the traditional visual guided landing methods, perching mechanism based methods, and tethered landing methods, the proposed system takes into account the stability during landing process and retains the high accessibility of the UAV. The proposed system consists of a winch subsystem and a magnetic catcher device. They establish an automatic tethered-UAV system for landing before the UAV touchdown. We analyzed the design principle as well as the feasibility of the magnetic catcher. An optimization problem is formulated to obtain a better layout of magnets on the catcher. The problem is relaxed based on interpolation simulation of attraction force. Experiments are conducted both in indoor and outdoor environments based on different UAV platforms respectively. The results validate that the catcher design and the capture system can achieve a successful landing in both cases.	https://doi.org/10.1109/ICRA46639.2022.9812270	Chongfeng Liu, Zixing Jiang, Ruoyu Xu, Xiaoqiang Ji, Lianxin Zhang, Huihuan Qian
Design and Quasistatic Modelling of Hybrid Continuum Multi-Arm Robots.	Continuum surgical robots can navigate anatomical pathways to reach pathological locations deep inside the human body. Their flexibility, however, generally comes with reduced dexterity at their tip and limited workspace. Building on recent work on eccentric tube robots, this paper proposes a new continuum robot architecture and theoretical framework that combines the flexibility of push/pull actuated snake robots and the dexterity offered by concentric tube robotic end-effectors. We designed and present a prototype system as a proof-of-concept, and developed a tailored quasistatic mechanics-based model that describes the shape and end-effector's pose for this new type robotic architecture. The model can accommodate an arbitrary number of arms placed eccentrically with respect to the backbone's neutral axis. Our experiments show that the error between model and experiment is on average 3.56% of the manipulator's overall length. This is in agreement with state of the art models of single type continuum architecture.	https://doi.org/10.1109/ICRA46639.2022.9811897	Zisos Mitros, S. M. Hadi Sadati, Sotirios Nousias, Lyndon Da Cruz, Christos Bergeles
Design and Tests of a Novel Adjustable-stiffness Force Sensor.	In this paper, a novel adjustable-stiffness force sensor is developed for multitask measurements requiring different force resolutions and ranges. The applied force of the force sensor is indirectly measured through the linear deformation instead of the structure strain through an optical linear encoder. The main structure of the force sensor is actually a linear variable stiffness mechanism with a compact size and a large stiffness change. Its stiffness can be continuously adjusted by changing the effective second moment of area of the structure. Thus, the force sensor has an adjustable range and resolution since the displacement resolution of the optical linear encoder is constant. The stiffness modeling of the sensor is performed based on the matrix method, which is then evaluated by the finite element analysis. A principle prototype is finally fabricated for the adjustable-stiffness test and a concrete application example. The testing results show that the stiffness and resolution of the force sensor can be changed by the proposed stiffness adjustment. Moreover, it is effective to measure different-resolution forces. This adjustable-stiffness approach can be also extended to the design of a torque sensor or a force/torque sensor.	https://doi.org/10.1109/ICRA46639.2022.9811826	Xiantao Sun, Xiaoyu Xiong, Wenjie Chen, Yali Zhi, Weihai Chen, Yan Jin
Design and experimental investigation of a vibro-impact self-propelled capsule robot with orientation control.	This paper presents a novel design and experimental investigation for a self-propelled capsule robot that can be used for painless colonoscopy during a retrograde progression from the patient's rectum. The steerable robot is driven forward and backward via its internal vibration and impact with orientation control by using an electromagnetic actuator. The actuator contains four sets of coils and a shaft made by permanent magnet. The shaft can be excited linearly in a controllable and tilted angle, so guide the progression orientation of the robot. Two control strategies are studied in this work and compared via simulation and experiment. Extensive results are presented to demonstrate the progression efficiency of the robot and its potential for robotic colonoscopy.	https://doi.org/10.1109/ICRA46639.2022.9812117	Jiajia Zhang, Jiyuan Tian, Dibin Zhu, Yang Liu, Shyam Prasad
Design by Robot: A Human-Robot Collaborative Framework for Improving Productivity of a Floor Cleaning Robot.	"In recent years, a rising trend of floor cleaning robots could be observed in the consumer electronic market. Area coverage performance is a crucial factor that determines the overall productivity of a floor cleaning robot. Nevertheless, the area coverage performance of commercially available floor cleaning robots is limited due to narrow spaces resulting from complex furniture arrangements. Traditionally, new robot designs (both hardware and algorithmic) are explored to over-come the coverage limitations. Developments of reconfiguration mechanisms and path planning algorithms for floor cleaning robots could be considered as examples. This paper proposes a novel concept called ""design by robot,"" enabling a floor cleaning robot to make suggestions on workspace modifications to maximize its area coverage performance in a given workspace. In this regard, the robot analyzes a workspace to be cleaned through internal simulations based on the metric map of the workspace. A metaheuristic optimization technique determines the optimum placings of objects. Particle Swarm Optimization (PSO), Surrogate Optimization (SO), and Generalized Pattern Search (GPS) are individually used in this regard. Experiments, including scenarios of robot deployments, have been considered for validation. The statistical outcomes of the experimental results validate that the area coverage performance of a floor cleaning robot could be significantly improved by considering the workspace modifications suggested by the robot. Moreover, the proposed concept ""design by robot"" enables users to gain significantly improved performance from floor cleaning robots through collaboration."	https://doi.org/10.1109/ICRA46639.2022.9812314	M. A. Viraj J. Muthugala, S. M. Bhagya P. Samarakoon, Mohan Rajesh Elara
Design of KAIST HOUND, a Quadruped Robot Platform for Fast and Efficient Locomotion with Mixed-Integer Nonlinear Optimization of a Gear Train.	This paper introduces a design method for an efficient and agile quadruped robot. A mixed-integer optimization formulation including the number of gear teeth is derived to obtain the optimal gear ratio that minimizes cost for a running-trot with the target speed of 3 m/s. With the inclusion of integer constraints related to the number of gear teeth, detailed design considerations of gear trains can be included in the optimization process. Thermal dissipation of the motor controller is also taken into account in the optimization to consider heat generation during high-speed running. KAIST Hound, a 45 kg robot, designed with the obtained design parameters has successfully demonstrated a 3 m/s running-trot using a nonlinear model predictive controller (NMPC). Furthermore, the robot has proved its robustness by the demonstration of additional experiments such as 22° slope climbing, 3.2 km walking, and traversing a 35 cm obstacle.	https://doi.org/10.1109/ICRA46639.2022.9811755	Young Ha Shin, Seungwoo Hong, Sangyoung Woo, Jonghun Choe, Harim Son, Gijeong Kim, Joon-Ha Kim, Kang Kyu Lee, Jemin Hwangbo, Hae-Won Park
Design of a Biomimetic Tactile Sensor for Material Classification.	Tactile sensing typically involves active exploration of unknown surfaces and objects, making it especially effective at processing the characteristics of materials and textures. A key property extracted by human tactile perception in material classification is surface roughness, which relies on measuring vibratory signals using the multi-layered fingertip structure. Existing robotic systems lack tactile sensors that are able to provide high dynamic sensing ranges, perceive material properties, and maintain a low hardware cost. In this work, we introduce the reference design and fabrication procedure of a miniature and low-cost tactile sensor consisting of a biomimetic cutaneous structure, including the artificial fingerprint, dermis, epidermis, and an embedded magnet-sensor structure which serves as a mechanoreceptor for converting mechanical information to digital signals. The presented sensor is capable of detecting high-resolution magnetic field data through the Hall effect and creating high-dimensional time-frequency domain features for material texture classification. Additionally, we investigate the effects of different superficial sensor fingerprint patterns for classifying materials through both simulation and physical experimentation. After extracting time series and frequency domain features, we assess a k-nearest neighbors classifier for distinguishing between different materials. The results from our experiments show that our biomimetic tactile sensors with fingerprint ridges can classify materials with more than 7.7% higher accuracy and lower variability than ridge-less sensors. These results, along with the low cost and customizability of our sensor, demonstrate high potential for lowering the barrier to entry for a wide array of robotic applications, including modelless tactile sensing for texture classification, material inspection, and object recognition.	https://doi.org/10.1109/ICRA46639.2022.9811543	Kevin Dai, Xinyu Wang, Allison M. Rojas, Evan Harber, Yu Tian, Nicholas Paiva, Joseph Gnehm, Evan Schindewolf, Howie Choset, Victoria A. Webster-Wood, Lu Li
Design of an Autonomous Latching System for Surface Vessels.	Autonomous latching is essential for autonomous surface vessels (ASV) to reach full independence from human intervention. As part of the ASV Roboat project, a new solution for self-latching maneuvers has been developed and is presented here. We propose a system that has the key requirements of full integration with the navigation control system and zero-gap connection with the dock, the latter being essential for wireless charging of the ASV. Dedicated markers are used to identify docking targets, relying on computer vision algorithms to determine distance and bearing to the target. In its idle state, the locking solution uses mechanical power-off brakes, minimizing energy consumption while ensuring the boat stays in position indefinitely once docked. A prototype of the proposed mechanism has been built and installed in Roboat. Experimental tests showing the mechanism performance and capability to autonomously approach the docking station are discussed in this work.	https://doi.org/10.1109/ICRA46639.2022.9811754	David Fernández-Gutiérrez, Niklas Hagemann, Wei Wang, Rens M. Doornbusch, Joshua Jordan, Jonathan Klein Schiphorst, Pietro Leoni, Fabio Duarte, Carlo Ratti, Daniela Rus
Designing a Highly Backdrivable and Kinematic Compatible Magneto-Rheological Knee Exoskeleton.	Lower limb exoskeletons have been successfully used in robotic-assisted rehabilitation. However, the design limitations of exoskeletons mechanics, such as weight and the lack of kinematic compatibility relative to the user's joints, limit the outcomes of treatment. To address these shortcomings, this work presents the design of a magneto-rheological fluid-based actuator for a knee exoskeleton, namely MRKE. The system was designed to ensure better mobility of the user, presenting high backdrivability and kinematic compatibility with the knee joint. The power train of system is a BLDC 70 W motor integrated to a harmonic drive gearbox. To improve kinematic compatibility relative to the user's knee, a four-bar crossed linkage mechanism (FBLM) was designed to follow the trajectory of the knee center of motion. A customized MR clutch was projected to decouple the motor-reducer from the FBLM, thus enabling high backdrivability. Preliminary results showed a small error (< 3 mm) between the FBLM and the knee center of rotation. Moreover, the MR clutch allowed for low backdrive torque (1.0 N.m) compared to the torque to backdrive the motor-reducer (16.6 N.m).	https://doi.org/10.1109/ICRA46639.2022.9812308	Rafhael M. de Andrade, Pedro H. F. Ulhoa, Claysson Bruno Santos Vimieiro
Detection of Slip from Vision and Touch.	Detecting the onset/ongoing of slip, i.e. if a grasped object is slipping or will slip from the gripper while being lifted, is crucial. Conventionally, it is regarded as a tactile sensing related problem. However, recently multi-modal robotic learning has become popular and is expected to boost the performance. In this paper we propose a novel CNN-TCN model to fuse tactile and visual information for detecting the onset/ongoing of slip. In our experiments, two uSkin tactile sensors and one Realsense435i camera are used. Data is collected by randomly grasping and lifting 35 daily objects 1050 times in total. Furthermore, we compare our CNN-TCN model with the widely used CNN-LSTM model. As a result, our proposed model achieves a 88.75% detection accuracy and outperforms the CNN-LSTM model combined with different pretrained vision networks.	https://doi.org/10.1109/ICRA46639.2022.9811589	Gang Yan, Alexander Schmitz, Tito Pradhono Tomo, Sophon Somlor, Satoshi Funabashi, Shigeki Sugano
Developing The Bottom-up Attentional System of A Social Robot.	This paper describes the development of a 3- stage signalling framework to trigger a social robot's bottom- up reactive behavior inspired by a biological model. In the first stage, low-level firing of stimuli due to external sources is constructed through perception grounding. This is followed by a saliency classifier which fires-up high level salient signals that require attention and are used to trigger the robot's reactive behavior. The whole framework evolves primarily on the knowledge ontology that defines the characteristics of the social robot and the querying mechanism that correlates the perceived stimuli with the ontology to trigger the reactive behavior. We evaluated the performance of our system with timing metrics and we achieved good results for our application.	https://doi.org/10.1109/ICRA46639.2022.9811759	Randy Gomez, Álvaro Páez, Yu Fang, Serge Thill, Luis Merino, Eric Nichols, Keisuke Nakamura, Heike Brock
Development and Analysis of a Biped Robot with Prismatic Compliance.	Previous studies suggest that bipedal robots that have prismatic compliance in the legs can achieve efficient walking. However, how this efficiency can be achieved still remains an open research problem. In this study, we developed a 2-degree-of-freedom planar bipedal robot comprising Neidhart springs and five-bar parallel mechanisms. The five-bar parallel mechanism allows the robot to achieve prismatic compliance. In addition, a lightweight torque limiter function is achieved by Neidhart springs with an original design. We implemented a simple controller and conducted walking experiments. Experimental results showed that the robot walked effectively using the regenerative energy stored in the prismatic springs.	https://doi.org/10.1109/ICRA46639.2022.9811962	Takumi Kamioka, Hirofumi Shin, Ryo Yamaguchi, Masaaki Muromachi
Development and Evaluation of a Gait Assistance System Based on Haptic Cane and Active Knee Orthosis.	Post-stroke gait rehabilitation is necessary to aid social re-integration. An active knee orthosis (AKO) can aid gait training through the provision of bodyweight support and assistive knee torque. However, its use may cause instability and it does not ensure improved gait symmetry and speed. Use of a speed regulation device such as a robotic cane in conjunction with and AKO may overcome these limitations. Therefore, to combine the beneficial effects of an AKO and speed regulation, we have devised a gait assistance system (GAS) that combines our developed AKO with our Haptic cane (HC) to provide combined knee assistance and speed regulation. The system can provide constant speed regulation and proprioceptive input to improve gait speed, symmetry and balance, while providing assistive torque to improve knee range of motion. The system is evaluated through tests with nine healthy subjects who wore ankle weights on one leg to simulate hemiparesis. The results show that for majority of the outcome measures (gait and balance parameters), use of the GAS and HC generated significantly better results than use of only the AKO. However, for nearly all the measures there were no significant differences between GAS and HC. Thus, the results indicate that the HC and GAS may be used according to patient's condition, where more severe patients who require assistive torque may use the GAS and less severe patients may use only the HC.	https://doi.org/10.1109/ICRA46639.2022.9812307	Hosu Lee, Amre Eizad, Junyeong Lee, Jungwon Yoon
Development of a Collaborative Wheeled Mobile Robot: Design Considerations, Drive Unit Torque Control, and Preliminary Result.	Nowadays, wheeled mobile robots constitute a considerable portion of robots in industrial applications. Generally, regardless of their purpose, these systems are not designed to physically interact with humans, other robots, or the environment. In this study, we present a novel safe autonomous mobile - SAM - robot, which is a torque-controlled compliant robot that is conceived for safe human-robot interaction. This work provides an overview of the development philosophy of the system, its mechanical and mechatronics structure along with control and navigation architecture. Preliminary results show the advantages of the proposed mobile robot while interacting with its surroundings. We believe that this study will bring the wheeled mobile robots one step closer to the proactive interaction with their environment and humans surrounding them.	https://doi.org/10.1109/ICRA46639.2022.9812006	Mehmet Can Yildirim, Mohamadreza Sabaghian, Thore Goll, Clemens Kössler, Christoph Jähne, Abdalla Swikir, Andriy Sarabakha, Sami Haddadin
Development of a Stereo-vision based High-throughput Robotic System for Mouse Tail Vein Injection.	In this paper, we present a robotic device for mouse tail vein injection. We propose a mouse holding mechanism to realize vein injection without anesthetizing the mouse, which consists of a tourniquet, vacuum port, and adaptive tail-end fixture. The position of the target vein in 3D space is reconstructed from a high-resolution stereo vision. The vein is detected by a simple but robust vein line detector. Thanks to the proposed two-staged calibration process, the total time for the injection process is limited to 1.5 minutes, despite that the position of needle and tail vein varies for each trial. We performed an injection experiment targeting 40 mice and succeeded to inject saline to 37 of them, resulting 92.5% success ratio.	https://doi.org/10.1109/ICRA46639.2022.9811804	Tianyi Ko, Koichi Nishiwaki, Koji Terada, Yusuke Tanaka, Shun Mitsumata, Ryuichi Katagiri, Taketo Junko, Naoshi Horiba, Hideyoshi Igata, Kazue Mizuno
Diff-Net: Image Feature Difference Based High-Definition Map Change Detection for Autonomous Driving.	Up-to-date High-Definition (HD) maps are essential for self-driving cars. To achieve constantly updated HD maps, we present a deep neural network (DNN), Diff-Net, to detect changes in them. Compared to traditional methods based on object detectors, the essential design in our work is a parallel feature difference calculation structure that infers map changes by comparing features extracted from the camera and rasterized images. To generate these rasterized images, we project map elements onto images in the camera view, yielding meaningful map representations that can be consumed by a DNN accordingly. As we formulate the change detection task as an object detection problem, we leverage the anchor-based structure that predicts bounding boxes with different change status categories. To the best of our knowledge, the proposed method is the first end-to-end network that tackles the high-definition map change detection task, yielding a single stage solution. Furthermore, rather than relying on single frame input, we introduce a spatio-temporal fusion module that fuses features from history frames into the current, thus improving the overall performance. Finally, we comprehensively validate our method's effectiveness using freshly collected datasets. Results demonstrate that our Diff-Net achieves better performance than the baseline methods and is ready to be integrated into a map production pipeline maintaining an up-to-date HD map.	https://doi.org/10.1109/ICRA46639.2022.9811573	Lei He, Shengjie Jiang, Xiaoqing Liang, Ning Wang, Shiyu Song
Digital Twin with Integrated Robot-Human/Environment Interaction Dynamics for an Industrial Mobile Manipulator.	To achieve real-time dynamic simulation analysis and optimization design, a dynamic digital twin of a nonholonomic mobile manipulator (one UR5e mounted on an industrial mobile robot MIR 200) has been developed in this paper. First, the digital twin integrated with dynamics of a mobile manipulator is established. The framework of the dynamic digital twin is presented in detail. Then, the dynamic model of the system has been established with the consideration of the physical interaction between the robot and humans/environments using Lagrange formulation. Finally, the experimental testing has been conducted to validate the dynamic model and evaluate the performances (such as real-time property, accuracy, etc.) of the dynamic digital twin that is integrated with the physical human/environment-robot interaction.	https://doi.org/10.1109/ICRA46639.2022.9812004	Zhengxue Zhou, Xingyu Yang, Hao Wang, Xuping Zhang
Dilated Continuous Random Field for Semantic Segmentation.	Mean field approximation methodology has laid the foundation of modern Continuous Random Field (CRF) based solutions for the refinement of semantic segmentation. In this paper, we propose to relax the hard constraint of mean field approximation - minimizing the energy term of each node from probabilistic graphical model, by a global optimization with the proposed dilated sparse convolution module (DSConv). In addition, adaptive global average-pooling and adaptive global max-pooling are implemented as replacements of fully connected layers. In order to integrate DSConv, we design an end-to-end, time-efficient DilatedCRF pipeline. The unary energy term is derived either from pre-softmax and post-softmax features, or the predicted affordance map using a conventional classifier, making it easier to implement DilatedCRF for varieties of classifiers. We also present superior experimental results of proposed approach on the suction dataset comparing to other CRF-based approaches.	https://doi.org/10.1109/ICRA46639.2022.9812064	Xi Mo, Xiangyu Chen, Cuncong Zhong, Rui Li, Kaidong Li, Usman Sajid
Discovering Synergies for Robot Manipulation with Multi-Task Reinforcement Learning.	Controlling robotic manipulators with high-dimensional action spaces for dexterous tasks is a challenging problem. Inspired by human manipulation, researchers have studied generating and using postural synergies for robot hands to accomplish manipulation tasks, leveraging the lower dimensional nature of synergistic action spaces. However, many of these works require pre-collected data from an existing controller in order to derive such a subspace by means of dimensionality reduction. In this paper, we present a framework that simultaneously discovers both a synergy space and a multi-task policy that operates on this low-dimensional action space to accomplish diverse manipulation tasks. We demonstrate that our end-to-end method is able to perform multiple tasks using few synergies, and outperforms sequential methods that apply dimensionality reduction to independently collected data. We also show that deriving synergies using multiple tasks can lead to a subspace that enables robots to efficiently learn new manipulation tasks and interactions with new objects.	https://doi.org/10.1109/ICRA46639.2022.9812170	Zhanpeng He, Matei T. Ciocarlie
Distributed Swarm Trajectory Optimization for Formation Flight in Dense Environments.	For aerial swarms, navigation in a prescribed formation is widely practiced in various scenarios. However, the associated planning strategies typically lack the capability of avoiding obstacles in cluttered environments. To address this deficiency, we present an optimization-based method that ensures collision-free trajectory generation for formation flight. In this paper, a novel differentiable metric is proposed to quantify the overall similarity distance between formations. We then formulate this metric into an optimization framework, which achieves spatial-temporal planning using polynomial trajectories. Minimization over collision penalty is also incorporated into the framework, so that formation preservation and obstacle avoidance can be handled simultaneously. To validate the efficiency of our method, we conduct benchmark comparisons with other cutting-edge works. Integrated with an autonomous distributed aerial swarm system, the proposed method demonstrates its efficiency and robustness in real-world experiments with obstacle-rich surroundings11https://www.youtube.com/watch?v=lFumtOrJci4. We will release the source code for the reference of the community22https://github.com/ZJU-FAST-Lab/Swarm-Formation.	https://doi.org/10.1109/ICRA46639.2022.9812050	Lun Quan, Longji Yin, Chao Xu, Fei Gao
Distributed Three Dimensional Flocking of Autonomous Drones.	Potential field approaches have been often used to describe and model interactions within a swarm of robots performing collective motion, also called flocking. Despite the high number of proposed approaches, most have only been tested in simulation and among the minority tested on real robots, even fewer abandoned the laboratory boundaries in favor of real-world scenarios. In this work, we propose a decentralized flocking approach that builds over the classical potential field models and that is proved to work well both in simulated and real-world environments. Each robot in the swarm relies on limited information and can only perceive its local neighbors through limited communication of noisy position information. No information on individual drone orientations, velocities, or accelerations is exchanged or needed. The novel experimental achievement of this paper is the realization of collective motion in three dimensions with the above sensing limitations. The swarm dynamically adapts to the environment by keeping a preferred distance from the ground and by changing formation. To show the general applicability of the proposed control algorithm, we study how it performs with the use of different potential functions proposed in the literature and by comparing them via extensive evaluation of the results in a realistic simulated environment. Lastly, we compare the performances of the proposed approach and of the different potentials on a real-drone swarm of up to fourteen robots flying both in two and three dimensional formations and in a challenging outdoor environment.	https://doi.org/10.1109/ICRA46639.2022.9811633	Dario Albani, Tiziano Manoni, Martin Saska, Eliseo Ferrante
Distributed Timed Elastic Band (DTEB) Planner: Trajectory Sharing and Collision Prediction for Multi-Robot Systems.	Autonomous navigation of mobile robots is a well-studied problem in robotics. However, the navigation task becomes challenging when multi-robot systems have to cooperatively navigate dynamic environments with deadlock-prone layouts. We present a Distributed Timed Elastic Band (DTEB) Planner that combines Prioritized Planning with the online TEB trajectory Planner, in order to extend the capabilities of the latter to multi-robot systems. The proposed planner is able to reactively avoid imminent collisions as well as predictively resolve potential deadlocks among a team of robots, while navigating in a complex environment. The results of our simulation demonstrate the reliable performance and the versatility of the planner in different environment settings. The code and tests for our approach are available online.	https://doi.org/10.1109/ICRA46639.2022.9811762	Yiu Ming Chung, Hazem Youssef, Moritz Roidl
Disturbance-injected Robust Imitation Learning with Task Achievement.	Robust imitation learning using disturbance injections overcomes issues of limited variation in demonstrations. However, these methods assume demonstrations are optimal, and that policy stabilization can be learned via simple augmentations. In real-world scenarios, demonstrations are often of diverse-quality, and disturbance injection instead learns sub-optimal policies that fail to replicate desired behavior. To address this issue, this paper proposes a novel imitation learning framework that combines both policy robustification and optimal demonstration learning. Specifically, this combinatorial approach forces policy learning and disturbance injection optimization to focus on mainly learning from high task achievement demonstrations, while utilizing low achievement ones to decrease the number of samples needed. The effectiveness of the proposed method is verified through experiments using an excavation task in both simulations and a real robot, resulting in high-achieving policies that are more stable and robust to diverse-quality demonstrations. In addition, this method utilizes all of the weighted sub-optimal demonstrations without eliminating them, resulting in practical data efficiency benefits.	https://doi.org/10.1109/ICRA46639.2022.9812376	Hirotaka Tahara, Hikaru Sasaki, Hanbit Oh, Brendan Michael, Takamitsu Matsubara
Domain Generalization for Vision-based Driving Trajectory Generation.	One of the challenges in vision-based driving trajectory generation is dealing with out-of-distribution scenarios. In this paper, we propose a domain generalization method for vision-based driving trajectory generation for autonomous vehicles in urban environments, which can be seen as a solution to extend the Invariant Risk Minimization (IRM) method in complex problems. We leverage an adversarial learning approach to train a trajectory generator as the decoder. Based on the pre-trained decoder, we infer the latent variables corresponding to the trajectories, and pre-train the encoder by regressing the inferred latent variable. Finally, we fix the decoder but fine-tune the encoder with the final trajectory loss. We compare our proposed method with the state-of-the-art trajectory generation method and some recent domain generalization methods on both datasets and simulation, demonstrating that our method has better generalization ability. Our project is available at https://sites.google.com/view/dg-traj-gen.	https://doi.org/10.1109/ICRA46639.2022.9812070	Yunkai Wang, Dongkun Zhang, Yuxiang Cui, Zexi Chen, Wei Jing, Junbo Chen, Rong Xiong, Yue Wang
Driving Swarm: A Swarm Robotics Framework for Intelligent Navigation in a Self-organized World.	Implementing and conducting reproducible experiments on multi-robot hardware platforms are challenging tasks due to variations in hardware, software, and most importantly the intensive implementation effort. In this paper, we aim to present the Driving Swarm software framework which is developed to facilitate the implementation, deployment, supervision, and analysis of multi-robot experiments. We use this framework with the TurtleBot3 hardware platform and measure its performance for two example scenarios: trajectory tracking and flocking behavior, with 5 and 6 robots. The goal of our experiments is to validate the simulation comparing to hardware implementations and to provide a baseline data for further experiments. While the simulated and real robots show similar behavior, we could observe that the simulated behavior is more robust than the real behavior in both scenarios. This effect is observed in the lower tracking error and better obstacle avoidance in both experiments. While the simulation proved to be a valuable tool during the development of the behaviors, the results confirm the importance of conducting experiments on a real-world test bed.	https://doi.org/10.1109/ICRA46639.2022.9811852	Sebastian Mai, Nele Traichel, Sanaz Mostaghim
Dual-scale robotic solution for middle ear surgery.	This paper deals with the control of a redundant robotic system for middle ear surgery (i.e., cholesteatoma tissues removal). The targeted robotic system is a macro-micro-scale robot composed of a redundant seven degrees of freedom (DoFs) on which is attached a two DoFs robotized flexible fiberscope. Two different control architectures are proposed to achieve a defined surgical procedure to remove the pathological tissue inside the middle ear cavity. The first proposed control mode is based on the position-based tele-operation of the entire system using a joystick (Phantom Omni) as a master arm. The second one combines comanipulation of the seven DoFs robotic arm using an embedded force/torque sensor and an end-frame tele-operation of the remaining two DoFs fiberscope using a lab-made in-hand joystick. Experimental validation is performed to evaluate and compare the performance of both developed control schemes. The obtained results using the lab-made platform and the proposed controllers are discussed.	https://doi.org/10.1109/ICRA46639.2022.9812365	Jae-Hun So, Brahim Tamadazte, Naresh Marturi, Jérôme Szewczyk
Dynamic Human-Robot Role Allocation based on Human Ergonomics Risk Prediction and Robot Actions Adaptation.	Even though cobots have high potential in bringing several benefits in the manufacturing and logistic processes, their rapid (re-)deployment in changing environments is still limited. To enable fast adaptation to new product demands and to boost the fitness of the human workers to the allocated tasks, we propose a novel method that optimizes assembly strategies and distributes the effort among the workers in human-robot cooperative tasks. The cooperation model exploits AND/OR Graphs that we adapted to solve also the role allocation problem. The allocation algorithm considers quantitative measurements that are computed online to describe human operators' ergonomic status and task properties. We conducted preliminary experiments to demonstrate that the proposed approach succeeds in controlling the task allocation process to ensure safe and ergonomic conditions for the human worker.	https://doi.org/10.1109/ICRA46639.2022.9812438	Elena Merlo, Edoardo Lamon, Fabio Fusaro, Marta Lorenzini, Alessandro Carfì, Fulvio Mastrogiovanni, Arash Ajoudani
Dynamic Mirror Descent based Model Predictive Control for Accelerating Robot Learning.	Recent works in Reinforcement Learning (RL) combine model-free (Mf)-RL algorithms with model-based (Mb)-RL approaches to get the best from both: asymptotic performance of Mf-RL and high sample-efficiency of Mb-RL. Inspired by these works, we propose a hierarchical framework that integrates online learning for the Mb-trajectory optimization with off-policy methods for the Mf-RL. In particular, two loops are proposed, where the Dynamic Mirror Descent based Model Predictive Control (DMD-MPC) is used as the inner loop Mb-RL to obtain an optimal sequence of actions. These actions are in turn used to significantly accelerate the outer loop Mf-RL. We show that our formulation is generic for a broad class of MPC based policies and objectives, and includes some of the well-known Mb-Mf approaches. We finally introduce a new algorithm: Mirror-Descent Model Predictive RL (M-DeMoRL), which uses Cross-Entropy Method (CEM) with elite fractions for the inner loop. Our experiments show faster convergence of the proposed hierarchical approach on benchmark MuJoCo tasks. We also demonstrate hardware training for trajectory tracking in a 2R leg, and hardware transfer for robust walking in a quadruped. We show that the inner-loop Mb-RL significantly decreases the number of training iterations required in the hardware setting, thereby validating the proposed approach.	https://doi.org/10.1109/ICRA46639.2022.9812089	Utkarsh A. Mishra, Soumya R. Samineni, Prakhar Goel, Chandravaran Kunjeti, Himanshu Lodha, Aman Singh, Aditya Sagi, Shalabh Bhatnagar, Shishir Kolathaya
Dynamic Modeling and Digital Twin of a Harmonic Drive Based Collaborative Robot Joint.	Collaborative robots are gradually taking over the leading position in automating the production and manufacturing of the SMEs, where the human-robot collaboration is highly emphasized. Therefore, estimating the force and simulating the performance of robots are of great importance. As a newly introduced technology, digital twin, has gained more attentions for simulation, process evaluation, real-time monitoring, etc. However, the current state-of-the-art of digital twin for robots still remains on the kinematic level, and the integrated robot system dynamics is too complex to be incorporated into the digital twin. Therefore, this research starts with the perspective of harmonic drive based robot joint, and proposes a dynamic model of robot joint by analyzing the composition, transmission principle, and internal interactions. Then the experimental parameter identification is performed to obtain the inherent parameters, which can reflect the system performance characteristics. Finally, a preliminary digital twin of robot joint integrated with dynamic model is established with Gazebo and MATLAB. The proposed approach could be used to simulate the dynamic behavior of robot joint in real time and make contributions to the state of the art for digital twin.	https://doi.org/10.1109/ICRA46639.2022.9812458	Xingyu Yang, Dong Qiang, Zixuan Chen, Hao Wang, Zhengxue Zhou, Xuping Zhang
Dynamic Robot Chain Networks for Swarm Foraging.	The objective of foraging robot swarms is to search for and collect resources in an unknown arena as quickly as possible. To avoid the congestion near the central collection zone, we previously proposed an extension to the multiple-place foraging in which robot chains are deployed dynamically so that foraging robots can deliver to the robot chains instead of the central collection zone. However, a robot chain can only reach one location at a time, and congestion can occur at the end of the robot chain. This paper presents an extension to dynamic robot chains called dynamic robot chain networks, which extends robot chains with branches, each of which reaches different resource clusters. We formulate the problem of finding the smallest dynamic robot chain networks as the Euclidean Steiner tree problem and explain how Steiner trees can be utilized to optimize the efficiency of the foraging operations. We implemented our foraging robot swarms in a simulator called ARGoS. Our experiments showed that dynamic robot chain networks can avoid obstacles and collect more resources when compared with the original robot chain design.	https://doi.org/10.1109/ICRA46639.2022.9811625	Dohee Lee, Qi Lu, Tsz-Chiu Au
Dynamic Underactuated Manipulator Using a Flexible Body with a Structural Anisotropy.	This paper presents a novel manipulation method utilizing dynamic deformation of a flexible body with a structural anisotropy. Employing a spiral flexible body, a dynamic underactuated manipulation using its various vibrational patterns is proposed. First, the orbit of the tip of flexible body for the vibrational input to its root is theoretically derived. Subsequently, for flexible bodies with and without the structural anisotropy, structural stiffness and vibrational orbit of the tip of body are analyzed. Through this analysis, the generation mechanism of the orbit change effect according to the input frequency is revealed. Finally, the proposed method is experimentally validated. After confirming the orbit change effect in a spiral flexible body, this effect is applied to an underactuated nonprehensile manipulation where three-Dof motion of an object is controlled by a single actuator.	https://doi.org/10.1109/ICRA46639.2022.9812191	Akihiro Maruo, Akihide Shibata, Mitsuru Higashimori
DynamicFilter: an Online Dynamic Objects Removal Framework for Highly Dynamic Environments.	Emergence of massive dynamic objects will diversify spatial structures when robots navigate in urban environments. Therefore, the online removal of dynamic objects is critical. In this paper, we introduce a novel online removal framework for highly dynamic urban environments. The framework consists of the scan-to-map front-end and the map-to-map back-end modules. Both the front- and back-ends deeply integrate the visibility-based approach and map-based approach. The experiments validate the framework in highly dynamic simulation scenarios and real-world dataset.	https://doi.org/10.1109/ICRA46639.2022.9812356	Tingxiang Fan, Bowen Shen, Hua Chen, Wei Zhang, Jia Pan
Dynamics-Aware Quality-Diversity for Efficient Learning of Skill Repertoires.	Quality-Diversity (QD) algorithms are powerful exploration algorithms that allow robots to discover large repertoires of diverse and high-performing skills. However, QD algorithms are sample inefficient and require millions of evaluations. In this paper, we propose Dynamics-Aware Quality-Diversity (DA-QD), a framework to improve the sample efficiency of QD algorithms through the use of dynamics models. We also show how DA-QD can then be used for continual acquisition of new skill repertoires. To do so, we incrementally train a deep dynamics model from experience obtained when performing skill discovery using QD. We can then perform QD exploration in imagination with an imagined skill repertoire. We evaluate our approach on three robotic experiments. First, our experiments show DA-QD is 20 times more sample efficient than existing QD approaches for skill discovery. Second, we demonstrate learning an entirely new skill repertoire in imagination to perform zero-shot learning. Finally, we show how DA-QD is useful and effective for solving a long horizon navigation task and for damage adaptation in the real world. Videos and source code are available at: https://sites.google.com/view/da-qd.	https://doi.org/10.1109/ICRA46639.2022.9811559	Bryan Lim, Luca Grillotti, Lorenzo Bernasconi, Antoine Cully
EDPLVO: Efficient Direct Point-Line Visual Odometry.	This paper introduces an efficient direct visual odometry (VO) algorithm using points and lines. Pixels on lines are generally adopted in direct methods. However, the original photometric error is only defined for points. It seems difficult to extend it to lines. In previous works, the collinear constraints for points on lines are either ignored [1] or introduce heavy computational load into the resulting optimization system [2]. This paper extends the photometric error for lines. We prove that the 3D points of the points on a 2D line are determined by the inverse depths of the endpoints of the 2D line, and derive a closed-form solution for this problem. This property can significantly reduce the number of variables to speed up the optimization, and can make the collinear constraint exactly satisfied. Furthermore, we introduce a two-step method to further accelerate the optimization, and prove the convergence of this method. The experimental results show that our algorithm outperforms the state-of-the-art direct VO algorithms.	https://doi.org/10.1109/ICRA46639.2022.9812133	Lipu Zhou, Guoquan Huang, Yinian Mao, Shengze Wang, Michael Kaess
Easing Reliance on Collision-free Planning with Contact-aware Control.	"We believe that the future of robot motion planning will look very different than how it looks today: instead of complex collision avoidance trajectories with a brittle dependence on sensing and estimation of the environment, motion plans should consist of smooth, simple trajectories and be executed by robots that are not afraid of making contact. Here we present a ""contact-aware"" controller which continues to execute a given trajectory despite unexpected collisions while keeping the contact force stable and small. We introduce a quadratic programming (QP) formulation, which minimizes a trajectory-tracking error subject to quasistatic dynamics and contact-force constraints. Compared with the classical null-space projection technique, the inequality constraint on contact forces in the proposed QP controller allows for more gentle release when the robot comes out of contact. In the quasistatic dynamics model, control actions consist only of commanded joint positions, allowing the QP controller to run on stiffness-controlled robots which do not have a straightforward torque-control interface nor accurate dynamic models. The effectiveness of the proposed QP controller is demonstrated on a KUKA iiwa arm. Project video: https://youtu.be/M-7JMQRkiPk."	https://doi.org/10.1109/ICRA46639.2022.9811631	Tao Pang, Russ Tedrake
Effectiveness of Augmented Reality for Human Swarm Interactions.	Human-Swarm Interaction (HSI) is a fast-growing research area in swarm robotics. One challenging aspect of HSI is facilitating effective handling of the many degrees-of-freedom present in robot swarms by humans. One emergent option is the use of Augmented Reality (AR) systems to encode information. AR based interfaces can help provide human operators with visual cues about the swarm's states and control to facilitate decision-making. In research settings, AR systems can address issues such as limited availability of lab spaces, limited access to robotics resources, and the need for the ability to simulate dynamic environments with which robots and humans can interact. Further, to make swarm robotics more accessible and ubiquitous, HSI systems that support remote interaction would allow humans to interact with robot swarms and multi-robot systems regardless of the geographical distance between humans and swarms. Taking these into consideration, we aim to investigate the effectiveness of AR based interfaces as tools for remote interaction in HSI systems. We developed a simple AR based interface and evaluated its effectiveness against an unaugmented interface, by means of remote human user studies where a human operator would control a team of robots remotely through a video call. Our finding suggests that augmentation can improve control accuracy and reduce collision safety violations when performing navigation tasks. Through experimental surveys, it is shown that operators with varying levels of robotics and technology experience overwhelmingly prefer the augmented interface to facilitate swarm control. These results suggest that AR-based interfaces are effective in improving the control experience in remote HSI.	https://doi.org/10.1109/ICRA46639.2022.9812080	Sarjana Oradiambalam Sachidanandam, Sara Honarvar, Yancy Diaz-Mercado
Effects of Interfaces on Human-Robot Trust: Specifying and Visualizing Physical Zones.	"In this paper we investigate the influence interfaces and feedback have on human-robot trust levels when operating in a shared physical space. The task we use is specifying a ""no-go"" region for a robot in an indoor environment. We evaluate three styles of interface (physical, AR, and map-based) and four feedback mechanisms (no feedback, robot drives around the space, an AR ""fence"", and the region marked on the map). Our evaluation looks at both usability and trust. Specifically, if the participant trusts that the robot ""knows"" where the no-go region is and their confidence in the robot's ability to avoid that region. We use both self-reported and indirect measures of trust and usability. Our key findings are: 1) interfaces and feedback do influence levels of trust; 2) the participants largely preferred a mixed interface-feedback pair, where the modality for the interface differed from the feedback."	https://doi.org/10.1109/ICRA46639.2022.9811538	Marisa Hudspeth, Sogol Balali, Cindy Grimm, Ross T. Sowell
Efficient Object Manipulation to an Arbitrary Goal Pose: Learning-Based Anytime Prioritized Planning.	We focus on the task of object manipulation to an arbitrary goal pose, in which a robot is supposed to pick an assigned object to place at the goal position with a specific orientation. However, limited by the execution space of the manipulator with gripper, one-step picking, moving and releasing might be failed, where a reorientation object pose is required as a transition. In this paper, we propose a learning-driven anytime prioritized search-based solver to find a feasible solution with low path cost in a short time. In our work, the problem is formulated as a hierarchical learning problem, with the high level finding a reorientation object pose, and the low level planning paths between adjacent grasps. We learn an offline-training path cost estimator to predict approximate path planning costs, which serve as pseudo rewards to allow for pre-training the high-level planner without interacting with the simulator. To deal with the problem of distribution mismatch of the cost net and the actual execution cost space, a refined training stage is conducted with simulation interaction. A series of experiments carried out in simulation and real world indicate that our system can achieve better performances in the object manipulation task with less time and less cost.	https://doi.org/10.1109/ICRA46639.2022.9811547	Kechun Xu, Hongxiang Yu, Renlang Huang, Dashun Guo, Yue Wang, Rong Xiong
Efficient and High-quality Prehensile Rearrangement in Cluttered and Confined Spaces.	Prehensile object rearrangement in cluttered and confined spaces has broad applications but is also challenging. For instance, rearranging products in a grocery shelf means that the robot cannot directly access all objects and has limited free space. This is harder than tabletop rearrangement where objects are easily accessible with top-down grasps, which simplifies robot-object interactions. This work focuses on problems where such interactions are critical for completing tasks. It proposes a new efficient and complete solver under general constraints for monotone instances, which can be solved by moving each object at most once. The monotone solver reasons about robot-object constraints and uses them to effectively prune the search space. The new monotone solver is integrated with a global planner to solve non-monotone instances with high-quality solutions fast. Furthermore, this work contributes an effective pre-processing tool to significantly speed up online motion planning queries for rearrangement in confined spaces. Experiments further demonstrate that the proposed monotone solver, equipped with the pre-processing tool, results in 57.3% faster computation and 3 times higher success rate than state-of-the-art methods. Similarly, the resulting global planner is computationally more efficient and has a higher success rate, while producing high-quality solutions for non-monotone instances (i.e., only 1.3 additional actions are needed on average). Videos of demonstrating solutions on a real robotic system and codes can be found at https://github.com/Rui1223/uniform_object_rearrangement.	https://doi.org/10.1109/ICRA46639.2022.9811934	Rui Wang, Yinglong Miao, Kostas E. Bekris
Efficient and Robust Semantic Mapping for Indoor Environments.	A key proficiency an autonomous mobile robot must have to perform high-level tasks is a strong understanding of its environment. This involves information about what types of objects are present, where they are, what their spatial extend is, and how they can be reached, i.e., information about free space is also crucial. Semantic maps are a powerful instrument providing such information. However, applying semantic segmentation and building 3D maps with high spatial resolution is challenging given limited resources on mobile robots. In this paper, we incorporate semantic information into efficient occupancy normal distribution transform (NDT) maps to enable real-time semantic mapping on mobile robots. On the publicly available dataset Hypersim, we show that, due to their sub-voxel accuracy, semantic NDT maps are superior to other approaches. We compare them to the recent state-of-the-art approach based on voxels and semantic Bayesian spatial kernel inference (S-BKI) and to an optimized version of it derived in this paper. The proposed semantic NDT maps can represent semantics to the same level of detail, while mapping is 2.7 to 17.5 times faster. For the same grid resolution, they perform significantly better, while mapping is up to more than 5 times faster. Finally, we prove the real-world applicability of semantic NDT maps with qualitative results in a domestic application.	https://doi.org/10.1109/ICRA46639.2022.9812205	Daniel Seichter, Patrick Langer, Tim Wengefeld, Benjamin Lewandowski, Dominik Höchemer, Horst-Michael Gross
Efficient and Robust Training of Dense Object Nets for Multi-Object Robot Manipulation.	We propose a framework for robust and efficient training of Dense Object Nets (DON) [1] with a focus on industrial multi-object robot manipulation scenarios. DON is a popular approach to obtain dense, view-invariant object descriptors, which can be used for a multitude of downstream tasks in robot manipulation, such as, pose estimation, state representation for control, etc. However, the original work [1] focused training on singulated objects, with limited results on instance-specific, multi-object applications. Additionally, a complex data collection pipeline, including 3D reconstruction and mask annotation of each object, is required for training. In this paper, we further improve the efficacy of DON with a simplified data collection and training regime, that consistently yields higher precision and enables robust tracking of keypoints with less data requirements. In particular, we focus on training with multi-object data instead of singulated objects, combined with a well-chosen augmentation scheme. We additionally propose an alternative loss formulation to the original pixel wise formulation that offers better results and is less sensitive to hyperparameters. Finally, we demonstrate the robustness and accuracy of our proposed framework on a real-world robotic grasping task.	https://doi.org/10.1109/ICRA46639.2022.9812274	David B. Adrian, Andras Gabor Kupcsik, Markus Spies, Heiko Neumann
Elastic Tracker: A Spatio-temporal Trajectory Planner for Flexible Aerial Tracking.	This paper proposes Elastic Tracker, a flexible trajectory planning framework that can deal with challenging tracking tasks with guaranteed safety and visibility. Firstly, an object detection and intension-free motion prediction method is designed. Then an occlusion-aware path finding method is proposed to provide a proper topology. A smart safe flight corridor generation strategy is designed with the guiding path. An analytical occlusion cost is evaluated. Finally, an effective trajectory optimization approach enables to generate a spatio-temporal optimal trajectory within the resultant flight corridor. Particular formulations are designed to guarantee both safety and visibility, with all the above requirements optimized jointly. The experimental results show that our method works more robustly but with less computation than the existing methods, even in some challenging tracking tasks.	https://doi.org/10.1109/ICRA46639.2022.9811688	Jialin Ji, Neng Pan, Chao Xu, Fei Gao
ElectroVoxel: Electromagnetically Actuated Pivoting for Scalable Modular Self-Reconfigurable Robots.	This paper introduces a cube-based reconfigurable robot that utilizes an electromagnet-based actuation framework to reconfigure in three dimensions via pivoting. While a variety of actuation mechanisms for self-reconfigurable robots have been explored, they often suffer from cost, complexity, assembly and sizing requirements that prevent scaled production of such robots. To address this challenge, we use an actuation mechanism based on electromagnets embedded into the edges of each cube to interchangeably create identically or oppositely polarized electromagnet pairs, resulting in repulsive or attractive forces, respectively. By leveraging attraction for hinge formation, and repulsion to drive pivoting maneuvers, we can reconfigure the robot by voxelizing it and actuating its constituent modules-termed Electrovoxels-via electromagnetically actuated pivoting. To demonstrate this, we develop fully untethered, three-dimensional self-reconfigurable robots and demonstrate 2D and 3D self-reconfiguration using pivot and traversal maneuvers on an air-table and in microgravity on a parabolic flight. This paper describes the hardware design of our robots, its pivoting framework, our reconfiguration planning software, and an evaluation of the dynamical and electrical characteristics of our system to inform the design of scalable self-reconfigurable robots.	https://doi.org/10.1109/ICRA46639.2022.9811746	Martin Nisser, Leon Cheng, Yashaswini Makaram, Ryo Suzuki, Stefanie Müller
Energy Sharing Mechanism for a Freeform Robotic System - FreeBOT.	Energy sharing in modular self-reconfigurable robots ensures the energy balance of the modules, thus allowing the system to work sustainably. This paper proposes an energy sharing mechanism for a novel modular self-reconfigurable robot that allows free connections among modules, termed as FreeBOT, such that each FreeBOT can share energy with peers through surface contact. Corresponding energy sharing rules are proposed to achieve an energy sharing network structure without invalid components. As alternative choices, several types of networks subjected to the above requirements are provided, which also maximize the number of FreeBOTs joining to share energy. We implement and test the prototype of the energy sharing mechanism on FreeBOT. The experimental results show that the mechanism can effectively achieve energy sharing among FreeBOTs.	https://doi.org/10.1109/ICRA46639.2022.9811860	Guanqi Liang, Yuxiao Tu, Lijun Zong, Junfeng Chen, Tin Lun Lam
Energy Tank-Based Policies for Robust Aerial Physical Interaction with Moving Objects.	Although manipulation capabilities of aerial robots greatly improved in the last decade, only few works addressed the problem of aerial physical interaction with dynamic environments, proposing strongly model-based approaches. However, in real scenarios, modeling the environment with high accuracy is often impossible. In this work, we aim at developing a control framework for Omnidirectional Micro Aerial Vehicles (OMAVs) for reliable physical interaction tasks with articulated and movable objects in the presence of possibly unforeseen disturbances, and without relying on an accurate model of the environment. Inspired by previous applications of energy-based controllers for physical interaction, we propose a passivity-based impedance and wrench tracking controller in combination with a momentum-based wrench estimator. This is combined with an energytank framework to guarantee the stability of the system, while energy and power flow-based adaptation policies are deployed to enable safe interaction with any type of passive environment. The control framework provides formal guarantees of stability, which is validated in practice considering the challenging task of pushing a cart of unknown mass, moving on a surface of unknown friction, as well as subjected to unknown disturbances. For this scenario, we present, evaluate and discuss three different policies.	https://doi.org/10.1109/ICRA46639.2022.9812342	Maximilian Brunner, Livio Giacomini, Roland Siegwart, Marco Tognon
Enhanced Prototypical Learning for Unsupervised Domain Adaptation in LiDAR Semantic Segmentation.	"Despite its importance, unsupervised domain adaptation (UDA) on LiDAR semantic segmentation is a task that has not received much attention from the research community. Only recently, a completion-based 3
D
method has been proposed to tackle the problem and formally set up the adaptive scenarios. However, the proposed pipeline is complex, voxel-based and requires multi-stage inference, which inhibits it for real-time inference. We propose a range image-based, effective and efficient method for solving UDA on LiDAR segmentation. The method exploits class prototypes from the source domain to pseudo label target domain pixels, which is a research direction showing good performance in UDA for natural image semantic segmentation. Applying such approaches to LiDAR scans has not been considered because of the severe domain shift and lack of pre-trained feature extractor that is unavailable in the LiDAR segmentation setup. However, we show that proper strategies, including reconstruction-based pre-training, enhanced prototypes, and selective pseudo labeling based on distance to prototypes, is sufficient enough to enable the use of prototypical approaches. We evaluate the performance of our method on the recently proposed LiDAR segmentation UDA scenarios. Our method achieves remarkable performance among contemporary methods."	https://doi.org/10.1109/ICRA46639.2022.9811838	Eojindl Yi, JuYoung Yang, Junmo Kim
Enhanced Spatial Attention Graph for Motion Planning in Crowded, Partially Observable Environments.	Collision-free navigation while moving amongst static and dynamic obstacles with a limited sensor range is still a great challenge for modern mobile robots. Therefore, the ability to avoid collisions with obstacles in crowded, partially observable environments is one of the most important indicators to measure the navigation performance of a mobile robot. In this paper, we propose a novel deep reinforcement learning architecture that combines a spatial graph and attention rea-soning to tackle this problem. We take the relative positions and velocities of observed humans as nodes of the spatial graph and robot-human pairs as nodes of the attention graph to capture the spatial relations between the robot and the humans. In this way, our approach enhances the modeling of the relationship between the moving robot, static obstacles, and the people in the surrounding. As a result, our proposed navigation framework significantly outperforms state-of-the-art approaches [1], [2] in crowded scenarios when the robot has only a limited sensor range in terms of a reduced collision rate. Furthermore, we realize a seriously decreased training time by applying parallel Double Deep Q-Learning.	https://doi.org/10.1109/ICRA46639.2022.9812322	Weixian Shi, Yanying Zhou, Xiangyu Zeng, Shijie Li, Maren Bennewitz
Enhancing Data-Driven Reachability Analysis using Temporal Logic Side Information.	This paper presents algorithms for performing data-driven reachability analysis under temporal logic side information. In certain scenarios, the data-driven reachable sets of a robot can be prohibitively conservative due to the inherent noise in the robot's historical measurement data. In the same scenarios, we often have side information about the robot's expected motion (e.g., limits on how much a robot can move in a one-time step) that could be useful for further specifying the reachability analysis. In this work, we show that if we can model this side information using a signal temporal logic (STL) fragment, we can constrain the data-driven reachability analysis and safely limit the conservatism of the computed reachable sets. Moreover, we provide formal guarantees that, even after incorporating side information, the computed reachable sets still properly over-approximate the robot's future states. Lastly, we empirically validate the prac-ticality of the over-approximation by computing constrained, data-driven reachable sets for the Small- Vehicles-for-Autonomy (SVEA) hardware platform in two driving scenarios.	https://doi.org/10.1109/ICRA46639.2022.9811706	Amr Alanwar, Frank J. Jiang, Maryam Sharifi, Dimos V. Dimarogonas, Karl Henrik Johansson
Enhancing Deep Reinforcement Learning Approaches for Multi-Robot Navigation via Single-Robot Evolutionary Policy Search.	"Recent Multi-Agent Deep Reinforcement Learning approaches factorize a global action-value to address non-stationarity and favor cooperation. These methods, however, hinder exploration by introducing constraints (e.g., additive value-decomposition) to guarantee the factorization. Our goal is to enhance exploration and improve sample efficiency of multi-robot mapless navigation by incorporating a periodical Evolutionary Policy Search (EPS). In detail, the multi-agent training ""specializes"" the robots' policies to learn the collision avoidance skills that are mandatory for the task. Concurrently, in this work we propose the use of Evolutionary Algorithms to explore different regions of the policy space in an environment with only a single robot. The idea is that core navigation skills, originated by the multi-robot policies using mutation operators, improve faster in the single-robot EPS. Hence, policy parameters can be injected into the multi-robot setting using crossovers, leading to improved performance and sample efficiency. Experiments in tasks with up to 12 robots confirm the beneficial transfer of navigation skills from the EPS to the multi-robot setting, improving the performance of prior methods."	https://doi.org/10.1109/ICRA46639.2022.9812341	Enrico Marchesini, Alessandro Farinelli
Enhancing Flexibility and Adaptability in Conjoined Human-Robot Industrial Tasks with a Minimalist Physical Interface.	This paper presents a physical interface for collaborative mobile manipulators in industrial manufacturing and logistics applications. The proposed work builds on our earlier MOCA-MAN interface, through which an operator could be physically coupled to a mobile manipulator to be assisted in performing daily activities. The previous interface was based on a magnetic clamp attached to one arm of the user for the coupling stage, and a bracelet based on EMG sensors on the other arm for human-robot communication via gestures. The new interface instead presents the following additions: i) An industrial-like design that allows the worker to couple/decouple easily and to operate mobile manipulators locally; ii) A simplistic communication channel via a simple buttons board that allows controlling the robot with one hand only; iii) The interface offers enhanced loco-manipulation capabilities that do not compromise the worker mobility. In addition, an experimental evaluation with six human subjects is carried out to analyze the enhanced locomotion and flexibility of the proposed interface in terms of mobility constraint, usability, and physical load reduction.	https://doi.org/10.1109/ICRA46639.2022.9812225	Juan M. Gandarias, Pietro Balatti, Edoardo Lamon, Marta Lorenzini, Arash Ajoudani
Enhancing Maneuverability via Gait Design.	"The gaits of locomoting systems are typically designed to maximize some sort of efficiency, such as cost of transport or speed. Equally important is the ability to modulate such a gait to effect turning maneuvers. For drag-dominated systems, geometric mechanics provides an elegant and practical framework for both ends—gait design and gait modulation. Within this framework, ""constraint curvature"" maps can be used to approximate the net displacement of robotic systems over cyclic gaits. Gait optimization is made possible under a previously reported ""soap-bubble"" algorithm. In this work, we propose both local and global gait morphing algorithms to modify a nominal gait to provide single-parameter steering control. Using a simplified swimmer, we numerically compare the two approaches and show that for modest turns, the local approach, while suboptimal, nevertheless proves effective for steering control. A potential advantage of the local approach is that it can be readily applied to soft robots or other systems where local approximations to the constraint curvature can be garnered from data, but for which obtaining an exact global model is infeasible."	https://doi.org/10.1109/ICRA46639.2022.9812061	Siming Deng, Ross L. Hatton, Noah J. Cowan
Ensemble Kalman Filter Based LiDAR Odometry for Skewed Point Clouds Using Scan Slicing.	In the presence of fast motion, point clouds obtained from mechanical spinning LiDAR can be easily distorted due to the slow scanning speed of the LiDAR. Existing LiDAR-only odometry algorithms generally ignore this distortion or compensate by linearly interpolating the estimated relative motion between scans. However, when there are abrupt and nonlinear motion changes, the linear interpolation method poorly compensates for the distortions, which can cause significant drift in motion estimates. In this work, we present a LiDAR-only odometry algorithm that estimates motion by slicing LiDAR scans into shorter times to compensate more agilely for point cloud distortions. Observations from only one small scan slice inevitably lack spatial uniqueness, so the multimodal problem needs to be addressed. For LiDAR-only odometry with small scan slices, we introduce the ensemble Kalman filter, a kind of Monte Carlo-based Bayesian filter. The proposed method makes it possible to perform odometry with only a very narrow field of view (FoV), and the robustness to point cloud distortion is improved. We demonstrate the effectiveness of the proposed method through Monte Carlo simulations and several tests with fast-moving scenarios. The experimental results prove the possibility of odometry with a very narrow FoV of down to 10 degrees and robustness against motion distortion.	https://doi.org/10.1109/ICRA46639.2022.9811710	Yeongkwon Choe, Jae-Hyung Jung, Chan Gook Park
Equivariant Filter Design for Inertial Navigation Systems with Input Measurement Biases.	Inertial Navigation Systems (INS) are a key technology for autonomous vehicles applications. Recent advances in estimation and filter design for the INS problem have exploited geometry and symmetry to overcome limitations of the classical Extended Kalman Filter (EKF) approach that formed the mainstay of INS systems since the mid-twentieth century. The industry standard INS filter, the Multiplicative Extended Kalman Filter (MEKF), uses a geometric construction for attitude estimation coupled with classical Euclidean construction for position, velocity and bias estimation. The recent Invariant Extended Kalman Filter (IEKF) provides a geometric framework for the full navigation states, integrating attitude, position and velocity, but still uses the classical Euclidean construction to model the bias states. In this paper, we use the recently proposed Equivariant Filter (EqF) framework to derive a novel observer for biased inertial-based navigation in a fully geometric framework. The introduction of virtual velocity inputs with associated virtual bias leads to a full equivariant symmetry on the augmented system. The resulting filter performance is evaluated with both simulated and real-world data, and demonstrates increased robustness to a wide range of erroneous initial conditions, and improved accuracy when compared with the industry standard Multiplicative EKF (MEKF) approach.	https://doi.org/10.1109/ICRA46639.2022.9811778	Alessandro Fornasier, Yonhon Ng, Robert E. Mahony, Stephan Weiss
Estimation of Upper Limb Kinematics with a Magnetometer-Free Egocentric Visual-Inertial System.	Most human activities in daily living or professional work rely on upper body motion. Measuring upper body motion is essential for many applications such as health evaluation, rehabilitation, human power augmentation, skill transferring, etc. Computer vision-based systems have been widely used to directly capture upper limb motion but are usually constrained in a restricted area. Wearable sensors such as inertial measurement units (IMUs) are promising to enable ambulant and out-of-lab measurements but also suffer from issues such as magnetic distortion and drifting. Some visual-inertial systems have been proposed recently to fuse these two complementary measurements but mostly apply in a restricted area. In this paper, we propose a fully wearable egocentric visual-inertial system to estimate the upper-limb pose. Magnetometers are not used to allow the system to work in complex industrial and daily living scenarios or to be integrated with motorized assistive devices. Methods to automatically calibrate the sensor-to-segment alignment and estimate upper body motion is presented and validated with an optical motion capture system. Experimental results showed the system can estimate the joint angles without drift and obtain accurate wrist position even with occlusion, verifying the efficacy of the proposed system and method.	https://doi.org/10.1109/ICRA46639.2022.9811733	Tong Li, Xiaoyu Wu, Huixu Dong, Haoyong Yu
Evaluation of Runtime Monitoring for UAV Emergency Landing.	To certify UAV operations in populated areas, risk mitigation strategies - such as Emergency Landing (EL) - must be in place to account for potential failures. EL aims at reducing ground risk by finding safe landing areas using on-board sensors. The first contribution of this paper is to present a new EL approach, in line with safety requirements introduced in recent research. In particular, the proposed EL pipeline includes mechanisms to monitor learning based components during execution. This way, another contribution is to study the behavior of Machine Learning Runtime Monitoring (MLRM) approaches within the context of a real-world critical system. A new evaluation methodology is introduced, and applied to assess the practical safety benefits of three MLRM mechanisms. The proposed approach is compared to a default mitigation strategy (open a parachute when a failure is detected), and appears to be much safer.	https://doi.org/10.1109/ICRA46639.2022.9811924	Joris Guérin, Kevin Delmas, Jérémie Guiochet
Event-Triggered Tracking Control Scheme for Quadrotors with External Disturbances: Theory and Validations.	This article studies the tracking control of a quadrotor unmanned aerial vehicle (UAV) under time-varying external disturbances. An event-triggered sliding mode control (SMC) strategy is proposed by introducing a new triggering condition form of desired trajectory, quadrotor position, and velocity. In the sense of Lyapunov theory, the stability of the entire closed-loop control system is analyzed, and it is proved that the tracking error is adjusted to an adjustable set around zero. We show that the Zeno phenomenon can be avoided; that is, a positive minimum inter-event time is assured. One of the salient features of the proposed strategy is that it can reduce the update frequency of the control efforts, thereby ensuring desirable tracking performance under limited communication bandwidth. Comparative simulation and experimental results are provided to show the efficacy of our framework.	https://doi.org/10.1109/ICRA46639.2022.9812326	Pengcheng Gao, Gang Wang, Yunfeng Ji, Qingdu Li, Jianwei Zhang, Yantao Shen, Peng Li
Evolved neuromorphic radar-based altitude controller for an autonomous open-source blimp.	Robotic airships offer significant advantages in terms of safety, mobility, and extended flight times. However, their highly restrictive weight constraints pose a major challenge regarding the available computational resources to perform the required control tasks. Neuromorphic computing stands for a promising research direction for addressing such problem. By mimicking the biological process for transferring information between neurons using spikes or impulses, spiking neural networks (SNNs) allow for low power consumption and asynchronous event-driven processing. In this paper, we propose an evolved altitude controller based on an SNN for a robotic airship which relies solely on the sensory feedback provided by an airborne radar. Starting from the design of a lightweight, low-cost, open-source airship, we also present an SNN-based controller architecture, an evolutionary framework for training the network in a simulated environment, and a control strategy for ameliorating the gap with reality. The system's performance is evaluated through real-world experiments, demonstrating the advantages of our approach by comparing it with an artificial neural network and a linear controller. The results show an accurate tracking of the altitude command with an efficient control effort.	https://doi.org/10.1109/ICRA46639.2022.9812149	Marina González-Álvarez, Julien Dupeyroux, Federico Corradi, Guido C. H. E. de Croon
Ex-DoF: Expansion of Action Degree-of-Freedom with Virtual Camera Rotation for Omnidirectional Image.	Inter-robot transfer of training data is a little explored topic in learning- and vision-based robot control. Here we propose a transfer method from a robot with a lower Degree-of-Freedom (DoF) to one with a higher DoF utilizing the omnidirectional camera image. The virtual rotation of the robot camera enables data augmentation in this transfer learning process. As an experimental demonstration, a vision-based control policy for a 6- DoF robot is trained using a dataset collected by a wheeled ground robot with only three DoFs. Towards the application of robotic manipulations, we also demonstrate a control system of a 6- DoF arm robot using multiple policies with different fields of view to enable object reaching tasks.	https://doi.org/10.1109/ICRA46639.2022.9812301	Kosuke Tahara, Noriaki Hirose
Exact-likelihood User Intention Estimation for Scene-compliant Shared-control Navigation.	A predictive model for mobility systems capable of understanding the trajectory a user intends to follow in the environment is proposed. Understanding user intention is paramount for any shared-control navigation strategy between a user and an active robotic agent. Equally important however is being able to go beyond simple sample generation to assign probabilistic meaning to the set of possible future trajectories, so most likely scenarios can be assumed. The framework estimates a distribution over possible intentions, proposing a novel generative model predicated on Normalizing Flows which accounts for past behaviours, as traditionally reported in the literature, but also incorporates visual scene information. As the model permits trajectories to be assigned exact likelihoods, tractable density estimates can be readily exploited to finalize an executable intention. Baseline comparisons with the publicly available and widely used KITTI navigational dataset show significant improvements (up to 11.08%) with respect to traditional metrics such as Average and Final Displacement Errors. A novel metric that stands independent of the number of samples is also proposed as a more fitting comparison for future works.	https://doi.org/10.1109/ICRA46639.2022.9811913	Kavindie Katuwandeniya, Stefan H. Kiss, Lei Shi, Jaime Valls Miró
Expanding the Design Space for Electrically-Driven Soft Robots Through Handed Shearing Auxetics.	Handed Shearing Auxetics (HSA) are a promising structure for making electrically driven robots with distributed compliance that convert a motors rotation and torque into extension and force. These structures expand and contract by changing an internal angle between links, the evolution of the structure as this angle changes is known as the auxetic trajectory. We overcome past limitations on the range of actuation, blocked force, and stiffness by focusing on two key design parameters: the point of an HSA's auxetic trajectory that is energetically preferred, and the number of cells along the HSAs length. Modeling the HSA as a programmable spring, we characterize the effect of both on blocked force, minimum energy length, spring constant, angle range and holding torque. We also examined the effect viscoelasticity has on actuation forces over time. By varying the preferred auxetic trajectory point, we were able to make actuators that can push, pull, or do both. We expanded the range of forces possible from 5 N to 150 N, and the range of stiffness from 2 N/mm to 89 N/mm. For a fixed point on the auxetic trajectory, we found decreasing length can improve force output, at the expense of needing higher torques, and having a shorter throw. We also found that the viscoelastic effects can limit the amount of force a 3D printed HSA can apply over time.	https://doi.org/10.1109/ICRA46639.2022.9812156	Ian Good, Tosh Brown-Moore, Aditya Patil, Daniel Revier, Jeffrey Ian Lipton
Experimental Validation of the Usage of Kinematic Singularities to Produce Periodic High-Powered Motion.	"This paper reports on preliminary experimental results of recently proposed mechanism kinematics for a legged robot. The proposed kinematics creates a mapping from a series-elastic actuator to a foot motion that includes a pair of singularities within a fully rotatable kinematic circuit. Such a circuit is less common and only possible with certain multi-loop linkages. A slice of the configuration space displaying series-elastic rotation versus linear foot motion presents a characteristic ""S"" shape, motivating the name S-curve kinematics. Our experimental results show that S-curve kinematics can enhance the energetic output of a series-elastic actuator in a hopping task versus the usage of a conventional rotary-to-linear mechanism. This is possible because S-curve kinematics enable elastic energy storage outside of stance that is released through a mechanical reflex. Compared to a conventional rotary-to-linear actuator, S-curve kinematics demonstrated up to a 4x increase in kinetic output."	https://doi.org/10.1109/ICRA46639.2022.9811546	Chang Liu, Mark M. Plecnik
Experiments in Adaptive Replanning for Fast Autonomous Flight in Forests.	Fast, autonomous flight in unstructured, cluttered environments such as forests is challenging because it requires the robot to compute new plans in realtime on a computationally-constrained platform. In this paper, we enable this capability with a search-based planning framework that adapts sampling density in realtime to find dynamically-feasible plans while remaining computationally tractable. A paramount challenge in search-based planning is that dense obstacles both necessitate large graphs (to guarantee completeness) and reduce the efficiency of graph search (as heuristics become less accurate). To address this, we develop a planning framework with two parts: one that maximizes planner completeness for a given graph size, and a second that dynamically maximizes graph size subject to computational constraints. This framework is enabled by motion planning graphs that are defined by a single parameter-dispersion-which quantifies the maximum trajectory cost to reach an arbitrary state from the graph. We show through real and simulated experiments how the dispersion can be adapted to different environments in realtime, allowing operation in environments with varying density. The simulated experiment demonstrates improved performance over a baseline search-based planning algorithm. We also demonstrate flight speeds of up to 2.5m/s in real-world cluttered pine forests.	https://doi.org/10.1109/ICRA46639.2022.9812235	Laura Jarin-Lipschitz, Xu Liu, Yuezhan Tao, Vijay Kumar
Exploiting Abstract Symmetries in Reinforcement Learning for Complex Environments.	Reinforcement Learning is rapidly establishing itself as the foremost choice for optimization of sequential autonomous decision-making problems. Encumbered by its sample inefficiency, the extension of the field to large state space and dynamic environments remains an open problem. We present a novel concept that exploits abstract spatial symmetry in complex environments for extending the skills of naïvely trained agents in local abstractions of the environment. The concept of EASE (Exploitation of Abstract Symmetry of Environments), when incorporated, improves the sample efficiency of traditional reinforcement learning algorithms. The presented work exemplifies the concept of EASE by presenting three distinct settings; EASE with heuristics-based planning, EASE with learning from demonstrations and EASE with state-space abstraction and proposes a novel algorithm for each setting.	https://doi.org/10.1109/ICRA46639.2022.9811652	Kashish Gupta, Homayoun Najjaran
Exploiting Playbacks in Unsupervised Domain Adaptation for 3D Object Detection in Self-Driving Cars.	Self-driving cars must detect other traffic participants like vehicles and pedestrians in 3D in order to plan safe routes and avoid collisions. State-of-the-art 3D object detectors, based on deep learning, have shown promising accuracy but are prone to over-fit domain idiosyncrasies, making them fail in new environments-a serious problem for the robustness of self-driving cars. In this paper, we propose a novel learning approach that reduces this gap by fine-tuning the detector on high-quality pseudo-labels in the target domain - pseudo-labels that are automatically generated after driving based on replays of previously recorded driving sequences. In these replays, object tracks are smoothed forward and backward in time, and detections are interpolated and extrapolated-crucially, leveraging future information to catch hard cases such as missed detections due to occlusions or far ranges. We show, across five autonomous driving datasets, that fine-tuning the object detector on these pseudo-labels substantially reduces the domain gap to new driving environments, yielding strong improvements detection reliability and accuracy.	https://doi.org/10.1109/ICRA46639.2022.9811722	Yurong You, Carlos Andres Diaz-Ruiz, Yan Wang, Wei-Lun Chao, Bharath Hariharan, Mark E. Campbell, Kilian Q. Weinberger
Exploration with Global Consistency Using Real-Time Re-integration and Active Loop Closure.	Despite recent progress of robotic exploration, most methods assume that drift-free localization is available, which is problematic in reality and causes severe distortion of the reconstructed map. In this work, we present a systematic exploration mapping and planning framework that deals with drifted localization, allowing efficient and globally consistent reconstruction. A real-time re-integration-based mapping approach along with a frame pruning mechanism is proposed, which rectifies map distortion effectively when drifted localization is corrected upon detecting loop-closure. Besides, an exploration planning method considering historical viewpoints is presented to enable active loop closing, which promotes a higher opportunity to correct localization errors and further improves the mapping quality. We evaluate both the mapping and planning methods as well as the entire system comprehensively in simulation and real-world experiments, showing their effectiveness in practice. The implementation of the proposed method will be made open-source for the benefit of the robotics community.	https://doi.org/10.1109/ICRA46639.2022.9811892	Yichen Zhang, Boyu Zhou, Luqi Wang, Shaojie Shen
Explore-Bench: Data Sets, Metrics and Evaluations for Frontier-based and Deep-reinforcement-learning-based Autonomous Exploration.	Autonomous exploration and mapping of unknown terrains employing single or multiple robots is an essential task in mobile robotics and has therefore been widely investigated. Nevertheless, given the lack of unified data sets, metrics, and platforms to evaluate the exploration approaches, we develop an autonomous robot exploration benchmark en-titled Explore-Bench. The benchmark involves various explo-ration scenarios and presents two types of quantitative metrics to evaluate exploration efficiency and multi-robot cooperation. Explore-Bench is extremely useful as, recently, deep rein-forcement learning (DRL) has been widely used for robot exploration tasks and achieved promising results. However, training DRL-based approaches requires large data sets, and additionally, current benchmarks rely on realistic simulators with a slow simulation speed, which is not appropriate for training exploration strategies. Hence, to support efficient DRL training and comprehensive evaluation, the suggested Explore-Bench designs a 3-level platform with a unified data flow and 12 × speed-up that includes a grid-based simulator for fast evaluation and efficient training, a realistic Gazebo simulator, and a remotely accessible robot testbed for high-accuracy tests in physical environments. The practicality of the proposed benchmark is highlighted with the application of one DRL-based and three frontier-based exploration approaches. Fur-thermore, we analyze the performance differences and provide some insights about the selection and design of exploration methods. Our benchmark is available at https://github.com/efc-robot/Explore-Bench.	https://doi.org/10.1109/ICRA46639.2022.9812344	Yuanfan Xu, Jincheng Yu, Jiahao Tang, Jiantao Qiu, Jian Wang, Yuan Shen, Yu Wang, Huazhong Yang
Extrinsic Calibration and Verification of Multiple Non-overlapping Field of View Lidar Sensors.	We demonstrate a multi-lidar calibration frame-work for large mobile platforms that jointly calibrate the extrinsic parameters of non-overlapping Field-of-View (FoV) lidar sensors, without the need for any external calibration aid. The method starts by estimating the pose of each lidar in its corresponding sensor frame in between subsequent timestamps. Since the pose estimates from the lidars are not necessarily synchronous, we first align the poses using a Dual Quaternion (DQ) based Screw Linear Interpolation. Afterward, a Hand-Eye based calibration problem is solved using the DQ-based formulation to recover the extrinsics. Furthermore, we verify the extrinsics by matching chosen lidar semantic features, obtained by projecting the lidar data into the camera perspective after time alignment using vehicle kinematics. Experimental results on the data collected from a Scania vehicle [~ 1 Km sequence] demonstrate the ability of our approach to obtain better calibration parameters than the provided vehicle CAD model calibration parameters. This setup can also be scaled to any combination of multiple lidars.	https://doi.org/10.1109/ICRA46639.2022.9811704	Sandipan Das, Navid Mahabadi, Addi Djikic, Cesar Nassir, Saikat Chatterjee, Maurice F. Fallon
FD-SLAM: 3-D Reconstruction Using Features and Dense Matching.	It is well known that visual SLAM systems based on dense matching are locally accurate but are also susceptible to long-term drift and map corruption. In contrast, feature matching methods can achieve greater long-term consistency but can suffer from inaccurate local pose estimation when feature information is sparse. Based on these observations, we propose an RGB-D SLAM system that leverages the advantages of both approaches: using dense frame-to-model odometry to build accurate sub-maps and on-the-fly feature-based matching across sub-maps for global map optimisation. In addition, we incorporate a learning-based loop closure component based on 3-D features which further stabilises map building. We have evaluated the approach on indoor sequences from public datasets, and the results show that it performs on par or better than state-of-the-art systems in terms of map reconstruction quality and pose estimation. The approach can also scale to large scenes where other systems often fail.	https://doi.org/10.1109/ICRA46639.2022.9812049	Xingrui Yang, Yuhang Ming, Zhaopeng Cui, Andrew Calway
FEJ2: A Consistent Visual-Inertial State Estimator Design.	In this paper, we propose a novel consistent state estimator design for visual-inertial systems. Motivated by first-estimates Jacobian (FEJ) based estimators - which uses the first-ever estimates as linearization points to preserve proper observability properties of the linearized estimator thereby improving the consistency - we carefully model measurement linearization errors due to its Jacobian evaluation and propose a methodology which still leverages FEJ to ensure the estimator's observability properties, but additionally explicitly compensate for linearization errors caused by poor first estimates. We term this estimator FEJ2, which directly addresses the discrepancy between the best Jacobian evaluated at the latest state estimate and the first-estimates Jacobian evaluated at the first-time-ever state estimate. We show that this process explicitly models that the FEJ used is imperfect and thus contributes additional error which, as in FEJ2, should be modeled and consistently increase the state covariance during update. The proposed FEJ2 is evaluated against state-of-the-art visual-inertial estimators in both Monte-Carlo simulations and real-world experiments, which has been shown to outperform existing methods and to robustly handle poor first estimates and high measurement noises.	https://doi.org/10.1109/ICRA46639.2022.9811831	Chuchu Chen, Yulin Yang, Patrick Geneva, Guoquan Huang
FFHNet: Generating Multi-Fingered Robotic Grasps for Unknown Objects in Real-time.	Grasping unknown objects with multi-fingered hands at high success rates and in real-time is an unsolved problem. Existing methods are limited in the speed of grasp synthesis or the ability to synthesize a variety of grasps from the same observation. We introduce Five-finger Hand Net (FFHNet), an ML model which can generate a wide variety of high-quality multi-fingered grasps for unseen objects from a single view. Generating and evaluating grasps with FFHNet takes only 30ms on a commodity GPU. To the best of our knowledge, FFHNet is the first ML-based real-time system for multi-fingered grasping with the ability to perform grasp inference at 30 frames per second (FPS). For training, we synthetically generate 180k grasp samples for 129 objects. We are able to achieve 91% grasping success for unknown objects in simulation and we demonstrate the model's capabilities of synthesizing high-quality grasps also for real unseen objects.	https://doi.org/10.1109/ICRA46639.2022.9811666	Vincent Mayer, Qian Feng, Jun Deng, Yunlei Shi, Zhaopeng Chen, Alois C. Knoll
FP-Loc: Lightweight and Drift-free Floor Plan-assisted LiDAR Localization.	We present a novel framework for floor plan-based, full six degree-of-freedom LiDAR localization. Our approach relies on robust ceiling and ground plane detection, which solves part of the pose and supports the segmentation of vertical structure elements such as walls and pillars. Our core contribution is a novel nearest neighbour data structure for an efficient look-up of nearest vertical structure elements from the floor plan. The registration is realized as a pair-wise regularized windowed pose graph optimization. Highly efficient, accurate and drift-free long-term localization is demonstrated on multiple scenes.	https://doi.org/10.1109/ICRA46639.2022.9812361	Ling Gao, Laurent Kneip
Fabrication of PEDOT: PSS based Soft Sensor for Feedback Control of Modular Bio-actuator.	In this paper, we fabricated a soft sensor based on PEDOT:PSS for thin film structure. The developed soft sensor can measure the contraction force at real time to be embedded in a modular bio-actuator [1]. The modular actuator generated contraction forces at 0.3 mN when applying electric pulse stimulation. To measure millinewton contraction forces and make a built in sensor, we fabricated a soft sensor using PEDOT:PSS-PDMS film. To verify that the sensor can measure the force of the actuator and can be integrated to the actuator, we analyzed characteristic of the sensor. First, we measure Young's modulus of the sensor and compare them with the bio-actuator. From the previous research [2], the Young's modulus of the bio-actuator and sensor were 45.8 kPa and 165 kPa, respectively. In addition, we simulated the sensors to estimate the change of the displacement according to the applied force. Next, we have experiments by stretching sensors using stepping motor to measure the resistance change of the sensor. From the simulation data, the displacement change is 23 µm when applying 0.3 mN of forces and then we detect the displacement change smaller than is 20 µm from the experiments. Finally, we analyzed the movement of the bio-actuator when applying stimulation using high speed camera and time response of the developed sensor. The actuator was contracted to the maximum after 150 ms from the electrical stimulation and the sensor detected the repeated motion at 10 Hz without time delay. As a result, the proposed sensor can measure the force of bioactuator at real time.	https://doi.org/10.1109/ICRA46639.2022.9811795	Eunhye Kim, Masaru Takeuchi, Takuto Nomura, Yasuhisa Hasegawa, Qiang Huang, Toshio Fukuda
Failure is an option: Task and Motion Planning with Failing Executions.	Future robotic deployments will require robots to be able to repeatedly solve a variety of tasks in application domains. Task and motion planning addresses complex robotic problems that combine discrete reasoning over states and actions and geometric interactions during action executions. Moving beyond deterministic settings, stochastic actions can be handled by modeling the problem as a Markov Decision Process. The underlying probabilities however are typically hard to model since failures might be caused by hardware imperfections, sensing noise, or physical interactions. We pro-pose a framework to address a task and motion planning setting where actions can fail during execution. To achieve a task goal actions need to be computed and executed despite failures. The robot has to infer which actions are robust and for each new problem effectively choose a solution that reduces expected execution failures. The key idea is to continually recover and refine the underlying beliefs associated with actions across multiple different problems in the domain. Our proposed method can find solutions that reduce the expected number of discrete, executed actions. Results in physics-based simulation indicate that our method outperforms baseline replanning strategies to deal with failing executions.	https://doi.org/10.1109/ICRA46639.2022.9812273	Tianyang Pan, Andrew M. Wells, Rahul Shome, Lydia E. Kavraki
Fast Collision Checking for Dual-Arm Collaborative Robots Working in Close Proximity.	We present a fast collision checking/avoidance algorithm for collaborative robot arms that work in close proximity. We formulate forward kinematics and separating distance function using DH convention and Taylor models (the tight enclosure of a function), and then compute their tight bounds for determining interference between robot arms. Our algorithm allows the collaborative robot arms to perform fine and dexterous tasks in close spatial proximity.	https://doi.org/10.1109/ICRA46639.2022.9811857	Miaoying Zhou, Xinyu Zhang
Fast Footstep Planning on Uneven Terrain Using Deep Sequential Models.	One of the fundamental challenges in realizing the potential of legged robots is generating plans to traverse challenging terrains. Control actions must be carefully selected so the robot will not crash or slip. The high dimensionality of the joint space makes directly planning low-level actions from onboard perception difficult, and control stacks that do not consider the low-level mechanisms of the robot in planning are ill-suited to handle fine-grained obstacles. One method for dealing with this is selecting footstep locations based on terrain characteristics. However, incorporating robot dynamics into footstep planning requires significant computation, much more than in the quasi-static case. In this work, we present an LSTM-based planning framework that learns probability distributions over likely footstep locations using both terrain lookahead and the robot's dynamics, and leverages the LSTM's sequential nature to find footsteps in linear time. Our framework can also be used as a module to speed up sampling-based planners. We validate our approach on a simulated one-legged hopper over a variety of uneven terrains.	https://doi.org/10.1109/ICRA46639.2022.9812264	Hersh Sanghvi, Camillo Jose Taylor
Fast Graph Refinement and Implicit Neural Representation for Tissue Tracking.	Tracking of tissue in the surgical environment is often done via locating frame-to-frame keypoint correspondences, and then using these correspondences to warp a prior underlying model such as a spline, mesh, or embedded deformation. We introduce a novel learned model which takes keypoint correspondences as input and enables a prior-free estimation of deformation at any location. For fast point tracking, our model allows for sparse queries, unlike dense grid based CNNs, which run on full images. Our model begins with a novel graph-based point refinement scheme which refines matched keypoints, updating their features and movement instead of discarding possible outliers. Then, we use these refined matches to learn a novel neural implicit representation for estimating movement of any location given its k-nearest neighbor (k-NN) keypoints. We name our implicit deformation model KINFlow (k-NN implicit neural flow). We demonstrate the performance of KINFlow photometrically on three different datasets. KINFlow is the first model to use a graph network to estimate flow of arbitrary query points, and can estimate movement of 1024 points in under 3 ms.	https://doi.org/10.1109/ICRA46639.2022.9811742	Adam Schmidt, Omid Mohareri, Simon P. DiMaio, Septimiu E. Salcudean
Fast High-Quality Tabletop Rearrangement in Bounded Workspace.	"In this paper, we examine the problem of rearranging many objects on a tabletop in a cluttered setting using overhand grasps. Efficient solutions for the problem, which capture a common task that we solve on a daily basis, are essential in enabling truly intelligent robotic manipulation. In a given instance, objects may need to be placed at temporary positions (""buffers"") to complete the rearrangement, but allocating these buffer locations can be highly challenging in a cluttered environment. To tackle the challenge, a two-step baseline planner is first developed, which generates a primitive plan based on inherent combinatorial constraints induced by start and goal poses of the objects and then selects buffer locations assisted by the primitive plan. We then employ the ""lazy"" planner in a tree search framework which is further sped up by adapting a novel preprocessing routine. Simulation experiments show our methods can quickly generate high-quality solutions and are more robust in solving large-scale instances than existing state-of-the-art approaches. source: github.com/arc-l/TRLB"	https://doi.org/10.1109/ICRA46639.2022.9812367	Kai Gao, Darren Lau, Baichuan Huang, Kostas E. Bekris, Jingjin Yu
Fast Object Inertial Parameter Identification for Collaborative Robots.	Collaborative robots (cobots) are machines designed to work safely alongside people in human-centric environments. Providing cobots with the ability to quickly infer the inertial parameters of manipulated objects will improve their flexibility and enable greater usage in manufacturing and other areas. To ensure safety, cobots are subject to kinematic limits that result in low signal-to-noise ratios (SNR) for velocity, acceleration, and force-torque data. This renders existing inertial parameter identification algorithms prohibitively slow and inaccurate. Motivated by the desire for faster model acquisition, we investigate the use of an approximation of rigid body dynamics to improve the SNR. Additionally, we introduce a mass discretization method that can make use of shape information to quickly identify plausible inertial parameters for a manipulated object. We present extensive simulation studies and real-world experiments demonstrating that our approach complements existing inertial parameter identification methods by specifically targeting the typical cobot operating regime.	https://doi.org/10.1109/ICRA46639.2022.9916213	Philippe Nadeau, Matthew Giamou, Jonathan Kelly
Fast Point Clouds Upsampling with Uncertainty Quantification for Autonomous Vehicles.	3D LiDAR is widely used in autonomous systems such as self-driving cars and autonomous robots because it provides accurate 3D point clouds of the surrounding environment under harsh conditions. However, a high-resolution LiDAR is expensive and bulky. Although a low-resolution LiDAR is compact and affordable, the obtained point clouds are so sparse that it is difficult to extract features that are meaningful for highlevel tasks. To solve this problem, several upsampling-based approaches have been proposed by estimating high-resolution point clouds from low-resolution point clouds. However, most works have focused on upsampling object-level or synthetic point clouds obtained from CAD models. Additionally, these approaches have a high computational cost, which makes them unusable in real-time applications such as autonomous driving vehicles. In this paper, we propose a real-time upsampling method with LiDAR for outdoor environments. The proposed method builds on conditional neural processes that are capable of uncertainty quantification. With this probabilistic property, we can remove the upsampled points that have high uncertainty, thus achieving high accuracy. Additionally, the proposed method can be trained in a simulated environment, and then directly applied to the real world. The experimental results on a simulated environment and a real-world dataset show that the proposed method is significantly faster than the state-of-the-art methods while achieving comparable performance.	https://doi.org/10.1109/ICRA46639.2022.9811914	Younghwa Jung, Seung-Woo Seo, Seong-Woo Kim
Fast Road Segmentation via Uncertainty-aware Symmetric Network.	"The high performance of RGB-D based road segmentation methods contrasts with their rare application in commercial autonomous driving, which is owing to two reasons: 1) the prior methods cannot achieve high inference speed and high accuracy in both ways; 2) the different properties of RGB and depth data are not well-exploited, limiting the reliability of predicted road. In this paper, based on the evidence theory, an uncertainty-aware symmetric network (USNet) is proposed to achieve a trade-off between speed and accuracy by fully fusing RGB and depth data. Firstly, cross-modal feature fusion operations, which are indispensable in the prior RGB-D based methods, are abandoned. We instead separately adopt two light-weight subnetworks to learn road representations from RGB and depth inputs. The light-weight structure guarantees the real-time inference of our method. Moreover, a multi-scale evidence collection (MEC) module is designed to collect evidence in multiple scales for each modality, which provides sufficient evidence for pixel class determination. Finally, in uncertainty-aware fusion (UAF) module, the uncertainty of each modality is perceived to guide the fusion of the two sub-networks. Experimental results demonstrate that our method achieves a state-of-the-art accuracy with real-time inference speed of
43+
FPS. The source code is available at https://github.com/morancyc/USNet."	https://doi.org/10.1109/ICRA46639.2022.9812452	Yicong Chang, Feng Xue, Fei Sheng, Wenteng Liang, Anlong Ming
Fast and Optimal Trajectory Planning for Multiple Vehicles in a Nonconvex and Cluttered Environment: Benchmarks, Methodology, and Experiments.	This paper is focused on the cooperative trajectory planning problem for multiple car-like robots in a cluttered and unstructured environment narrowed by static obstacles. The concerned multi-vehicle trajectory planning (MVTP) problem is challenging because i) the scenario is nonconvex and tiny; ii) the vehicle kinematics is nonconvex; and iii) a feasible homotopy class is unavailable a priori. We propose a two-stage MVTP method: Stage 1 identifies a feasible homotopy class, and Stage 2 quickly finds a local optimum based on the identified homotopy class. Numerical optimal control, adaptive scaling, grouping, and trust region construction strategies are integrated into the proposed planner. Our planner is extensively compared in 100 benchmark cases with the state-of-the-art MVTP methods such as incremental sequential convex programming, numerical optimal control, conflict-based search, priority-based trajectory optimizer, and optimal reciprocal collision avoidance. The simulation results demonstrate our method's superiority in runtime and optimality. Experiments with three car-like robots demonstrate the efficiency of our proposed planner. Source codes are in https://github.com/libai1943/MVTP_benchmark.	https://doi.org/10.1109/ICRA46639.2022.9812126	Yakun Ouyang, Bai Li, Youmin Zhang, Tankut Acarman, Yuqing Guo, Tantan Zhang
Fast-MbyM: Leveraging Translational Invariance of the Fourier Transform for Efficient and Accurate Radar Odometry.	Masking by Moving (MByM), provides robust and accurate radar odometry measurements through an exhaustive correlative search across discretised pose candidates. However, this dense search creates a significant computational bottleneck which hinders real-time performance when high-end GPUs are not available. Utilising the translational invariance of the Fourier Transform, in our approach, Fast Masking by Moving (f-MByM), we decouple the search for angle and translation. By maintaining end-to-end differentiability a neural network is used to mask scans and trained by supervising pose prediction directly. Training faster and with less memory, utilising a decoupled search allows f-MbyM to achieve significant run-time performance improvements on a CPU (168 %) and to run in real-time on embedded devices, in stark contrast to MbyM. Throughout, our approach remains accurate and competitive with the best radar odometry variants available in the literature – achieving an end-point drift of 2.01 % in translation and 6.3 deg /km on the Oxford Radar RobotCar Dataset.	https://doi.org/10.1109/ICRA46639.2022.9812063	Rob Weston, Matthew Gadd, Daniele De Martini, Paul Newman, Ingmar Posner
Few-Shot Keypoint Detection as Task Adaptation via Latent Embeddings.	Dense object tracking, the ability to localize specific object points with pixel-level accuracy, is an important computer vision task with numerous downstream applications in robotics. Existing approaches either compute dense keypoint embeddings in a single forward pass, meaning the model is trained to track everything at once, or allocate their full capacity to a sparse predefined set of points, trading generality for accuracy. In this paper we explore a middle ground based on the observation that the number of relevant points at a given time are typically relatively few, e.g. grasp points on a target object. Our main contribution is a novel architecture, inspired by few-shot task adaptation, which allows a sparse-style network to condition on a keypoint embedding that indicates which point to track. Our central finding is that this approach provides the generality of dense-embedding models, while offering accuracy significantly closer to sparse-keypoint approaches. We present results illustrating this capacity vs. accuracy trade-off, and demonstrate the ability to zero-shot transfer to new object instances (within-class) using a real-robot pick-and-place task.	https://doi.org/10.1109/ICRA46639.2022.9812209	Mel Vecerík, Jackie Kay, Raia Hadsell, Lourdes Agapito, Jon Scholz
FishGym: A High-Performance Physics-based Simulation Framework for Underwater Robot Learning.	"Bionic underwater robots have demonstrated their superiority in many applications. Yet, training their intelligence for a variety of tasks that mimic the behavior of underwater creatures poses a number of challenges in practice, mainly due to lack of a large amount of available training data as well as the high cost in real physical environment. Alternatively, simulation has been considered as a viable and important tool for acquiring datasets in different environments, but it mostly targeted rigid and soft body systems. There is currently dearth of work for more complex fluid systems interacting with immersed solids that can be efficiently and accurately simulated for robot training purposes. In this paper, we propose a new platform called ""FishGym"", which can be used to train fish-like underwater robots. The framework consists of a robotic fish modeling module using articulated body with skinning, a GPU-based high-performance localized two-way coupled fluid-structure interaction simulation module that handles both finite and infinitely large domains, as well as a reinforcement learning module. We leveraged existing training methods with adaptations to underwater fish-like robots and obtained learned control policies for multiple benchmark tasks. The training results are demonstrated with reasonable motion trajectories, with comparisons and analyses to empirical models as well as known real fish swimming behaviors to highlight the advantages of the proposed platform."	https://doi.org/10.1109/ICRA46639.2022.9812066	Wenji Liu, Kai Bai, Xuming He, Shuran Song, Changxi Zheng, Xiaopei Liu
Fixed and Sliding FBG Sensors-Based Triaxial Tip Force Sensing for Cable-Driven Continuum Robots.	Tip force sensing for cable-driven continuum robots are vital to provide the force information for safe and reliable human-robot interaction. However, traditional triaxial force sensors usually have a complicated structure occupying its inner lumen, without enough space for additional instrumental tools. To solve this, this paper proposes a fixed and sliding fiber Bragg grating (FBG) sensors-based triaxial force sensing method for cable-driven continuum robots. The fixed FBG sensors are attached to the circumferential surface of continuum robot at the tip and base, and the sliding optical fibers with FBG sensors are located in the actuation channels as the sensing integrated pulling cables. This configuration guarantees a compact structure and large inner lumen. Two five-degreed-of-freedom (5-DOF) electromagnetic (EM) and a 6-DOF EM sensors are assembled to the tip and the base of the robot respectively, which can obtain the pose of the tip with respect to the base. The tip force in three directions can be decoupled using the information of the Bragg wavelength changes and EM sensors. Results show that the mean errors of force sensing along x-direction, y-direction, and z-direction are 4.1%, 4.7%, and 9.8%, respectively. The proposed sensing method does not rely on the elasticity of continuum robot, enabling its wide applicability for other cable-driven pseudo-continuum robots.	https://doi.org/10.1109/ICRA46639.2022.9811947	Zecai Lin, Huanghua Liu, Xiaojie Ai, Weidong Chen, Anzhu Gao, Zhenglong Sun, Yun Zou, Guang-Zhong Yang, Hao Wu, Huan Jia
Flow Supervised Neural Radiance Fields for Static-Dynamic Decomposition.	We present an approach to synthesize novel views from dynamics scenes captured by multi-view videos of cameras mounted on a driving vehicle. We unify existing methods and propose a new training loss to explicitly disentangle the static background from the dynamic foreground objects using scene flow's magnitude, learnt only from proxy 2D optical flow supervision. We obtain high quality static and dynamic contents separately, which allow us to combine them freely for novel view and time syntheses. We establish a dataset consisting of 5 dynamic scenes with varying difficulties on which we conduct experiments, and show that our method is able to handle challenging scenarios in real-world traffics and create high quality novel view and time syntheses.	https://doi.org/10.1109/ICRA46639.2022.9811680	Quei-An Chen, Akihiro Tsukada
Flow-Based Control of Marine Robots in Gyre-Like Environments.	We present a flow-based control strategy that enables resource-constrained marine robots to patrol gyre-like flow environments on an orbital trajectory with a periodicity in a given range. The controller does not require a detailed model of the flow field and relies only on the robot's location relative to the center of the gyre. Instead of precisely tracking a pre-defined trajectory, the robots are tasked to stay in between two bounding trajectories with known periodicity. Furthermore, the proposed strategy leverages the surrounding flow field to minimize control effort. We prove that the proposed strategy enables robots to cycle in the flow satisfying the desired periodicity requirements. Our method is tested and validated both in simulation and in experiments using a low-cost, underactuated, surface swimming robot, i.e. the Modboat.	https://doi.org/10.1109/ICRA46639.2022.9812331	Gedaliah Knizhnik, Peihan Li, Xi Yu, M. Ani Hsieh
Foothold Evaluation Criterion for Dynamic Transition Feasibility for Quadruped Robots.	To traverse complex scenarios reliably a legged robot needs to move its base aided by the ground reaction forces, which can only be generated by the legs that are momentarily in contact with the ground. A proper selection of footholds is crucial for maintaining balance. In this paper, we propose a foothold evaluation criterion that considers the transition feasibility for both linear and angular dynamics to overcome complex scenarios. We devise convex and nonlinear formulations as a direct extension of [1] in a receding-horizon fashion to grant dynamic feasibility for future behaviours. The criterion is integrated with a Vision-based Foothold Adaptation (VFA) strategy that takes into account the robot kinematics, leg collisions and terrain morphology. We verify the validity of the selected footholds and the generated trajectories in simulation and experiments with the 90kg quadruped robot HyQ.	https://doi.org/10.1109/ICRA46639.2022.9812434	Luca Clemente, Octavio Villarreal, Angelo Bratta, Michele Focchi, Victor Barasuol, Giovanni Gerardo Muscolo, Claudio Semini
Formal Verification of Stochastic Systems with ReLU Neural Network Controllers.	In this work, we address the problem of formal safety verification for stochastic cyber-physical systems (CPS) equipped with ReLU neural network (NN) controllers. Our goal is to find the set of initial states from where, with a predetermined confidence, the system will not reach an unsafe configuration within a specified time horizon. Specifically, we consider discrete-time LTI systems with Gaussian noise, which we abstract by a suitable graph. Then, we formulate a Satisfiability Modulo Convex (SMC) problem to estimate upper bounds on the transition probabilities between nodes in the graph. Using this abstraction, we propose a method to compute tight bounds on the safety probabilities of nodes in this graph, despite possible over-approximations of the transition probabilities between these nodes. Additionally, using the proposed SMC formula, we devise a heuristic method to refine the abstraction of the system in order to further improve the estimated safety bounds. Finally, we corroborate the efficacy of the proposed method with simulation results considering a robot navigation example and comparison against a state-of-the-art verification scheme.	https://doi.org/10.1109/ICRA46639.2022.9811866	Shiqi Sun, Yan Zhang, Xusheng Luo, Panagiotis Vlantis, Miroslav Pajic, Michael M. Zavlanos
Formation-containment tracking and scaling for multiple quadcopters with an application to choke-point navigation.	This paper investigates the cooperative control problem of choke-point navigation for multiple quadcopters when only their subgroup is equipped with obstacle detecting sensors. We define a quadcopter as a leader if it is equipped with an obstacle detecting sensor; otherwise, it is a follower. In addition, we introduce a virtual leader agent to create the group motion. First, we apply the leader-follower approach and propose a formation-containment tracking controller for multiple quadcopters to track the time-varying velocity of the virtual leader agent. At the same time, the leader quadcopters form the prescribed formation while the follower quadcopters converge inside a safe region, which is the convex hull spanned by those leaders. Then, we introduce a scaling vector into the displacement-based formation constraints. When the leader quadcopters identify the choke-point via their obstacle detecting sensors, they update the scaling variable to adjust the size of the formation (i.e. the safe region) and guide all quadcopters to safely pass through the choke-point. The proposed cooperative controllers are distributed because each quadcopter's control command only relies on the information states from its neighbours. Finally, two autonomous flight experiments, including formation-containment tracking and choke-point navigation, are provided to validate the effectiveness of the proposed cooperative control laws.	https://doi.org/10.1109/ICRA46639.2022.9812172	Yu-Hsiang Su, Alexander Lanzon
Forward Kinematics and Control of a Segmented Tunable-Stiffness 3-D Continuum Manipulator.	In this work, we consider the problem of controlling the end effector position of a continuum manipulator through local stiffness changes. Continuum manipulators offer the advantage of continuous deformation along their lengths, and recent advances in smart material actuators further enable local compliance changes, which can affect the manipulator's bulk motion. However, leveraging local stiffness change to control motion remains lightly explored. We build a kinematic model of a continuum manipulator as a sequence of segments consisting of symmetrically arranged springs around the perimeter of every segment, and we show that this system has a closed form solution to its forward kinematics. The model includes common constraints such as restriction of torsional or shearing movement. Based on this model, we propose a controller on the spring stiffnesses for a single segment and provide provable guarantees on convergence to a desired goal position. The results are verified in simulation and compared to physical hardware.	https://doi.org/10.1109/ICRA46639.2022.9812098	Shivangi Misra, Cynthia R. Sung
Forward Models That Integrate High-Dimensional and Localized Sensing of Peripheral Muscle Behavior Enable Task-Independent Prediction of Lower-Limb Joint Torque and Position Future States.	We develop a task-independent predictive framework that estimates hip, knee and ankle future behavior from sonomyographic sensing of quadriceps musculature. Two regression models, support vector regression and Gaussian process regression, were trained and tested such that no ambulation mode recognition was required. Sonomyography features of the anterior thigh musculature were extracted during the swing phase of level, incline and stair ambulation tasks as inputs to the two models for continuous prediction of the future stance phase hip, knee and ankle moments. Next, sonomyography features of the anterior thigh musculature were extracted during the stance phase and used to predict the following swing phase hip, knee and ankle angles. Leave-one-stride-out cross-validation is used to evaluate this continuous prediction framework. Additionally, initial, peak and terminal joint moment and angle parameters are extracted from trajectories and evaluated. Both regression models were able to accurately predict continuous future joint moments and angles, as well as initial, peak and terminal value parameters of future joint moments and angles. However, the support vector regression model required relatively lower computational cost. Thus, we recommend the support vector regression model as an optimal model for forward prediction of joint mechanics from sonomyographic sensing during ambulation.	https://doi.org/10.1109/ICRA46639.2022.9812035	Kaitlin G. Rabe, Nicholas P. Fey
Free Energy Principle for State and Input Estimation of a Quadcopter Flying in Wind.	The free energy principle from neuroscience provides a brain-inspired perception scheme through a data-driven model learning algorithm called Dynamic Expectation Maximization (DEM). This paper aims at introducing an exper-imental design to provide the first experimental confirmation of the usefulness of DEM as a state and input estimator for real robots. Through a series of quadcopter flight experiments under unmodelled wind dynamics, we prove that DEM can leverage the information from colored noise for accurate state and input estimation through the use of generalized coordinates. We demonstrate the superior performance of DEM for state es-timation under colored noise with respect to other benchmarks like State Augmentation, SMIKF and Kalman Filtering through its minimal estimation error. We demonstrate the similarities in the performance of DEM and Unknown Input Observer (UIO) for input estimation. The paper concludes by showing the influence of prior beliefs in shaping the accuracy-complexity trade-off during DEM's estimation.	https://doi.org/10.1109/ICRA46639.2022.9812415	Fred Bos, Ajith Anil Meera, Dennis Benders, Martijn Wisse
Free-Space Ellipsoid Graphs for Multi-Agent Target Monitoring.	We apply a novel framework for decomposing and reasoning about free space in an environment to a multi-agent persistent monitoring problem. Our decomposition method represents free space as a collection of ellipsoids associated with a weighted connectivity graph. The same ellipsoids used for reasoning about connectivity and distance during high level planning can be used as state constraints in a Model Predictive Control algorithm to enforce collision-free motion. This structure allows for streamlined implementation in distributed multi-agent tasks in 2D and 3D environments. We illustrate its effectiveness for a team of tracking agents tasked with monitoring a group of target agents. Our algorithm uses the ellipsoid decomposition as a primitive for the coordination, path planning, and control of the tracking agents. Simulations with four tracking agents monitoring fifteen dynamic targets in obstacle-rich environments demonstrate the performance of our algorithm.	https://doi.org/10.1109/ICRA46639.2022.9812306	Aaron Ray, Alyssa Pierson, Daniela Rus
FreeSN: A Freeform Strut-node Structured Modular Self-reconfigurable Robot - Design and Implementation.	This paper proposes a novel freeform strut-node structured modular self-reconfigurable robot (MSRR) called FreeSN, consisting of strut and node modules. A node module is mainly a low-carbon steel spherical shell. A strut module contains two freeform connectors, which provide strong magnetic connections and flexible spherical motions. The FreeSN system shares the benefits of freeform connection and strut-node structures. The freeform connection brings good adaptability to the environment. The triangle substructures inside the system configuration significantly improve the structural stability. The parallel execution of module motions can superpose the module capabilities and makes the system more scalable. The modules can combine these robot features by selecting the system configuration and better fit different circumstances and tasks. Four demonstrations, including assembly, obstacle crossing, transportation, and object manipulation, are designed to show the capabilities of the FreeSN system in different aspects. The results show the great performance and versatility of this MSRR system.	https://doi.org/10.1109/ICRA46639.2022.9811583	Yuxiao Tu, Guanqi Liang, Tin Lun Lam
From Scratch to Sketch: Deep Decoupled Hierarchical Reinforcement Learning for Robotic Sketching Agent.	We present an automated learning framework for a robotic sketching agent that is capable of learning stroke-based rendering and motor control simultaneously. We formulate the robotic sketching problem as a deep decoupled hierarchical reinforcement learning; two policies for stroke-based rendering and motor control are learned independently to achieve sub-tasks for drawing, and form a hierarchy when cooperating for real-world drawing. Without hand-crafted features, drawing sequences or trajectories, and inverse kinematics, the proposed method trains the robotic sketching agent from scratch. We performed experiments with a 6-DoF robot arm with 2F gripper to sketch doodles. Our experimental results show that the two policies successfully learned the sub-tasks and collaborated to sketch the target images. Also, the robustness and flexibility were examined by varying drawing tools and surfaces.	https://doi.org/10.1109/ICRA46639.2022.9811858	Ganghun Lee, Minji Kim, Min Su Lee, Byoung-Tak Zhang
Fully Automatic and Real-Time Microrobot Detection and Tracking based on Ultrasound Imaging using Deep Learning.	Micro-scale robots introduce great prospective into many different medical applications such as targeted drug delivery, minimally invasive surgery and localized bio-metric diagnostics. This research presents a method for object detection and tracking system of a chain-like magnetic microsphere robots using ultrasound imaging in an in-vitro environment. The method estimates the position of the microrobot in real-time using deep learning techniques. The experiments showed that a spherical microrobot with about 500 m in diameter can be detected and tracked in real-time with a high accuracy in dynamic environments. The results exhibit a high detection and tracking accuracy for one, two and three sphere microrobots with the highest accuracy in detection and tracking around 95 % and 93% respectively.	https://doi.org/10.1109/ICRA46639.2022.9812114	Karim Botros, Mohammad Alkhatib, David Folio, Antoine Ferreira
Fully Persistent Spatial Data Structures for Efficient Queries in Path-Dependent Motion Planning Applications.	Motion planning is a ubiquitous problem that is often a bottleneck in robotic applications. We demonstrate that motion planning problems such as minimum constraint removal, belief-space planning, and visibility-aware motion planning (VAMP) benefit from a path-dependent formulation, in which the state at a search node is represented implicitly by the path to that node. A naïve approach to computing the feasibility of a successor node in such a path-dependent formulation takes time linear in the path length to the node, in contrast to a (possibly very large) constant time for a more typical search formulation. For long-horizon plans, performing this linear-time computation, which we call the lookback, for each node becomes prohibitive. To improve upon this, we introduce the use of a fully persistent spatial data structure (FPSDS), which bounds the size of the lookback. We then focus on the application of the FPSDS in VAMP, which involves incremental geometric computations that can be accelerated by filtering configurations with bounding volumes using nearest-neighbor data structures. We demonstrate an asymptotic and practical improvement in the runtime of finding VAMP solutions in several illustrative domains. To the best of our knowledge, this is the first use of a fully persistent data structure for accelerating motion planning.	https://doi.org/10.1109/ICRA46639.2022.9812173	Sathwik Karnik, Tomás Lozano-Pérez, Leslie Pack Kaelbling, Gustavo Nunes Goretkin
Fusing Event-based and RGB camera for Robust Object Detection in Adverse Conditions.	The ability to detect objects, under image corruptions and different weather conditions is vital for deep learning models especially when applied to real-world applications such as autonomous driving. Traditional RGB-based detection fails under these conditions and it is thus important to design a sensor suite that is redundant to failures of the primary frame-based detection. Event-based cameras can complement frame-based cameras in low-light conditions and high dynamic range scenarios that an autonomous vehicle can encounter during navigation. Accordingly, we propose a redundant sensor fusion model of event-based and frame-based cameras that is robust to common image corruptions. The method utilizes a voxel grid representation for events as input and proposes a two-parallel feature extractor network for frames and events. Our sensor fusion approach is more robust to corruptions by over 30% compared to only frame-based detections and outperforms the only event-based detection. The model is trained and evaluated on the publicly released DSEC dataset.	https://doi.org/10.1109/ICRA46639.2022.9812059	Abhishek Tomy, Anshul Paigwar, Khushdeep Singh Mann, Alessandro Renzaglia, Christian Laugier
Fusion-FlowNet: Energy-Efficient Optical Flow Estimation using Sensor Fusion and Deep Fused Spiking-Analog Network Architectures.	Standard frame-based cameras that sample light intensity frames are heavily impacted by motion blur for high-speed motion and fail to perceive scene accurately in high-dynamic range environments. Event-based cameras, on the other hand, overcome these limitations by asynchronously detecting the variation in individual pixel intensities. However, event cameras only capture pixels in motion, leading to sparse information. Hence, estimating the overall dense behavior of pixels is difficult. To address aforementioned issues associated with both sensors, we present Fusion-FlowNet, a sensor fusion framework for energy -efficient optical flow estimation. Fusion-FlowNet utilizes both frame- and event-based sensors, leveraging their complementary characteristics. Our proposed network architecture is also a fusion of Spiking Neural Net-works (SNNs) and Analog Neural Networks (ANNs) where each network is designed to simultaneously process asynchronous event streams and regular frame-based images, respectively. We perform end-to-end training using unsupervised learning to avoid expensive video annotations. Our method generalizes well across distinct environments (rapid motion and challenging lighting conditions) and demonstrates state-of-the-art optical flow prediction on the Multi-Vehicle Stereo Event Camera (MVSEC) dataset. Furthermore, the usage of SNNs in our architecture offers substantial savings in terms of the number of network parameters and computational energy cost.	https://doi.org/10.1109/ICRA46639.2022.9811821	Chankyu Lee, Adarsh Kumar Kosta, Kaushik Roy
FusionNet: Coarse-to-Fine Extrinsic Calibration Network of LiDAR and Camera with Hierarchical Point-pixel Fusion.	In this paper, we propose a novel network, Fusion-Net, which can estimate the extrinsic calibration matrix between LiDAR and a monocular RGB camera with high accuracy and robustness. FusionNet is a coarse-to-fine method, providing an online and end-to-end solution that can automatically detect and correct the decalibration without any specially designed targets or environments. First, the network applies deep-learning-based technologies to extract the features of LiDAR point clouds and RGB images. Then a novel method is adopted to fuse the features got from different sensors by projecting LiDAR features onto RGB feature maps, searching for the RGB features with the projected points as centers and concatenating the extracted RGB features with LiDAR features. To increase the accuracy, we apply a coarse-to-fine method in the network, by transforming LiDAR points and estimating the extrinsic calibration matrices from the coarse scale to the fine scale. The network is trained on random artificial decalibration matrices. Compared to existing approaches, our method doesn't need to train additional iterative networks, but it can also adapt to different ranges of decalibration.	https://doi.org/10.1109/ICRA46639.2022.9811945	Guangming Wang, Jiahao Qiu, Yanfeng Guo, Hesheng Wang
GCLO: Ground Constrained LiDAR Odometry with Low-drifts for GPS-denied Indoor Environments.	LiDAR is widely adopted in Simultaneous Localization And Mapping (SLAM) and High Definition (HD) map production. The accuracy of LiDAR Odometry (LO) is of great importance, especially in GPS-denied environments. However, we found typical LO results are prone to drift upwards along the vertical direction in underground parking lots, leading to poor mapping results. This paper proposes a Ground Constrained LO method named GCLO, which exploits planar grounds in these specific environments to compress the vertical pose drifts. GCLO is divided into three parts. First, a sensor-centric sliding map is maintained, and the point-to-plane ICP method is implemented to perform the scan-to-map registration. Then, at each key-frame, the sliding map is recorded as a local map. Ground points nearby are segmented and modeled as a planar landmark in the form of Closest Point (CP) parameterization. Finally, planar ground landmarks observed at different key-frames are associated. The ground landmark observation constraints are fused into the pose graph optimization framework to improve the LO performance. Experimental results in HIK and KITTI datasets demonstrate GCLO's superior performances in terms of accuracy in indoor multi-floor parking lots and flat outdoor sites. The limitation of GCLO in adaptability for other environments is also discussed.	https://doi.org/10.1109/ICRA46639.2022.9812336	Xin Wei, Jixin Lv, Jie Sun, Erbao Dong, Shiliang Pu
GOHOME: Graph-Oriented Heatmap Output for future Motion Estimation.	In this paper, we propose GOHOME, a method leveraging graph representations of the High Definition Map and sparse projections to generate a heatmap output representing the future position probability distribution for a given agent in a traffic scene. This heatmap output yields an unconstrained 2D grid representation of agent future possible locations, allowing inherent multimodality and a measure of the uncertainty of the prediction. Our graph-oriented model avoids the high computation burden of representing the surrounding context as squared images and processing it with classical CNNs, but focuses instead only on the most probable lanes where the agent could end up in the immediate future. GOHOME reaches 2nd on Argoverse Motion Forecasting Benchmark on the Misskate6metric while achieving significant speed-up and memory burden diminution compared to Argoverse 1st place method HOME. We also highlight that heatmap output enables multimodal ensembling and improve 1st place MissRate6by more than 15% with our best ensemble on Argoverse. Finally, we evaluate and reach state-of-the-art performance on the other trajectory prediction datasets nuScenes and Interaction, demonstrating the generalizability of our method.	https://doi.org/10.1109/ICRA46639.2022.9812253	Thomas Gilles, Stefano Sabatini, Dzmitry Tsishkou, Bogdan Stanciulescu, Fabien Moutarde
GOMP-FIT: Grasp-Optimized Motion Planning for Fast Inertial Transport.	High-speed motions in pick-and-place operations are critical to making robots cost-effective in many automation scenarios, from warehouses and manufacturing to hospitals and homes. However, motions can be too fast-such as when the object being transported has an open-top, is fragile, or both. One way to avoid spills or damage, is to move the arm slowly. We propose an alternative: Grasp-Optimized Motion Planning for Fast Inertial Transport (GOMP-FIT), a time-optimizing motion planner based on our prior work, that includes con-straints based on accelerations at the robot end-effector. With GOMP-FIT, a robot can perform high-speed motions that avoid obstacles and use inertial forces to its advantage. In experiments transporting open-top containers with varying tilt tolerances, whereas GOMP computes sub-second motions that spill up to 90 % of the contents during transport, GOMP-FIT generates motions that spill 0 % of contents while being slowed by as little as 0 % when there are few obstacles, 30 % when there are high obstacles and 45-degree tolerances, and 50 % when there 15-degree tolerances and few obstacles. Videos and more at: https://berkeleyautomation.github.io/gomp-fit/.	https://doi.org/10.1109/ICRA46639.2022.9812387	Jeffrey Ichnowski, Yahav Avigal, Yi Liu, Ken Goldberg
GPS-Denied Global Visual-Inertial Ground Vehicle State Estimation via Image Registration.	Robotic systems such as unmanned ground vehicles (UGVs) often depend on GPS for navigation in outdoor environments. In GPS-denied environments, one approach to maintain a global state estimate is localizing based on preexisting georeferenced aerial or satellite imagery. However, this is inherently challenged by the significantly differing perspectives between the UGV and reference images. In this paper, we introduce a system for global localization of UGVs in remote, natural environments. We use multi-stereo visual inertial odometry (MSVIO) to provide local tracking. To overcome the challenge of differing viewpoints we use a probabilistic occupancy model to generate synthetic orthographic images from color images taken by the UGV. We then derive global information by scan matching local images to existing reference imagery and then use a pose graph to fuse the measurements to provide uninterrupted global positioning after loss of GPS signal. We show that our system generates visually accurate orthographic images of the environment, provides reliable global measurements, and maintains an accurate global state estimate in GPS-denied conditions.	https://doi.org/10.1109/ICRA46639.2022.9812364	Yehonathan Litman, Daniel McGann, Eric Dexheimer, Michael Kaess
GPU-Accelerated Policy Optimization via Batch Automatic Differentiation of Gaussian Processes for Real-World Control.	The ability of Gaussian processes (GPs) to predict the behavior of dynamical systems as a more sample-efficient alternative to parametric models seems promising for real-world robotics research. However, the computational complexity of GPs has made policy search a highly time and memory consuming process that has not been able to scale to larger problems. In this work, we develop a policy optimization method by leveraging fast predictive sampling methods to process batches of trajectories in every forward pass, and compute gradient updates over policy parameters by automatic differentiation of Monte Carlo evaluations, all on GPU. We demonstrate the effectiveness of our approach in training policies on a set of reference-tracking control experiments with a heavy-duty machine. Benchmark results show a significant speedup over exact methods and showcase the scalability of our method to larger policy networks, longer horizons, and up to thousands of trajectories with a sublinear drop in speed.	https://doi.org/10.1109/ICRA46639.2022.9811876	Abdolreza Taheri, Joni Pajarinen, Reza Ghabcheloo
GRiD: GPU-Accelerated Rigid Body Dynamics with Analytical Gradients.	We introduce GRiD: a GPU-accelerated library for computing rigid body dynamics with analytical gradients. GRiD was designed to accelerate the nonlinear trajectory opti-mization subproblem used in state-of-the-art robotic planning, control, and machine learning, which requires tens to hundreds of naturally parallel computations of rigid body dynamics and their gradients at each iteration. GRiD leverages URDF parsing and code generation to deliver optimized dynamics kernels that not only expose GPU-friendly computational patterns, but also take advantage of both fine-grained parallelism within each computation and coarse-grained parallelism between computations. Through this approach, when performing multiple computations of rigid body dynamics algorithms, GRiD provides as much as a 7.2x speedup over a state-of-the-art, multi-threaded CPU implementation, and maintains as much as a 2.5x speedup when accounting for I/O overhead. We release GRiD as an open-source library for use by the wider robotics community.	https://doi.org/10.1109/ICRA46639.2022.9812384	Brian Plancher, Sabrina M. Neuman, Radhika Ghosal, Scott Kuindersma, Vijay Janapa Reddi
GTGraffiti: Spray Painting Graffiti Art from Human Painting Motions with a Cable Driven Parallel Robot.	We present GTGraffiti, a graffiti painting system from Georgia Tech that tackles challenges in art, hardware, and human-robot collaboration. The problem of painting graffiti in a human style is particularly challenging and requires a system-level approach because the robotics and art must be designed around each other. The robot must be highly dynamic over a large workspace while the artist must work within the robot's limitations. Our approach consists of three stages: artwork capture, robot hardware, and planning & control. We use motion capture to capture collaborator painting motions which are then composed and processed into a time-varying linear feedback controller for a cable-driven parallel robot (CDPR) to execute. In this work, we will describe the capturing process, the design and construction of a purpose-built CDPR, and the software for turning an artist's vision into control commands. Our work represents an important step towards faithfully recreating human graffiti artwork by demonstrating that we can reproduce artist motions up to 2m/s and 20m/s2 within 9.3mm RMSE to paint artworks.	https://doi.org/10.1109/ICRA46639.2022.9812008	Gerry Chen, Sereym Baek, Juan-Diego Florez, Wanli Qian, Sang-won Leigh, Seth Hutchinson, Frank Dellaert
Game-Theoretic Planning for Autonomous Driving among Risk-Aware Human Drivers.	We present a novel approach for risk-aware planning with human agents in multi-agent traffic scenarios. Our approach takes into account the wide range of human driver behaviors on the road, from aggressive maneuvers like speeding and overtaking, to conservative traits like driving slowly and conforming to the right-most lane. In our approach, we learn a mapping from a data-driven human driver behavior model called the CMetric to a driver's entropic risk preference. We then use the derived risk preference within a game-theoretic risk-sensitive planner to model risk-aware interactions among human drivers and an autonomous vehicle in various traffic scenarios. We demonstrate our method in a merging scenario, where our results show that the final trajectories obtained from the risk-aware planner generate desirable emergent behaviors. Particularly, our planner recognizes aggressive human drivers and yields to them while maintaining a greater distance from them. In a user study, participants were able to distinguish between aggressive and conservative simulated drivers based on trajectories generated from our risk-sensitive planner. We also observe that aggressive human driving results in more frequent lane-changing in the planner. Finally, we compare the performance of our modified risk-aware planner with existing methods and show that modeling human driver behavior leads to safer navigation.	https://doi.org/10.1109/ICRA46639.2022.9811865	Rohan Chandra, Mingyu Wang, Mac Schwager, Dinesh Manocha
Gaussian Belief Trees for Chance Constrained Asymptotically Optimal Motion Planning.	In this paper, we address the problem of sampling-based motion planning under motion and measurement un-certainty with probabilistic guarantees. We generalize traditional sampling-based, tree-based motion planning algorithms for deterministic systems and propose belief-A, a framework that extends any kinodynamical tree-based planner to the belief space for linear (or linearizable) systems. We introduce appropriate sampling techniques and distance metrics for the belief space that preserve the probabilistic completeness and asymptotic optimality properties of the underlying planner. We demonstrate the efficacy of our approach for finding safe low-cost paths efficiently and asymptotically optimally in simulation, for both holonomic and non-holonomic systems.	https://doi.org/10.1109/ICRA46639.2022.9812343	Qi Heng Ho, Zachary N. Sunberg, Morteza Lahijanian
Gaussian Process Self-triggered Policy Search in Weakly Observable Environments.	The environments of such large industrial machines as waste cranes in waste incineration plants are often weakly observable, where little information about the environ-mental state is contained in the observations due to technical difficulty or maintenance cost (e.g., no sensors for observing the state of the garbage to be handled). Based on the findings that skilled operators in such environments choose predetermined control strategies (e.g., grasping and scattering) and their durations based on sensor values, we propose a novel non-parametric policy search algorithm: Gaussian process self-triggered policy search (GPSTPS). GPSTPS has two types of control policies: action and duration. A gating mechanism either maintains the action selected by the action policy for the duration specified by the duration policy or updates the action and duration by passing new observations to the policy; therefore, it is categorized as self-triggered. GPSTPS simultaneously learns both policies by trial and error based on sparse GP priors and variational learning to maximize the return. To verify the performance of our proposed method, we conducted experiments on garbage-grasping-scattering task for a waste crane with weak observations using a simulation and a robotic waste crane system. As experimental results, the proposed method acquired suitable policies to determine the action and duration based on the garbage's characteristics.	https://doi.org/10.1109/ICRA46639.2022.9811781	Hikaru Sasaki, Terushi Hirabayashi, Kaoru Kawabata, Takamitsu Matsubara
GelSlim 3.0: High-Resolution Measurement of Shape, Force and Slip in a Compact Tactile-Sensing Finger.	This work presents a new version of tactile-sensing finger, GelSlim 3.0, which integrates the ability to sense high-resolution shape, force, and slip in a more compact form factor than previous implementations, designed for cluttered bin-picking scenarios. The novel design integrates real-time model-based algorithms to measure shape, estimate the 3-D contact force distribution, and detect incipient slip. The constraints imposed by the photometric stereo algorithm used for depth reconstruction and the implementation of a planar sensing surface make the miniaturization of previous designs nontrivial. To achieve a compact integration, we optimize the optical path from illumination source to camera. Using an optical simulation environment, we develop an illumination shaping lens and position the source LEDs and camera. The optimized optical configuration is integrated into a finger design composed of a robust and easily replaceable snap-to-fit fingertip module that facilitates manufacture, assembly, use, and repair. To stimulate future research in tactile-sensing and provide the robotics community access to a reliable and easily reproducible tactile finger with a diversity of sensing modalities, we open-source the design, fabrication methods, and software at https://github.com/mcubelab/gelslim.	https://doi.org/10.1109/ICRA46639.2022.9811832	Ian H. Taylor, Siyuan Dong, Alberto Rodriguez
Generalizable task representation learning from human demonstration videos: a geometric approach.	We study the problem of generalizable task learning from human demonstration videos without extra training on the robot or pre-recorded robot motions. Given a set of human demonstration videos showing a task with different objects/tools (categorical objects), we aim to learn a representation of visual observation that generalizes to categorical objects and enables efficient controller design. We propose to introduce a geometric task structure to the representation learning problem that geometrically encodes the task specification from human demonstration videos, and that enables generalization by building task specification correspondence between categorical objects. Specifically, we propose CoVGS-IL, which uses a graph-structured task function to learn task representations under structural constraints. Our method enables task generalization by selecting geometric features from different objects whose inner connection relationships define the same task in geometric constraints. The learned task representation is then transferred to a robot controller using uncalibrated visual servoing (UVS); thus, the need for extra robot training or pre-recorded robot motions is removed.	https://doi.org/10.1109/ICRA46639.2022.9812195	Jun Jin, Martin Jägersand
Generalized 3D Rigid Point Set Registration with Anisotropic Positional Error Based on Bayesian Coherent Point Drift.	This paper presents a novel, robust, and accurate three-dimensional (3D) rigid point set registration (PSR) method, which is achieved by generalizing the state-of-the-art (SOTA) Bayesian coherent point drift (BCPD) theory to the scenario that high-dimensional point sets(PSs) are aligned and that the anisotropic positional noise is considered. Our contributions in this paper are three folds. First, the problem of rigidly aligning two general point sets (PSs) with normal vectors is incorporated into a variational Bayesian inference framework, which is solved by generalizing the BCPD approach while the anisotropic positional noise is considered. Second, the updated parameters during the algorithm's iterations are given in closed-form or iterative solutions. Third, extensive experiments have been done to validate the proposed approach and its significant improvements over the BCPD.	https://doi.org/10.1109/ICRA46639.2022.9812395	Ang Zhang, Zhe Min, Xing Yang, Zhengyan Zhang, Jin Pan, Max Q.-H. Meng
Generalized Affordance Templates for Mobile Manipulation.	This paper presents recent advances to the Affordance Template (AT) task description language. Affordance Templates provide standardized, easy-to-use tools for defining robot manipulation tasks that provide a high level of augmented reality capabilities to facilitate human-in-the-loop operation, but can also be used to support robot autonomy when coupled with various planning tools. While initially defined in terms of end effector waypoint sequences for bimanual robots, such as the NASA Valkyrie and Robonaut 2, this paper extends the original specification to support integrated mobile manipulation, object-centric template definitions, autonomous grasp determination, and integration with custom and off-the-shelf collision free motion planners. ATs have proved highly adaptable to new robots and new domains by both the authors and third-party groups, and have been used in numerous contexts for NASA, DOD, and industry. As such, we believe that the AT framework provides a strong foundation for robot development in multiple real-world contexts that can be increasingly built upon and expanded to meet the challenges of many new applications.	https://doi.org/10.1109/ICRA46639.2022.9812082	Stephen Hart, Ana C. Huamán Quispe, Michael William Lanighan, Seth Gee
Generalized Omega Turn Gait Enables Agile Limbless Robot Turning in Complex Environments.	Reorientation (turning in plane) plays a critical role for all robots in any field application, especially those that in confined spaces. While important, reorientation remains a relatively unstudied problem for robots, including limbless mechanisms, often called snake robots. Instead of looking at snakes, we take inspiration from observations of the turning behavior of tiny nematode worms C. elegans. Our previous work presented an in-place and in-plane turning gait for limbless robots, called an omega turn, and prescribed it using a novel two-wave template [1]. In this work, we advance omega turn-inspired controllers in three aspects: 1) we use geometric methods to vary joint angle amplitudes and forward wave spatial frequency in our turning equation to establish a wide and precise amplitude modulation and frequency modulation on omega turn; 2) we use this new relationship to enable robots with fewer internal degrees of freedom (i.e., fewer joints in the body) to achieve desirable performance, and 3) we apply compliant control methods to this relationship to handle unmodelled effects in the environment. We experimentally validate our approach on a limbless robot that the omega turn can produce effective and robust turning motion in various types of environments, such as granular media and rock pile.	https://doi.org/10.1109/ICRA46639.2022.9811929	Tianyu Wang, Baxi Chong, Yuelin Deng, Ruijie Fu, Howie Choset, Daniel I. Goldman
Generalizing to New Domains by Mapping Natural Language to Lifted LTL.	Recent work on using natural language to specify commands to robots has grounded that language to LTL. However, mapping natural language task specifications to LTL task specifications using language models require probability distributions over finite vocabulary. Existing state-of-the-art methods have extended this finite vocabulary to include unseen terms from the input sequence to improve output generalization. However, novel out-of-vocabulary atomic propositions cannot be generated using these methods. To overcome this, we introduce an intermediate contextual query representation which can be learned from single positive task specification examples, associating a contextual query with an LTL template. We demonstrate that this intermediate representation allows for generalization over unseen object references, assuming accurate groundings are available. We compare our method of mapping natural language task specifications to intermediate contextual queries against state-of-the-art CopyNet models capable of translating natural language to LTL, by evaluating whether correct LTL for manipulation and navigation task specifications can be output, and show that our method outperforms the CopyNet model on unseen object references. We demonstrate that the grounded LTL our method outputs can be used for planning in a simulated OO-MDP environment. Finally, we discuss some common failure modes encountered when translating natural language task specifications to grounded LTL.	https://doi.org/10.1109/ICRA46639.2022.9812169	Eric Hsiung, Hiloni Mehta, Junchi Chu, Xinyu Liu, Roma Patel, Stefanie Tellex, George Konidaris
Globally Consistent and Tightly Coupled 3D LiDAR Inertial Mapping.	This paper presents a real-time 3D mapping framework based on global matching cost minimization and LiDAR-IMU tight coupling. The proposed framework comprises a preprocessing module and three estimation modules: odometry estimation, local mapping, and global mapping, which are all based on the tight coupling of the GPU-accelerated voxelized GICP matching cost factor and the IMU preintegration factor. The odometry estimation module employs a keyframe-based fixed-lag smoothing approach for efficient and low-drift trajectory estimation, with a bounded computation cost. The global mapping module constructs a factor graph that minimizes the global registration error over the entire map with the support of IMU constraints, ensuring robust optimization in feature-less environments. The evaluation results on the Newer College dataset and KAIST urban dataset show that the proposed framework enables accurate and robust localization and mapping in challenging environments.	https://doi.org/10.1109/ICRA46639.2022.9812385	Kenji Koide, Masashi Yokozuka, Shuji Oishi, Atsuhiko Banno
Globally Optimal Relative Pose Estimation for Multi-Camera Systems with Known Gravity Direction.	Multiple-camera systems have been widely used in self-driving cars, robots, and smartphones. In addition, they are typically also equipped with IMUs (inertial measurement units). Using the gravity direction extracted from the IMU data, the y-axis of the body frame of the multi-camera system can be aligned with this common direction, reducing the original three degree-of-freedom(DOF) relative rotation to a single DOF one. This paper presents a novel globally optimal solver to compute the relative pose of a generalized camera. Existing optimal solvers based on LM (Levenberg-Marquardt) method or SDP (semidefinite program) are either iterative or have high computational complexity. Our proposed optimal solver is based on minimizing the algebraic residual objective function. According to our derivation, using the least-squares algorithm, the original optimization problem can be converted into a system of two polynomials with only two variables. The proposed solvers have been tested on synthetic data and the KITTI benchmark. The experimental results show that the proposed methods have competitive robustness and accuracy compared with the existing state-of-the-art solvers.	https://doi.org/10.1109/ICRA46639.2022.9812380	Qianliang Wu, Yaqing Ding, Xinlei Qi, Jin Xie, Jian Yang
Go With the Flow: Energy Minimising Periodic Trajectories for UVMS.	For Underwater Vehicle Manipulator Systems (UVMS), the ability to keep a fixed end effector pose is required for intervention tasks. Maintaining a static configuration in a dynamic underwater environment requires significant amounts of energy over time, limiting the operational time for battery powered systems. In this work we consider learning the periodic components of the dynamic flow in order to generate periodic trajectories which keep the end effector fixed, yet minimise the energy expenditure over time. We compare this proposed 'go with the flow' approach to the static configuration case for a fixed end effector pose, and show a significant reduction in energy use.	https://doi.org/10.1109/ICRA46639.2022.9811786	Wilhelm Johan Marais, Stefan B. Williams, Oscar Pizarro
Google Scanned Objects: A High-Quality Dataset of 3D Scanned Household Items.	Interactive 3D simulations have enabled break-throughs in robotics and computer vision, but simulating the broad diversity of environments needed for deep learning requires large corpora of photo-realistic 3D object models. To address this need, we present Google Scanned Objects, an open-source collection of over one thousand 3D-scanned household items released under a Creative Commons license; these models are preprocessed for use in Ignition Gazebo and the Bullet simulation platforms, but are easily adaptable to other simulators. We describe our object scanning and curation pipeline, then provide statistics about the contents of the dataset and its usage. We hope that the diversity, quality, and flexibility of Google Scanned Objects will lead to advances in interactive simulation, synthetic perception, and robotic learning.	https://doi.org/10.1109/ICRA46639.2022.9811809	Laura Downs, Anthony Francis, Nate Koenig, Brandon Kinman, Ryan Hickman, Krista Reymann, Thomas Barlow McHugh, Vincent Vanhoucke
Graph Grammar-Based Automatic Design for Heterogeneous Fleets of Underwater Robots.	Autonomous underwater vehicles (AUVs) are spe-cialized robots that are commonly used for seafloor surveying and ocean water sampling. Computational design approaches have emerged to reduce the effort required to design both individual AUVs as well as fleets. As the number and scale of underwater missions increases beyond the capabilities of a single vehicle, fleet level design will become more important. Depending on the mission, the optimal fleet may consist of multiple distinct types of AUVs designed to a variety of specifications. Moreover, the AUVs may differ in both continuous parameters (such as battery capacity) and discrete parameters (such as number and model of thrusters). In this work, we present a computational pipeline for designing these heterogeneous AUV fleets. Using a novel shape design space based on a graph grammar and deformation cages, we can express a variety of AUV architectures with different topologies, component selections, and dimensions. We search this space using a combination of discrete graph search and gradient-based continuous optimization, enabled by a differentiable AUV simulator. Finally, we formulate heterogeneous fleet design as a modified knapsack problem, and solve it using an efficient backtracking-based algorithm. We evaluate our pipeline on a simulated mission with nonuniform design requirements-surveying a section of seafloor with varying depth-and show that the best heterogeneous fleet outperforms the best fleet composed of a single vehicle type.	https://doi.org/10.1109/ICRA46639.2022.9811808	Allan Zhao, Jie Xu, Juan Salazar, Wei Wang, Pingchuan Ma, Daniela Rus, Wojciech Matusik
Graph Neural Network Based Relation Learning for Abnormal Perception Information Detection in Self-Driving Scenarios.	Robustness and safety concerns of perception systems are of great importance for autonomous vehicle navigation applications. Recent researches demonstrate that the surrounding dynamic object detection results of current perception systems can be easily interfered or attacked to mislead the navigation performance of the victim vehicle. In this paper, we develop a GNN based relation learning network to detect the abnormal information in the vehicle perception results, by investigating the relations among the surrounding dynamic objects and also the overall scenario information. Our underlying logic is that the motion of each surrounding object is also affected by its neighbors as well as the whole traffic scenario information, so there should exist a certain amount of consistency among those agents. Learning their spatiotemporal relations provides critical information for detecting the abnormal perception information. Experimental results on the standard CARLA simulator demonstrate our effectiveness in various scenarios and scalability to unseen cases.	https://doi.org/10.1109/ICRA46639.2022.9812411	Kefan Jin, Hongye Wang, Changxing Liu, Yu Zhai, Ling Tang
Graph-based Cluttered Scene Generation and Interactive Exploration using Deep Reinforcement Learning.	We introduce a novel method to teach a robotic agent to interactively explore cluttered yet structured scenes, such as kitchen pantries and grocery shelves, by leveraging the physical plausibility of the scene. We propose a novel learning framework to train an effective scene exploration policy to discover hidden objects with minimal interactions. First, we define a novel scene grammar to represent structured clutter. Then we train a Graph Neural Network (GNN) based Scene Generation agent using deep reinforcement learning (deep RL), to manipulate this Scene Grammar to create a diverse set of stable scenes, each containing multiple hidden objects. Given such cluttered scenes, we then train a Scene Exploration agent, using deep RL, to uncover hidden objects by interactively rearranging the scene. We show that our learned agents hide and discover significantly more objects than the baselines. We present quantitative results that prove the generalization capabilities of our agents. We also demonstrate sim-to-real transfer by successfully deploying the learned policy on a real UR10 robot to explore real-world cluttered scenes. The supplemental video can be found at: https://www.youtube.com/watch?v=T2Jo7wwaXss.	https://doi.org/10.1109/ICRA46639.2022.9811874	K. Niranjan Kumar, Irfan Essa, Sehoon Ha
Graph-based Multi-sensor Fusion for Consistent Localization of Autonomous Construction Robots.	Enabling autonomous operation of large-scale construction machines, such as excavators, can bring key benefits for human safety and operational opportunities for applications in dangerous and hazardous environments. To facilitate robot autonomy, robust and accurate state-estimation remains a core component to enable these machines for operation in a diverse set of complex environments. In this work, a method for multi-modal sensor fusion for robot state-estimation and localization is presented, enabling operation of construction robots in real-world scenarios. The proposed approach presents a graph-based prediction-update loop that combines the benefits of filtering and smoothing in order to provide consistent state estimates at high update rate, while maintaining accurate global localization for large-scale earth-moving excavators. Furthermore, the proposed approach enables a flexible integration of asynchronous sensor measurements and provides consistent pose estimates even during phases of sensor dropout. For this purpose, a dual-graph design for switching between two distinct optimization problems is proposed, directly addressing temporary failure and the subsequent return of global position estimates. The proposed approach is implemented on-board two Menzi Muck walking excavators and validated during real-world tests conducted in representative operational environments.	https://doi.org/10.1109/ICRA46639.2022.9812386	Julian Nubert, Shehryar Khattak, Marco Hutter
Grasp Pose Selection Under Region Constraints for Dirty Dish Grasps Based on Inference of Grasp Success Probability through Self-Supervised Learning.	In the literature on object grasping, the robot often determines the grasp point and posture from visual information. They predict the grasping point uniquely from the object's shape characteristics. However, as a practical matter, there are cases where there are constraints on grasp point due to the object states, the limitation of the robot's hardware and the surrounding environment. In this study, we propose a neural network that can easily constrain the input. It determines the grasp pose from visual information and outputs the grasp success probability. The grasp pose is modified using backpropagation to increase the success rate of the grasp. As for the target object, we deal with some dirty tableware scattered on the table. We have developed a system that autonomously collects supervised data so that the robot can learn by itself whether it has succeeded in a grasp attempt. Finally, the robot can grasp an object which avoids dirty parts and find the suboptimal grasp pose.	https://doi.org/10.1109/ICRA46639.2022.9812084	Shumpei Wakabayashi, Shingo Kitagawa, Kento Kawaharazuka, Takayuki Murooka, Kei Okada, Masayuki Inaba
Grasp Transfer for Deformable Objects by Functional Map Correspondence.	Handling object deformations for robotic grasping is still a major problem to solve. In this paper, we propose an efficient learning-free solution for this problem where generated grasp hypotheses of a region of an object are adapted to its deformed configurations. To this end, we investigate the applicability of functional map (FM) correspondence, where the shape matching problem is treated as searching for correspondences between geometric functions in a reduced basis. For a user selected region of an object, a ranked list of grasp candidates is generated with local contact moment (LoCoMo) based grasp planner. The proposed FM-based methodology maps these candidates to an instance of the object that has suffered arbitrary level of deformation. The best grasp, by analysing its kinematic feasibility while respecting the original finger configuration as much as possible, is then executed on the object. We have compared the performance of our method with two different state-of-the-art correspondence mapping techniques in terms of grasp stability and region grasping accuracy for 4 different objects with 5 different deformations.	https://doi.org/10.1109/ICRA46639.2022.9812141	Cristiana de Farias, Brahim Tamadazte, Rustam Stolkin, Naresh Marturi
Gripper positioning for object deformation tasks.	Shape control involves bringing a deformable object to a desired shape. In the shape control literature, the positioning of the grippers on the object is usually predefined (user-defined) and therefore considered as input information. In this paper we address the gripper positioning problem for shape control. We propose a deformation process within a simulated fully-actuated scenario and introduce multi-scale centroid paths as geometry describing points for which we prove individual control feasibility. Analysis on the evolution of multi-scale centroid paths through the fully-actuated deformation process allows us to define an importance metric for gripper candidates. Final gripper positions, based on the importance metric, are obtained through optimisation. We present simulation results for global and local shape control problems.	https://doi.org/10.1109/ICRA46639.2022.9812304	Ignacio Cuiral-Zueco, Gonzalo López-Nicolás, Helder Araújo
Grounding Predicates through Actions.	"Symbols representing abstract states such as ""dish in dishwasher"" or ""cup on table"" allow robots to reason over long horizons by hiding details unnecessary for high-level planning. Current methods for learning to identify symbolic states in visual data require large amounts of labeled training data, but manually annotating such datasets is prohibitively expensive due to the combinatorial number of predicates in images. We propose a novel method for automatically labeling symbolic states in large-scale video activity datasets by exploiting known pre- and post-conditions of actions. This automatic labeling scheme only requires weak supervision in the form of an action label that describes which action is demonstrated in each video. We use our framework to train predicate classifiers to identify symbolic relationships between objects when prompted with object bounding boxes, and demonstrate that such predicate classifiers can match the performance of those trained with full supervision at a fraction of the labeling cost. We also apply our framework to an existing large-scale human activity dataset, and demonstrate the ability of these predicate classifiers trained on human data to enable closed-loop task planning in the real world."	https://doi.org/10.1109/ICRA46639.2022.9812016	Toki Migimatsu, Jeannette Bohg
Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for Group-Aware Dense Crowd Trajectory Forecasting.	Accurate, long-term forecasting of pedestrian trajectories in highly dynamic and interactive scenes is a longstanding challenge. Recent advances in using data-driven approaches have achieved significant improvements in terms of prediction accuracy. However, the lack of group-aware analysis has limited the performance of forecasting models. This is especially nonnegligible in highly crowded scenes, where pedestrians are moving in groups and the interactions between groups are extremely complex and dynamic. In this paper, we present Grouptron, a multi-scale dynamic forecasting framework that leverages pedestrian group detection and utilizes individual-level, group-level and scene-level information for better understanding and representation of the scenes. Our approach employs spatio-temporal clustering algorithms to identify pedestrian groups, creates spatio-temporal graphs at the individual, group, and scene levels. It then uses graph neural networks to encode dynamics at different scales and aggregate the embeddings for trajectory prediction. We conducted extensive comparisons and ablation experiments to demonstrate the effectiveness of our approach. Our method achieves 9.3% decrease in final displacement error (FDE) compared with state-of-the-art methods on ETH/UCY benchmark datasets, and 16.1% decrease in FDE in more crowded scenes where extensive human group interactions are more frequently present.	https://doi.org/10.1109/ICRA46639.2022.9811585	Rui Zhou, Hongyu Zhou, Huidong Gao, Masayoshi Tomizuka, Jiachen Li, Zhuo Xu
HATP/EHDA: A Robot Task Planner Anticipating and Eliciting Human Decisions and Actions.	The variety and complexity of tasks autonomous robots can tackle is constantly increasing, yet we seldom see robots collaborating with humans. Indeed, humans are either requested for punctual help or are given the lead on the whole task. We propose a human-aware task planning approach allowing the robot to plan for a task while also considering and emulating the human decision, action, and reaction processes. Our approach, named Human-Aware Task Planner with Emulation of Human Decisions and Actions (HATP/EHDA), is based on the exploration of multiple hierarchical tasks networks albeit differently whether the agent is considered to be controllable (the robot) or uncontrollable (the human). We present the rationale of our approach along with a formalization and show its potential on an illustrative example.	https://doi.org/10.1109/ICRA46639.2022.9812227	Guilhem Buisan, Anthony Favier, Amandine Mayima, Rachid Alami
HD Ground - A Database for Ground Texture Based Localization.	We present the HD Ground Database, a comprehensive database for ground texture based localization. It contains sequences of a variety of textures, obtained using a downward facing camera. In contrast to existing databases of ground images, the HD Ground Database is larger, has a greater variety of textures, and has a higher image resolution with less motion blur. Also, our database enables the first systematic study of how natural changes of the ground that occur over time affect localization performance, and it allows to examine a teach-and-repeat navigation scenario. We use the HD Ground Database to evaluate four state-of-the-art localization approaches for global localization, localization with the approximate pose being known, and relative localization.	https://doi.org/10.1109/ICRA46639.2022.9811977	Jan Fabian Schmid, Stephan F. Simon, Raaghav Radhakrishnan, Simone Frintrop, Rudolf Mester
HDMapNet: An Online HD Map Construction and Evaluation Framework.	Constructing HD semantic maps is a central component of autonomous driving. However, traditional pipelines require a vast amount of human efforts and resources in annotating and maintaining the semantics in the map, which limits its scalability. In this paper, we introduce the problem of HD semantic map learning, which dynamically constructs the local semantics based on onboard sensor observations. Meanwhile, we introduce a semantic map learning method, dubbed HDMapNet. HDMapNet encodes image features from surrounding cameras and/or point clouds from LiDAR, and predicts vectorized map elements in the bird's-eye view. We benchmark HDMapNet on nuScenes dataset and show that in all settings, it performs better than baseline methods. Of note, our camera-LiDAR fusion-based HDMapNet outperforms existing methods by more than 50 % in all metrics. In addition, we develop semantic-level and instance-level metrics to evaluate the map learning performance. Finally, we showcase our method is capable of predicting a locally consistent map. By introducing the method and metrics, we invite the community to study this novel map learning problem.	https://doi.org/10.1109/ICRA46639.2022.9812383	Qi Li, Yue Wang, Yilun Wang, Hang Zhao
HGC-Net: Deep Anthropomorphic Hand Grasping in Clutter.	Grasping in cluttered environments is one of the most fundamental skills in robotic manipulation. Most of the current works focus on estimating grasp poses for parallel-jaw or suction-cup end effectors. However, the study for dexterous anthropomorphic hand grasping in clutter remains a great challenge. In this paper, we propose HGC-Net, a single-shot network that learns to predict dense hand grasp configurations in clutter from single-view point cloud input. Our end-to-end neural network can predict hand grasp proposals efficiently and effectively. To enhance generalization, we built a large-scale synthetic grasping dataset with 179 household objects, 5K cluttered scenes and over 10M hand annotations. Experiments in simulation show that our model can predict dense and robust hand grasps and clear over 78% of unseen objects in clutter without any post-processing and outperform baseline methods by a large margin. Experiments on the real robot platform also demonstrate that the model trained on synthetic data performs well in natural environments. Code is available at https://github.com/yimingli1998/hgc_net.	https://doi.org/10.1109/ICRA46639.2022.9811756	Yiming Li, Wei Wei, Daheng Li, Peng Wang, Wanyi Li, Jun Zhong
HMD-former: a Transformer-based Human Mesh Deformer with Inter-layer Semantic Consistency.	We present a transformer-based network, Human Mesh Deformer (HMD-former), to tackle the problem of 3D human mesh reconstruction from a single RGB image. HMD-former applies a pre-trained CNN to extract image grid features and a transformer decoder to gradually warp the template 3D mesh to the deformed mesh. On each decoder layer, the fine-grained local information of grid features is well utilized using cross-attention by softly and content-dependently transforming the grid features to vertex embeddings. Auxiliary losses and proposed bi-directional mapping layers inherently ensure semantic consistency throughout the whole decoder, which free the network from learning unnecessary embedding transformation between layers. This further induces each layer of the decoder to focus on refining vertex embeddings and makes the whole network work in a progressively refining manner. Experiments on different public datasets Human3.6M and 3DPW show better reconstruction accuracy and faster inference speed than previous state-of-the-art methods, demonstrating the effectiveness and generalizability of HMD-former. Code is publicly available at https://github.com/siyuzou/HMD-former.	https://doi.org/10.1109/ICRA46639.2022.9812024	Siyu Zou, Sheng Liu, Chaonan Li, Lu Yao, Shengyong Chen
HR-Planner: A Hierarchical Highway Tactical Planner based on Residual Reinforcement Learning.	Tactical planning is crucial for safe and efficient driving on the highway. However, the problem is complicated by the uncertain intention of surrounding vehicles, as well as observation noise caused by measurement noise and perception errors. Rule-based tactical planning methods are ineffective in handling dynamic scenarios with uncertainty, and susceptible to observation noise. To tackle this problem, we propose a hierarchical tactical planning framework based on residual reinforcement learning. Besides, a new reinforcement learning from demonstrations scheme that views rule-based methods as soft guidance is developed to combine prior knowledge with data-driven methods. Based on the framework and the training scheme, rule-based methods not only can be improved in highway scenarios with uncertainty and observation noise, but also will guide the training procedure for increased sampling efficiency. Additionally, to boost in-depth and consistent exploration in a vehicle system with inertia, we employ noisy networks to explore the optimal policy. The proposed method is validated in a stochastic and uncertain simulation environment, and the results reveal that our method outperforms both rule-based methods and pure data-driven methods in terms of safety and driving efficiency under noisy observations and uncertainty.	https://doi.org/10.1109/ICRA46639.2022.9812400	Haoran Wu, Yueyuan Li, Hanyang Zhuang, Chunxiang Wang, Ming Yang
HYPER: Learned Hybrid Trajectory Prediction via Factored Inference and Adaptive Sampling.	Modeling multi-modal high-level intent is important for ensuring diversity in trajectory prediction. Existing approaches explore the discrete nature of human intent before predicting continuous trajectories, to improve accuracy and support explainability. However, these approaches often assume the intent to remain fixed over the prediction horizon, which is problematic in practice, especially over longer horizons. To overcome this limitation, we introduce HYPER, a general and expressive hybrid prediction framework that models evolving human intent. By modeling traffic agents as a hybrid discrete-continuous system, our approach is capable of predicting discrete intent changes over time. We learn the probabilistic hybrid model via a maximum likelihood estimation problem and leverage neural proposal distributions to sample adaptively from the exponentially growing discrete space. The overall approach affords a better trade-off between accuracy and coverage. We train and validate our model on the Argoverse dataset, and demonstrate its effectiveness through comprehensive ablation studies and comparisons with state-of-the-art models.	https://doi.org/10.1109/ICRA46639.2022.9812254	Xin Huang, Guy Rosman, Igor Gilitschenski, Ashkan Jasour, Stephen G. McGill, John J. Leonard, Brian C. Williams
HandoverSim: A Simulation Framework and Benchmark for Human-to-Robot Object Handovers.	"We introduce a new simulation benchmark ""Han-doverSim"" for human-to-robot object handovers. To simulate the giver's motion, we leverage a recent motion capture dataset of hand grasping of objects. We create training and evaluation environments for the receiver with standardized protocols and metrics. We analyze the performance of a set of baselines and show a correlation with a real-world evaluation.11Code is open sourced at https://handover-sim.github.io."	https://doi.org/10.1109/ICRA46639.2022.9812302	Yu-Wei Chao, Chris Paxton, Yu Xiang, Wei Yang, Balakumar Sundaralingam, Tao Chen, Adithyavairavan Murali, Maya Cakmak, Dieter Fox
HiTPR: Hierarchical Transformer for Place Recognition in Point Cloud.	Place recognition or loop closure detection is one of the core components in a full SLAM system. In this paper, aiming at strengthening the relevancy of local neighboring points and the contextual dependency among global points simultaneously, we investigate the exploitation of transformer-based network for feature extraction, and propose a Hierarchical Transformer for Place Recognition (HiTPR). The HiTPR consists of four major parts: point cell generation, short-range transformer (SRT), long-range transformer (LRT) and global descriptor aggregation. Specifically, the point cloud is initially divided into a sequence of small cells by down-sampling and nearest neighbors searching. In the SRT, we extract the local feature for each point cell. While in the LRT, we build the global dependency among all of the point cells in the whole point cloud. Experiments on several standard benchmarks demonstrate the superiority of the HiTPR in terms of average recall rate, achieving 93.71 % at top 1 % and 86.63 % at top 1 on the Oxford RobotCar dataset for example.	https://doi.org/10.1109/ICRA46639.2022.9811737	Zhixing Hou, Yan Yan, Chengzhong Xu, Hui Kong
Hierarchical Policy Learning for Mechanical Search.	Retrieving objects from clutters is a complex task, which requires multiple interactions with the environment until the target object can be extracted. These interactions involve executing action primitives like grasping or pushing as well as setting priorities for the objects to manipulate and the actions to execute. Mechanical Search (MS) [1] is a framework for object retrieval, which uses a heuristic algorithm for pushing and rule-based algorithms for high-level planning. While rule-based policies profit from human intuition in how they work, they usually perform sub-optimally in many cases. Deep reinforcement learning (RL) has shown great performance in complex tasks such as taking decisions through evaluating pixels, which makes it suitable for training policies in the context of object-retrieval. In this work, we first formulate the MS problem in a principled formulation as a hierarchical POMDP. Based on this formulation, we propose a hierarchical policy learning approach for the MS problem. For demonstration, we present two main parameterized sub-policies: a push policy and an action selection policy. When integrated into the hierarchical POMDP's policy, our proposed sub-policies increase the success rate of retrieving the target object from less than 32% to nearly 80%, while reducing the computation time for push actions from multiple seconds to less than 10 milliseconds.	https://doi.org/10.1109/ICRA46639.2022.9811572	Oussama Zenkri, Ngo Anh Vien, Gerhard Neumann
Hierarchical Representations and Explicit Memory: Learning Effective Navigation Policies on 3D Scene Graphs using Graph Neural Networks.	Representations are crucial for a robot to learn effective navigation policies. Recent work has shown that mid-level perceptual abstractions, such as depth estimates or 2D semantic segmentation, lead to more effective policies when provided as observations in place of raw sensor data (e.g., RGB images). However, such policies must still learn latent three-dimensional scene properties from mid-level abstractions. In contrast, high-level, hierarchical representations such as 3D scene graphs explicitly provide a scene's geometry, topology, and semantics, making them compelling representations for navigation. In this work, we present a reinforcement learning framework that leverages high-level hierarchical representations to learn navigation policies. Towards this goal, we propose a graph neural network architecture and show how to embed a 3D scene graph into an agent-centric feature space, which enables the robot to learn policies that map 3D scene graphs to a platform-agnostic control space (e.g., go straight, turn left). For each node in the scene graph, our method uses features that capture occupancy and semantic content, while explicitly retaining memory of the robot trajectory. We demonstrate the effectiveness of our method against commonly used visuomotor policies in a challenging multi-object search task. These experiments and supporting ablation studies show that our method leads to more effective object search behaviors, exhibits improved long-term memory, and successfully leverages hierarchical information to guide its navigation objectives.	https://doi.org/10.1109/ICRA46639.2022.9812179	Zachary Ravichandran, Lisa Peng, Nathan Hughes, J. Daniel Griffith, Luca Carlone
High Definition, Inexpensive, Underwater Mapping.	In this paper we present a complete framework for Underwater SLAM utilizing a single inexpensive sensor. Over the recent years, imaging technology of action cameras is producing stunning results even under the challenging conditions of the underwater domain. The GoPro 9 camera provides high definition video in synchronization with an Inertial Measurement Unit (IMU) data stream encoded in a single mp4 file. The visual inertial SLAM framework is augmented to adjust the map after each loop closure. Data collected at an artificial wreck of the coast of South Carolina and in caverns and caves in Florida demonstrate the robustness of the proposed approach in a variety of conditions.	https://doi.org/10.1109/ICRA46639.2022.9811695	Bharat Joshi, Marios Xanthidis, Sharmin Rahman, Ioannis M. Rekleitis
HoloOcean: An Underwater Robotics Simulator.	Due to the difficulty and expense of underwater field trials, a high fidelity underwater simulator is a necessity for testing and developing algorithms. To fill this need, we present HoloOcean, an open source underwater simulator, built upon Unreal Engine 4 (UE4). HoloOcean comes equipped with multi-agent support, various sensor implementations of common underwater sensors, and simulated communications support. We also implement a novel sonar sensor model that leverages an octree representation of the environment for efficient and realistic sonar imagery generation. Due to being built upon UE4, new environments are straightforward to add, enabling easy extensions to be built. Finally, HoloOcean is controlled via a simple python interface, allowing simple installation via pip, and requiring few lines of code to execute simulations.	https://doi.org/10.1109/ICRA46639.2022.9812353	Easton R. Potokar, Spencer Ashford, Michael Kaess, Joshua G. Mangelson
HoloSeg: An Efficient Holographic Segmentation Network for Real-time Scene Parsing.	Real-time semantic segmentation is a crucial but challenging dense prediction task for scene parsing. However, the existing CNN-based methods commonly bias the model in favor of speed-boosting compromising spatial resolution due to business requirements and hardware constrains, which impedes the high-accuracy segmentation result. To address the dilemma, we provide a novel Holographic Segmentation Network (HoloSeg), which presents a strong ability of comprehensive information preservation and extraction, and achieves a better trade-off between speed and accuracy. We first design a Lossless Sample Pair (LSP) without any stride for early spatial preservation and later resolution recovery while modeling long-range context dependence. Then, we propose Distributed Pyramid Learning (DPL) to efficiently extract multiscale features and saves a lot of computation. Finally, we propose Resolution Fusion and Restoration (RFR) to fuse multi-level semantic representations across stages and generate output without decoder. Without bells and whistles, HoloSeg achieves state-of-the-art performance on the Cityscapes benchmark which reports 76.24% mIoU at 231 FPS. Code is available online: https://github.com/LiShuTJ/HoloSeg.	https://doi.org/10.1109/ICRA46639.2022.9811930	Shu Li, Qingqing Yan, Chengju Liu, Ming Liu, Qijun Chen
How to Build a Curb Dataset with LiDAR Data for Autonomous Driving.	Curbs are one of the essential elements of urban and highway traffic environments. Robust curb detection provides road structure information for motion planning in an autonomous driving system. Commonly, video cameras and 3D LiDARs are mounted on autonomous vehicles for curb detection. However, camera-based methods suffer from challenging illumination conditions. During the long period of time before wide application of Deep Neural Network (DNN) with point clouds, LiDAR-based curb detection methods are based on hand-crafted features, which suffer from poor detection in some complex scenes. Recently, DNN-based dynamic object detection using LiDAR data has become prevalent, while few works pay attention to curb detection with a DNN approach due to lack of labeled data. A dataset with curb annotations or an efficient curb labeling approach, hence, is of high demand. In this paper, we present how to build a curb dataset with LiDAR data for autonomous driving highly automatically. Firstly, a Semantic High Definition map (SHD map) in a global coordinate frame is generated by applying both SLAM and semantic segmentation on consecutive LiDAR frames. Next, a Road HD map (RHD map) is generated from the SHD map by removing its dynamic noise caused by road users e.g. cars. After that, a Curb Instance map (CI map) can be obtained from the filtered RHD map by a series of curb point extraction and growing. Finally, the CI map can be projected back to single frames for direct, highly automatic curb labeling. In order to validate our proposed labeling method, on top of an open public LiDAR semantic dataset SemanticKITTI [1], an additional curb dataset is built. We run both semantic segmentation and instance segmentation methods on this built dataset. Experimental results show that the curb annotations have good consistency and accuracy. We released this dataset and it is publicly available at https://download.mindspore.cn.	https://doi.org/10.1109/ICRA46639.2022.9811676	Dongfeng Bai, Tongtong Cao, Jingming Guo, Bingbing Liu
Human Navigational Intent Inference with Probabilistic and Optimal Approaches.	Although human navigational intent inference has been studied in the literature, none have adequately considered both the dynamics that describe human motion and internal human parameters that may affect human navigational behaviour. In this paper, we propose a general probabilistic framework to infer the probability distribution over future navigational states of a human. Our framework incorporates an extended Dubins car dynamics to model human movement, which captures differences in human navigational behaviour depending on their position, heading, and movement speed. We assume a noisily rational model of human behaviour that incorporates a) human navigational intent that may change over time, b) how optimal a person's actions are given the navigational intent, and c) how far ahead in time a person considers when choosing navigational actions. These parameters are recursively and continuously updated in a Bayesian fashion. To make the Bayesian update and inference tractable, we exploit properties of the time-to-reach value function from optimal control and the extended Dubins car dynamics to construct a utility function on which the human policy is based, and employ particle representations of probability distributions where necessary. We demonstrate the effectiveness of our method by comparing our results with a recent approach using synthetic data and validate it on real world data.	https://doi.org/10.1109/ICRA46639.2022.9811883	Pedram Agand, Mahdi Taherahmadi, Angelica Lim, Mo Chen
Human-Following and -guiding in Crowded Environments using Semantic Deep-Reinforcement-Learning for Mobile Service Robots.	Assistance robots have gained widespread attention in various industries such as logistics and human assistance. The tasks of guiding or following a human in a crowded environment such as airports or train stations to carry weight or goods is still an open problem. In these use cases, the robot is not only required to intelligently interact with humans, but also to navigate safely among crowds. Thus, especially highly dynamic environments pose a grand challenge due to the volatile behavior patterns and unpredictable movements of humans. In this paper, we propose a Deep-Reinforcement-Learning-based agent for human-guiding and -following tasks in crowded environments. Therefore, we incorporate semantic information to provide the agent with high-level information like the social states of humans, safety models, and class types. We evaluate our proposed approach against a benchmark approach without semantic information and demonstrated enhanced navigational safety and robustness. Moreover, we demonstrate that the agent could learn to adapt its behavior to humans, which improves the human-robot interaction significantly.	https://doi.org/10.1109/ICRA46639.2022.9812111	Linh Kästner, Bassel Fatloun, Zhengcheng Shen, Daniel Gawrisch, Jens Lambrecht
Human-Guided Motion Planning in Partially Observable Environments.	Motion planning is a core problem in robotics, with a range of existing methods aimed to address its diverse set of challenges. However, most existing methods rely on complete knowledge of the robot environment; an assumption that seldom holds true due to inherent limitations of robot perception. To enable tractable motion planning for high-DOF robots under partial observability, we introduce BLIND, an algorithm that leverages human guidance. BLIND utilizes inverse reinforcement learning to derive motion-level guidance from human critiques. The algorithm overcomes the computational challenge of reward learning for high-DOF robots by projecting the robot's continuous configuration space to a motion-planner-guided discrete task model. The learned reward is in turn used as guidance to generate robot motion using a novel motion planner. We demonstrate BLIND using the Fetch robot and perform two simulation experiments with partial observability. Our experiments demonstrate that, despite the challenge of partial observability and high dimensionality, BLIND is capable of generating safe robot motion and outperforms baselines on metrics of teaching efficiency, success rate, and path quality.	https://doi.org/10.1109/ICRA46639.2022.9811893	Carlos Quintero-Peña, Constantinos Chamzas, Zhanyi Sun, Vaibhav V. Unhelkar, Lydia E. Kavraki
Human-Robot Shared Control for Surgical Robot Based on Context-Aware Sim-to-Real Adaptation.	Human-robot shared control, which integrates the advantages of both humans and robots, is an effective approach to facilitate efficient surgical operation. Learning from demonstration (LfD) techniques can be used to automate some of the surgical sub tasks for the construction of the shared control mechanism. However, a sufficient amount of data is required for the robot to learn the manoeuvres. Using a surgical simulator to collect data is a less resource-demanding approach. With sim-to-real adaptation, the manoeuvres learned from a simulator can be transferred to a physical robot. To this end, we propose a sim-to-real adaptation method to construct a human-robot shared control framework for robotic surgery. In this paper, a desired trajectory is generated from a simulator using LfD method, while dynamic motion primitives (DMP) is used to transfer the desired trajectory from the simulator to the physical robotic platform. Moreover, a role adaptation mechanism is developed such that the robot can adjust its role according to the surgical operation contexts predicted by a neural network model. The effectiveness of the proposed framework is validated on the da Vinci Research Kit (dVRK). Results of the user studies indicated that with the adaptive human-robot shared control framework, the path length of the remote controller, the total clutching number and the task completion time can be reduced significantly. The proposed method outperformed the traditional manual control via teleoperation.	https://doi.org/10.1109/ICRA46639.2022.9812379	Dandan Zhang, Zicong Wu, Junhong Chen, Ruiqi Zhu, Adnan Munawar, Bo Xiao, Yuan Guan, Hang Su, Wuzhou Hong, Yao Guo, Gregory S. Fischer, Benny Lo, Guang-Zhong Yang
Humanoid Arm Motion Planning for Improved Disturbance Recovery Using Model Hierarchy Predictive Control.	Humans noticeably swing their arms for balancing and locomotion. Although the underlying biomechanical mechanisms have been studied, it is unclear how robots can fully take advantage of these appendages. Most controllers that exploit arms for balance and locomotion rely on feedback and cannot anticipate incoming disturbances and future states. Model predictive controllers readily address these drawbacks but are computationally expensive. Here, we leverage recent work on model hierarchy predictive control (MHPC). We develop an MHPC formulation that plans arm motions in reaction to expected or unexpected disturbances. We tested multiple model compositions using simulated balance experiments with the MIT Humanoid undergoing various disturbances. We found that an MHPC formulation that plans over a full-body kino-dynamic model for a 0.3 s horizon followed by a single rigid body model for 0.5 s horizon runs at 40 Hz and increases the set of disturbances that the robot can withstand. Arms allow the robot to dissipate momentum quickly and move the center of mass independently from the lower body. This kinematic advantage helps generate ground wrenches while avoiding kinematic singularities and keeping the center of mass and center pressure within the support polygon. We note similar advantages when allowing the MHPC to anticipate incoming disturbances.	https://doi.org/10.1109/ICRA46639.2022.9811878	Charles Khazoom, Sangbae Kim
Hybrid Event Shaping to Stabilize Periodic Hybrid Orbits.	Many controllers for legged robotic systems leverage open- or closed-loop control at discrete hybrid events to enhance stability. These controllers appear in several well studied phenomena such as the Raibert stepping controller, paddle juggling, and swing leg retraction. This work introduces hybrid event shaping (HES): a generalized method for analyzing and designing stable hybrid event controllers. HES utilizes the saltation matrix, which gives a closed-form equation for the effect that hybrid events have on stability. We also introduce shape parameters, which are higher order terms that can be tuned completely independently from the system dynamics to promote stability. Optimization methods are used to produce values of these parameters that optimize a stability measure. Hybrid event shaping captures previously developed control methods while also producing new optimally stable trajectories without the need for continuous-domain feedback.	https://doi.org/10.1109/ICRA46639.2022.9811782	James Zhu, Nathan J. Kong, George Council, Aaron M. Johnson
Hybrid Imitative Planning with Geometric and Predictive Costs in Off-road Environments.	Geometric methods for solving open-world off-road navigation tasks, by learning occupancy and metric maps, provide good generalization but can be brittle in outdoor environments that violate their assumptions (e.g., tall grass). Learning-based methods can directly learn collision-free behavior from raw observations, but are difficult to integrate with standard geometry-based pipelines. This creates an unfortunate conflict – either use learning and lose out on well-understood geometric navigational components, or do not use it, in favor of extensively hand-tuned geometry-based cost maps. In this work, we reject this dichotomy by designing the learning and non-learning-based components in a way such that they can be effectively combined in a self-supervised manner. Both components contribute to a planning criterion: the learned component contributes predicted traversability as rewards, while the geometric component contributes obstacle cost information. We instantiate and comparatively evaluate our system in both in-distribution and out-of-distribution environments, showing that this approach inherits complementary gains from the learned and geometric components and significantly outperforms either of them.	https://doi.org/10.1109/ICRA46639.2022.9811540	Nitish Dashora, Daniel Shin, Dhruv Shah, Henry A. Leopold, David D. Fan, Ali-Akbar Agha-Mohammadi, Nicholas Rhinehart, Sergey Levine
Hybrid Physical Metric For 6-DoF Grasp Pose Detection.	6-DoF grasp pose detection of multi-grasp and multi-object is a challenge task in the field of intelligent robot. To imitate human reasoning ability for grasping objects, data driven methods are widely studied. With the introduction of large-scale datasets, we discover that a single physical metric usually generates several discrete levels of grasp confidence scores, which cannot finely distinguish millions of grasp poses and leads to inaccurate prediction results. In this paper, we propose a hybrid physical metric to solve this evaluation insufficiency. First, we define a novel metric is based on the force-closure metric, supplemented by the measurement of the object flatness, gravity and collision. Second, we leverage this hybrid physical metric to generate elaborate confidence scores. Third, to learn the new confidence scores effectively, we design a multi-resolution network called Flatness Gravity Collision GraspNet (FGC-GraspNet). FGC-GraspNet proposes a multi-resolution features learning architecture for multiple tasks and introduces a new joint loss function that enhances the average precision of the grasp detection. The network evaluation and adequate real robot experiments demonstrate the effectiveness of our hybrid physical metric and FGC-GraspNet. Our method achieves 90.5% success rate in real-world cluttered scenes. Our code is available at https://github.com/luyh20IFGC-GraspNet.	https://doi.org/10.1109/ICRA46639.2022.9811961	Yuhao Lu, Beixing Deng, Zhenyu Wang, Peiyuan Zhi, Yali Li, Shengjin Wang
Hydraulic Servo Booster for Serially Configured Modular Robots.	This paper presents a proposal of new hydraulic circuit, designated as a modular hydraulic servo booster (MHSB), aimed at the realization of modular hydraulic robots. The modular robots, however, have important shortcomings compared to non-modular robots, such as separate power sources and power imbalance between axes when applied to serially configured robots. To mitigate those difficulties, we take advantage of pressure boost and flow summing by multiple servo pumps and switching valves, which are connected through the hydraulic rails shared between the circuits. Coordinated control of the pump and valve greatly improves energy efficiency over conventional servo valve systems. After presenting realization of the circuit and possible operating modes, the control method for each mode is explained. The experimentally obtained results for position control of a two-link serial manipulator validate the proposed method, especially by the shared boost mode, where small pumps work together to have high torque and speed of the proximal joint.	https://doi.org/10.1109/ICRA46639.2022.9812145	Sang-Ho Hyon, Tomoro Kai
Hydraulically Actuated Soft Tubular Gripper.	There is an increasing interest in soft robotic grippers as they exhibit an ability to grip objects of differing shapes, sizes, textures, and even deformable materials, all of which present a difficult challenge to traditional rigid grippers. An ideal soft gripper would exhibit universal gripping with high gripping force and consists of low-cost materials with simple fabrication processes. This paper investigates the development of a strong and scalable hydraulic soft tubular gripper (HSTG) using facile fabrication method and low-cost materials. The HSTG which consists of a single long hydraulically actuated artificial muscle, soft 3D printed element, and commercial weaving yarn can expand and contract its orifice to grasp objects using a miniature hydraulic syringe. Grasping experiments show that the new HSTG can successfully grasp convex, nonconvex, and flat objects as well as the ones with cavity. The soft gripper uniquely exhibits high normal contact force at minimal pressure and energy use due to the nature of its working principle. A 26 g HSTG can produce at least 40 N of gripping force, can hold at least 88 N in external gripping mode (~346 times of its weight), 0.34 N in internal mode, and 1.74 N in suction gripping mode. The design and mechanical properties of its components can be fine-tuned to produce tailored performance for different grasping tasks.	https://doi.org/10.1109/ICRA46639.2022.9811983	James Davies, Phuoc Thien Phan, Diana Huang, Trung Thien Hoang, Harrison Low, Mai Thanh Thai, Chi Cong Nguyen, Emanuele Nicotra, Nigel H. Lovell, Thanh Nho Do
I Know What You Draw: Learning Grasp Detection Conditioned on a Few Freehand Sketches.	In this paper, we are interested in the problem of generating target grasps by understanding freehand sketches. The sketch is useful for the persons who cannot formulate language and the cases where a textual description is not available on the fly. However, very few works are aware of the usability of this novel interactive way between humans and robots. To this end, we propose a method to generate a potential grasp configuration relevant to the sketch -depicted objects. Due to the inherent ambiguity of sketches with abstract details, we take the advantage of the graph by incorporating the structure of the sketch to enhance the representation ability. This graph-represented sketch is further validated to improve the generalization of the network, capable of learning the sketch-queried grasp detection by using a small collection (around 100 samples) of hand-drawn sketches. Additionally, our model is trained and tested in an end-to-end manner which is easy to be implemented in real-world applications. Experiments on the multi-object VMRD and GraspNet-1Billion datasets demonstrate the good generalization of the proposed method. The physical robot experiments confirm the utility of our method in object-cluttered scenes.	https://doi.org/10.1109/ICRA46639.2022.9812372	Haitao Lin, Chilam Cheang, Yanwei Fu, Xiangyang Xue
I Know You Can't See Me: Dynamic Occlusion-Aware Safety Validation of Strategic Planners for Autonomous Vehicles Using Hypergames.	A particular challenge for both autonomous and human driving is dealing with risk associated with dynamic occlusion, i.e., occlusion caused by other vehicles in traffic. Based on the theory of hypergames, we develop a novel multi-agent dynamic occlusion risk (DOR) measure for assessing situational risk in dynamic occlusion scenarios. Furthermore, we present a white-box, scenario-based, accelerated safety validation framework for assessing safety of strategic planners in AV. Based on evaluation over a large naturalistic database, our proposed validation method achieves a 4000% speedup compared to direct validation on naturalistic data, a more diverse coverage, and ability to generalize beyond the dataset and generate commonly observed dynamic occlusion crashes in traffic in an automated manner.	https://doi.org/10.1109/ICRA46639.2022.9812041	Maximilian Kahn, Atrisha Sarkar, Krzysztof Czarnecki
IPC-GraspSim: Reducing the Sim2Real Gap for Parallel-Jaw Grasping with the Incremental Potential Contact Model.	Accurately simulating whether an object will be lifted securely or dropped during grasping is a longstanding Sim2Real challenge. Soft compliant jaw tips are almost universally used with parallel-jaw robot grippers due to their ability to increase contact area and friction between the jaws and the object to be manipulated. However, interactions between the compliant surfaces and rigid objects are notoriously difficult to model. We introduce IPC-GraspSim, a novel grasp simulator that extends Incremental Potential Contact (IPC) - a highly accurate collision + deformation model developed in 2020 for computer graphics. IPC-GraspSim models both the dynamics and the deformation of compliant jaw tips to reduce Sim2Real gap for robot grasping. We evaluate IPC-GraspSim using a set of 2,000 physical grasps across 16 adversarial objects where analytic models perform poorly. In comparison to both analytic quasistatic contact models (soft point contact, REACH, 6DFC) and dynamic grasp simulators (Isaac Gym with FleX), results suggest IPC-GraspSim can predict robustness with higher precision and recall (F1 = 0.85). IPC-GraspSim increases F1 score by 0.03 to 0.20 over analytic baselines and 0.09 over Isaac Gym, at a cost of 8000x and 1.5x more compute time, respectively. All data, code, videos, and supplementary material are available at https://sites.google.com/berkeley.edu/ipcgraspsim.	https://doi.org/10.1109/ICRA46639.2022.9811777	Chung Min Kim, Michael Danielczuk, Isabella Huang, Ken Goldberg
IPS300+: a Challenging multi-modal data sets for Intersection Perception System.	Due to high complexity and occlusion, insufficient perception in the crowded urban intersection can be a serious safety risk for both human drivers and autonomous algorithms, whereas CVIS (Cooperative Vehicle Infrastructure System) is a proposed solution for full-participants perception under this scenario. However, the research on roadside multi-modal perception is still in its infancy, and there is no open-source data sets for such scene. Accordingly, this paper fills the gap. Through an IPS (Intersection Perception System) installed at the diagonal of the intersection, this paper proposes a high-quality multi-modal data sets for the intersection perception task. The center of the experimental intersection covers an area of 3000m2, and the extended distance reaches 300m, which is typical for CVIS. The first batch of open-source data includes 14198 frames, and each frame has an average of 319.84 labels, which is 9.6 times larger than the most crowded data sets (H3D data sets in 2019) by now. Our data sets is available at: http://www.openmpd.com/column/IPS300.	https://doi.org/10.1109/ICRA46639.2022.9811699	Huanan Wang, Xinyu Zhang, Zhiwei Li, Jun Li, Kun Wang, Zhu Lei, Haibing Ren
Immersive Virtual Walking System Using an Avatar Robot.	The ongoing COVID-19 pandemic has enforced governments across the world to impose social restrictions on the movement of people and confined them to their homes to avoid the spread of the disease. This not only forbids them from leaving their homes but also greatly reduces their physical activities. This situation has brought attention to virtual technologies such as virtual tours or telepresence robots. While these technologies allow people to remotely participate in activities, it does not address the problem of reduction in physical activities due to the pandemic. In this paper, we propose a telepresence robotic system driven by the user's gait to provide an immersive virtual walking experience in remote locations. To this end, we developed a control interface consisting of an automated treadmill that adjusts its speed to the user's pace automatically. This interface is used to control an avatar robot that sends a 360-degree live image back to the user for visual feedback. We conducted an evaluation experiment to compare the experience using the proposed system in two different conditions to that of regular walking. The results indicated that the proposed system gives an immersive and realistic virtual walking experience while demanding physical effort from the user.	https://doi.org/10.1109/ICRA46639.2022.9811588	Kengkij Promsutipong, Jose V. Salazar Luces, Ankit A. Ravankar, Seyed Amir Tafrishi, Yasuhisa Hirata
Impact Planning and Pre-configuration based on Hierarchical Quadratic Programming.	Impacts and other non-smooth behaviors are usually unwanted in robotic applications. However, several industrial tasks such as deburring, removing excess material, and assembling/fitting, involve impacts between objects, which can benefit from robotic automation due to the risks posed to human health. Towards this objective, in this paper, we propose a method for optimal impact planning and pre-configuration for torque-controlled robots. We thus employ a well-known impulsive contact model to plan the impact force and create a hierarchical quadratic programming based controller capable of minimizing the robot's peak torques by reconfiguring its joints optimally, before the impact occurs. The results obtained from multiple experiments during an industrial deburring task are discussed. Using a 7-DoF manipulator, we show consistent results, both in terms of accuracy of the impact force tracking with respect to the desired forces, and in terms of peak torques reduction and uniform torques distribution.	https://doi.org/10.1109/ICRA46639.2022.9811681	Francesco Tassi, Soheil Gholami, Simone Giudice, Arash Ajoudani
Implicit Differential Dynamic Programming.	Over the past decade, the Differential Dynamic Programming (DDP) method has gained in maturity and popularity within the robotics community. Several recent contributions have led to the integration of constraints within the original DDP formulation, hence enlarging its domain of application while making it a strong and easy-to-implement competitor against alternative methods of the state of the art such as collocation or multiple-shooting approaches. Yet, and similarly to its competitors, DDP remains unable to cope with high-dimensional dynamics within a receding horizon fashion, such as in the case of online generation of athletic motion on humanoid robots. In this paper, we propose to make a step towards this objective by reformulating classical DDP as an implicit optimal control problem, allowing the use of more advanced integration schemes such as implicit or variational integrators. To that end, we introduce a primal-dual proximal Lagrangian approach capable of handling dynamical and path constraints in a unified manner, while taking advantage of the time sparsity inherent to optimal control problems. We show that this reformulation enables us to relax the dynamics along the optimization process by solving it inexactly: far from the optimality conditions, the dynamics are only partially fulfilled, but continuously enforced as the solver gets closer to the local optimal solution. This inexactness enables our approach to robustly handle large time steps (100 ms or more), unlike other DDP solvers of the state of the art, as experimentally validated through different robotic scenarii.	https://doi.org/10.1109/ICRA46639.2022.9811647	Wilson Jallet, Nicolas Mansard, Justin Carpentier
Implicit Kinematic Policies: Unifying Joint and Cartesian Action Spaces in End-to-End Robot Learning.	Action representation is an important yet often overlooked aspect in end-to-end robot learning with deep networks. Choosing one action space over another (e.g. target joint positions, or Cartesian end-effector poses) can result in surprisingly stark performance differences between various downstream tasks - and as a result, considerable research has been devoted to finding the right action space for a given application. However, in this work, we instead investigate how our models can discover and learn for themselves which action space to use. Leveraging recent work on implicit behavioral cloning, which takes both observations and actions as input, we demonstrate that it is possible to present the same action in multiple different spaces to the same policy - allowing it to learn inductive patterns from each space. Specifically, we study the benefits of combining Cartesian and joint action spaces in the context of learning manipulation skills. To this end, we present Implicit Kinematic Policies (IKP), which incorporates the kinematic chain as a differentiable module within the deep network. Quantitative experiments across several simulated continuous control tasks-from scooping piles of small objects, to lifting boxes with elbows, to precise block insertion with miscalibrated robots-suggest IKP not only learns complex prehensile and non-prehensile manipulation from pixels better than baseline alternatives, but also can learn to compensate for small joint encoder offset errors. Finally, we also run qualitative experiments on a real UR5e to demonstrate the feasibility of our algorithm on a physical robotic system with real data. See https://tinyurl.com/4wz3nf86 for code and supplementary material.	https://doi.org/10.1109/ICRA46639.2022.9812165	Aditya Ganapathi, Pete Florence, Jake Varley, Kaylee Burns, Ken Goldberg, Andy Zeng
Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction.	Super-resolution of LiDAR range images is crucial to improving many downstream tasks such as object detection, recognition, and tracking. While deep learning has made a remarkable advances in super-resolution techniques, typical convolutional architectures limit upscaling factors to specific output resolutions in training. Recent work has shown that a continuous representation of an image and learning its implicit function enable almost limitless upscaling. However, the detailed approach, predicting values (depths) for neighbor pixels in the input and then linearly interpolating them, does not best fit the LiDAR range images since it does not fill the unmeasured details but creates a new image with regression in a high-dimensional space. In addition, the linear interpolation blurs sharp edges providing important boundary information of objects in 3-D points. To handle these problems, we propose a novel network, Implicit LiDAR Network (ILN), which learns not the values per pixels but weights in the interpolation so that the super-resolution can be done by blending the input pixel depths but with non-linear weights. Also, the weights can be considered as attentions from the query to the neighbor pixels, and thus an attention module in the recent Transformer architecture can be leveraged. Our experiments with a novel large-scale synthetic dataset demonstrate that the proposed network reconstructs more accurately than the state-of-the-art methods, achieving much faster convergence in training.	https://doi.org/10.1109/ICRA46639.2022.9811992	Youngsun Kwon, Minhyuk Sung, Sung-Eui Yoon
Important Object Identification with Semi-Supervised Learning for Autonomous Driving.	"Accurate identification of important objects in the scene is a prerequisite for safe and high-quality decision making and motion planning of intelligent agents (e.g., autonomous vehicles) that navigate in complex and dynamic environments. Most existing approaches attempt to employ attention mechanisms to learn importance weights associated with each object indirectly via various tasks (e.g., trajectory prediction), which do not enforce direct supervision on the importance estimation. In contrast, we tackle this task in an explicit way and formulate it as a binary classification (""important"" or ""unimportant"") problem. We propose a novel approach for important object identification in egocentric driving scenarios with relational reasoning on the objects in the scene. Besides, since human annotations are limited and expensive to obtain, we present a semi-supervised learning pipeline to enable the model to learn from unlimited unlabeled data. Moreover, we propose to leverage the auxiliary tasks of ego vehicle behavior prediction to further improve the accuracy of importance estimation. The proposed approach is evaluated on a public egocentric driving dataset (H3D) collected in complex traffic scenarios. A detailed ablative study is conducted to demonstrate the effectiveness of each model component and the training strategy. Our approach also outperforms rule-based baselines by a large margin."	https://doi.org/10.1109/ICRA46639.2022.9812234	Jiachen Li, Haiming Gang, Hengbo Ma, Masayoshi Tomizuka, Chiho Choi
Improved Kalman-Particle Kernel Filter on Lie Groups Applied to Angles-Only UAV Navigation.	Kalman-Particle Kernel Filter (KPKF) is a sub-class of Particle Filter (PF) that uses Gaussian kernels as particles, which enables a local Kalman update for each measurement in addition to the usual weight update. Besides, recent research about filtering on Lie groups brought powerful theoretical results, and showed the superiority of this approach. Hence, this paper extends the Euclidean KPKF to a new formulation on Lie groups and introduces substantial improvements based on Lie groups Kalman filters theory and Laplace Particle Filters on Lie groups (LG-LPF) for improved resampling. The proposed algorithm is tested on an angles-only UAV navigation scenario with challenging initial errors. It shows superior robustness and accuracy compared to Lie group Extended Kalman Filter (LG-EKF), with near-to optimal performance, even with a limited amount of particles.	https://doi.org/10.1109/ICRA46639.2022.9812192	Clément Chahbazian, Karim Dahia, Nicolas Merlinge, Bénédicte Winter-Bonnet, Kévin Honore, Christian Musso
Improved Soft Duplicate Detection in Search-Based Motion Planning.	Search-based techniques have shown great success in motion planning problems such as robotic navigation by discretizing the state space and precomputing motion primitives. However in domains with complex dynamic constraints, constructing motion primitives in a discretized state space is non-trivial. This requires operating in continuous space which can be challenging for search-based planners as they can get stuck in local minima regions. Previous work [1] on planning in continuous spaces introduced soft duplicate detection which requires search to compute the duplicity of a state with respect to previously seen states to avoid exploring states that are likely to be duplicates, especially in local minima regions. They propose a simple metric utilizing the Euclidean distance between states, and proximity to obstacles to compute the duplicity. In this paper, we improve upon this metric by introducing a kinodynamically informed metric, subtree overlap, between two states as the similarity between their successors that can be reached within a fixed time horizon using kinodynamic motion primitives. This captures the intuition that, due to robot dynamics, duplicate states can be far in Euclidean distance and result in very similar successor states, while non-duplicate states can be close and result in widely different successors. Our approach computes the new metric offline for a given robot dynamics, and stores the subtree overlap value for all possible relative state configurations. During search, the planner uses these precomputed values to speed up duplicity computation, and achieves fast planning times in continuous spaces in addition to completeness and sub-optimality guarantees. Empirically, we show that our improved metric for soft duplicity detection in search-based planning outperforms previous approaches in terms of planning time, by a factor of 1.5 to 2× on 3D and 5D planning domains with highly constrained dynamics.	https://doi.org/10.1109/ICRA46639.2022.9812206	Nader Maray, Anirudh Vemula, Maxim Likhachev
Improved State Propagation through AI-based Pre-processing and Down-sampling of High-Speed Inertial Data.	We present a novel approach to improve 6 degree-of-freedom state propagation for unmanned aerial vehicles in a classical filter through pre-processing of high-speed inertial data with AI algorithms. We evaluate both an LSTM-based approach as well as a Transformer encoder architecture. Both algorithms take as input short sequences of fixed length N of high-rate inertial data provided by an inertial measurement unit (IMU) and are trained to predict in turn one pre-processed IMU sample that minimizes the state propagation error of a classical filter across M sequences. This setup allows us to provide sufficient temporal history to the networks for good performance while maintaining a high propagation rate of pre-processed IMU samples important for later deployment on real-world systems. In addition, our network architectures are formulated to directly accept input data at variable rates thus minimizing necessary data preprocessing. The results indicate that the LSTM based architecture outperforms the Transformer encoder architecture and significantly improves the propagation error even for long IMU propagation times.	https://doi.org/10.1109/ICRA46639.2022.9811989	Jan Steinbrener, Christian Brommer, Thomas Jantos, Alessandro Fornasier, Stephan Weiss
Improved Task Planning through Failure Anticipation in Human-Robot Collaboration.	Human-Robot Collaboration (HRC) has become a major trend in robotics in recent years with the idea of combining the strengths from both humans and robots. In order to share the work to be done, many task planning approaches have been implemented. However, they don't fully satisfy the required adaptability in human-robot collaborative tasks, with most approaches not considering neither the state of the human partner nor the possibility of adapting the collaborative plan during execution or even anticipating failures. In this paper, we present a planning system for human-robot collaborative plans that takes into account the agents' states and deals with unforeseen human behaviour, by replanning in anticipation when the human state changes to prevent action failure. The human state is defined in terms of capacity, knowledge and motivation. The system has been implemented in a standardised environment using the Planning Domain Definition Language (PDDL) and the modular ROSPlan framework, and we have validated the approach in multiple simulation settings. Our results show that using the human model fosters an appropriate task allocation while allowing failure anticipation, replanning in time to prevent it.	https://doi.org/10.1109/ICRA46639.2022.9812236	Silvia Izquierdo-Badiola, Gerard Canal, Carlos Rizzo, Guillem Alenyà
Improving Haptic Exploration of Object Shape by Discovering Symmetries.	The shapes of most real-world objects are symmetric with respect to at least one plane of symmetry. This information is unconsciously used by humans when they attempt to estimate the shape of an object in presence of uncertainty or missing evidence, for example if the object is partially occluded or if they are exploring the object by touch (i.e. haptic exploration). In robotics, this concept has been used for the visual estimation of object shape. However, no attempt has been made so far to incorporate this idea into haptic-based estimation. This work presents a method for the haptic exploration of object shape that includes the assumption that a symmetry could exist. The approach combines a tailored version of Gaussian Processes and a novel exploratory procedure that is able to detect the position and orientation of any plane of symmetry. Our results show that, if one or more symmetries exist, the object shape can be estimated faster and more accurately. Interestingly, in the case that no symmetry is present, the exploration process is only slightly slower, and the final accuracy of the shape estimation is not compromised.	https://doi.org/10.1109/ICRA46639.2022.9812200	Aramis Augusto Bonzini, Lucia Seminara, Lorenzo Jamone
Improving Safety in Deep Reinforcement Learning using Unsupervised Action Planning.	"One of the key challenges to deep reinforcement learning (deep RL) is to ensure safety at both training and testing phases. In this work, we propose a novel technique of unsupervised action planning to improve the safety of on-policy reinforcement learning algorithms, such as trust region policy optimization (TRPO) or proximal policy optimization (PPO). We design our safety-aware reinforcement learning by storing all the history of ""recovery"" actions that rescue the agent from dangerous situations into a separate ""safety"" buffer and finding the best recovery action when the agent encounters similar states. Because this functionality requires the algorithm to query similar states, we implement the proposed safety mechanism using an unsupervised learning algorithm, k-means clustering. We evaluate the proposed algorithm on six robotic control tasks that cover navigation and manipulation. Our results show that the proposed safe RL algorithm can achieve higher rewards compared with multiple baselines in both discrete and continuous control problems. The supplemental video can be found at: https://youtu.be/AFTeWSohILo."	https://doi.org/10.1109/ICRA46639.2022.9812181	Hao-Lun Hsu, Qiuhua Huang, Sehoon Ha
Improving Standing Balance Performance through the Assistance of a Mobile Collaborative Robot.	This paper presents the design and development of a robotic system to give physical assistance to the elderly or people with neurological disorders such as Ataxia or Parkin-son's. In particular, we propose using a mobile collaborative robot with an interaction-assistive whole-body interface to help people unable to maintain balance. The robotic system consists of an Omni-directional mobile base, a high-payload robotic arm, and an admittance-type interface acting as a support handle while measuring human-sourced interaction forces. The postural balance of the human body is estimated through the projection of the body Center of Mass (CoM) to the support polygon (SP) representing the quasi-static Center of Pressure (CoP). In response to the interaction forces and the tracking of the human posture, the robot can create assistive forces to restore balance in case of its loss. Otherwise, during normal stance or walking, it will follow the user with minimum/no opposing forces through the generation of coupled arm and base movements. As the balance-restoring strategy, we propose two strategies and evaluate them in a laboratory setting on healthy human participants. Quantitative and qualitative results of a 12-subjects experiment are then illustrated and discussed, comparing the performances of the two strategies and the overall system.	https://doi.org/10.1109/ICRA46639.2022.9812284	Francisco J. Ruiz-Ruiz, Alberto Giammarino, Marta Lorenzini, Juan M. Gandarias, Jesús M. Gómez de Gabriel, Arash Ajoudani
Improving the Feasibility of DS-based Collision Avoidance Using Non-Linear Model Predictive Control.	In this paper we present a novel strategy for reactive collision-free feasible motion planning for robotic manipulators operating inside an environment populated by moving obstacles. The proposed strategy embeds the Dynamical System (DS) based obstacle avoidance algorithm into a constrained non-linear optimization problem following the Model Predictive Control (MPC) approach. The solution of the problem allows the robot to avoid undesired collision with moving obstacles ensuring at the same time that its motion is feasible and does not overcome the designed constraints on velocity and acceleration. Simulations demonstrate that the introduction of the MPC prediction horizon helps the optimization solver in finding the solution leading to obstacle avoidance in situations where a non predictive implementation of the DS-based method would fail. Finally, the proposed strategy has been validated in an experimental work-cell using a Franka-Emika Panda robot.	https://doi.org/10.1109/ICRA46639.2022.9811700	Saverio Farsoni, Alessio Sozzi, Marco Minelli, Cristian Secchi, Marcello Bonfè
Incorporating Rich Social Interactions Into MDPs.	Much of what we do as humans is engage socially with other agents, a skill that robots must also eventually possess. We demonstrate that a rich theory of social interactions originating from microsociology can be formalized by extending a nested MDP where agents reason about arbitrary functions of each other's rewards. This extended Social MDP allows us to encode the five basic interactions that underlie microsociology: cooperation, conflict, coercion, competition, and exchange. The result is a robotic agent capable of executing social interactions in new environments with no interaction-specific training; like humans it can engage socially in novel ways even without a single example of that social interaction. Moreover, the estimations of these Social MDPs align closely with the judge-ments of humans when considering which social interaction is taking place in an environment. This method both sheds light on the nature of social interactions, by providing concrete mathematical definitions, and brings rich social interactions into a mathematical framework that has proven to be natural for robotics.	https://doi.org/10.1109/ICRA46639.2022.9811991	Ravi Tejwani, Yen-Ling Kuo, Tianmin Shu, Bennett Stankovits, Dan Gutfreund, Joshua B. Tenenbaum, Boris Katz, Andrei Barbu
Incremental Abstraction in Distributed Probabilistic SLAM Graphs.	Scene graphs represent the key components of a scene in a compact and semantically rich way, but are difficult to build during incremental SLAM operation because of the challenges of robustly identifying abstract scene elements and optimising continually changing, complex graphs. We present a distributed, graph-based SLAM framework for incrementally building scene graphs based on two novel components. First, we propose an incremental abstraction framework in which a neural network proposes abstract scene elements that are incorporated into the factor graph of a feature-based monocular SLAM system. Scene elements are confirmed or rejected through optimisation and incrementally replace the points yielding a more dense, semantic and compact representation. Second, enabled by our novel routing procedure, we use Gaussian Belief Propagation (GBP) for distributed inference on a graph processor. The time per iteration of GBP is structure-agnostic and we demonstrate the speed advantages over direct methods for inference of heterogeneous factor graphs. We run our system on real indoor datasets using planar abstractions and recover the major planes with significant compression.	https://doi.org/10.1109/ICRA46639.2022.9812078	Joseph Ortiz, Talfan Evans, Edgar Sucar, Andrew J. Davison
Incremental Few-Shot Object Detection for Robotics.	Incremental few-shot learning is highly expected for practical robotics applications. On one hand, robot is desired to learn new tasks quickly and flexibly using only few annotated training samples; on the other hand, such new additional tasks should be learned in a continuous and incremental manner without forgetting the previous learned knowledge dramatically. In this work, we propose a novel Class-Incremental Few- Shot Object Detection (CI-FSOD) framework that enables deep object detection network to perform effective continual learning from just few-shot samples without re-accessing the previous training data. We achieve this by equipping the widely-used Faster-RCNN detector with three elegant components. Firstly, to best preserve performance on the pre-trained base classes, we propose a novel Dual-Embedding-Space (DES) architecture which decouples the representation learning of base and novel categories into different spaces. Secondly, to mitigate the catastrophic forgetting on the accumulated novel classes, we propose a Sequential Model Fusion (SMF) method, which is able to achieve long-term memory without additional storage cost. Thirdly, to promote inter-task class separation in feature space, we propose a novel regularization technique that extends the classification boundary further away from the previous classes to avoid misclassification. Overall, our framework is simple yet effective and outperforms the previous SOTA with a significant margin of 2.4 points in AP performance.	https://doi.org/10.1109/ICRA46639.2022.9811856	Yiting Li, Haiyue Zhu, Sichao Tian, Fan Feng, Jun Ma, Chek Sing Teo, Cheng Xiang, Prahlad Vadakkepat, Tong Heng Lee
Incremental Learning for Enhanced Personalization of Autocomplete Teleoperation.	Remote controlling robots without any automated help is difficult due to various limitations. Autocomplete mitigates this difficulty by automatically detecting and completing the intended motions on robots from the input of the user. Such an approach can improve the system performance and reduce the load on the operator. Usually, recognizing intended motions is achieved using pre-trained Deep Learning (DL) models. In this paper, we introduce personalization to the autocomplete teleoperation framework when new operators take over by customizing the autocomplete DL model using incremental learning. Also, we tackle the problem of concept drift that arises in real-life applications; the data distribution of already learned classes may change in unforeseen ways as new observations of these classes come sequentially over time. We create and update an exemplar set using new observations of the classes online so that the model can be trained to adapt to the new observations. Several scenarios have been evaluated to balance the speed of learning with the accuracy of the model, and results demonstrate the effectiveness of the proposed models and their advantage in adapting to the specific operator versus our previous framework: personalization using transfer learning with full feedback.	https://doi.org/10.1109/ICRA46639.2022.9812108	Mohammad Haj Hussein, Batool Ibrahim, Imad H. Elhajj, Daniel C. Asmar
Indoor Localization for Quadrotors using Invisible Projected Tags.	Augmented reality (AR) technology has been in-troduced into the robotics field to narrow the visual gap between indoor and outdoor environments. However, without signals from satellite navigation systems, flight experiments in these indoor AR scenarios need other accurate localization approaches. This work proposes a real-time centimeter-level indoor localization method based on psycho-visually invisible projected tags (IPT), requiring a projector as the sender and quadrotors with high-speed cameras as the receiver. The method includes a modulation process for the sender, as well as demodulation and pose estimation steps for the receiver, where screen-camera communication technology is applied to hide fiducial tags using human vision property. Experiments have demonstrated that IPT can achieve accuracy within ten centimeters and a speed of about ten FPS. Compared with other localization methods for AR robotics platforms, IPT is affordable by using only a projector and high-speed cameras as hardware consumption and convenient by omitting a coordinate alignment step. To the authors' best knowledge, this is the first time screen-camera communication is utilized for AR robot localization.	https://doi.org/10.1109/ICRA46639.2022.9812449	Jinjie Li, Liang Han, Zhang Ren
Informative Planning for Worst-Case Error Minimisation in Sparse Gaussian Process Regression.	We present a planning framework for min-imising the deterministic worst-case error in sparse Gaus-sian process (GP) regression. We first derive a univer-sal worst-case error bound for sparse GP regression with bounded noise using interpolation theory on reproducing kernel Hilbert spaces (RKHSs). By exploiting the conditional inde-pendence (CI) assumption central to sparse GP regression, we show that the worst-case error minimisation can be achieved by solving a posterior entropy minimisation problem. In turn, the posterior entropy minimisation problem is solved using a Gaussian belief space planning algorithm. We corroborate the proposed worst-case error bound in a simple 1D example, and test the planning framework in simulation for a 2D vehicle in a complex flow field. Our results demonstrate that the proposed posterior entropy minimisation approach is effective in minimising deterministic error, and outperforms the conventional measurement entropy maximisation formulation when the inducing points are fixed.	https://doi.org/10.1109/ICRA46639.2022.9812375	Jennifer Wakulicz, Ki Myung Brian Lee, Chanyeol Yoo, Teresa A. Vidal-Calleja, Robert Fitch
Informative Planning in the Presence of Outliers.	Informative planning seeks a sequence of actions that guide the robot to collect the most informative data to build a large-scale environmental model or learn a dynamical system. Existing work in informative planning mainly focuses on proposing new planners and applying them to various robotic applications such as environmental monitoring, autonomous exploration, and system identification. The informative planners optimize an objective given by a probabilistic model, e.g., Gaussian process regression (GPR). In practice, the ubiquitous sensing outliers can easily affect the model, resulting in a misleading objective. A straightforward solution is to filter out the outliers in the sensing data stream using an off-the-shelf outlier detector. However, informative samples are also scarce by definition so they might be falsely filtered out. In this paper, we propose a method to enable the robot to re-visit the locations where outliers were sampled besides optimizing the informative planning objective. The robot can collect more samples in the vicinity of outliers and update the outlier detector to reduce the number of false alarms. We achieve this by designing a new objective for the Pareto Monte Carlo tree search (MCTS). We demonstrate that the proposed framework performs better than applying an outlier detector naively.	https://doi.org/10.1109/ICRA46639.2022.9812267	Weizhe Chen, Lantao Liu
Infrastructure-Enabled Autonomy: An Attention Mechanism for Occlusion Handling.	Although there has been tremendous progress in autonomous driving, navigating environments and predicting the behavior of other drivers in the presence of occlusions remains challenging. Cities have started investing in infrastructure sensors that could provide information about occluded spaces. We propose a framework that integrates infrastructure-to-vehicle communication in autonomous vehicle decision making, improving operational safety and mobility in challenging environments. By framing the problem as a partially observable Markov decision process in which querying an infrastructure sensor is a data-gathering action, we reduce the computational complexity associated with sensor processing while maintaining equivalent performance compared to an omniscient actor and demonstrate the value of infrastructure communication through a series of experiments.	https://doi.org/10.1109/ICRA46639.2022.9812389	Victoria Magdalena Dax, Mykel J. Kochenderfer, Ransalu Senanayake, Umair Ibrahim
InsertionNet 2.0: Minimal Contact Multi-Step Insertion Using Multimodal Multiview Sensory Input.	We address the problem of devising the means for a robot to rapidly and safely learn insertion skills with just a few human interventions and without hand-crafted rewards or demonstrations. Our InsertionNet version 2.0 provides an improved technique to robustly cope with a wide range of use-cases featuring different shapes, colors, initial poses, etc. In particular, we present a regression-based method based on multimodal input from stereo perception and force, augmented with contrastive learning for the efficient learning of valuable features. In addition, we introduce a one-shot learning technique for insertion, which relies on a relation network scheme to better exploit the collected data and to support multi-step insertion tasks. Our method improves on the results obtained with the original InsertionNet, achieving an almost perfect score (above 97.5% on 200 trials) in 16 real-life insertion tasks while minimizing the execution time and contact during insertion. We further demonstrate our method's ability to tackle a real-life 3-step insertion task and perfectly solve an unseen insertion task without learning.	https://doi.org/10.1109/ICRA46639.2022.9811798	Oren Spector, Vladimir Tchuiev, Dotan Di Castro
Inside LineRanger: Mechanism Design to Optimize Operation and Performances of Powerline Inspection Robot.	Even if UAVs undoubtedly had a profound effect on the visual inspection capabilities of transmission lines, rolling robots, especially for bundled configurations, will still play an extensive role in the maintenance of these strategic assets. As such, LineRanger is among the most efficient and capable wheeled platform, that can travel at an average speed of 8 km/h. In this paper, LineRanger mechanical design insights are shared, unfolding how strictly mechanical solutions deals with ease of obstacle crossing, ease of installation procedure without requiring any linemen to access the high voltage environment area, and ease of deployment of dedicated, custom-made sensors onto the line component of interest. This novel robotic platform is now being deployed onto Hydro-Quebec power grid network, performing high value applications.	https://doi.org/10.1109/ICRA46639.2022.9811366	Pierre-Luc Richard, François Morin, Marco Lepage, Philippe Hamelin, Ghislain Lambert, Alex Sartor, Camille Hébert, Nicolas Pouliot
Instinctive Real-time sEMG-based Control of Prosthetic Hand with Reduced Data Acquisition and Embedded Deep Learning Training.	Achieving instinctive multi-grasp control of prosthetic hands typically still requires a large number of sensors, such as electromyography (EMG) electrodes mounted on a residual limb, that can be costly and time consuming to position, with their signals difficult to classify. Deep-learning-based EMG classifiers however have shown promising results over traditional methods, yet due to high computational requirements, limited work has been done with in-prosthetic training. By targeting specific muscles non-invasively, separating grasping action into hold and release states, and implementing data augmentation, we show in this paper that accurate results for embedded, instinctive, multi-grasp control can be achieved with only 2 low-cost sensors, a simple neural network, and minimal amount of training data. The presented controller, which is based on only 2 surface EMG (sEMG) channels, is implemented in an enhanced version of the OLYMPIC prosthetic hand. Results demonstrate that the controller is capable of identifying all 7 specified grasps and gestures with 93% accuracy, and is successful in achieving several real-life tasks in a real world setting.	https://doi.org/10.1109/ICRA46639.2022.9811741	Zeyu Yang, Angus B. Clark, Digby Chappell, Nicolás Rojas
Insulator Aiming Using Multi-Feature Fusion-Based Visual Servo Control for Washing Drone.	Insulator visual aiming is difficult for washing drone due to the complex washing environment, strong dis-turbance, lack of debugging environment, and other factors. Conventional visual servo control methods often fail to consider these complex factors adequately and fall short in reliable insulator visual aiming. To address these problems, we propose a novel multi-feature fusion-based drone visual servo control method for accurate insulator visual aiming. A multi-feature fusion neural network (MFFNet) is proposed to map the dif-ferent input modalities into an embedding space spanned by the learned deep features. Suitable control commands are generated by the simple combination of learned deep features. These deep features represent the intrinsic structural properties of the insulator and the motion pattern of the drones. Particularly, our method is trained purely in simulation and transferred to a real drone directly. Moreover, accurate visual aiming is guaranteed even in strong disturbance environments. Simulation and experimental results verify the high accurate insulator aiming, anti-disturbance, and sim-to-real transfer capabilities of the proposed method. Video: https://youtu.be/Ptlajzvp46A.	https://doi.org/10.1109/ICRA46639.2022.9812338	Jian Di, Shaofeng Chen, Xinghu Wang, Hepeng Zhang, Haibo Ji
Integrated Learning of Robot Motion and Sentences: Real-Time Prediction of Grasping Motion and Attention based on Language Instructions.	"We propose a motion generation model that can achieve robust behavior against environmental changes based on language instructions at a low cost. Conventional robots that communicate with humans use a restricted environment and language to build up a mapping between language and motion, and thus need to prepare a huge training set in order to achieve versatility. Our method trains pairs of language, visual, and motor information of the robot, and generates motions in real-time based on the ""attention"" of the language instructions. Specifically, the robot generates motions while focusing on the indicated objects by the human when multiple objects are in the field of view. In addition, since position recognition and motion generation of the indicated object are performed in real-time, robust motion generation is possible in response to changes in the object position and lighting conditions. We clarified that features related to the object name and its location are self-organized in the latent (PB: Parametric Bias) space by end-to-end learning of robot motion and sentences. These observations may indicate the importance of integrated learning of robot motion and sentences since such feature representations cannot be obtained by learning motions alone."	https://doi.org/10.1109/ICRA46639.2022.9811815	Hiroshi Ito, Hideyuki Ichiwara, Kenjiro Yamamoto, Hiroki Mori, Tetsuya Ogata
Integrating Deep Reinforcement and Supervised Learning to Expedite Indoor Mapping.	The challenge of mapping indoor environments is addressed. Typical heuristic algorithms for solving the motion planning problem are frontier-based methods, that are especially effective when the environment is completely unknown. However, in cases where prior statistical data on the environment's architectonic features is available, such algorithms can be far from optimal. Furthermore, their calculation time may increase substantially as more areas are exposed. In this paper we propose two means by which to overcome these shortcomings. One is the use of deep reinforcement learning to train the motion planner. The second is the inclusion of a pre-trained generative deep neural network, acting as a map predictor. Each one helps to improve the decision making through use of the learned structural statistics of the environment, and both, being realized as neural networks, ensure a constant calculation time. We show that combining the two methods can shorten the duration of the mapping process by up to 4 times, compared to frontier-based motion planning.	https://doi.org/10.1109/ICRA46639.2022.9811861	Elchanan Zwecher, Eran Iceland, Sean R. Levy, Shmuel Y. Hayoun, Oren Gal, Ariel Barel
Integrating Point and Line Features for Visual-Inertial Initialization.	Accurate and robust initialization is crucial in visual-inertial system, which significantly affects the localization accuracy. Most of the existing feature-based initialization methods rely on point features to estimate initial parameters. However, the performance of these methods often decreases in real scene, as point features are unstable and may be discontinuously observed especially in low textured environments. By contrast, line features, providing richer geometrical information than points, are also very common in man-made buildings. Thereby, in this paper, we propose a novel visual-inertial initialization method integrating both point and line features. Specifically, a closed-form method of line features is presented for initialization, which is combined with point-based method to build an integrated linear system. Parameters including initial velocity, gravity, point depth and line's endpoints depth can be jointly solved out. Furthermore, to refine these parameters, a global optimization method is proposed, which consists of two novel nonlinear least squares problems for respective points and lines. Both gravity magnitude and gyroscope bias are considered in refinement. Extensive experimental results on both simulated and public datasets show that integrating point and line features in initialization stage can achieve higher accuracy and better robustness compared with pure point-based methods.	https://doi.org/10.1109/ICRA46639.2022.9811641	Hong Liu, Junyin Qiu, Weibo Huang
Interactive Human-in-the-loop Coordination of Manipulation Skills Learned from Demonstration.	Learning from demonstration (LfD) provides a fast, intuitive and efficient framework to program robot skills, which has gained growing interest both in research and industrial applications. Most complex manipulation tasks are long-term and involve a set of skill primitives. Thus it is crucial to have a reliable coordination scheme that selects the correct sequence of skill primitive and the correct parameters for each skill, under various scenarios. Instead of relying on a precise simulator, this work proposes a human-in-the-loop coordination framework for LfD skills that: builds parameterized skill models from kinesthetic demonstrations; constructs a geometric task network (GTN) on-the-fly from human instructions; learns a hierarchical control policy incrementally during execution. This framework can reduce significantly the manual design efforts, while improving the adaptability to new scenes. We show on a 7-DoF robotic manipulator that the proposed approach can teach complex industrial tasks such as bin sorting and assembly in less than 30 minutes.	https://doi.org/10.1109/ICRA46639.2022.9811813	Meng Guo, Mathias Bürger
Interactive Robotic Grasping with Attribute-Guided Disambiguation.	"Interactive robotic grasping using natural language is one of the most fundamental tasks in human-robot interaction. However, language can be a source of ambiguity, particularly when there are ambiguous visual or linguistic contents. This paper investigates the use of object attributes in disambiguation and develops an interactive grasping system capable of effectively resolving ambiguities via dialogues. Our approach first predicts target scores and attribute scores through vision-and-language grounding. To handle ambiguous objects and commands, we propose an attribute-guided formulation of the partially observable Markov decision process (Attr-POMDP) for disambiguation. The Attr-POMDP utilizes target and attribute scores as the observation model to calculate the expected return of an attribute-based (e.g., ""what is the color of the target, red or green?"") or a pointing-based (e.g., ""do you mean this one?"") question. Our disambiguation module runs in real time on a real robot, and the interactive grasping system achieves a 91.43 % selection accuracy in the real-robot experiments, outperforming several baselines by large margins. Supplementary material is available at https://sites.google.com/umn.eduJattr-disam."	https://doi.org/10.1109/ICRA46639.2022.9812360	Yang Yang, Xibai Lou, Changhyun Choi
Interleaving Monte Carlo Tree Search and Self-Supervised Learning for Object Retrieval in Clutter.	In this study, working with the task of object retrieval in clutter, we have developed a robot learning framework in which Monte Carlo Tree Search (MCTS) is first applied to enable a Deep Neural Network (DNN) to learn the intricate interactions between a robot arm and a complex scene containing many objects, allowing the DNN to partially clone the behavior of MCTS. In turn, the trained DNN is integrated into MCTS to help guide its search effort. We call this approach learning-guided Monte Carlo tree search for Object REtrieval (MORE), which delivers significant computational efficiency gains and added solution optimality. MORE is a self-supervised robotics framework/pipeline capable of working in the real world that successfully embodies the System 2 → System 1 learning philosophy proposed by Kahneman, where learned knowledge, used properly, can help greatly speed up a time-consuming decision process over time. Videos and supplementary material can be found at https://github.com/arc-l/more.	https://doi.org/10.1109/ICRA46639.2022.9812132	Baichuan Huang, Teng Guo, Abdeslam Boularias, Jingjin Yu
Interval-based Visual-Inertial LiDAR SLAM with Anchoring Poses.	We present a novel interval-based visual-inertial LiDAR SLAM (i-VIL SLAM) method that solely assumes sensor errors to be bounded and propagates the error from the input sources to the estimated map and trajectory using interval analysis. The method allows us to restrict the solution set of the robot poses and the position of the landmarks to the set that is consistent with the measurements. If the error limits are not violated, it is guaranteed that the estimated set contains the true solution. The accumulation of the uncertainty is stabilized by anchoring poses derived from GNSS/INS data. Furthermore, for the first time we compare confidence ellipses determined by a classical SLAM graph optimization approach with the interval estimates of the robot poses provided by our method. In this work, we experimentally show that the marginal co-variances computed by the classical SLAM graph optimization are too overconfident and underestimate the uncertainty of the poses. While the 99.9 %-ellipsoids derived from the marginal covariances of the poses only enclose less than 64 % of the ground truth in the worst case, our method provides interval bounds for the pose parameters that enclose the ground truth for more than 96 % of all frames.	https://doi.org/10.1109/ICRA46639.2022.9812425	Aaronkumar Ehambram, Raphael Voges, Claus Brenner, Bernardo Wagner
Intrinsically Motivated Self-supervised Learning in Reinforcement Learning.	In vision-based reinforcement learning (RL) tasks, it is prevalent to assign auxiliary tasks with a surrogate self-supervised loss so as to obtain more semantic representations and improve sample efficiency. However, abundant information in self-supervised auxiliary tasks has been disregarded, since the representation learning part and the decision-making part are separated. To sufficiently utilize information in auxiliary tasks, we present a simple yet effective idea to employ self-supervised loss as an intrinsic reward, called Intrinsically Motivated Self-Supervised learning in Reinforcement learning (IM-SSR). We formally show that the self-supervised loss can be decomposed as exploration for novel states and robustness improvement from nuisance elimination. IM-SSR can be effortlessly plugged into any reinforcement learning with self-supervised auxiliary objectives with nearly no additional cost. Combined with IM-SSR, the previous underlying algorithms achieve salient improvements on both sample efficiency and generalization in various vision-based robotics tasks from the DeepMind Control Suite, especially when the reward signal is sparse.	https://doi.org/10.1109/ICRA46639.2022.9812213	Yue Zhao, Chenzhuang Du, Hang Zhao, Tiejun Li
Introducing RH5 Manus: A Powerful Humanoid Upper Body Design for Dynamic Movements.	It is well established that a stiff structure along with an optimal mass distribution are key features to perform dynamic movements, and parallel designs provide these characteristics to a robot. This work presents the new upper-body design of the humanoid robot RH5 named RH5 Manus with series-parallel hybrid design. The new design choices allow us to perform dynamic motions including tasks that involve a payload of 4 kg in each hand and fast boxing motions. The parallel kinematics combined with an overall serial chain of the robot provides us with high force production along with a larger range of motion and low peripheral inertia. The robot is equipped with backdrivable actuators with current sensing, force-torque sensors, stereo camera, laser scanners, high-resolution encoders etc that provide interaction with operators and environment. We generate several diverse dynamic motions using trajectory optimization, and successfully execute them on the robot with accurate trajectory and velocity tracking, while respecting joint rotation, velocity, and torque limits.	https://doi.org/10.1109/ICRA46639.2022.9811843	Melya Boukheddimi, Shivesh Kumar, Heiner Peters, Dennis Mronga, Rohan Budhiraja, Frank Kirchner
Intrusion Distance and Reaction Time Estimation for Safe and Efficient Industrial Robots.	Circular economy and agile manufacturing require a safe and efficient industrial robot system working in close human proximity. Although, close proximity local sensing enables safe collaboration with small cobots. However, they cannot ensure safety at high velocities with a heavy-duty industrial robot. Stereo-camera and 3D LiDAR-based touch-less global sensing methods exist, but they do not address the safety standards. This work proposes a novel method for estimating the safety parameters in speed and separation monitoring mode for 3D vision sensors. Accurate estimation of these parameters ensures compact sensing zones. Thus, enabling efficient human-robot collaboration for permanent operator presence. The method requires less effort in setup. The developed software with a graphical user interface enables workers from wide technical expertise to perform safety measurements at a precision of ±15ms in reaction time estimation. The experiments are repeatable and capture the statistical data for low error in estimation. The estimated parameters for two exemplary 3D sensors enable a human to work in close proximity of 20 cm while enabling safety from a collision.	https://doi.org/10.1109/ICRA46639.2022.9811900	Aquib Rashid, Ibrahim Al Nasser, Shuxiao Hou, Mohamad Bdiwi, Matthias Putz, Steffen Ihlenfeldt
Is it Worth to Reason about Uncertainty in Occupancy Grid Maps during Path Planning?	"This paper investigates the usefulness of reasoning about the uncertain presence of obstacles during path planning, which typically stems from the usage of probabilistic occupancy grid maps for representing the environment when mapping via a noisy sensor like a stereo camera. The traditional planning paradigm prescribes using a hard threshold on the occupancy probability to declare that a cell is an obstacle, and to plan a single path accordingly while treating unknown space as free. We compare this approach against a new uncertainty-aware planner, which plans two different path hypotheses and then merges their initial trajectory segments into a single one ending in a ""next-best view"" pose. After this informative view is taken, the planner commits to one of the hypotheses, or to a completely new one if a collision is imminent. Simulations were conducted comparing the proposed and traditional planner. Results show the existence of planning scenarios -like when the environment contains a dead-end, or when the goal is placed close to an obstacle- in which reasoning about uncertainty can significantly decrease the robot's traveled distance and increase the chances of reaching the goal. The new planner was also validated on a real Clearpath Jackal robot equipped with a ZED 2 stereo camera."	https://doi.org/10.1109/ICRA46639.2022.9812431	Jacopo Banfi, Lindsey Woo, Mark Campbell
Iterative Mesh Modification Planning: A new Method for Automatic Disassembly Planning of Complex Industrial Components.	Automatic disassembly planning for complex industrial products like vehicles checks the expandability of components already at early stages of design. For a fast computation of collision-free disassembly paths, sampling-based rigid body motion planning is used in the literature. However, in real-world scenarios there are circumstances that prevent the finding of plausible collision-free disassembly paths with these conventional motion planners. The most difficult problem is that many components have deformable fastening elements that are modeled in a relaxed state and often as a part of the rigid object. The fastening elements cause unavoidable collisions of the component with its environment along the actual disassembly path. In this paper, we present Iterative Mesh Modification Planning (IMMP). Given the information about fastening elements in advance, our method applies a controlled iterative process of geometric deformations and planning attempts to the component to be disassembled. With this process, we are able to disassemble the component from its installed position with a conventional rigid body motion planner taking fastening elements and also overpressure into account. We demonstrate the effectiveness of our method on real-world planning scenarios from the automotive industry.	https://doi.org/10.1109/ICRA46639.2022.9812116	Robert Hegewald, Nicola Wolpert, Elmar Schömer
JST: Joint Self-training for Unsupervised Domain Adaptation on 2D&3D Object Detection.	2D&3D object detection always suffers from a dramatic performance drop when transferring the model trained in the source domain to the target domain due to various domain shifts. In this paper, we propose a Joint Self-Training (JST) framework to improve 2D image and 3D point cloud detectors with aligned outputs simultaneously during the transferring. The proposed framework contains three novelties to overcome object biases and unstable self-training processes: 1) an anchor scaling scheme is developed to efficiently eliminate the object size biases without any modification on point clouds; 2) a 2D&3D bounding box alignment method is proposed to generate high-quality pseudo labels for the self-training process; 3) a model smoothing based training strategy is developed to reduce the training oscillation properly. Experiment results show that the proposed approach improves the performance of 2D and 3D detectors in the target domain simultaneously; especially the superior accuracy of 3D detection can be achieved on benchmark datasets over the state-of-the-art methods.	https://doi.org/10.1109/ICRA46639.2022.9811975	Guangyao Ding, Meiying Zhang, E. Li, Qi Hao
Jerk Constrained Velocity Planning for an Autonomous Vehicle: Linear Programming Approach.	Velocity Planning for self-driving vehicles in a complex environment is one of the most challenging tasks. It must satisfy the following three requirements: safety with regards to collisions; respect of the maximum velocity limits defined by the traffic rules; comfort of the passengers. In order to achieve these goals, the jerk and dynamic objects should be considered, however, it makes the problem as complex as a non-convex optimization problem. In this paper, we propose a linear programming (LP) based velocity planning method with jerk limit and obstacle avoidance constraints for an autonomous driving system. To confirm the efficiency of the proposed method, a comparison is made with several optimization-based approaches, and we show that our method can generate a velocity profile which satisfies the aforementioned requirements more efficiently than the compared methods. In addition, we tested our algorithm on a real vehicle at a test field to validate the effectiveness of the proposed method.	https://doi.org/10.1109/ICRA46639.2022.9812155	Yutaka Shimizu, Takamasa Horibe, Fumiya Watanabe, Shinpei Kato
Joint Communication and Motion Planning for Cobots.	The increasing deployment of robots in co-working scenarios with humans has revealed complex safety and efficiency challenges in the computation of the robot behavior. Movement among humans is one of the most fundamental —and yet critical—problems in this frontier. While several approaches have addressed this problem from a purely navigational point of view, the absence of a unified paradigm for communicating with humans limits their ability to prevent deadlocks and compute feasible solutions. This paper presents a joint communication and motion planning framework that selects from an arbitrary input set of robot's communication signals while computing robot motion plans. It models a human co-worker's imperfect perception of these communications using a noisy sensor model and facilitates the specification of a variety of social/workplace compliance priorities with a flexible cost function. Theoretical results and simulator-based empirical evaluations show that our approach efficiently computes motion plans and communication strategies that reduce conflicts between agents and resolve potential deadlocks.	https://doi.org/10.1109/ICRA46639.2022.9812261	Mehdi Dadvar, Keyvan Majd, Elena Oikonomou, Georgios Fainekos, Siddharth Srivastava
Joint State and Input Estimation of Agent Based on Recursive Kalman Filter Given Prior Knowledge.	Modern autonomous systems are purposed for many challenging scenarios, where agents will face unexpected events and complicated tasks. The presence of disturbance noise with control command and unknown inputs can negatively impact robot performance. Previous research of joint input and state estimation separately studied the continuous and discrete cases without any prior information. This paper combines the continuous and discrete input cases into a unified theory based on the Expectation-Maximum (EM) algorithm. By introducing prior knowledge of events as the constraint, inequality optimization problems are formulated to determine a gain matrix or dynamic weights to realize an optimal input estimation with lower variance and more accurate decision-making. Finally, statistical results from experiments show that our algorithm owns 81% improvement of the variance than KF and 47% improvement than RKF in continuous space; a remarkable improvement of right decision-making probability of our input estimator in discrete space, identification ability is also analyzed by experiments.	https://doi.org/10.1109/ICRA46639.2022.9811636	Zida Wu, Zhaoliang Zheng, Ankur Mehta
KEMP: Keyframe-Based Hierarchical End-to-End Deep Model for Long- Term Trajectory Prediction.	Predicting future trajectories of road agents is a critical task for autonomous driving. Recent goal-based trajectory prediction methods, such as DenseTNT and PECNet [1], [2], have shown good performance on prediction tasks on public datasets. However, they usually require complicated goal-selection algorithms and optimization. In this work, we propose KEMP, a hierarchical end-to-end deep learning framework for trajectory prediction. At the core of our framework is keyframe-based trajectory prediction, where keyframes are representative states that trace out the general direction of the trajectory. KEMP first predicts keyframes conditioned on the road con-text, and then fills in intermediate states conditioned on the keyframes and the road context. Under our general framework, goal-conditioned methods are special cases in which the number of keyframes equal to one. Unlike goal-conditioned methods, our keyframe predictor is learned automatically and does not require hand-crafted goal-selection algorithms. We evaluate our model on public benchmarks and our model ranked 1st on Waymo Open Motion Dataset Leaderboard (as of September 1, 2021).	https://doi.org/10.1109/ICRA46639.2022.9812337	Qiujing Lu, Weiqiao Han, Jeffrey Ling, Minfa Wang, Haoyu Chen, Balakrishnan Varadarajan, Paul Covington
KHAOS: a Kinematic Human Aware Optimization-based System for Reactive Planning of Flying-Coworker.	The use of drones in human-populated areas is increasing day by day. Such robots flying in close proximity to humans and potentially interacting with them, as in object handover or delivery, need to carefully plan their navigation considering the presence of humans. We propose a humanaware 3D reactive planner based on stochastic optimization for drone navigation. Besides considering the kinematics constraints of the drone, we propose two criteria to produce socially acceptable trajectories. The first, called discomfort, considers the unease caused to the humans spatially close to fast-moving drones. The second, called visibility, promotes the drone's visibility for humans. We demonstrate the planner's performance and adaptability in various simulated experiments.	https://doi.org/10.1109/ICRA46639.2022.9811803	Jérôme Truc, Phani-Teja Singamaneni, Daniel Sidobre, Serena Ivaldi, Rachid Alami
Keypoint-Based Category-Level Object Pose Tracking from an RGB Sequence with Uncertainty Estimation.	We propose a single-stage, category-level 6-DoF pose estimation algorithm that simultaneously detects and tracks instances of objects within a known category. Our method takes as input the previous and current frame from a monocular RGB video, as well as predictions from the previous frame, to predict the bounding cuboid and 6- DoF pose (up to scale). Internally, a deep network predicts distributions over object keypoints (vertices of the bounding cuboid) in image coordinates, after which a novel probabilistic filtering process integrates across estimates before computing the final pose using PnP. Our framework allows the system to take previous uncertainties into consideration when predicting the current frame, resulting in predictions that are more accurate and stable than single frame methods. Extensive experiments show that our method outperforms existing approaches on the challenging Objectron benchmark of annotated object videos. We also demonstrate the usability of our work in an augmented reality setting.	https://doi.org/10.1109/ICRA46639.2022.9811720	Yunzhi Lin, Jonathan Tremblay, Stephen Tyree, Patricio A. Vela, Stan Birchfield
Kinematic Structure Estimation of Arbitrary Articulated Rigid Objects for Event Cameras.	We propose a novel method that estimates the Kinematic Structure (KS) of arbitrary articulated rigid objects from event-based data. Event cameras are emerging sensors that asynchronously report brightness changes with a time resolution of microseconds, making them suitable candidates for motion-related perception. By assuming that an articulated rigid object is composed of body parts whose shape can be approximately described by a Gaussian distribution, we jointly segment the different parts by combining an adapted Bayesian inference approach and incremental event-based motion estimation. The respective KS is then generated based on the segmented parts and their respective biharmonic distance, which is estimated by building an affinity matrix of points sampled from the estimated Gaussian distributions. The method outperforms frame-based methods in sequences obtained by simulating events from video sequences and achieves a solid performance on new high-speed motions sequences, which frame-based KS estimation methods can not handle.	https://doi.org/10.1109/ICRA46639.2022.9812430	Urbano Miguel Nunes, Yiannis Demiris
Kinematic Transfer Learning of Sampling Distributions for Manipulator Motion Planning.	Recent research has shown that guiding sampling-based planners with sampling distributions, learned from previous experiences via density estimation, can significantly decrease computation times for motion planning. We propose an algorithm that can estimate the density from the experiences of a robot with different kinematic structure, on the same task. The method allows to generalize collected data from one source manipulator to similarly designed target manipulators, significantly reducing the computation time for new queries for the target manipulator. We evaluate the algorithm in two experiments, including a constrained manipulation task with five different collaborative robots, and show that transferring information can significantly decrease planning time.	https://doi.org/10.1109/ICRA46639.2022.9811915	Peter Lehner, Máximo A. Roa, Alin Albu-Schäffer
Kinematics Learning of Massive Heterogeneous Serial Robots.	Kinematics and instantaneous kinematics are fundamental in many robotic tasks, such as positioning and collision avoidance. Existing learning methods mainly concern a single robot, and small-scale networks are sufficient for considerable approximation accuracy. A question is: Can we learn a kinematics model that can generalize to various robots rather than a single robot? This paper studies the kinematics learning of massive heterogeneous serial robots and the transfer of these general models to reality. We generate a dataset by randomizing dimensions, configurations, and link lengths and employ a network based on the generative pre-trained transformer to learn general kinematics mappings. We directly transfer our models for accuracy and use distillation-based transfer for computational efficiency. The results validate that our method can accurately approximate the kinematics of thousands of robot models and demonstrates generality in transfer.	https://doi.org/10.1109/ICRA46639.2022.9812021	Dengpeng Xing, Wannian Xia, Bo Xu
KinoJGM: A framework for efficient and accurate quadrotor trajectory generation and tracking in dynamic environments.	Unmapped areas and aerodynamic disturbances render autonomous navigation with quadrotors extremely challenging. To fly safely and efficiently, trajectory planners and trackers must be able to navigate unknown environments with unpredictable aerodynamic effects in real-time. When encountering aerodynamic effects such as strong winds, most current approaches to quadrotor trajectory planning and tracking will not attempt to deviate from a determined plan, even if it is risky, in the hope that any aerodynamic disturbances can be resisted by a robust controller. This paper presents a novel systematic trajectory planning and tracking framework for autonomous quadrotors. We propose a Kinodynamic Jump Space Search (Kino-JSS) to generate a safe and efficient route in unknown environments with aerodynamic disturbances. A real-time Gaussian Process is employed to model the errors caused by aerodynamic disturbances, which we then integrate with a Model Predictive Controller to achieve efficient and accurate trajectory optimization and tracking. We demonstrate our system to improve the efficiency of trajectory generation in unknown environments by up to 75% in the cases tested, compared with recent state-of-the-art. We also show that our system improves the accuracy of tracking in selected environments with unpredictable aerodynamic effects. Our implementation is available in an open source package11https://github.com/Alex-yanranwang/Imperial-KinoJGM.	https://doi.org/10.1109/ICRA46639.2022.9812352	Yanran Wang, James O'Keeffe, Qiuchen Qian, David E. Boyle
KoopNet: Joint Learning of Koopman Bilinear Models and Function Dictionaries with Application to Quadrotor Trajectory Tracking.	Nonlinear dynamical effects are crucial to the operation of many agile robotic systems. Koopman-based model learning methods can capture these nonlinear dynamical system effects in higher dimensional lifted bilinear models that are amenable to optimal control. However, standard methods that lift the system state using a fixed function dictionary before model learning result in high dimensional models that are intractable for real time control. This paper presents a novel method that jointly learns a function dictionary and lifted bilinear model purely from data by incorporating the Koopman model in a neural network architecture. Nonlinear MPC design utilizing the learned model can be performed readily. We experimentally realized this method on a multirotor drone for agile trajectory tracking at low altitudes where the aerodynamic ground effect influences the system's behavior. Experimental results demonstrate that the learning-based controller achieves similar performance as a nonlinear MPC based on a nominal dynamics model in medium altitude. However, our learning-based system can reliably track trajectories in near-ground flight regimes while the nominal controller crashes due to unmodeled dynamical effects that are captured by our method.	https://doi.org/10.1109/ICRA46639.2022.9811896	Carl Folkestad, Skylar X. Wei, Joel W. Burdick
L1Adaptive Augmentation for Geometric Tracking Control of Quadrotors.	"This paper introduces an L
1adaptive control aug-mentation for geometric tracking control of quadrotors. In the proposed design, the L
1 augmentation handles nonlinear (time-and state-dependent) uncertainties in the quadrotor dynamics without assuming or enforcing parametric structures, while the baseline geometric controller achieves stabilization of the known nonlinear model of the system dynamics. The L
1augmentation applies to both the rotational and the translational dynamics. Experimental results demonstrate that the augmented geomet-ric controller shows consistent and (on average five times) smaller trajectory tracking errors compared with the geometric controller alone when tested for different trajectories and under various types of uncertainties/disturbances."	https://doi.org/10.1109/ICRA46639.2022.9811946	Zhuohuan Wu, Sheng Cheng, Kasey A. Ackerman, Aditya Gahlawat, Arun Lakshmanan, Pan Zhao, Naira Hovakimyan
LADC: Learning-Based Anti-Disturbance Control for Washing Drone.	Disturbance mainly caused by recoil force in-evitably makes washing drone seriously deviate from the desired position, thereby reducing the cleaning efficiency. It is neces-sary to develop an effective anti-disturbance control method. Although some progresses have been made, the position error thereof is still large, rendering existing methods inapplicable in washing drone. In this paper, we propose a learning-based anti-disturbance control (LADC) method to significantly reduce the position error by combining robust nonlinear control and partial differential equation network (PDENet). Taking data noise into account, we use differential spectral normalization in the training of the PDENet. A distinguishing feature of our method is to directly learn PDENet parameters from flight logs without installing extra sensors. Experimental results indicate that the proposed method outperforms classical PD method and extended state observer (ESO) based control method with 70 % and 50 % reduced position error, respectively, and can be further applied in variable scenarios. Video: https: / / youtu.be/gNfLFAXalkI	https://doi.org/10.1109/ICRA46639.2022.9812305	Jian Di, Shaofeng Chen, Han Yan, Xinghu Wang, Hepeng Zhang, Haibo Ji, Tao Jin
LB-L2L-Calib: Accurate and Robust Extrinsic Calibration for Multiple 3D LiDARs with Long Baseline and Large Viewpoint Difference.	Multi-LiDAR system is an important part of V2X (Vehicle to Everything) to enhance the perception information for unmanned vehicles. To fuse the information from multiple 3D LiDARs, accurate extrinsic calibration between the LiDARs is essential. However, the existing multi-LiDAR calibration methods mainly focus on short baseline scenarios, where multiple LiDARs are closely mounted on a single platform (e.g., an unmanned vehicle). Besides, most methods typically use a planar target for calibration. Some of the methods require the motion of the multi-LiDAR system. The above conditions severely limit the application of these methods to V2X, where LiDARs are non-movable, the baseline and viewpoint difference between the LiDARs can be very large. In order to meet these challenges, we propose an accurate and robust extrinsic calibration method for long baseline multi-LiDAR systems, named LB-L2L-Calib (Large Baseline LiDAR to LiDAR extrinsic Calibration). (1) We use a sphere as the calibration target for multiple LiDARs with large viewpoint difference, leveraging the viewpoint-invariance of the sphere. (2) A improved sphere detection and sphere center estimation strategy is introduced to detect and extract the sphere center from a cluttered point cloud in large-scale outdoor scenario. (3) A extrinsic parameter regression scheme is introduced. Both simulation and real experiments demonstrate that LB-L2L-Calib is highly accurate and robust. Quantitative results show that the rotation and translation error is less than 0.01m and 0.01° (in simulation, Gauss noise 0.03m, the distance and viewpoint difference between two LiDARs is more than 30m and 90°).	https://doi.org/10.1109/ICRA46639.2022.9812062	Jun Zhang, Qiyang Lyu, Guohao Peng, Zhenyu Wu, Qiao Yan, Danwei Wang
LEGS: Learning Efficient Grasp Sets for Exploratory Grasping.	While deep learning has enabled significant progress in designing general purpose robot grasping systems, there remain objects which still pose challenges for these systems. Recent work on Exploratory Grasping has formalized the problem of systematically exploring grasps on these adversarial objects and explored a multi-armed bandit model for identifying high-quality grasps on each object stable pose. However, these systems are still limited to exploring a small number or grasps on each object. We present Learned Efficient Grasp Sets (LEGS), an algorithm that efficiently explores thousands of possible grasps by maintaining small active sets of promising grasps and determining when it can stop exploring the object with high confidence. Experiments suggest that LEGS can identify a high-quality grasp more efficiently than prior algorithms which do not use active sets. In simulation experiments, we measure the gap between the success probability of the best grasp identified by LEGS, baselines, and the most-robust grasp (verified ground truth). After 3000 exploration steps, LEGS outperforms baseline algorithms on 10/14 and 25/39 objects on the Dex-Net Adversarial and EGAD! datasets respectively. We then evaluate LEGS in physical experiments; trials on 3 challenging objects suggest that LEGS converges to high-performing grasps significantly faster than baselines. See https://sites.google.com/view/LEGS-exp-grasping for supplemental material and videos.	https://doi.org/10.1109/ICRA46639.2022.9812138	Letian Fu, Michael Danielczuk, Ashwin Balakrishna, Daniel S. Brown, Jeffrey Ichnowski, Eugen Solowjow, Ken Goldberg
LLOL: Low-Latency Odometry for Spinning Lidars.	In this paper, we present a low-latency odometry system designed for spinning lidars. Many existing lidar odometry methods wait for an entire sweep from the lidar before processing the data. This introduces a large delay between the first laser firing and its pose estimate. To reduce this latency, we treat the spinning lidar as a streaming sensor and process packets as they arrive. This effectively distributes expensive operations across time, resulting in a very fast and lightweight system with a much higher throughput and lower latency. Our open source implementation is available at https://github.com/versatran01/llol.	https://doi.org/10.1109/ICRA46639.2022.9811605	Chao Qu, Shreyas S. Shivakumar, Wenxin Liu, Camillo J. Taylor
LT-mapper: A Modular Framework for LiDAR-based Lifelong Mapping.	Long-term 3D map management is a fundamental capability required by a robot to reliably navigate in the non-stationary real-world. This paper develops open-source, modular, and readily available LiDAR-based lifelong mapping for urban sites. This is achieved by dividing the problem into successive subproblems: multi-session SLAM (MSS), high/low dynamic change detection, and positive/negative change management. The proposed method leverages MSS and minimizes potential trajectory error; thus, a manual or good initial alignment is not required for change detection. Our change management scheme preserves efficacy in both memory and computation costs, providing automatic object segregation from a large-scale point cloud map. We verify the framework's reliability and applicability even under permanent year-level variation, through extensive real-world experiments with multiple temporal gaps (from day to year).	https://doi.org/10.1109/ICRA46639.2022.9811916	Giseop Kim, Ayoung Kim
LTSR: Long-term Semantic Relocalization based on HD Map for Autonomous Vehicles.	Highly accurate and robust relocalization or localization initialization ability is of great importance for autonomous vehicles (AVs). Traditional GNSS-based methods are not reliable enough in occlusion and multipath conditions. In this paper we propose a novel long-term semantic relocalization algorithm based on HD map and semantic features which are compact in representation. Semantic features appear widely on urban roads, and are robust to illumination, weather, view-point and appearance changes. Repeated structures, missed and false detections make data association (DA) highly ambiguous. To this end, a robust semantic feature matching method based on a new local semantic descriptor which encodes the spatial and normal relationship between semantic features is performed. Further, we introduce an accurate, efficient, yet simple outlier removal method which works by assessing the local and global geometric consistencies and temporal consistency of semantic matching pairs. The experimental results on our urban dataset demonstrate that our approach performs better in accuracy and robustness compared with the current state-of-the-art methods.	https://doi.org/10.1109/ICRA46639.2022.9811855	Huayou Wang, Changliang Xue, Yu Tang, Wanlong Li, Feng Wen, Hongbo Zhang
Large-angle and High-speed Trajectory Tracking Control of a Quadrotor UAV based on Reachability.	This paper solves the tracking control problem for a quadrotor system under the tasks of large-angle rotation and high-speed trajectory tracking. A quadrotor dynamic model is presented taking both disturbances and drag force into account. A reachability control strategy is developed for a quadrotor to track the planned attitude and position. Outdoor experiments of a circle trajectory tracking at different flight speeds validate the robustness of the proposed method. A task of flip is demonstrated to verify the effectiveness of the proposed controller under a large tilt angle.	https://doi.org/10.1109/ICRA46639.2022.9811879	Zhou Liu, Lilong Cai
Large-scale Network Traffic Prediction With LSTM and Temporal Convolutional Networks.	Real-time and precise prediction for traffic of networks is critically important for allocating the optimal computing/network resources based on users' business requirements, analyzing the network performance, and realizing intelligent congestion control and high-accuracy anomaly detection. The dramatic growth of users' applications significantly increases the volume, uncertainty, and complexity of workload, thereby making it highly challenging to precisely predict future net-work traffic. Temporal Convolutional Networks (TCNs) and Long Short-Term Memory (LSTM) can be effectively used to analyze and predict time series. This work designs an improved prediction approach for the prediction of network traffic, which combines a Savitzky-Golay filter, TCN, and LSTM, called ST-LSTM for short. It first removes the noise of data with the filter of Savitzky-Golay. It then investigates temporal characteristics of data by using TCN. At last, it investigates the long-term dependency in the time series by using LSTM. Experimental results on a real-life website dataset show the prediction accuracy of ST-LSTM is higher than autoregressive integrated moving average, support vector regression, eXtreme Gradient Boosting, backpropagation, TCN, and LSTM, in terms of several commonly used performance indicators.	https://doi.org/10.1109/ICRA46639.2022.9812427	Jing Bi, Haitao Yuan, Kangyuan Xu, Haisen Ma, MengChu Zhou
Latent Imagination Facilitates Zero-Shot Transfer in Autonomous Racing.	World models learn behaviors in a latent imagination space to enhance the sample-efficiency of deep reinforcement learning (RL) algorithms. While learning world models for high-dimensional observations (e.g., pixel inputs) has become practicable on standard RL benchmarks and some games, their effectiveness in real-world robotics applications has not been explored. In this paper, we investigate how such agents generalize to real-world autonomous vehicle control tasks, where advanced model-free deep RL algorithms fail. In particular, we set up a series of time-lap tasks for an F1TENTH racing robot, equipped with a high-dimensional LiDAR sensor, on a set of test tracks with a gradual increase in their complexity. In this continuous-control setting, we show that model-based agents capable of learning in imagination substantially outperform model-free agents with respect to performance, sample efficiency, successful task completion, and generalization. Moreover, we show that the generalization ability of model-based agents strongly depends on the choice of their observation model. We provide extensive empirical evidence for the effectiveness of world models provided with long enough memory horizons in sim2real tasks.	https://doi.org/10.1109/ICRA46639.2022.9811650	Axel Brunnbauer, Luigi Berducci, Andreas Brandstätter, Mathias Lechner, Ramin M. Hasani, Daniela Rus, Radu Grosu
Learn to Grasp with Less Supervision: A Data-Efficient Maximum Likelihood Grasp Sampling Loss.	Robotic grasping for a diverse set of objects is essential in many robot manipulation tasks. One promising approach is to learn deep grasping models from large training datasets of object images and grasp labels. However, empirical grasping datasets are typically sparsely labeled (i.e., a small number of successful grasp labels**Labels refer to marking the image to indicate a successful robotic grasp. in each image). The data sparsity issue can lead to insufficient supervision and false-negative labels, and thus results in poor learning results. This paper proposes a Maximum Likelihood Grasp Sampling Loss (MLGSL) to tackle the data sparsity issue. The proposed method supposes that successful grasps are stochastically sampled from the predicted grasp distribution and maximizes the observing likelihood. MLGSL is utilized for training a fully convolutional network that generates thousands of grasps simultaneously. Training results suggest that models based on MLGSL can learn to grasp with datasets composing of 2 labels per image. Compared to previous works, which require training datasets of 16 labels per image, MLGSL is 8× more data-efficient. Meanwhile, physical robot experiments demonstrate an equivalent performance at a 90.7% grasp success rate on household objects. Codes and videos are available at [1].	https://doi.org/10.1109/ICRA46639.2022.9811685	Xinghao Zhu, Yefan Zhou, Yongxiang Fan, Lingfeng Sun, Jianyu Chen, Masayoshi Tomizuka
Learning 6-DoF Object Poses to Grasp Category-Level Objects by Language Instructions.	This paper studies the task of any objects grasping from the known categories by free-form language instructions. This task demands the technique in computer vision, natural language processing, and robotics. We bring these disciplines together on this open challenge, which is essential to human-robot interaction. Critically, the key challenge lies in inferring the category of objects from linguistic instructions and accurately estimating the 6-DoF information of unseen objects from the known classes. In contrast, previous works focus on inferring the pose of object candidates at the instance level. This significantly limits its applications in real-world scenarios. In this paper, we propose a language-guided 6-DoF category-level object localization model to achieve robotic grasping by comprehending human intention. To this end, we propose a novel two-stage method. Particularly, the first stage grounds the target in the RGB image through language description of names, attributes, and spatial relations of objects. The second stage extracts and segments point clouds from the cropped depth image and estimates the full 6-DoF object pose at category-level. Under such a manner, our approach can locate the specific object by following human instructions, and estimate the full 6-DoF pose of a category-known but unseen instance which is not utilized for training the model. Extensive experimental results show that our method is competitive with the state-of-the-art language-conditioned grasp method. Importantly, we deploy our approach on a physical robot to validate the usability of our framework in real-world applications. Please refer to the supplementary for the demo videos of our robot experiments.	https://doi.org/10.1109/ICRA46639.2022.9811367	Chilam Cheang, Haitao Lin, Yanwei Fu, Xiangyang Xue
Learning Controller Gains on Bipedal Walking Robots via User Preferences.	Experimental demonstration of complex robotic behaviors relies heavily on finding the correct controller gains. This painstaking process is often completed by a domain expert, requiring deep knowledge of the relationship between parameter values and the resulting behavior of the system. Even when such knowledge is possessed, it can take significant effort to navigate the nonintuitive landscape of possible parameter combinations. In this work, we explore the extent to which preference-based learning can be used to optimize controller gains online by repeatedly querying the user for their preferences. This general methodology is applied to two variants of control Lyapunov function based nonlinear controllers framed as quadratic programs, which provide theoretical guarantees but are challenging to realize in practice. These controllers are successfully demonstrated both on the planar underactuated biped, AMBER, and on the 3D underactuated biped, Cassie. We experimentally evaluate the performance of the learned controllers and show that the proposed method is repeatably able to learn gains that yield stable and robust locomotion.	https://doi.org/10.1109/ICRA46639.2022.9811541	Noel Csomay-Shanklin, Maegan Tucker, Min Dai, Jenna Reher, Aaron D. Ames
Learning Crowd-Aware Robot Navigation from Challenging Environments via Distributed Deep Reinforcement Learning.	This paper presents a deep reinforcement learning (DRL) sframework for safe and efficient navigation in crowded environments. Here, the robot learns cooperative behavior using a new reward function that penalizes robot actions interfering with the pedestrian's movement. Also, we propose a simulated pedestrian policy reflecting data from actual pedestrian movements. Furthermore, we introduce a collision detection that considers the pedestrian's personal space to generate affinity robot behavior. To efficiently explore this simulation environment, we propose distributed learning using Ape-X [1]. We deployed the robot in a real environment and verified its crowd-aware navigation performance compared with an actual human in terms of path length, travel time, and the number of abrupt avoidances.	https://doi.org/10.1109/ICRA46639.2022.9812011	Sango Matsuzaki, Yuji Hasegawa
Learning Design and Construction with Varying-Sized Materials via Prioritized Memory Resets.	Can a robot autonomously learn to design and construct a bridge from varying-sized blocks without a blueprint? It is a challenging task with long horizon and sparse reward - the robot has to figure out physically stable design schemes and feasible actions to manipulate and transport blocks. Due to diverse block sizes, the state space and action trajectories are vast to explore. In this paper, we propose a hierarchical approach for this problem. It consists of a reinforcement-learning designer to propose high-level building instructions and a motion-planning-based action generator to manipulate blocks at the low level. For high-level learning, we develop a novel technique, prioritized memory resetting (PMR) to improve exploration. PMR adaptively resets the state to those most critical configurations from a replay buffer so that the robot can resume training on partial architectures instead of from scratch. Furthermore, we augment PMR with auxiliary training objectives and fine-tune the designer with the locomotion generator. Our experiments in simulation and on a real deployed robotic system demonstrate that it is able to effectively construct bridges with blocks of varying sizes at a high success rate. Demos can be found at https://sites.google.com/view/bridge-pmr.	https://doi.org/10.1109/ICRA46639.2022.9811624	Yunfei Li, Tao Kong, Lei Li, Yi Wu
Learning Efficient and Robust Multi-Modal Quadruped Locomotion: A Hierarchical Approach.	Four-legged animals are able to change their gaits adaptively for lower energy consumption. However, designing a robust controller for their robot counterparts with multi-modal locomotion remains challenging. In this paper, we present a hierarchical control framework that decomposes this challenge into two kinds of problems: high-level decision-making for gait selection and robust low-level control in complex application environments. For gait transitions, we use reinforcement learning (RL) to design a gait policy that selects the optimal gaits in different environments. After the gait is decided, model predictive control (MPC) is applied to implement the desired gait. To improve the robustness of the locomotion, a model adaptation policy is developed to optimize the input parameters of our MPC controller adaptively. The control framework is first trained and tested in simulation, and then it is applied directly to a quadruped robot in real without any fine-tuning. We show that our control framework is more energy efficient by choosing different gaits and is more robust by adjusting model parameters compared to baseline controllers.	https://doi.org/10.1109/ICRA46639.2022.9811640	Shaohang Xu, Lijun Zhu, Chin Pang Ho
Learning Emergent Discrete Message Communication for Cooperative Reinforcement Learning.	Communication is an important factor that en-ables agents to work cooperatively in multi-agent reinforcement learning (MARL) contexts. Prior work used continuous message communication whose high representational capacity comes at the expense of interpretability. Allowing agents to learn their own discrete emergent message communication protocols can increase the interpretability for human designers and other agents. This paper proposes a method to generate discrete messages analogous to human languages. Discrete message communication is achieved by a broadcast-and-listen mecha-nism based on self-attention. We show that discrete message communication has performance comparable to continuous message communication but with a much smaller vocabulary size. Discrete message communication protocols can potentially be used for human-agent interaction.	https://doi.org/10.1109/ICRA46639.2022.9812285	Sheng Li, Yutai Zhou, Ross E. Allen, Mykel J. Kochenderfer
Learning Friction Model for Magnet-Actuated Tethered Capsule Robot.	The potential diagnostic applications of magnet-actuated capsules have been greatly increased in recent years. For most of these potential applications, accurate position control of the capsule have been highly demanding. However, the friction between the robot and the environment as well as the drag force from the tether play a significant role during the motion control of the capsule. Moreover, these forces especially the friction force are typically hard to model beforehand. In this paper, we first designed a magnet-actuated tethered capsule robot, where the driving magnet is mounted on the end of a robotic arm. Then, we proposed a learning-based approach to model the friction force between the capsule and the environment, with the goal of increasing the control accuracy of the whole system. Finally, several real robot experiments are demonstrated to showcase the effectiveness of our proposed approach.	https://doi.org/10.1109/ICRA46639.2022.9811587	Yi Wang, Yuyang Tu, Yuchen He, Xutian Deng, Ziwei Lei, Jianwei Zhang, Miao Li
Learning Insertion Primitives with Discrete-Continuous Hybrid Action Space for Robotic Assembly Tasks.	"This paper introduces a discrete-continuous action space to learn insertion primitives for robotic assembly tasks. Primitives are sequences of elementary actions with certain exit conditions, such as ""pushing down the peg until contact"". Since the primitive is an abstraction of robot control commands and encodes human prior knowledge, it reduces the exploration difficulty and yields better learning efficiency. In this paper, we learn robot assembly skills via primitives. Specifically, we formulate insertion primitives as parameterized actions: hybrid actions consisting of discrete primitive types and continuous primitive parameters. Compared with the previous work using a set of discretized parameters for each primitive, the agent in our method can freely choose primitive parameters from a continuous space, which is more flexible and efficient. To learn these insertion primitives, we propose Twin-Smoothed Multi-pass Deep Q-Network (TS-MP-DQN), an advanced version of MP-DQN with twin Q-network to reduce the Q-value over-estimation. Extensive experiments are conducted in the simulation and real world for validation. From experiment results, our approach achieves higher success rates than three baselines: MP-DQN with parameterized actions, primitives with discrete parameters, and continuous velocity control. Furthermore, learned primitives are robust to sim-to-real transfer and can generalize to challenging assembly tasks such as tight round peg-hole and complex shaped electric connectors with promising success rates. Experiment videos are available at https://msc.berkeley.edu/research/insertion-primitives.html."	https://doi.org/10.1109/ICRA46639.2022.9811973	Xiang Zhang, Shiyu Jin, Changhao Wang, Xinghao Zhu, Masayoshi Tomizuka
Learning Interactive Driving Policies via Data-driven Simulation.	Data-driven simulators promise high data-efficiency for driving policy learning. When used for modelling interactions, this data-efficiency becomes a bottleneck: small underlying datasets often lack interesting and challenging edge cases for learning interactive driving. We address this challenge by proposing a data-driven simulation engine† that uses inpainted ado vehicles for learning robust driving policies. Thus, our approach can be used to learn policies that involve multi-agent interactions and allows for training via state-of-the-art policy learning methods. We evaluate the approach for learning standard interaction scenarios in driving. In extensive experiments, our work demonstrates that the resulting policies can be directly transferred to a full-scale autonomous vehicle without making use of any traditional sim-to-real transfer techniques such as domain randomization.	https://doi.org/10.1109/ICRA46639.2022.9812407	Tsun-Hsuan Wang, Alexander Amini, Wilko Schwarting, Igor Gilitschenski, Sertac Karaman, Daniela Rus
Learning Latent Actions without Human Demonstrations.	We can make it easier for disabled users to control assistive robots by mapping the user's low-dimensional joystick inputs to high-dimensional, complex actions. Prior works learn these mappings from human demonstrations: a non-disabled human either teleoperates or kinesthetically guides the robot arm through a variety of motions, and the robot learns to reproduce the demonstrated behaviors. But this framework is often impractical — disabled users will not always have access to external demonstrations! Here we instead learn diverse teleoperation mappings without either human demonstrations or pre-defined tasks. Under our unsupervised approach the robot first optimizes for object state entropy: i.e., the robot autonomously learns to push, pull, open, close, or otherwise change the state of nearby objects. We then embed these diverse, object-oriented behaviors into a latent space for real-time control: now pressing the joystick causes the robot to perform dexterous motions like pushing or opening. We experimentally show that — with a best-case human operator — our unsupervised approach actually outperforms the teleoperation mappings learned from human demonstrations, particularly if those demonstrations are noisy or imperfect. But our user study results were less clear-cut: although our approach enabled participants to complete tasks more quickly and with fewer changes of direction, users were confused when the unsupervised robot learned unexpected behaviors. See videos of the user study here: https://youtu.be/BkqHQjsUKDg	https://doi.org/10.1109/ICRA46639.2022.9812230	Shaunak A. Mehta, Sagar Parekh, Dylan P. Losey
Learning Latent Graph Dynamics for Visual Manipulation of Deformable Objects.	Manipulating deformable objects, such as ropes and clothing, is a long-standing challenge in robotics, because of their large degrees of freedom, complex non-linear dynamics, and self-occlusion in visual perception. The key difficulty is a suitable representation, rich enough to capture the object shape, dynamics for manipulation and yet simple enough to be estimated reliably from visual observations. This work aims to learn latent Graph dynamics for DefOrmable Object Manipulation (G-DOOM). G-DOOM approximates a deformable object as a sparse set of interacting keypoints, which are extracted automatically from images via unsupervised learning. It learns a graph neural network that captures abstractly the geometry and the interaction dynamics of the keypoints. To handle object self-occlusion, G-DOOM uses a recurrent neural network to track the keypoints over time and condition their interactions on the history. We then train the resulting recurrent graph dynamics model through contrastive learning in a high-fidelity simulator. For manipulation planning, G-DOOM reasons explicitly about the learned dynamics model through model-predictive control applied at each keypoint. Preliminary experiments of G-DOOM on a set of challenging rope and cloth manipulation tasks indicate strong performance, compared with state-of-the-art methods. Although trained in a simulator, G-DOOM transfers directly to a real robot for both rope and cloth manipulation 11Demo video available online at https://youtu.be/oCfbNMx2sQI.	https://doi.org/10.1109/ICRA46639.2022.9811597	Xiao Ma, David Hsu, Wee Sun Lee
Learning Local Event-based Descriptor for Patch-based Stereo Matching.	Stereo matching is an indispensable function that enables machine vision system to obtain depth information of its environment. However, most of existing algorithms rely on conventional camera, which follows the frame-based scheme and has several shortcomings: low dynamic range, low temporal resolution and high power consumption. To address these issues, we propose two novel patch-based stereo matching methods that exploit the output from a pair of neuromorphic vision sensors. Compared to frame-based camera, neuromorphic vision sensor has independent pixels that generates events at the time intensity changes occur. Based on this unique output, we first construct event representations and present a novel encoding method, which integrates with attention mechanism to encode rich spatial-temporal information of event streams. Then, we design efficient and accuracy networks and propose corresponding loss to train them, which are used to extract event-based descriptors from representations. Finally, the disparity maps are calculated based on local features and refined by two simple smoothing methods. Extensive experiments on the Multi Vehicle Stereo Event Camera Dataset demonstrate the effectiveness of our methods.	https://doi.org/10.1109/ICRA46639.2022.9811687	Peigen Liu, Guang Chen, Zhijun Li, Huajin Tang, Alois C. Knoll
Learning Model Predictive Control for Quadrotors.	Aerial robots can enhance their safe and agile navigation in complex and cluttered environments by efficiently exploiting the information collected during a given task. In this paper, we address the learning model predictive control problem for quadrotors. We design a learning receding-horizon nonlinear control strategy directly formulated on the system nonlinear manifold configuration space SO(3)×R3. The proposed approach exploits past successful task iterations to improve the system performance over time while respecting system dynamics and actuator constraints. We further relax its computational complexity making it compatible with real-time quadrotor control requirements. We show the effectiveness of the proposed approach in learning a minimum time control task, respecting dynamics, actuators, and environment constraints. Several experiments in simulation and real-world set-up validate the proposed approach.	https://doi.org/10.1109/ICRA46639.2022.9812077	Guanrui Li, Alex Tunchez, Giuseppe Loianno
Learning Multi-Task Transferable Rewards via Variational Inverse Reinforcement Learning.	Many robotic tasks are composed of a lot of temporally correlated sub-tasks in a highly complex environment. It is important to discover situational intentions and proper actions by deliberating on temporal abstractions to solve problems effectively. To understand the intention separated from changing task dynamics, we extend an empowerment-based regularization technique to situations with multiple tasks based on the framework of a generative adversarial network. Under the multitask environments with unknown dynamics, we focus on learning a reward and policy from the unlabeled expert examples. In this study, we define situational empowerment as the maximum of mutual information representing how an action conditioned on both a certain state and sub-task affects the future. Our proposed method derives the variational lower bound of the situational mutual information to optimize it. We simultaneously learn the transferable multi-task reward function and policy by adding an induced term to the objective function. By doing so, the multi-task reward function helps to learn a robust policy for environmental change. We validate the advantages of our approach on multi-task learning and multi-task transfer learning. We demonstrate our proposed method has the robustness of both randomness and changing task dynamics. Finally, we prove that our method has significantly better performance and data efficiency than existing imitation learning methods on various benchmarks.	https://doi.org/10.1109/ICRA46639.2022.9811697	Se-Wook Yoo, Seung-Woo Seo
Learning Multi-step Robotic Manipulation Policies from Visual Observation of Scene and Q-value Predictions of Previous Action.	In this work, we focus on multi-step manipulation tasks that involve long-horizon planning and considers progress reversal. Such tasks interlace high-level reasoning that consists of the expected states that can be attained to achieve an overall task and low-level reasoning that decides what actions will yield these states. We propose a sample efficient Previous Action Conditioned Robotic Manipulation Network (PAC-RoManNet) to learn the action-value functions and predict manipulation action candidates from visual observation of the scene and action-value predictions of the previous action. We define a Task Progress based Gaussian (TPG) reward function that computes the reward based on actions that lead to successful motion primitives and progress towards the overall task goal. To balance the ratio of exploration/exploitation, we introduce a Loss Adjusted Exploration (LAE) policy that determines actions from the action candidates according to the Boltzmann distribution of loss estimates. We demonstrate the effectiveness of our approach by training PAC-RoManNet to learn several challenging multi-step robotic manipulation tasks in both simulation and real-world. Experimental results show that our method outperforms the existing methods and achieves state-of-the-art performance in terms of success rate and action efficiency. The ablation studies show that TPG and LAE are especially beneficial for tasks like multiple block stacking. Additional experiments on Ravens-10 benchmark tasks suggest good generalizability of the proposed PAC-RoManNet.	https://doi.org/10.1109/ICRA46639.2022.9812251	Sulabh Kumra, Shirin Joshi, Ferat Sahin
Learning Object Relations with Graph Neural Networks for Target-Driven Grasping in Dense Clutter.	Robots in the real world frequently come across identical objects in dense clutter. When evaluating grasp poses in these scenarios, a target-driven grasping system requires knowledge of spatial relations between scene objects (e.g., proximity, adjacency, and occlusions). To efficiently complete this task, we propose a target-driven grasping system that simultaneously considers object relations and predicts 6-DoF grasp poses. A densely cluttered scene is first formulated as a grasp graph with nodes representing object geometries in the grasp coordinate frame and edges indicating spatial relations between the objects. We design a Grasp Graph Neural Network (G2N2) that evaluates the grasp graph and finds the most feasible 6-DoF grasp pose for a target object. Additionally, we develop a shape completion-assisted grasp pose sampling method that improves sample quality and consequently grasping efficiency. We compare our method against several baselines in both simulated and real settings. In real-world experiments with novel objects, our approach achieves a 77.78% grasping accuracy in densely cluttered scenarios, surpassing the best-performing baseline by more than 15%. Supplementary material is available at https://sites.google.com/umn.edu/graph-grasping.	https://doi.org/10.1109/ICRA46639.2022.9811601	Xibai Lou, Yang Yang, Changhyun Choi
Learning Observation-Based Certifiable Safe Policy for Decentralized Multi-Robot Navigation.	Safety is of great importance in multi-robot navigation problems. In this paper, we propose a control barrier function (CBF) based optimizer that ensures robot safety with both high probability and flexibility, using only sensor measurement. The optimizer takes action commands from the policy network as initial values and provides refinement to drive the potentially dangerous ones back into safe regions. With the help of a deep world model that predicts the evolution of surrounding dynamics and the consequences of different actions, the CBF module can guide the optimization within a reasonable time horizon. We also present a novel joint training framework that improves the cooperation between the Reinforcement Learning (RL) based policy and the CBF-based optimizer by utilizing reward feedback from the CBF module. We observe that our policy can achieve a higher success rate while maintaining the safety of multiple robots in significantly fewer episodes. Experiments are conducted in multiple scenarios both in simulation and the real world, the results demonstrate the effectiveness of our method in maintaining the safety of multiple robots. Code is available at https://github.com/YuxiangCui/MARL-OCBF.	https://doi.org/10.1109/ICRA46639.2022.9811950	Yuxiang Cui, Longzhong Lin, Xiaolong Huang, Dongkun Zhang, Yunkai Wang, Wei Jing, Junbo Chen, Rong Xiong, Yue Wang
Learning Periodic Tasks from Human Demonstrations.	We develop a method for learning periodic tasks from visual demonstrations. The core idea is to leverage periodicity in the policy structure to model periodic aspects of the tasks. We use active learning to optimize parameters of rhythmic dynamic movement primitives (rDMPs) and propose an objective to maximize the similarity between the motion of objects manipulated by the robot and the desired motion in human video demonstrations. We consider tasks with deformable objects and granular matter whose states are challenging to represent and track: wiping surfaces with a cloth, winding cables, and stirring granular matter with a spoon. Our method does not require tracking markers or manual annotations. The initial training data consists of 10-minute videos of random unpaired interactions with objects by the robot and human. We use these for unsupervised learning of a keypoint model to get task-agnostic visual correspondences. Then, we use Bayesian optimization to optimize rDMPs from a single human video demonstration within few robot trials. We present simulation and hardware experiments to validate our approach.	https://doi.org/10.1109/ICRA46639.2022.9812402	Jingyun Yang, Junwu Zhang, Connor Settle, Akshara Rai, Rika Antonova, Jeannette Bohg
Learning Purely Tactile In-Hand Manipulation with a Torque-Controlled Hand.	We show that a purely tactile dextrous in-hand manipulation task with continuous regrasping, requiring permanent force closure, can be learned from scratch and executed robustly on a torque-controlled humanoid robotic hand. The task is rotating a cube without dropping it, but in contrast to OpenAI's seminal cube manipulation task [1], the palm faces downwards and no cameras but only the hand's position and torque sensing are used. Although the task seems simple, it combines for the first time all the challenges in execution as well as learning that are important for using in-hand manipulation in real-world applications. We efficiently train in a precisely modeled and identified rigid body simulation with off-policy deep reinforcement learning, significantly sped up by a domain adapted curriculum, leading to a moderate 600 CPU hours of training time. The resulting policy is robustly transferred to the real humanoid DLR Hand-II, e.g., reaching more than 46 full 2\\pi\nrotations of the cube in a single run and allowing for disturbances like different cube sizes, hand orientation, or pulling a finger.	https://doi.org/10.1109/ICRA46639.2022.9812093	Leon Sievers, Johannes Pitz, Berthold Bäuml
Learning Scalable Policies over Graphs for Multi-Robot Task Allocation using Capsule Attention Networks.	This paper presents a novel graph reinforcement learning (RL) architecture to solve multi-robot task allocation (MRTA) problems that involve tasks with deadlines and workload, and robot constraints such as work capacity. While drawing motivation from recent graph learning methods that learn to solve combinatorial optimization (CO) problems such as multi-Traveling Salesman and Vehicle Routing Problems using RL, this paper seeks to provide better performance (compared to non-learning methods) and important scalability (compared to existing learning architectures) for the stated class of MRTA problems. The proposed neural architecture, called Capsule Attention-based Mechanism or CapAM acts as the policy network, and includes three main components: 1) an encoder: a Capsule Network based node embedding model to represent each task as a learnable feature vector; 2) a decoder: an attention-based model to facilitate a sequential output; and 3) context: that encodes the states of the mission and the robots. To train the CapAM model, the policy-gradient method based on REINFORCE is used. When evaluated over unseen scenar-ios, CapAM demonstrates better task completion performance and > 10 times faster decision-making compared to standard non-learning based online MRTA methods. CapAM's advantage in generalizability, and scalability to test problems of size larger than those used in training, are also successfully demonstrated in comparison to a popular approach for learning to solve CO problems, namely the purely attention mechanism.	https://doi.org/10.1109/ICRA46639.2022.9812370	Steve Paul, Payam Ghassemi, Souma Chowdhury
Learning Sensorimotor Primitives of Sequential Manipulation Tasks from Visual Demonstrations.	This work aims to learn how to perform complex robot manipulation tasks that are composed of several, consecutively executed low-level sub-tasks, given as input a few visual demonstrations of the tasks performed by a person. The sub-tasks consist of moving the robot's end-effector until it reaches a sub-goal region in the task space, performing an action, and triggering the next sub-task when a pre-condition is met. Most prior work in this domain has been concerned with learning only low-level tasks, such as hitting a ball or reaching an object and grasping it. This paper describes a new neural network-based framework for learning simultaneously low-level policies as well as high-level policies, such as deciding which object to pick next or where to place it relative to other objects in the scene. A key feature of the proposed approach is that the policies are learned directly from raw videos of task demonstrations, without any manual annotation or post-processing of the data. Empirical results on object manipulation tasks with a robotic arm show that the proposed network can efficiently learn from real visual demonstrations to perform the tasks, and outperforms popular imitation learning algorithms.	https://doi.org/10.1109/ICRA46639.2022.9811703	Junchi Liang, Bowen Wen, Kostas E. Bekris, Abdeslam Boularias
Learning Spatiotemporal Occupancy Grid Maps for Lifelong Navigation in Dynamic Scenes.	We present a novel method for generating, predicting, and using Spatiotemporal Occupancy Grid Maps (SOGM), which embed future information of dynamic scenes. Our au-tomated generation process creates groundtruth SOGMs from previous navigation data. We build on prior work to annotate lidar points based on their dynamic properties, which are then projected on time-stamped 2D grids: SOGMs. We design a 3D-2D feedforward architecture, trained to predict the future time steps of SOGMs, given 3D lidar frames as input. Our pipeline is entirely self-supervised, thus enabling lifelong learning for robots. The network is composed of a 3D back-end that extracts rich features and enables the semantic segmentation of the lidar frames, and a 2D front-end that predicts the future information embedded in the SOGMs within planning. We also design a navigation pipeline that uses these predicted SOGMs. We provide both quantitative and qualitative insights into the predictions and validate our choices of network design with a comparison to the state of the art and ablation studies.	https://doi.org/10.1109/ICRA46639.2022.9812297	Hugues Thomas, Matthieu Gallet de Saint Aurin, Jian Zhang, Timothy D. Barfoot
Learning Stable Dynamical Systems for Visual Servoing.	This work presents the dual benefit of integrating imitation learning techniques, based on the dynamical systems formalism, with the visual servoing paradigm. On the one hand, dynamical systems allow to program additional skills without explicitly coding them in the visual servoing law, but leveraging few demonstrations of the full desired behavior. On the other, visual servoing allows to consider exteroception into the dynam-ical system architecture and be able to adapt to unexpected environment changes. The beneficial combination of the two concepts is proven by applying three existing dynamical systems methods to the visual servoing case. Simulations validate and compare the methods; experiments with a robot manipulator show the validity of the approach in a real-world scenario.	https://doi.org/10.1109/ICRA46639.2022.9811944	Antonio Paolillo, Matteo Saveriano
Learning Visual Shape Control of Novel 3D Deformable Objects from Partial-View Point Clouds.	If robots could reliably manipulate the shape of 3D deformable objects, they could find applications in fields ranging from home care to warehouse fulfillment to surgical assistance. Analytic models of elastic, 3D deformable objects require numerous parameters to describe the potentially infinite degrees of freedom present in determining the object's shape. Previous attempts at performing 3D shape control rely on hand-crafted features to represent the object shape and require training of object-specific control models. We overcome these issues through the use of our novel DeformerNet neural network architecture, which operates on a partial-view point cloud of the object being manipulated and a point cloud of the goal shape to learn a low-dimensional representation of the object shape. This shape embedding enables the robot to learn to define a visual servo controller that provides Cartesian pose changes to the robot end-effector causing the object to deform towards its target shape. Crucially, we demonstrate both in simulation and on a physical robot that DeformerNet reliably generalizes to object shapes and material stiffness not seen during training and outperforms comparison methods for both the generic shape control and the surgical task of retraction.	https://doi.org/10.1109/ICRA46639.2022.9812215	Bao Thach, Brian Y. Cho, Alan Kuntz, Tucker Hermans
Learning from Imperfect Demonstrations via Adversarial Confidence Transfer.	Existing learning from demonstration algorithms usually assume access to expert demonstrations. However, this assumption is limiting in many real-world applications since the collected demonstrations may be suboptimal or even consist of failure cases. We therefore study the problem of learning from imperfect demonstrations by learning a confidence predictor. Specifically, we rely on demonstrations along with their confidence values from a different correspondent environment (source environment) to learn a confidence predictor for the environment we aim to learn a policy in (target environment-where we only have unlabeled demonstrations). We learn a common latent space through adversarial distribution matching of multi-length partial trajectories to enable the transfer of confidence across source and target environments. The learned confidence reweights the demonstrations to enable learning more from informative demonstrations and discarding the irrelevant ones. Our experiments in three simulated environments and a real robot reaching task demonstrate that our approach learns a policy with the highest expected return. We show the videos of our experiments on our website.	https://doi.org/10.1109/ICRA46639.2022.9811891	Zhangjie Cao, Zihan Wang, Dorsa Sadigh
Learning to Detect Slip with Barometric Tactile Sensors and a Temporal Convolutional Neural Network.	The ability to perceive object slip via tactile feedback enables humans to accomplish complex manipulation tasks including maintaining a stable grasp. Despite the utility of tactile information for many applications, tactile sensors have yet to be widely deployed in industrial robotics settings; part of the challenge lies in identifying slip and other events from the tactile data stream. In this paper, we present a learning-based method to detect slip using barometric tactile sensors. These sensors have many desirable properties including high durability and reliability, and are built from inexpensive, off-the-shelf components. We train a temporal convolution neural network to detect slip, achieving high detection accuracies while displaying robustness to the speed and direction of the slip motion. Further, we test our detector on two manipulation tasks involving a variety of common objects and demonstrate successful generalization to real-world scenarios not seen during training. We argue that barometric tactile sensing technology, combined with data-driven learning, is suitable for many manipulation tasks such as slip compensation.	https://doi.org/10.1109/ICRA46639.2022.9811592	Abhinav Grover, Philippe Nadeau, Christopher Grebe, Jonathan Kelly
Learning to Fill the Seam by Vision: Sub-millimeter Peg-in-hole on Unseen Shapes in Real World.	In the peg insertion task, human pays attention to the seam between the peg and the hole and tries to fill it continuously with visual feedback. By imitating the human's behavior, we design architectures with position and orientation estimators based on the seam representation for pose alignment, which proves to be general to the unseen peg geometries. By putting the estimators into the closed-loop control with reinforcement learning, we further achieve higher or comparable success rate, efficiency, and robustness compared with the baseline methods. The policy is trained totally in simulation without any manual intervention. To achieve sim-to-real, a learnable segmentation module with automatic data collecting and labeling can be easily trained to decouple the perception and the policy, which helps the model trained in simulation quickly adapting to the real world with negligible effort. Results are presented in simulation and on a physical robot. Code, videos, and supplemental material are available at https://github.com/xieliang555/SFN.git	https://doi.org/10.1109/ICRA46639.2022.9812429	Liang Xie, Hongxiang Yu, Yinghao Zhao, Haodong Zhang, Zhongxiang Zhou, Minhang Wang, Yue Wang, Rong Xiong
Learning to Infer Kinematic Hierarchies for Novel Object Instances.	Manipulating an articulated object requires perceiving its kinematic hierarchy: its parts, how each can move, and how those motions are coupled. Previous work has explored perception for kinematics, but none infers a complete kinematic hierarchy on never-before-seen object instances, without relying on a schema or template. We present a novel perception system that achieves this goal. Our system infers the moving parts of an object and the kinematic couplings that relate them. To infer parts, it uses a point cloud instance segmentation neural network and to infer kinematic hierarchies, it uses a graph neural network to predict the existence, direction, and type of edges (i.e. joints) that relate the inferred parts. We train these networks using simulated scans of synthetic 3D models. We evaluate our system on simulated scans of 3D objects, and we demonstrate a proof-of-concept use of our system to drive real-world robotic manipulation.	https://doi.org/10.1109/ICRA46639.2022.9811968	Hameed Abdul-Rashid, Miles Freeman, Ben Abbatematteo, George Konidaris, Daniel Ritchie
Learning to Listen and Move: An Implementation of Audio-Aware Mobile Robot Navigation in Complex Indoor Environment.	Sound is an essential navigation cue that intelligent robots can leverage for localizing sound-emitting targets. This work introduces a framework for the audio-aware navigation task of mobile robots equipped with a microphone array in a complex indoor environment. The robot initialized at a random starting position has to accurately localize a distant sound source and plan an optimal path towards the sound-emitting target. Auto-encoders are used to extract implicit acoustic features that are robust against environmental noise and reverberation. The proposed framework is based on two key ideas - a sound inference module (SIM) that maps the perceived acoustic information to a given geometric map of the physical space, and a path planner that generates a path from the robot's current position to the estimated position of the sound source. Experimental results show that the SIM achieved a minimum and maximum localization error of 0.31 m and 0.70 m at a robot-source distance of 1 m and 6 m, respectively at different environmental configurations. Additionally, the proposed framework achieved a minimum and maximum reliability of 4.38 m^{-1} and 2.31 m^{-1} at a robot-source distance of 1 m and 6 m, respectively under the influence of background noise.	https://doi.org/10.1109/ICRA46639.2022.9812193	Pratyaksh P. Rao, Abhra Roy Chowdhury
Learning to Localize, Grasp, and Hand Over Unmodified Surgical Needles.	Robotic Surgical Assistants (RSAs) are commonly used to perform minimally invasive surgeries by expert surgeons. However, long procedures filled with tedious and repetitive tasks such as suturing can lead to surgeon fatigue, motivating the automation of suturing. As visual tracking of a thin reflective needle is extremely challenging, prior work has modified the needle with nonreflective contrasting paint. As a step towards automation of a suturing subtask without modifying the needle, we propose HOUSTON: Handover of Unmodified, Surgical, Tool-Obstructed Needles, a problem and algorithm that uses a learned active sensing policy with a stereo camera to iteratively localize and align the needle into a visible and accessible pose for the other gripper. To compensate for robot positioning and needle perception errors, the algorithm then executes a high-precision grasping motion that uses multiple cameras. Physical experiments with the da Vinci Research Kit (dVRK) suggest a success rate of 96.7% on needles used in training, and 75 - 92.9% on needles unseen in training. On sequential handovers, HOUSTON successfully executes 32.4 handovers on average before failure. To our knowledge, this work is the first to study handover of unmodified surgical needles. See https: / /tinyurl. com/houston-surgery for additional materials including details about offline datasets and model architectures.	https://doi.org/10.1109/ICRA46639.2022.9812393	Albert Wilcox, Justin Kerr, Brijen Thananjeyan, Jeffrey Ichnowski, Minho Hwang, Samuel Paradis, Danyal Fer, Ken Goldberg
Learning to Navigate Intersections with Unsupervised Driver Trait Inference.	Navigation through uncontrolled intersections is one of the key challenges for autonomous vehicles. Identifying the subtle differences in hidden traits of other drivers can bring significant benefits when navigating in such environments. We propose an unsupervised method for inferring driver traits such as driving styles from observed vehicle trajectories. We use a variational autoencoder with recurrent neural networks to learn a latent representation of traits without any ground truth trait labels. Then, we use this trait representation to learn a policy for an autonomous vehicle to navigate through a T-intersection with deep reinforcement learning. Our pipeline enables the autonomous vehicle to adjust its actions when dealing with drivers of different traits to ensure safety and efficiency. Our method demonstrates promising performance and outperforms state-of-the-art baselines in the T-intersection scenario.	https://doi.org/10.1109/ICRA46639.2022.9811635	Shuijing Liu, Peixin Chang, Haonan Chen, Neeloy Chakraborty, Katherine Rose Driggs-Campbell
Learning to Navigate by Pushing.	In this work, we investigate a form of dynamic contact-rich locomotion in which a robot pushes off from obstacles in order to move through its environment. We present a reflex-based approach that switches between optimized hand-crafted reflex controllers and produces smooth and predictable motions. In contrast to previous work, our approach does not rely on periodic movements, complex models of robot and contact dynamics, or extensive hand tuning. We demonstrate the effectiveness of our approach and evaluate its performance compared to a standard model-free RL algorithm. We identify continuous clusters of similar behaviours, which allows us to successfully transfer different push-off motions directly from simulation to a physical robot without further retraining.	https://doi.org/10.1109/ICRA46639.2022.9812194	Cornelia Bauer, Dominik Bauer, Alisa Allaire, Christopher G. Atkeson, Nancy S. Pollard
Learning to Optimize in Model Predictive Control.	Sampling-based Model Predictive Control (MPC) is a flexible control framework that can reason about non-smooth dynamics and cost functions. Recently, significant work has focused on the use of machine learning to improve the performance of MPC, often through learning or fine-tuning the dynamics or cost function. In contrast, we focus on learning to optimize more effectively. In other words, to improve the update rule within MPC. We show that this can be particularly useful in sampling-based MPC, where we often wish to minimize the number of samples for computational reasons. Unfortunately, the cost of computational efficiency is a reduction in performance; fewer samples results in noisier updates. We show that we can contend with this noise by learning how to update the control distribution more effectively and make better use of the few samples that we have. Our learned controllers are trained via imitation learning to mimic an expert which has access to substantially more samples. We test the efficacy of our approach on multiple simulated robotics tasks in sample-constrained regimes and demonstrate that our approach can outperform a MPC controller with the same number of samples.	https://doi.org/10.1109/ICRA46639.2022.9812369	Jacob Sacks, Byron Boots
Learning to Pick by Digging: Data-Driven Dig-Grasping for Bin Picking from Clutter.	We present a data-driven approach for effective bin picking from clutter. Recent bin picking solutions usually lead to a direct pinch grasp on a target object without addressing any other potential contact interaction in clutter. However, appropriate physical interaction can be essential to successful singulation and subsequent secure picking, the goal of bin picking. In this work, we contribute a framework that learns physically interactive actions for object picking end-to-end from a visual input in a self-supervised manner. The learned actions enable the robot to purposefully interact with a target object by performing a digging operation through the clutter. By leveraging a fully convolutional network (FCN), we predict picking success probabilities for a set of interactive action primitives that will in turn specify an optimal action to perform. The FCN is trained in a simulated environment through trial and error. Moreover, new datasets are collected using the latest network through iterative self-supervision. Extensive real-world bin picking experiments show the effectiveness and generalizability of the approach.	https://doi.org/10.1109/ICRA46639.2022.9811736	Chao Zhao, Zhekai Tong, Juan Rojas, Jungwon Seo
Learning to Retrieve Relevant Experiences for Motion Planning.	Recent work has demonstrated that motion planners' performance can be significantly improved by retrieving past experiences from a database. Typically, the experience database is queried for past similar problems using a similarity function defined over the motion planning problems. However, to date, most works rely on simple hand-crafted similarity functions and fail to generalize outside their corresponding training dataset. To address this limitation, we propose (FIRE), a framework that extracts local representations of planning problems and learns a similarity function over them. To generate the training data we introduce a novel self-supervised method that identifies similar and dissimilar pairs of local primitives from past solution paths. With these pairs, a Siamese network is trained with the contrastive loss and the similarity function is realized in the network's latent space. We evaluate FIRE on an 8-DOF manipulator in five categories of motion planning problems with sensed environments. Our experiments show that FIRE retrieves relevant experiences which can informatively guide sampling-based planners even in problems outside its training distribution, outperforming other baselines.	https://doi.org/10.1109/ICRA46639.2022.9812076	Constantinos Chamzas, Aedan Cullen, Anshumali Shrivastava, Lydia E. Kavraki
Learning to Rock-and-Walk: Dynamic, Non-Prehensile, and Underactuated Object Locomotion Through Reinforcement Learning.	When moving objects that are too bulky or heavy to be grasped or lifted, robotic manipulation can benefit from the object's interaction with the support surface and its natural dynamics under gravity. In this work, we show that such dynamic, underactuated manipulation capability can be acquired through reinforcement learning and deployed on real robot systems. First, we present a framework to learn a control policy for object transport in a dynamic simulation environment, featuring the object and the support surface. We then demonstrate successful object locomotion with the learned policy through a set of simulated and real-world experiments, performed with a robot arm and an aerial robot interacting with the object in a non-prehensile manner. While the object, which is in contact with the support surface, oscillates sideways passively under gravity, the robot uses the learned policy to move the object forward with a steady gait by regulating the mechanical energy and the posture of the object. Our experiment results show that the learned policy can transport the object through unmodeled effects of terrain and perturbation.	https://doi.org/10.1109/ICRA46639.2022.9811554	Abdullah Nazir, Xu Pu, Juan Rojas, Jungwon Seo
Learning to Socially Navigate in Pedestrian-rich Environments with Interaction Capacity.	Existing navigation policies for autonomous robots tend to focus on collision avoidance while ignoring human-robot interactions in social life. For instance, robots can pass along the corridor safer and easier if pedestrians notice them. Sounds have been considered as an efficient way to attract the attention of pedestrians, which can alleviate the freezing robot problem. In this work, we present a new deep reinforcement learning (DRL) based social navigation approach for autonomous robots to move in pedestrian-rich environments with interaction capacity. Most existing DRL based methods intend to train a general policy that outputs both navigation actions, i.e., expected robot's linear and angular velocities, and interaction actions, i.e., the beep action, in the context of reinforcement learning. Different from these methods, we intend to train the policy via both supervised learning and reinforcement learning. In specific, we first train an interaction policy in the context of supervised learning, which provides a better understanding of the social situation, then we use this interaction policy to train the navigation policy via multiple reinforcement learning algorithms. We evaluate our approach in various simulation environments and compare it to other methods. The experimental results show that our approach outperforms others in terms of the success rate. We also deploy the trained policy on a real-world robot, which shows a nice performance in crowded environments.	https://doi.org/10.1109/ICRA46639.2022.9811662	Quecheng Qiu, Shunyi Yao, Jing Wang, Jun Ma, Guangda Chen, Jianmin Ji
Learning to Swarm with Knowledge-Based Neural Ordinary Differential Equations.	Understanding decentralized dynamics from collective behaviors in swarms is crucial for informing robot controller designs in artificial swarms and multi-agent robotic systems. However, the complexity in agent-to-agent interactions and the decentralized nature of most swarms pose a significant challenge to the extraction of single-robot control laws from collective behaviors. In this work, we consider the important task of learning decentralized single-robot controllers based solely on the state observations of a swarm's trajectory. We present a general framework by adopting knowledge-based neural ordinary differential equations (KNODE) ─ a hybrid machine learning method capable of combining artificial neural networks with known agent dynamics. Our approach distinguishes itself from most prior works in that we do not require action data for learning. We apply our framework to two different flocking swarms in 2D and 3D respectively, and demonstrate efficient training by leveraging the graphical structure of the swarms' information network. We further show that the learnt single-robot controllers can not only mimic flocking behavior in the original swarm but also scale to swarms with more robots.	https://doi.org/10.1109/ICRA46639.2022.9811997	Tom Z. Jiahao, Lishuo Pan, M. Ani Hsieh
Learning to Synthesize Volumetric Meshes from Vision-based Tactile Imprints.	Vision-based tactile sensors typically utilize a deformable elastomer and a camera mounted above to provide high-resolution image observations of contacts. Obtaining accurate volumetric meshes for the deformed elastomer can provide direct contact information and benefit robotic grasping and manipulation. This paper focuses on learning to synthesize the volumetric mesh of the elastomer based on the image imprints acquired from vision-based tactile sensors. Synthetic image-mesh pairs and real-world images are gathered from 3D finite element methods (FEM) and physical sensors, respectively. A graph neural network (GNN) is introduced to learn the image-to-mesh mappings with supervised learning. A self-supervised adaptation method and image augmentation techniques are proposed to transfer networks from simulation to reality, from primitive contacts to unseen contacts, and from one sensor to another. Using these learned and adapted networks, our proposed method can accurately reconstruct the deformation of the real-world tactile sensor elastomer in various domains, as indicated by the quantitative and qualitative results.	https://doi.org/10.1109/ICRA46639.2022.9812092	Xinghao Zhu, Siddarth Jain, Masayoshi Tomizuka, Jeroen van Baar
Learning-Guided Exploration for Efficient Sampling-Based Motion Planning in High Dimensions.	Optimal motion planning is a long-studied problem with a wide range of applications in robotics, from grasping to navigation. While sampling-based motion planning methods have made solving such problems significantly more feasible, these methods still often struggle in high-dimensional spaces wherein exploration is computationally costly. In this paper, we propose a new motion planning algorithm that reduces the computational burden of the exploration process. The proposed algorithm utilizes a guidance policy acquired offline through model-free reinforcement learning. The guidance policy is used to bias the exploration process in motion planning and to guide it toward promising regions of the state space. Moreover, we show that the gradients of the corresponding learned value function can be used to locally fine-tune the sampled states. We empirically demonstrate that the proposed approach can significantly reduce planning time and improve success rate and path quality.	https://doi.org/10.1109/ICRA46639.2022.9812184	Liam Schramm, Abdeslam Boularias
Learning-based Ellipse Detection for Robotic Grasps of Cylinders and Ellipsoids.	In our daily life, there are many objects represented by cylindrical shapes and ellipsoids. The tops of these objects are formed by elliptic shape primitives. Thus, it is available for a robot to manipulate these objects by ellipse detection. In this work, we propose a novel approach to generating ground truth for training the model based on domain randomization. Using synthetic data generated in this manner, we build an end-to-end deep neural network with a detection backbone and then, combine multiple branches archived from the backbone for sharing the multiple-scale features; further, after employing active rotation filters, the features pass through the region proposal net to form the prediction branches of the box, orientation regression, and object classification; finally, these branches are fused to do ellipse detection, allowing robotic manipulations of cylinders and ellipsoids. To demonstrate the capabilities of the proposed detector, we show the comparison results with the state-of-the-art detector on synthetic and public datasets. The proposed model for ellipse detection and data generation pipeline based on domain randomization in a simulation are evaluated by a series of robotic manipulations implemented in real application scenarios. The results illustrate a high success rate on real-world grasp attempts despite having only been trained on a synthetic dataset. (A video of some robotic experiments is available on YouTube: https://youtu.be/Ueg1XSI2S98).	https://doi.org/10.1109/ICRA46639.2022.9812363	Huixu Dong, Jiadong Zhou, Chen Qiu, Dilip K. Prasad, I-Ming Chen
Legged Robots that Keep on Learning: Fine-Tuning Locomotion Policies in the Real World.	Legged robots are physically capable of traversing a wide range of challenging environments, but designing controllers that are sufficiently robust to handle this diversity has been a long-standing challenge in robotics. Reinforcement learning presents an appealing approach for automating the controller design process and has been able to produce remarkably robust controllers when trained in a suitable range of environments. However, it is difficult to predict all likely conditions the robot will encounter during deployment and enumerate them at training-time. What if instead of training controllers that are robust enough to handle any eventuality, we enable the robot to continually learn in any setting it finds itself in? This kind of real-world reinforcement learning poses a number of challenges, including efficiency, safety, and autonomy. To address these challenges, we propose a practical robot reinforcement learning system for fine-tuning locomotion policies in the real world. We demonstrate that a modest amount of real-world training can substantially improve performance during deployment, and this enables a real A1 quadrupedal robot to autonomously fine-tune multiple locomotion skills in a range of environments, including an outdoor lawn and a variety of indoor terrains. (Videos and code11https://sites.google.com/berkele.edu/fine-tuning-locomotion)	https://doi.org/10.1109/ICRA46639.2022.9812166	Laura M. Smith, J. Chase Kew, Xue Bin Peng, Sehoon Ha, Jie Tan, Sergey Levine
Let Them Have Bubbles! Filling Gaps in Toy-Like Behaviors for Child-Robot Interaction.	Robot-mediated interventions are one promising and novel approach for encouraging motor exploration in young children, but knowledge about the effectiveness of toy-like features for child-robot interaction is limited. We were interested in understanding the characteristics of current toys to inform the design of interactive abilities for assistive robots. This work first provides a systematic review of toy characteristics in n=154 Fisher-Price products and then analyzes the effectiveness of common and uncommon toy-like behaviors from our custom assistive robot. Toy review results showed that light and sound features were significantly more common than bubbles, wheels, and self-propulsion. Exploratory play sessions with our assistive robot showed that bubbles were significantly more successful at encouraging child motion than other robot behaviors. Further, all studied robot behaviors demonstrated the capability to encourage child motion. The products of this work can inform the efforts of human-robot interaction and child development experts who study child mobility interventions.	https://doi.org/10.1109/ICRA46639.2022.9812031	Ameer Helmi, Samantha Noregaard, Natasha Giulietti, Samuel W. Logan, Naomi T. Fitter
Let's Collaborate: Regret-based Reactive Synthesis for Robotic Manipulation.	"As robots gain capabilities to enter our humancentric world, they require formalism and algorithms that enable smart and efficient interactions. This is challenging, especially for robotic manipulators with complex tasks that may require collaboration with humans. Prior works approach this problem through reactive synthesis and generate strategies for the robot that guarantee task completion by assuming an adversarial human. While this assumption gives a sound solution, it leads to an ""unfriendly"" robot that is agnostic to the human intentions. We relax this assumption by formulating the problem using the notion of regret. We identify an appropriate definition for regret and develop regret-minimizing synthesis framework that enables the robot to seek cooperation when possible while preserving task completion guarantees. We illus-trate the efficacy of our framework via various case studies."	https://doi.org/10.1109/ICRA46639.2022.9812298	Karan Muvvala, Peter Amorese, Morteza Lahijanian
Leveraging Smooth Attention Prior for Multi-Agent Trajectory Prediction.	Multi-agent interactions are important to model for forecasting other agents' behaviors and trajectories. At a certain time, to forecast a reasonable future trajectory, each agent needs to pay attention to the interactions with only a small group of most relevant agents instead of unnecessarily paying attention to all the other agents. However, existing attention modeling works ignore that human attention in driving does not change rapidly, and may introduce fluctuating attention across time steps. In this paper, we formulate an attention model for multi-agent interactions based on a total variation temporal smoothness prior and propose a trajectory prediction architecture that leverages the knowledge of these attended interactions. We demonstrate how the total variation attention prior along with the new sequence prediction loss terms leads to smoother attention and more sample-efficient learning of multi-agent trajectory prediction, and show its advantages in terms of prediction accuracy by comparing it with the state-of-the-art approaches on both synthetic and naturalistic driving data. We demonstrate the performance of our algorithm for trajectory prediction on the INTERACTION dataset on our website11https://sites.google.com/view/smoothness-attention.	https://doi.org/10.1109/ICRA46639.2022.9811718	Zhangjie Cao, Erdem Biyik, Guy Rosman, Dorsa Sadigh
Leveraging distributed contact force measurements for slip detection: a physics-based approach enabled by a data-driven tactile sensor.	Grasping objects whose physical properties are unknown is still a great challenge in robotics. Most solutions rely entirely on visual data to plan the best grasping strategy. However, to match human abilities and be able to reliably pick and hold unknown objects, the integration of an artificial sense of touch in robotic systems is pivotal. This paper describes a novel model-based slip detection pipeline that can predict possibly failing grasps in real-time and signal a necessary increase in grip force. As such, the slip detector does not rely on manually collected data, but exploits physics to generalize across different tasks. To evaluate the approach, a state-of-the-art vision-based tactile sensor that accurately estimates distributed forces was integrated into a grasping setup composed of a six degrees-of-freedom cobot and a two-finger gripper. Results show that the system can reliably predict slip while manipulating objects of different shapes, materials, and weights. The sensor can detect both translational and rotational slip in various scenarios, making it suitable to improve the stability of a grasp.	https://doi.org/10.1109/ICRA46639.2022.9812186	Pietro Griffa, Carmelo Sferrazza, Raffaello D'Andrea
Lifting 2D Object Locations to 3D by Discounting LiDAR Outliers across Objects and Views.	We present a system for automatic converting of 2D mask object predictions and raw LiDAR point clouds into full 3D bounding boxes of objects. Because the LiDAR point clouds are partial, directly fitting bounding boxes to the point clouds is meaningless. Instead, we suggest that obtaining good results requires sharing information between all objects in the dataset jointly, over multiple frames. We then make three improvements to the baseline. First, we address ambiguities in predicting the object rotations via direct optimization in this space while still backpropagating rotation prediction through the model. Second, we explicitly model outliers and task the network with learning their typical patterns, thus better discounting them. Third, we enforce temporal consistency when video data is available. With these contributions, our method significantly outperforms previous work despite the fact that those methods use significantly more complex pipelines, 3D models and additional human-annotated external sources of prior information.	https://doi.org/10.1109/ICRA46639.2022.9811693	Robert McCraith, Eldar Insafutdinov, Lukás Neumann, Andrea Vedaldi
Liftoff of A Motor-Driven Flapping Wing Rotorcraft with Mechanically Decoupled Wings.	Flapping Wing Rotorcraft (FWR) combines flapping and rotating wing motion in one element. Such a hybrid design integrates the high-efficiency characteristics of the rotating wing and the high-lift feature of the flapping wing under low Reynolds number, providing a broader range of simultaneous lift and power efficiency optimization. Nevertheless, the flight performance of the current FWRs is limited by their complex transmission mechanisms. Such mechanical constraints not only induce coupled wing kinematics but also render tedious assembly work and fabrication imperfections. In order to fundamentally address the constraints, we propose a motor-driven FWR with mechanically decoupled wings. The wing of the proposed DFWR is directly actuated by two bi-directional rotating motors instead of using the crank rocker (or alike) transmission. The proposed DFWR flaps within 25Hz to 35Hz, with about 12.4 grams of system weight and 185mm wingspan. With the direct-drive principle, the wing kinematics can be modulated properly by real-time motor control. In particular, we tuned the flapping frequency, stroke amplitude, and mid-stroke angle of the proposed direct-drive FWR to attain its best lift performance. As a result, it can generate about 16 grams of maximum total lift. In order to validate the proposed design, free flight tests have been conducted. The proposed FWR demonstrates stable liftoff.	https://doi.org/10.1109/ICRA46639.2022.9812350	Fangyuan Liu, Song Li, Ziyu Wang, Xin Dong, Daochun Li, Zhan Tu
Lightweight Monocular Depth Estimation through Guided Decoding.	We present a lightweight encoder-decoder architecture for monocular depth estimation, specifically designed for embedded platforms. Our main contribution is the Guided Upsampling Block (GUB) for building the decoder of our model. Motivated by the concept of guided image filtering, GUB relies on the image to guide the decoder on upsampling the feature representation and the depth map reconstruction, achieving high resolution results with fine-grained details. Based on multiple GUBs, our model outperforms the related methods on the NYU Depth V2 dataset in terms of accuracy while delivering up to 35.1 fps on the NVIDIA Jetson Nano and up to 144.5 fps on the NVIDIA Xavier NX. Similarly, on the KITTI dataset, inference is possible with up to 23.7 fps on the Jetson Nano and 102.9 fps on the Xavier NX. Our code and models are made publicly available14https://github.com/mic-rud/GuidedDecoding.	https://doi.org/10.1109/ICRA46639.2022.9812220	Michael Rudolph, Youssef Dawoud, Ronja Güldenring, Lazaros Nalpantidis, Vasileios Belagiannis
LoGG3D-Net: Locally Guided Global Descriptor Learning for 3D Place Recognition.	Retrieval-based place recognition is an efficient and effective solution for re-localization within a pre-built map, or global data association for Simultaneous Localization and Mapping (SLAM). The accuracy of such an approach is heavily dependant on the quality of the extracted scene-level representation. While end-to-end solutions - which learn a global descriptor from input point clouds - have demonstrated promising results, such approaches are limited in their ability to enforce desirable properties at the local feature level. In this paper, we introduce a local consistency loss to guide the network towards learning local features which are consistent across revisits, hence leading to more repeatable global descriptors resulting in an overall improvement in 3D place recognition performance. We formulate our approach in an end-to-end trainable architecture called LoGG3D-Net. Experiments on two large-scale public benchmarks (KITTI and MulRan) show that our method achieves mean F1max scores of 0.939 and 0.968 on KITTI and MulRan respectively, achieving state-of-the-art performance while operating in near real-time. The open-source implementation is available at: https://github.com/csiro-robotics/LoGG3D-Net.	https://doi.org/10.1109/ICRA46639.2022.9811753	Kavisha Vidanapathirana, Milad Ramezani, Peyman Moghadam, Sridha Sridharan, Clinton Fookes
Load-sensitive Data Acquisition for a Tactile Sensor System of Multi-fingered Robotic Hands.	In this paper, we present a data acquisition method to realize a distributed tactile sensor system that can provide wide-range, and high-sensitivity with a small data size for communication. Since the data size is proportional to the number of acquired data and the resolution of the data, we propose systems to increase the resolution of the sensor output values without increasing the amount of data and to reduce the sampling frequency without reducing the time resolution. The system to increase the data resolution is based on a mechanism to dynamically change the gain of an amplifier circuit for a tactile sensor depending on the input value in the local controller. The system to reduce the number of data acquisitions consists of an analog circuit to judge the amount of change in the tactile sensor output based on a threshold at the hardware level. We demonstrate that the system reduces the data size for communication on a sensor system in our robotic hand. The experimental results indicate that the tactile sensor systems could sense high-resolution data with a small data size for communication.	https://doi.org/10.1109/ICRA46639.2022.9812260	Ryusuke Ishizaki, Shun Ogiwara, Fumiya Hamatsu, Tomoyuki Sakurai, Hirofumi Shin, Takahide Yoshiike
Localization of a Smart Infrastructure Fisheye Camera in a Prior Map for Autonomous Vehicles.	This work presents a technique for localization of a smart infrastructure node, consisting of a fisheye camera, in a prior map. These cameras can detect objects that are outside the line of sight of the autonomous vehicles (AV) and send that information to AVs using V2X technology. However, in order for this information to be of any use to the AV, the detected objects should be provided in the reference frame of the prior map that the AV uses for its own navigation. Therefore, it is important to know the accurate pose of the infrastructure camera with respect to the prior map. Here we propose to solve this localization problem in two steps, (i) we perform feature matching between perspective projection of fisheye image and bird's eye view (BEV) satellite imagery from the prior map to estimate an initial camera pose, (ii) we refine the initialization by maximizing the Mutual Information (MI) between intensity of pixel values of fisheye image and reflectivity of 3D LiDAR points in the map data. We validate our method on simulated data and also present results with real world data.	https://doi.org/10.1109/ICRA46639.2022.9811793	Subodh Mishra, Armin Parchami, Enrique Corona, Punarjay Chakravarty, Ankit Vora, Devarth Parikh, Gaurav Pandey
Locomotion as a Risk-mitigating Behavior in Uncertain Environments: A Rapid Planning and Few-shot Failure Adaptation Approach.	"We want robots to complete assigned tasks even when unexpected task pressures arise, either from the robot or the environment. This paper presents a method of both learning sources of task failure in situ and rapidly planning new motions on-the-fly to accommodate them. This ""risk-adaptive"" approach to robot control uses a few encounters with a novel failure mode to generate a probabilistic failure model which we use to optimize a risk-mitigating motion plan. We demonstrate two toy problems, where risk-adaptive double-integrator agents are introduced to separate environments, each with their own tasks and modes of failure. The agents are not aware a priori of any risks the environments might present, but after one failure, the agents quickly adapt their motion plans and ensure task completion. We further conduct numerical experiments to characterize the algorithm's speed of adaptation with respect to environmental uncertainty. We see this framework as a natural extension for the myriad of robotic applications using model-based motion planners."	https://doi.org/10.1109/ICRA46639.2022.9812103	Jacob Hackett, Dylan Epstein-Gross, Monica A. Daley, Christian Hubicki
Long-Horizon Manipulation of Unknown Objects via Task and Motion Planning with Estimated Affordances.	We present a strategy for designing and building very general robot manipulation systems using a general-purpose task-and-motion planner with both engineered and learned modules that estimate properties and affordances of unknown objects. Such systems are closed-loop policies that map from RGB images, depth images, and robot joint encoder measurements to robot joint position commands. We show that this strategy leads to intelligent behaviors even without a priori knowledge regarding the set of objects, their geometries, and their affordances. We show how these modules can be flexibly composed with robot-centric primitives using the PDDLStream task and motion planning framework. Finally, we demonstrate that this strategy can enable a single policy to perform a wide variety of real-world multi-step manipulation tasks, generalizing over a broad class of objects, arrangements, and goals, without prior knowledge of the environment or re-training.	https://doi.org/10.1109/ICRA46639.2022.9812057	Aidan Curtis, Xiaolin Fang, Leslie Pack Kaelbling, Tomás Lozano-Pérez, Caelan Reed Garrett
Look and Listen: A Multi-Sensory Pouring Network and Dataset for Granular Media from Human Demonstrations.	Humans have the ability to pour various media, both liquid and granular, to desired ends in various containers. We do this by using multiple senses simultaneously in a constant feedback loop to complete a pouring task. Combining multiple sensing modalities, similar to humans, could aid in robotic pouring control outside of a structured or industrial setting. We present a multi-sensory pouring dataset consisting of human pouring demonstrations of various granular media, coupled with two multi-sensory networks that estimate pouring rate and pouring average height. For both pouring metrics, a combined input of audio and visual data provides a lower median error than either the audio network or visual network. The multi-sensory network achieves a median error of 6.4 mm for average height estimation and 0.06 N/s for pouring rate estimation.	https://doi.org/10.1109/ICRA46639.2022.9812125	Alexis Burns, Siyuan Xiang, Daewon Lee, Larry D. Jackel, Shuran Song, Volkan Isler
Looking for Trouble: Informative Planning for Safe Trajectories with Occlusions.	Planning a safe trajectory for an ego vehicle through an environment with occluded regions is a challenging task. Existing methods use some combination of metrics to evaluate a trajectory, either taking a worst case view or allowing for some probabilistic estimate, to eliminate or minimize the risk of collision respectively. Typically, these approaches assume occluded regions of the environment are unsafe and must be avoided, resulting in overly conservative trajectories-particularly when there are no hidden risks present. We propose a local trajectory planning algorithm which generates safe trajectories that maximize observations on un-certain regions. In particular, we seek to gain information on occluded areas that are most likely to pose a risk to the ego vehicle on its future path. Calculating the information gain is a computationally complex problem; our method approximates the maximum information gain and results in vehicle motion that remains safe but is less conservative than state-of-the-art approaches. We evaluate the performance of the proposed method within the CARLA simulator in different scenarios.	https://doi.org/10.1109/ICRA46639.2022.9811994	Barry Gilhuly, Armin Sadeghi, Peyman Yadmellat, Kasra Rezaee, Stephen L. Smith
Loop Closure Detection and SLAM in Vineyards with Deep Semantic Cues.	Automation of vineyards cultivation necessitates for mobile robots to retain accurate localization system. The paper introduces a stereo vision-based Graph-Simultaneous Localization and Mapping (Graph-SLAM) pipeline custom-tailored to the specificities of vineyard fields. Graph-SLAM is reinforced with a Loop Closure Detection (LCD) based on semantic segmentation of the vine trees. The Mask R-CNN network is applied to segment the trunk regions of images, on which unique visual features are extracted. These features are used to populate the bag of visual words (BoVW s) retained on the formulated graph. A nearest neighbor search is applied to each query trunk-image to associate each unique feature descriptor with the corresponding node in the graph using a voting procedure. We apply a probabilistic method to select the most suitable loop closing pair and, upon an LCD appearance, the 3D points of the trunks are employed to estimate the loop closure constraint to the graph. The traceable features on trunk segments drastically reduce the number of retained BoVWs, which in turn expedites significantly the loop closure and graph optimization, rendering our method suitable for large scale mapping in vineyards. The pipeline has been evaluated on several data sequences gathered from real vineyards, in different seasons, when the appearance of vine trees vary significantly, and exhibited robust mapping in long distances.	https://doi.org/10.1109/ICRA46639.2022.9812419	Alexios Papadimitriou, Ioannis Kleitsiotis, Ioannis Kostavelis, Ioannis Mariolis, Dimitrios Giakoumis, Spiridon Likothanassis, Dimitrios Tzovaras
MOSAIX: a Swarm of Robot Tiles for Social Human-Swarm Interaction.	MOSAIX is a new robot swarm platform built to be used in social settings. Consisting of up to 100 individual robot Tiles, MOSAIX is a social swarm system, aimed at helping humans in social tasks such as opinion-mixing and brainstorming. MOSAIX also has the potential to be used as a platform to study human-swarm interaction and swarm expressivity. MOSAIX is intended to be used outside laboratory settings and has already been used to collect 154 opinions about climate change in a local shopping mall, used by participants to create collaborative art and used as an educational tool for schoolchildren. We also discuss future applications, such as MOSAIX acting as smart post-it notes for ideation activities.	https://doi.org/10.1109/ICRA46639.2022.9811723	Merihan Alhafnawi, Edmund R. Hunt, Séverin Lemaignan, Paul J. O'Dowd, Sabine Hauert
Magnetically Steerable Asymmetric Magnetized Soft Continuum Robot (AMSCR) for Minimally Invasive Surgery.	Soft continuum robots have been widely used as guide wires or catheters for minimally invasive surgery (MIS), and the miniaturization and dexterity are very important characteristics of soft continuum robots. As a representative actuation method for soft continuum robots, the steering using an external magnetic field has been actively studied. The magnetic actuation method is appropriate for the miniaturization of soft continuum robots but shows limitations in implementing high dexterity. To achieve miniaturization and high dexterity, this paper proposes a magnetically steerable asymmetric magnetized soft continuum robot (AMSCR). The proposed AMSCR includes an active steering part (ASP) of a thin PDMS cylinder in which NdFeB powder is uniformly dispersed and magnetized asymmetrically to the longitudinal direction. Therefore, compared to the conventional symmetric magnetized soft continuum robot (SMSCR), the proposed AMSCR has a larger steering range and high dexterity. Through various experiments, simulations, and phantom experiments using the proposed AMSCR, we analyzed its characteristics, verified its enhanced steering range, and demonstrated the applicability to the surgeries requiring high dexterity in the eye or cerebrovascular.	https://doi.org/10.1109/ICRA46639.2022.9811361	Joowon Park, Hyoryong Lee, Hyunchul Choi, Sunwoo Sohn, Hyeonwoo Kee, Joohack Lee, Gyungrae Cha, Sukho Park
Manipulation of unknown objects via contact configuration regulation.	We present an approach to robotic manipulation of unknown objects through regulation of the object's contact configuration: the location, geometry, and mode of all contacts between the object, robot, and environment. A contact configu-ration constrains the forces and motions that can be applied to the object; however, synthesizing these constraints generally requires knowledge of the object's pose and geometry. We develop an object-agnostic approach for estimation and control that circumvents this need. Our framework directly estimates a set of wrench and motion constraints which it uses to regulate the contact configuration. We use this to reactively manipulate unknown planar objects in the gravity plane. A video describing our work can be found on our project page: http://mcube.mit.edu/research/contactConfig.html.	https://doi.org/10.1109/ICRA46639.2022.9811713	Neel Doshi, Orion Taylor, Alberto Rodriguez
Map-based Visual-Inertial Localization: A Numerical Study.	We revisit the problem of efficiently leveraging prior map information within a visual-inertial estimation framework. The use of traditional landmark-based maps with 2D-to-3D measurements along with the recently introduced keyframe-based maps with 2D-to-2D measurements are inves-tigated. The full joint estimation of the prior map is compared within a visual-inertial simulator to the Schmidt-Kalman filter (SKF) and measurement inflation methods in terms of their computational complexity, consistency, accuracy, and memory usage. This study shows that the SKF can enable efficient and consistent estimation for small workspace scenarios and the use of 2D-to-3D landmark maps have the highest levels of accuracy. Keyframe-based 2D-to-2D maps can reduce the required state size while still enabling accuracy gains. Finally, we show that measurement inflation methods, after tuning, can be accurate and efficient for large-scale environments if the guarantee of consistency is relaxed.	https://doi.org/10.1109/ICRA46639.2022.9811829	Patrick Geneva, Guoquan Huang
Mapping Unknown Environments With Instrumented Honey Bees.	Recent innovations in miniature sensors are driving a shift from robotic to bio-hybrid systems for exploration of unstructured environments. The ubiquity of honey bees in modern agriculture and ecology along with their superior agility, olfactory sense, and collective foraging skills make them a promising complement to traditional robots. This paper explores the potential of such systems based on a custom honey bee foraging simulator and models of state-of-the art miniature flight recorders which can measure solar heading at regular time intervals, as well as exploratory data collected from the sensor mounted on an autonomous quadrotor. The size and functionality of the sensor is heavily influenced by its memory footprint, therefore, we investigate the impact of sensor sampling time on map accuracy. Our results indicate that a sampling rate down to 5Hz can be used to sense obstacle locations in a 5-acre field with an accuracy corresponding to 70% of the obstacle radius, and within 4% of its true area. This technique shows promise for using instrumented honey bees to map and monitor unstructured environments which are difficult or costly for robots to robustly navigate, monitor, and map.	https://doi.org/10.1109/ICRA46639.2022.9812399	Haron Abdel-Raziq, Daniel Palmer, Alyosha C. Molnar, Kirstin Petersen
Maximal Manipulation Framework using Quadratic Programming for a Teleoperated Robotic System with Articulated bodies.	This paper proposes a teleoperation framework to exploit the maximum manipulation capability during teleoperation. Here, exploiting maximum manipulation capacity means that the robot moves with its maximum control input while not violating the given constraints, and it is a nonlinear optimization problem with nonlinear constraints which is hard to be solved. The proposed framework relaxes the optimization problem into a simple QP problem and unifies the various constraints in the joint configuration space and Cartesian task space by utilizing control barrier function and control Lyapunov function techniques. The joint angle, velocity, acceleration limits are imposed on a teleoperated robot so that the robot does not generate any emergency stop during the teleoperation. Especially, the robot shows stable motion even near the kinematic singularity, so the operator can explore almost every reachable and admissible state of the robot via teleoperation.	https://doi.org/10.1109/ICRA46639.2022.9811602	Donghyeon Lee, Dongwoo Ko, Wan Kyun Chung, Keehoon Kim
Maximum Entropy Differential Dynamic Programming.	In this paper, we present a novel maximum entropy formulation of the Differential Dynamic Programming algorithm and derive two variants using unimodal and multimodal value functions parameterizations. By combining the maximum entropy Bellman equations with a particular approximation of the cost function, we are able to obtain a new formulation of Differential Dynamic Programming which is able to escape from local minima via exploration with a multimodal policy. To demonstrate the efficacy of the proposed algorithm, we provide experimental results using four systems on tasks that are represented by cost functions with multiple local minima and compare them against vanilla Differential Dynamic Programming. Furthermore, we discuss connections with previous work on the linearly solvable stochastic control framework and its extensions in relation to compositionality. Link to Video.	https://doi.org/10.1109/ICRA46639.2022.9812228	Oswin So, Ziyi Wang, Evangelos A. Theodorou
Maximum Likelihood Constraint Inference on Continuous State Spaces.	When a robot observes another agent unexpectedly modifying their behavior, inferring the most likely cause is a valuable tool for maintaining safety and reacting appropriately. In this work, we present a novel method for inferring constraints that works on continuous, possibly sub-optimal demonstrations. We first learn a representation of the continuous-state maximum entropy trajectory distribution using deep reinforcement learning. We then use Monte Carlo sampling from this distribution to generate expected constraint violation probabilities and perform constraint inference. When the demonstrator's dynamics and objective function are known in advance, this process can be performed offline, allowing for real-time constraint inference at the moment demonstrations are observed. We evaluate our approach on two continuous dynamical systems: a 2-dimensional inverted pendulum model, and a 4-dimensional unicycle model that was successfully used for fast constraint inference on a 1/10 scale car remote-controlled by a human.	https://doi.org/10.1109/ICRA46639.2022.9811705	Kaylene C. Stocking, David Livingston McPherson, Robert P. Matthew, Claire J. Tomlin
Mean Reflected Mass: A Physically Interpretable Metric for Safety Assessment and Posture Optimization in Human-Robot Interaction.	In physical human-robot interaction (pHRI), safety is a key requirement. As collisions between humans and robots can generally not be avoided, it must be ensured that the human is not harmed. The robot reflected mass, the contact geometry, and the relative velocity between human and robot are the parameters that have the most significant influence on human injury severity during a collision. The reflected mass depends on the robot configuration and can be optimized especially in kinematically redundant robots. In this paper, we propose the Mean Reflected Mass (MRM) metric. The MRM is independent of the direction of contact/motion and enables assessing and optimizing the robot posture w.r.t. safety. In contrast to existing metrics, it is physically interpretable, meaning that it can be related to biomechanical injury data for realistic and model-independent safety analysis. For the Franka Emika Panda, we demonstrate in simulation that an optimization of the robot's MRM reduces the mean collision force. Finally, the relevance of the MRM for real pHRI applications is confirmed through a collision experiment.	https://doi.org/10.1109/ICRA46639.2022.9811582	Thomas Steinecker, Alexander Kurdas, Nico Mansfeld, Mazin Hamad, Robin Jeanne Kirschner, Saeed Abdolshah, Sami Haddadin
"Mechanical Search on Shelves using a Novel ""Bluction"" Tool."	Shelves are common in homes, warehouses, and commercial settings due to their storage efficiency. However, this efficiency comes at the cost of reduced visibility and accessibility. When looking from a side (lateral) view of a shelf, most objects will be fully occluded, resulting in a constrained lateral-access mechanical search problem. To address this problem, we introduce: (1) a novel bluction tool, which combines a thin pushing blade and a suction cup gripper, (2) a simulation pipeline and perception model that combine ray-casting with 2D Minkowski sums to efficiently generate target occupancy distributions, and (3) a novel search policy, which optimally reduces target object distribution support area using the bluction tool. Experimental data from 2000 simulated shelf trials and 18 trials with a physical Fetch robot suggest that a bluction tool can improve the average success rate by 26% in simulation and 67% in physical experiments over the highest-performing push-only policy.	https://doi.org/10.1109/ICRA46639.2022.9811622	Huang Huang, Michael Danielczuk, Chung Min Kim, Letian Fu, Zachary Tam, Jeffrey Ichnowski, Anelia Angelova, Brian Ichter, Ken Goldberg
Memory-Efficient Gaussian Fitting for Depth Images in Real Time.	Computing consumes a significant portion of energy in many robotics applications, especially the ones involving energy-constrained robots. In addition, memory access accounts for a significant portion of the computing energy. For mapping a 3D environment, prior approaches reduce the map size while incurring a large memory overhead used for storing sensor measurements and temporary variables during computation. In this work, we present a memory-efficient algorithm, named Single-Pass Gaussian Fitting (SPGF), that accurately constructs a compact Gaussian Mixture Model (GMM) which approximates measurements from a depthmap generated from a depth camera. By incrementally constructing the GMM one pixel at a time in a single pass through the depthmap, SPGF achieves higher throughput and orders-of-magnitude lower memory overhead than prior multipass approaches. By processing the depthmap row-by-row, SPGF exploits intrinsic properties of the camera to efficiently and accurately infer surface geometries, which leads to higher precision than prior approaches while maintaining the same compactness of the GMM. Using a low-power ARM Cortex-A57 CPU on the NVIDIA Jetson TX2 platform, SPGF operates at 32fps, requires 43KB of memory overhead, and consumes only 0.11J per frame (depthmap). Thus, SPGF enables real-time mapping of large 3D environments on energy-constrained robots.	https://doi.org/10.1109/ICRA46639.2022.9811682	Peter Zhi Xuan Li, Sertac Karaman, Vivienne Sze
Memory-based gaze prediction in deep imitation learning for robot manipulation.	Deep imitation learning is a promising approach that does not require hard-coded control rules in autonomous robot manipulation. The current applications of deep imitation learning to robot manipulation have been limited to reactive control based on the states at the current time step. However, future robots will also be required to solve tasks utilizing their memory obtained by experience in complicated environments (e.g., when the robot is asked to find a previously used object on a shelf). In such a situation, simple deep imitation learning may fail because of distractions caused by complicated environments. We propose that gaze prediction from sequential visual input enables the robot to perform a manipulation task that requires memory. The proposed algorithm uses a Transformer-based self-attention architecture for the gaze estimation based on sequential data to implement memory. The proposed method was evaluated with a real robot multi-object manipulation task that requires memory of the previous states.	https://doi.org/10.1109/ICRA46639.2022.9812087	Heecheol Kim, Yoshiyuki Ohmura, Yasuo Kuniyoshi
Message Passing Framework for Vision Prediction Stability in Human Robot Interaction.	In Human Robot Interaction (HRI) scenarios, robot systems would benefit from an understanding of the user's state, actions and their effects on the environments to enable better interactions. While there are specialised vision algorithms for different perceptual channels, such as objects, scenes, human pose, and human actions, it is worth considering how their interaction can help improve each other's output. In computer vision, individual prediction modules for these perceptual channels frequently produce noisy outputs due to the limited datasets used for training and the compartmentalisation of the perceptual channels, often resulting in noisy or unstable prediction outcomes. To stabilise vision prediction results in HRI, this paper presents a novel message passing framework that uses the memory of individual modules to correct each other's outputs. The proposed framework is designed utilising common-sense rules of physics (such as the law of gravity) to reduce noise while introducing a pipeline that helps to effectively improve the output of each other's modules. The proposed framework aims to analyse primitive human activities such as grasping an object in a video captured from the perspective of a robot. Experimental results show that the proposed framework significantly reduces the output noise of individual modules compared to the case of running independently. This pipeline can be used to measure human reactions when interacting with a robot in various HRI scenarios.	https://doi.org/10.1109/ICRA46639.2022.9812439	Youngkyoon Jang, Yiannis Demiris
Meta-confidence estimation for stereo matching.	We propose a novel framework to estimate the confidence of a disparity map taking into account, for the first time, the uncertainty affecting the confidence estimation process itself. Conversely to other tasks such as disparity estimation, the uncertainty of confidence directly hints that the confidence should be increased if initially low, but with high uncertainty, decreased otherwise. By modelling such a cue in the form of a second-level confidence, or meta-confidence, our solution allows for finding incorrect predictions inferred by confidence estimator and for learning a correction for them. Our strategy is suited for any state-of-the-art method known in literature, either implemented using random forest classifiers or deep neural networks. Especially, for deep neural networks-based models, we present a multi-headed confidence estimator followed by an uncertainty network, so as to predict mean confidence and meta-confidence within a single network without the cost of lower accuracy, a known limitation in literature for uncertainty estimation. Experimental results on a variety of stereo algorithms and confidence estimation models prove that the modeled meta-confidence is meaningful of the reliability of the estimated confidence and allows for refining it.	https://doi.org/10.1109/ICRA46639.2022.9811620	Seungryong Kim, Matteo Poggi, Sunok Kim, Kwanghoon Sohn, Stefano Mattoccia
Meta-path Analysis on Spatio-Temporal Graphs for Pedestrian Trajectory Prediction.	Spatio-temporal graphs (ST-graphs) have been used to model time series tasks such as traffic forecasting, human motion modeling, and action recognition. The high-level structure and corresponding features from ST-graphs have led to improved performance over traditional architectures. However, current methods tend to be limited by simple features, despite the rich information provided by the full graph structure, which leads to inefficiencies and suboptimal performance in downstream tasks. We propose the use of features derived from meta-paths, walks across different types of edges, in ST-graphs to improve the performance of Structural Recurrent Neural Network. In this paper, we present the Meta-path Enhanced Structural Recurrent Neural Network (MESRNN), a generic framework that can be applied to any spatio-temporal task in a simple and scalable manner. We employ MESRNN for pedestrian trajectory prediction, utilizing these meta-path based features to capture the relationships between the trajectories of pedestrians at different points in time and space. We compare our MESRNN against state-of-the-art ST-graph methods on standard datasets to show the performance boost provided by meta-path information. The proposed model consistently outperforms the baselines in trajectory prediction over long time horizons by over 32%, and produces more socially compliant trajectories in dense crowds. For more information please refer to the project website at https://sites.google.com/illinois.edu/mesrnn/home.	https://doi.org/10.1109/ICRA46639.2022.9811632	Aamir Hasan, Pranav Sriram, Katherine Rose Driggs-Campbell
Metareasoning for Safe Decision Making in Autonomous Systems.	Although experts carefully specify the high-level decision-making models in autonomous systems, it is infeasible to guarantee safety across every scenario during operation. We therefore propose a safety metareasoning system that optimizes the severity of the system's safety concerns and the interference to the system's task: the system executes in parallel a task process that completes a specified task and safety processes that each address a specified safety concern with a conflict resolver for arbitration. This paper offers a formal definition of a safety metareasoning system, a recommendation algorithm for a safety process, an arbitration algorithm for a conflict resolver, an application of our approach to planetary rover exploration, and a demonstration that our approach is effective in simulation.	https://doi.org/10.1109/ICRA46639.2022.9811887	Justin Svegliato, Connor Basich, Sandhya Saisubramanian, Shlomo Zilberstein
Microgripper Using Flexible Wire Hinge for Robotic Intraocular Snake.	A substantially advance skill-set is a prerequisite in the domain of retinal surgery, given that the surgical instruments, constrained by small incisions made on the sclera, should be manipulated in a confined intraocular space. Therefore, robotic technologies with a snake-like architecture may be critical in retinal surgery to overcome this problem. These robots are expected to approach a target on the retina from a suitable direction when accessing its anterior portion for procedures such as vein cannulation or membrane peeling. Typical end-effectors or tools for retinal surgery include needles, light pipes, pipettes, and grippers. However, there are no retinal surgery robots or devices equipped with enough bending and grasping functionalities. We developed an Improved Integrated Robotic Intraocular Snake (I2RIS) in previous works. I2RIS has a user interface (a tactile switch or joystick unit) to provide maneuverability to the snake-like distal end. This study presents a new microgripper with its drive mechanism and an interface for retinal surgery; this microgripper is implemented into I2RIS. The proposed microgripper has a simple mechanism; it comprised only three parts, including a nitinol drive wire that functions as a flexible hinge. The microgripper diameter is 0.9 mm, and the length is 2.6 mm. A real-size prototype model was used to demonstrate the effectiveness of the proposed microgripper. In addition, a pick-and-place task using an eye model was performed by I2RIS with the proposed microgripper. It is trusted that the utility of this microgripper can extend beyond retinal surgery into other microsurgical applications.	https://doi.org/10.1109/ICRA46639.2022.9812022	Makoto Jinno, Iulian Iordachita
Mini Cheetah, the Falling Cat: A Case Study in Machine Learning and Trajectory Optimization for Robot Acrobatics.	Seemingly in defiance of basic physics, cats consistently land on their feet after falling. In this paper, we design a controller that lands the Mini Cheetah quadruped robot on its feet as well. Specifically, we explore how trajectory optimization and machine learning can work together to enable highly dynamic bioinspired behaviors. We find that a reflex approach, in which a neural network learns entire state trajectories, outperforms a policy approach, in which a neural network learns a mapping from states to control inputs. We validate our proposed controller in both simulation and hardware experiments, and are able to land the robot on its feet from falls with initial pitch angles between −90 and 90 degrees.	https://doi.org/10.1109/ICRA46639.2022.9812120	Vince Kurtz, He Li, Patrick M. Wensing, Hai Lin
Mixed Control for Whole-Body Compliance of a Humanoid Robot.	The hierarchical quadratic programming (HQP) is commonly applied to consider strict hierarchies of multi-tasks and robot's physical inequality constraints during whole-body compliance. However, for the one-step HQP, the solution can oscillate when it is close to the boundary of constraints. It is because the abrupt hit of the bounds gives rise to unrealizable jerks and even infeasible solutions. This paper proposes the mixed control, which blends the single-axis model predictive control (MPC) and proportional derivative (PD) control for the whole-body compliance to overcome these deficiencies. The MPC predicts the distances between the bounds and the control target of the critical tasks, and it provides smooth and feasible solutions by prediction and optimization in advance. However, applying MPC will inevitably increase the computation time. Therefore, to achieve a 500 Hz servo rate, the PD controllers still regulate other tasks to save computation resources. Also, we use a more efficient null space projection (NSP) whole-body controller instead of the HQP and distribute the single-axis MPCs into four CPU cores for parallel computation. Finally, we validate the desired capabilities of the proposed strategy via simulations and the experiment on the humanoid robot Walker X.	https://doi.org/10.1109/ICRA46639.2022.9812196	Xiaozhu Ju, Jiajun Wang, Gang Han, Mingguo Zhao
Mixed Reality as Communication Medium for Human-Robot Collaboration.	Humans engaged in collaborative activities are naturally able to convey their intentions to teammates through multi-modal communication, which is made up of explicit and implicit cues. Similarly, a more natural form of human-robot collaboration may be achieved by enabling robots to convey their intentions to human teammates via multiple communication channels. In this paper, we postulate that a better communication may take place should collaborative robots be able to anticipate their movements to human teammates in an intuitive way. In order to support such a claim, we propose a robot system's architecture through which robots can communicate planned motions to human teammates leveraging a Mixed Reality interface powered by modern head-mounted displays. Specifically, the robot's hologram, which is superimposed to the real robot in the human teammate's point of view, shows the robot's future movements, allowing the human to understand them in advance, and possibly react to them in an appropriate way. We conduct a preliminary user study to evaluate the effectiveness of the proposed anticipatory visualization during a complex collaborative task. The experimental results suggest that an improved and more natural collaboration can be achieved by employing this anticipatory communication mode.	https://doi.org/10.1109/ICRA46639.2022.9812233	Simone Macciò, Alessandro Carfì, Fulvio Mastrogiovanni
Model Identification and Control of a Low-cost Mobile Robot with Omnidirectional Wheels using Differentiable Physics.	We present a new data-driven technique for pre-dicting the motion of a low-cost omnidirectional mobile robot under the influence of motor torques and friction forces. Our method utilizes a novel differentiable physics engine for analytically computing the gradient of the deviation between predicted motion trajectories and real-world trajectories. This allows to automatically learn and fine-tune the unknown friction coefficients on-the-fly, by minimizing a carefully designed loss function using gradient descent. Experiments show that the predicted trajectories are in excellent agreement with their real-world counterparts. Our proposed approach is computationally superior to existing black-box optimization methods, requiring very few real-world samples for accurate trajectory prediction compared to physics-agnostic techniques, such as neural net-works. Experiments also demonstrate that the proposed method allows the robot to quickly adapt to changes in the terrain. Our proposed approach combines the data-efficiency of classical analytical models that are derived from first principles, with the flexibility of data-driven methods, which makes it appropriate for low-cost mobile robots. Project website: https://go.rutgers.edu/mqxn2x6h	https://doi.org/10.1109/ICRA46639.2022.9812454	Edgar Granados, Abdeslam Boularias, Kostas E. Bekris, Mridul Aanjaneya
Model Predictive Control for Fluid Human-to-Robot Handovers.	Human-robot handover is a fundamental yet challenging task in human-robot interaction and collaboration. Recently, remarkable progressions have been made in human-to-robot handovers of unknown objects by using learning-based grasp generators. However, how to responsively generate smooth motions to take an object from a human is still an open question. Specifically, planning motions that take human comfort into account is not a part of the human-robot handover process in most prior works. In this paper, we propose to generate smooth motions via an efficient model-predictive control (MPC) framework that integrates perception and complex domain-specific constraints into the optimization problem. We introduce a learning-based grasp reachability model to select candidate grasps which maximize the robot's manipulability, giving it more freedom to satisfy these constraints. Finally, we integrate a neural net force/torque classifier that detects contact events from noisy data. We conducted human-to-robot handover experiments on a diverse set of objects with several users (N=4) and performed a systematic evaluation of each module. The study shows that the users preferred our MPC approach over the baseline system by a large margin.	https://doi.org/10.1109/ICRA46639.2022.9812109	Wei Yang, Balakumar Sundaralingam, Chris Paxton, Iretiayo Akinola, Yu-Wei Chao, Maya Cakmak, Dieter Fox
Model Predictive Control with Gaussian Processes for Flexible Multi-Modal Physical Human Robot Interaction.	Physical human-robot interaction can improve human ergonomics, task efficiency, and the flexibility of automation, but often requires application-specific methods to detect human state and determine robot response. At the same time, many potential human-robot interaction tasks involve discrete modes, such as phases of a task or multiple possible goals, where each mode has a distinct objective and human behavior. In this paper, we propose a novel method for multi-modal physical human-robot interaction that builds a Gaussian process model for human force in each mode of a collaborative task. These models are then used for Bayesian inference of the mode, and to determine robot reactions through model predictive control. This approach enables optimization of robot trajectory based on the belief of human intent, while considering robot impedance and human joint configuration, according to ergonomic- and/or task-related objectives. The proposed method reduces programming time and complexity, requiring only a low number of demonstrations (here, three per mode) and a mode-specific objective function to commission a flexible online human-robot collaboration task. We validate the method with experiments on an admittance-controlled robot, performing a collaborative assembly task with two modes where assistance is provided in full six degrees of freedom. It is shown that the developed algorithm robustly re-plans to changes in intent or robot initial position, achieving online control at 15 Hz.	https://doi.org/10.1109/ICRA46639.2022.9811590	Kevin Haninger, Christian Hegeler, Luka Peternel
Model-based State Estimation of Two-Wheelers.	Comprehensive and correct state estimation with meaningful uncertainties is the basis of object-based perception for automated mobile platforms. According to fatality statistics, the most endangered group of vulnerable road users are single-track two-wheelers (ST2W), consisting mainly of cyclists, motorcyclists, and scooter riders. Due to counter-steering, they need more time to adjust their driving state to a new situation compared to four-wheelers that can directly steer in the desired direction without loosing balance. Therefore, the roll angle gives valuable information about possible future actions, especially for short, safety-critical prediction horizons. In this work, we present a basic, robust state estimation approach that is tailored to ST2W. Due to the lack of publicly available ST2W datasets with dynamic driving maneuvers and a highly accurate state, we recorded, labeled and published three different ST2W tracks ourselves. According to our results, the roll angle can be estimated bias-free with a standard deviation of between 4.4○to 6.4○, outperforming the chosen baseline.	https://doi.org/10.1109/ICRA46639.2022.9811758	Florian Wirth, Julian Wadephul, Alexander Scheid, Carlos Fernández Lopez, Christoph Stiller
Model-driven reinforcement learning and action dimension extension method for efficient asymmetric assembly.	Complex assembly tasks remain huge challenge for robots because the traditional control methods rely on complicated contact state analysis. Reinforcement learning (RL) becomes one of the preferred embodiments to construct the control strategy of complex tasks. In this paper, the method of model-driven RL (MDRL) is employed to construct the control strategy. Then a completely innovative action dimension extension (ADE) mechanism is proposed to further accelerate the training process of RL. The simulation and experiment results demonstrate that the control strategy obtained through combining MDRL and ADE guarantees a more compliant assembly process. Besides, ADE method will enhance the data-efficiency of RL algorithms greatly (about 30%~40%) as well as increase the stable reward.	https://doi.org/10.1109/ICRA46639.2022.9811792	Yuhang Gai, Jiuming Guo, Dan Wu, Ken Chen
Modeling of viscoelastic dielectric elastomer actuators based on the sparse identification method.	Dielectric elastomer actuators (DEAs) have been widely employed to drive various soft robots, due to their quiet fast muscle-like behavior. It is significant but challenging to model and control these soft actuators, due to their viscoelastic property, irregular geometry, complex structure, etc. In this paper, we propose a data-driven sparse identification method to discover the hidden governing equations of DEAs. These equations can help us interpret the nonlinear properties of DEAs. Due to their low computational cost, we can further use these equations to explore classic model-based control methods for real-time accurate control of viscoelastic DEAs. The experiments show that the proposed method can model the viscoelastic behavior of the DEAs with reasonable accuracy. A feedforward controller is finally developed to validate the effectiveness of the proposed method. It is expected that this modeling method can pave the way for accurate control of soft actuators/robots with structural and material nonlinearities.	https://doi.org/10.1109/ICRA46639.2022.9811609	Jisen Li, Hao Wang, Jian Zhu
Modeling the dynamics of soft robots by discs and threads.	In this paper, we propose a new tractable ordinary differential equation formulation for dynamic simulation of fabric- reinforced inflatable soft robots. The method performs a lumped-parameter discretization of the continuum robot into discrete discs (inertia), spring elements, and threads (representing the inextensible fabric reinforcement). Using the repetition in the structure of the Lagrangian formulation of the dynamic equations of motion, a method is developed that outputs machine- readable analytical expressions for the equations of motion. The method does not require symbolic computation of derivatives. The recursive nature allows us to scale the model to an arbitrary number N discs, and can represent buckling, twisting, and pleating that is commonly seen in very soft robots. The expressions generated were validated against manually-derived equations of motion for the two-disc case using both Lagrangian and Newton-Euler means. A simulation environment which parses and evaluates the analytical expressions generated at run-time was used to numerically integrate and predict the response of a four-disc example robot. Trajectories observed varied smoothly and plausibly predicted the behavior envisioned in robots like these.	https://doi.org/10.1109/ICRA46639.2022.9812286	Joshua A. Schultz, Haley Sanders, Phuc Duc Hong Bui, Brett Layer, Marc D. Killpack
Modeling, Validation, and Design Investigation of a Passive Biped Walker with Knees and Biomimetic Feet.	This paper studies a passive biped walker with knees and biomimetic feet and its behavior, as a function of key parameters. The model includes a continuous dynamic representation of the knee joint's interaction with a viscoelastic kneecap, as well as a complete kinematic description of feet that are designed to mimic the human rollover shape. First, the analytical model is derived and studied numerically for its passive walking capabilities. Then, the model is verified through independent simulations in a different platform. Finally, to increase the efficiency of its passive gaits and to map out its walking capabilities, the model is investigated parametrically. The methods used as well as the results obtained can offer significant assistance in the field of designing passivity-based biomimetic walking robots and prosthetic devices.	https://doi.org/10.1109/ICRA46639.2022.9812129	Aikaterini Smyrli, Evangelos Papadopoulos
Modelling and control of a variable-length flexible beam on inspection ground robot.	Stabilising an inverted pendulum on a cart is a well-known control problem. This paper proposes the mechan-ical and control design for solving the oscillation problem of a variable-length flexible beam mounted on a mobile robot. The system under consideration is the robot PovRob, used at the European Organization for Nuclear Research (CERN) for visual and remote inspection tasks of particle accelerators. The flexible beam mounted on the robot houses cameras and sensors. The innovative aspect of the approach concerns the use of actuated masses mounted at the end of the rod, which induces an impulsive moment due to their inertia and angular acceleration. The modelling of the flexible rod has been suitably simplified in a lumped-parameter system, with dynamic parameters related to the rod's flexibility. A linearisation of the dynamic model allows a linear-quadratic control to stabilise the system. Experimental results support the identification and the validation of the dynamic model, while simulation results evaluate the performances of the designed control law.	https://doi.org/10.1109/ICRA46639.2022.9812444	Giancarlo D'Ago, Marie Lefebvre, Luca Rosario Buonocore, Fabio Ruggiero, Mario Di Castro, Vincenzo Lippiello
Modular Adaptive Policy Selection for Multi- Task Imitation Learning through Task Division.	Deep imitation learning requires many expert demonstrations, which can be hard to obtain, especially when many tasks are involved. However, different tasks often share similarities, so learning them jointly can greatly benefit them and alleviate the need for many demonstrations. But, joint multi-task learning often suffers from negative transfer, sharing information that should be task-specific. In this work, we introduce a method to perform multi-task imitation while allowing for task-specific features. This is done by using proto-policies as modules to divide the tasks into simple sub-behaviours that can be shared. The proto-policies operate in parallel and are adaptively chosen by a selector mechanism that is jointly trained with the modules. Experiments on different sets of tasks show that our method improves upon the accuracy of single agents, task-conditioned and multi-headed multi-task agents, as well as state-of-the-art meta learning agents. We also demonstrate its ability to autonomously divide the tasks into both shared and task-specific sub-behaviours.	https://doi.org/10.1109/ICRA46639.2022.9811819	Dafni Antotsiou, Carlo Ciliberto, Tae-Kyun Kim
Modular End-Effector System for Autonomous Robotic Maintenance & Repair.	This paper describes the development of a modular end-effector system (MEES) for autonomous robotic maintenance and repair tasks. The design consists of the following major components: Robot Side Mating Socket Module (RSMS), End-Effector Side Mating Socket Module (EEMS), the Modular Camera System (MCS), and Tool Holder/Changer unit. Multiple prototypes for each component have been manufactured, tested, and evaluated resulting in the final concept. Existing robotic tool-changer systems on the market were evaluated and features were built into the Modular End-Effector System to overcome the current limitations of those systems. A notable advantage to the MEES is that it is a robot agnostic system and simply uses an ISO standard bolt mounting pattern to physically attached to the robot of choice along with an ethernet connection. No external cables are required that could restrain the workspace of the robot manipulator. Additionally, it is compatible with customized wrist-mounted sensors and end-effectors without any modification of the actual robot circuitry. The MEES is demonstrated working with three different end-effectors and two different robots.	https://doi.org/10.1109/ICRA46639.2022.9812152	Juncheng Li, Clark B. Teeple, Robert J. Wood, David J. Cappelleri
Modular Robot Design Optimization with Generative Adversarial Networks.	Modular robots are made up of a set of components which can be configured and reconfigured to form customized robots for a wide range of tasks. Fully utilizing the flexibility of modular robots is challenging, as it requires the identification of optimal modular designs for each given task, often with limited computation and time. Previous works in design automation achieve efficient run-times by utilizing machine learning to create a one-to-one mapping from task to design. However, the problem of robot design is often multimodal, where multiple distinct designs can be similarly or equally good for a task. Alternative design solutions may be needed in the field, for instance, if a module in the optimal design fails and no replacement is available. This paper presents a novel method based on generative adversarial networks (GANs) that learns a one-to-many mapping from task to a distribution of designs. We apply our method to construct locomoting modular robots for terrains with varying obstacle heights and infill. We compare our method against the state-of-the-art, and find that our algorithm results in better solution quality, diversity, and alternatives for when the optimal design fails.	https://doi.org/10.1109/ICRA46639.2022.9812091	Jiaheng Hu, Julian Whitman, Matthew J. Travers, Howie Choset
Monitoring the Mental State of Cooperativeness for Guiding an Elderly Person in Sit-to-Stand Assistance.	In providing physical assistance to elderly people, ensuring cooperative behavior from the elderly persons is a critical requirement. In sit-to-stand assistance, for example, an older adult must lean forward, so that the body mass can shift towards the feet before a caregiver starts lifting the body. An experienced caregiver guides the older adult through verbal communications and physical interactions, so that the older adult may be cooperative throughout the process. This guidance is of paramount importance and is a major challenge in introducing a robotic aid to the eldercare environment. The wide-scope goal of the current work is to develop an in-telligent eldercare robot that can a) monitor the mental state of an older adult, and b) guide the older adult through an assisting procedure so that he/she can be cooperative in being assisted. The current work presents a basic modeling framework for describing a human's physical behaviors reflecting an internal mental state, and an algorithm for estimating the mental state through interactive observations. The sit-to-stand assistance problem is considered for the initial study. A simple Kalman Filter is constructed for estimating the level of cooperativeness in response to applied cues, with a thresholding scheme being used to make judgments on the cooperativeness state.	https://doi.org/10.1109/ICRA46639.2022.9812422	John Bell, H. Harry Asada
Monocular Depth Distribution Alignment with Low Computation.	The performance of monocular depth estimation generally depends on the amount of parameters and computational cost. It leads to a large accuracy contrast between light-weight networks and heavy-weight networks, which limits their application in the real world. In this paper, we model the majority of accuracy contrast between them as the difference of depth distribution, which we call 'Distribution drift'. To this end, a distribution alignment network (DANet) is proposed. We firstly design a pyramid scene transformer (PST) module to capture inter-region interaction in multiple scales. By perceiving the difference of depth features between every two regions, DANet tends to predict a reasonable scene structure, which fits the shape of distribution to ground truth. Then, we propose a local-global optimization (LGO) scheme to realize the supervision of global range of scene depth. Thanks to the alignment of depth distribution shape and scene depth range, DANet sharply alleviates the distribution drift, and achieves a comparable performance with prior heavy-weight methods, but uses only 1% floating-point operations per second (FLOPs) of them. The experiments on two datasets, namely the widely used NYUDv2 dataset and the more challenging iBims-1 dataset, demonstrate the effectiveness of our method. The source code is available at https://github.com/YiLiM1/DANet.	https://doi.org/10.1109/ICRA46639.2022.9811937	Fei Sheng, Feng Xue, Yicong Chang, Wenteng Liang, Anlong Ming
Monte Carlo Tree Search Gait Planner for Non-Gaited Legged System Control.	In this work, a non-gaited framework for legged system locomotion is presented. The approach decouples the gait sequence optimization by considering the problem as a decision-making process. The redefined contact sequence problem is solved by utilizing a Monte Carlo Tree Search (MCTS) algorithm that exploits optimization-based simulations to evaluate the best search direction. The proposed scheme has proven to have a good trade-off between exploration and exploitation of the search space compared to the state-of-the-art Mixed-Integer Quadratic Programming (MIQP). The model predictive control (MPC) utilizes the gait generated by the MCTS to optimize the ground reaction forces and future footholds position. The simulation results, performed on a quadruped robot, showed that the proposed framework could generate known periodic gait and adapt the contact sequence to the encountered conditions, including external forces and terrain with unknown and variable properties. When tested on robots with different layouts, the system has also shown its reliability.	https://doi.org/10.1109/ICRA46639.2022.9812421	Lorenzo Amatucci, Joon-Ha Kim, Jemin Hwangbo, Hae-Won Park
Motion Primitives-based Navigation Planning using Deep Collision Prediction.	This paper contributes a method to design a novel navigation planner exploiting a learning-based collision prediction network. The neural network is tasked to predict the collision cost of each action sequence in a predefined motion primitives library in the robot's velocity-steering angle space, given only the current depth image and the estimated linear and angular velocities of the robot. Furthermore, we account for the uncertainty of the robot's partial state by utilizing the Unscented Transform and the uncertainty of the neural network model by using Monte Carlo dropout. The uncertainty-aware collision cost is then combined with the goal direction given by a global planner in order to determine the best action sequence to execute in a receding horizon manner. To demonstrate the method, we develop a resilient small flying robot integrating lightweight sensing and computing resources. A set of simulation and experimental studies, including a field deployment, in both cluttered and perceptually-challenging environments is conducted to evaluate the quality of the prediction network and the performance of the proposed planner.	https://doi.org/10.1109/ICRA46639.2022.9812231	Huan Nguyen, Sondre Holm Fyhn, Paolo De Petris, Kostas Alexis
MotionHint: Self-Supervised Monocular Visual Odometry with Motion Constraints.	We present a novel self-supervised algorithm named MotionHint for monocular visual odometry (VO) that takes motion constraints into account. A key aspect of our approach is to use an appropriate motion model that can help existing self-supervised monocular VO (SSM-VO) algorithms to overcome issues related to the local minima within their self-supervised loss functions. The motion model is expressed with a neural network named PPnet. It is trained to coarsely predict the next pose of the camera and the uncertainty of this prediction. Our self-supervised approach combines the original loss and the motion loss, which is the weighted difference between the prediction and the generated ego-motion. Taking two existing SSM-VO systems as our baseline, we evaluate our MotionHint algorithm on the standard KITTI benchmark. Experimental results show that our MotionHint algorithm can be easily applied to existing open-sourced state-of-the-art SSM-VO systems to greatly improve the performance by reducing the resulting ATE by up to 28.73%.	https://doi.org/10.1109/ICRA46639.2022.9812288	Cong Wang, Yu-Ping Wang, Dinesh Manocha
Multi-Agent Dynamic Ergodic Search with Low-Information Sensors.	"The long-term goal of this work is to enable agents with low-information sensors to perform tasks usually restricted to ones with more sophisticated, high-information sensing capabilities. Our approach is to regulate the motion of these low-information agents to obtain ""high-information"" results. As a first step, we consider a multi-agent system tasked with locating and tracking a moving target using only noisy binary sensors that measure the presence (or lack thereof) of a target in the sensor's field of view. To generate effective paths for these agents, we use ergodic trajectory optimization with a novel mutual information map that is fast to compute and can handle the discontinuous measurement models often associated with low-information sensing. We compare our approach with existing motion planning methods in multiple simulated experiments. Our experiments show that agents using our method outperform purely coverage-based approaches as well as naive ergodic approaches."	https://doi.org/10.1109/ICRA46639.2022.9812037	Howard Coffin, Ian Abraham, Guillaume Sartoretti, Tyler Dillstrom, Howie Choset
Multi-Agent Path Finding with Prioritized Communication Learning.	Multi-agent pathfinding (MAPF) has been widely used to solve large-scale real-world problems, e.g., automation warehouses. The learning-based, fully decentralized framework has been introduced to alleviate real-time problems and simultaneously pursue optimal planning policy. However, existing methods might generate significantly more vertex conflicts (or collisions), which lead to a low success rate or more makespan. In this paper, we propose a PrIoritized COmmunication learning method (PICO), which incorporates the implicit planning priorities into the communication topology within the decentralized multi-agent reinforcement learning framework. Assembling with the classic coupled planners, the implicit priority learning module can be utilized to form the dynamic communication topology, which also builds an effective collision-avoiding mechanism. PICO performs significantly better in large-scale MAPF tasks in success rates and collision rates than state-of-the-art learning-based planners.	https://doi.org/10.1109/ICRA46639.2022.9811643	Wenhao Li, Hongjun Chen, Bo Jin, Wenzhe Tan, Hongyuan Zha, Xiangfeng Wang
Multi-Agent Variational Occlusion Inference Using People as Sensors.	Autonomous vehicles must reason about spatial occlusions in urban environments to ensure safety without being overly cautious. Prior work explored occlusion inference from observed social behaviors of road agents, hence treating people as sensors. Inferring occupancy from agent behaviors is an inherently multimodal problem; a driver may behave similarly for different occupancy patterns ahead of them (e.g., a driver may move at constant speed in traffic or on an open road). Past work, however, does not account for this multimodality, thus neglecting to model this source of aleatoric uncertainty in the relationship between driver behaviors and their environment. We propose an occlusion inference method that characterizes observed behaviors of human agents as sensor measurements, and fuses them with those from a standard sensor suite. To capture the aleatoric uncertainty, we train a conditional variational autoencoder with a discrete latent space to learn a multimodal mapping from observed driver trajectories to an occupancy grid representation of the view ahead of the driver. Our method handles multi-agent scenarios, combining measurements from multiple observed drivers using evidential theory to solve the sensor fusion problem. Our approach is validated on a cluttered, real-world intersection, outperforming baselines and demonstrating real-time capable performance. Our code is available at https://github.com/sisl/MultiAgentVariationalOcclusionInferenc	https://doi.org/10.1109/ICRA46639.2022.9811774	Masha Itkina, Ye-Ji Mun, Katherine Driggs-Campbell, Mykel J. Kochenderfer
Multi-Arm Payload Manipulation via Mixed Reality.	Multi-Robot Systems (MRS) present many advantages over single robots, e.g. improved stability and payload capacity. Being able to operate or teleoperate these systems is therefore of high interest in industries such as construction or logistics. However, controlling the collective motion of a MRS can place a significant cognitive burden on the operator. We present a Mixed Reality (MR) control interface, which allows an operator to specify payload target poses for a MRS in real-time, while effectively keeping the system away from unfavorable configurations. To this end, we solve the inverse kinematics problem for each arm individually and leverage redundant degrees of freedom to optimize for a secondary objective. Using the manipulability index as a secondary objective in particular, allows us to significantly improve the tracking and singularity avoidance capabilities of our MRS in comparison to the unoptimized scenario. This enables more secure and intuitive teleoperation. We simulate and test our approach on different setups and over different input trajectories, and analyse the convergence properties of our method. Finally, we show that the method also works well when deployed on to a dual-arm ABB YuMi robot.	https://doi.org/10.1109/ICRA46639.2022.9811580	Florian Kennel-Maushart, Roi Poranne, Stelian Coros
Multi-Class 3D Object Detection with Single-Class Supervision.	"While multi-class 3D detectors are needed in many robotics applications, training them with fully labeled datasets can be expensive in labeling cost. An alternative approach is to have targeted single-class labels on disjoint data samples. In this paper, we are interested in training a multi-class 3D object detection model, while using these single-class labeled data. We begin by detailing the unique stance of our ""Single-Class Supervision"" (SCS) setting with respect to related concepts such as partial supervision and semi supervision. Then, based on the case study of training the multi-class version of Range Sparse Net (RSN), we adapt a spectrum of algorithms - from supervised learning to pseudo-labeling - to fully exploit the properties of our SCS setting, and perform extensive ablation studies to identify the most effective algorithm and practice. Empirical experiments on the Waymo Open Dataset show that proper training under SCS can approach or match full supervision training while saving labeling costs."	https://doi.org/10.1109/ICRA46639.2022.9812282	Mao Ye, Chenxi Liu, Maoqing Yao, Weiyue Wang, Zhaoqi Leng, Charles R. Qi, Dragomir Anguelov
Multi-Dimensional Compliance of Soft Grippers Enables Gentle Interaction with Thin, Flexible Objects.	In this paper, we discuss the role of gripper compliance in successful grasping and manipulation of thin, flexible materials. We show, both conceptually and empirically, that each axis of compliance in a planar gripper provides unique benefits in this domain. Vertical compliance allows robust grasping of thin materials in the presence of large uncertainty in positioning. Lateral compliance increases opportunity to respond to unexpected snags by increasing the time window over which tensile forces are applied. Rotational compliance avoids damage to objects by decreasing the maximum tensile forces applied during snags. We explore these three benefits through empirical tests comparing a rigid gripper to a soft gripper, evaluating the level of vertical uncertainty each can handle for prehensile and non-prehensile manipulation, as well as the forces and displacements incurred during snags. The results show how a soft gripper's three-axis compliance provides a passive ability to prevent damage to delicate materials.	https://doi.org/10.1109/ICRA46639.2022.9812324	Clark B. Teeple, Justin Werfel, Robert J. Wood
Multi-Dimensional Proprioception and Stiffness Tuning for Soft Robotic Joints.	"Proprioception and variable stiffness are two trending topics in soft robotics research. The former could endow soft robots with the ability to perceive the environment as well as their internal states without the need of dedicated sensors, while the latter could strengthen the otherwise excessive compliance, enabling soft robots for tasks which require a higher force. Both directions have been extensively reported in existing literature, achieving both concurrently was even more challenging. The major limiting factor was the limited stiffness due to the hyper elasticity of conventional soft robots, which increases the difficulties in capturing the continues deformation. In this work, we proposed an alternative approach to tackle these two challenges, a novel ""tune-down"" approach, combining proprioception with stiffness regulation and implemented over-constrained soft robotic joint designs to further strengthen this spirit. As a result, the soft robotic joint could achieve multi-directional proprioception, as well as variable stiffness tuning, concurrently, using merely an on-board sensor for basic pneumatic control. The concept, design, modeling, actuation/control, and experimental validation were presented in detail, demonstrating the efficacy and potential of the proposed approach."	https://doi.org/10.1109/ICRA46639.2022.9811555	Zhonggui Fang, Chaoyi Huang, Yaxi Wang, Jiahao Xu, Jiyong Tan, Bin Li, Zichen Wang, Yige Wu, Anlun Huang, Juan Yi, Sicong Liu, Zheng Wang
Multi-Object Grasping - Types and Taxonomy.	This paper proposes 12 multi-object grasps (MOGs) types from a human and robot grasping data set. The grasp types are then analyzed and organized into a MOG taxonomy. This paper first presents three MOG data collection setups: a human finger tracking setup for multi-object grasping demonstrations, a real system with Barretthand, UR5e arm, and a MOG algorithm, a simulation system with the same settings as the real system. Then the paper describes a novel stochastic grasping routine designed based on a biased random walk to explore the robotic hand's configuration space for feasible MOGs. Based on obser-vations in both the human demonstrations and robotic MOG solutions, this paper proposes 12 MOG types in two groups: shape-based types and function-based types. The new MOG types are compared using six characteristics and then compiled into a taxonomy. This paper then introduces the observed MOG type combinations and shows examples of 16 different combinations.	https://doi.org/10.1109/ICRA46639.2022.9812388	Yu Sun, Eliza Amatova, Tianze Chen
Multi-Operator Control of Connectivity-Preserving Robot Swarms Using Supervisory Control Theory.	Involving human operators to support swarms of robots can be beneficial to address increasingly complex scenarios. However, the shared control between multiple operators remains a challenge, especially where communication between the operators is not available. This paper studies the problem of forming a dynamic chain of robots connecting two operators moving within an environment. The robot chain enables operators to share information and robots among themselves. Based on supervisory control theory, we propose a distributed solution which formally guarantees that the deployed robot controllers match the modeled specifications. We validate the controllers through simulations with groups of up to 40 mobile robots in an environment with obstacles, demonstrating the feasibility of the approach.	https://doi.org/10.1109/ICRA46639.2022.9812242	Genki Miyauchi, Yuri K. Lopes, Roderich Groß
Multi-Robot Persistent Environmental Monitoring Based on Constraint-Driven Execution of Learned Robot Tasks.	This paper considers a multi-robot team tasked with monitoring an environmental field of interest over long time horizons. The approach is based on a control-theoretic measure of the information collected by the robots, namely a norm of the constructability Gramian. This measure is leveraged in order to learn a distributed multi-robot control policy using the reinforcement learning paradigm. The learned policy is then combined with energy constraints using the constraint-driven control framework in order to achieve persistent environmental monitoring. The proposed approach is tested in a simulated multi-robot persistent environmental monitoring scenario where a team of robots with limited availability of energy is to be controlled in a coordinated fashion in order to estimate the concentration of a gas diffusing in the environment.	https://doi.org/10.1109/ICRA46639.2022.9811673	Gennaro Notomista, Claudio Pacchierotti, Paolo Robuffo Giordano
Multi-Target Encirclement with Collision Avoidance via Deep Reinforcement Learning using Relational Graphs.	In this paper, we propose a novel decentralized method based on deep reinforcement learning using robot-level and target-level relational graphs, to solve the problem of multi-target encirclement with collision avoidance (MECA). Specifically, the robot-level relational graphs, composed of three heterogeneous relational graphs between each robot and other robots, targets and obstacles, are modeled and learned through using graph attention networks (GATs) for extracting different spatial relational representations. Moreover, for each target within the observation of each robot, a target-level relational graph is built with GAT to construct spatial relations from the robot. Furthermore, the movement of each target is modeled by the target-level relational graph and learned through supervised learning for predicting the trajectory of the target. In addition, a knowledge-embedded compound reward function is defined to solve the multi-objective problem in MECA, and guide the policy learning for deriving the behavior of MECA. An actor-critic training algorithm based on the centralized training and decentralized execution framework is adopted to train the policy network. Simulation and real-world experiment results demonstrate the effectiveness and generalization of our method.	https://doi.org/10.1109/ICRA46639.2022.9812151	Tianle Zhang, Zhen Liu, Zhiqiang Pu, Jianqiang Yi
Multi-Task Learning with Sequence-Conditioned Transporter Networks.	Enabling robots to solve multiple manipulation tasks has a wide range of industrial applications. While learning-based approaches enjoy flexibility and generalizability, scaling these approaches to solve such compositional tasks remains a challenge. In this work, we aim to solve multi-task learning through the lens of sequence-conditioning and weighted sampling. First, we propose a new suite of benchmark specifically aimed at compositional tasks, MultiRavens, which allows defining custom task combinations through task modules that are inspired by industrial tasks and exemplify the difficulties in vision-based learning and planning methods. Second, we propose a vision-based end-to-end system architecture, Sequence-Conditioned Transporter Networks, which augments Goal-Conditioned Transporter Networks with sequence-conditioning and weighted sampling and can efficiently learn to solve multi-task long horizon problems. Our analysis suggests that not only the new framework significantly improves pick-and-place performance on novel 10 multi-task benchmark problems, but also the multi-task learning with weighted sampling can vastly improve learning and agent performances on individual tasks.	https://doi.org/10.1109/ICRA46639.2022.9812096	Michael H. Lim, Andy Zeng, Brian Ichter, Maryam Bandari, Erwin Coumans, Claire J. Tomlin, Stefan Schaal, Aleksandra Faust
Multi-UAV Disaster Environment Coverage Planning with Limited-Endurance.	Disaster areas involving floods and earthquakes are commonly large, with the rescue time being quite tight, suggesting multi-Unmanned Aerial Vehicles (UAV) exploration rather than employing a single UAV. For such scenarios, current UAV exploration is modeled as a Coverage Path Planning (CPP) problem to achieve full area coverage in the presence of obstacles. However, the UAV's endurance capability is limited, and the rescue time is constrained, prohibiting even multiple UAVs from completing disaster area coverage on time. Therefore, this paper defines a multi-Agent Endurance-limited CPP (MAEl-CPP) problem that is based on an a priori known heatmap of the disaster area, which affords to explore the most valuable areas under UAV limited energy constraints. Furthermore, we propose a path planning algorithm for the MAEl-CPP problem by ranking the possible disaster areas according to their importance through satellite or remote sensing aerial images and completing path planning according to this ranking. Experimental results demonstrate that the search efficiency of the proposed algorithm is 4.2 times that of the existing algorithm.	https://doi.org/10.1109/ICRA46639.2022.9812201	Hongyu Song, Jincheng Yu, Jiantao Qiu, Zhixiao Sun, Kuijun Lang, Qing Luo, Yuan Shen, Yu Wang
Multi-modal Motion Prediction with Transformer-based Neural Network for Autonomous Driving.	Predicting the behaviors of other agents on the road is critical for autonomous driving to ensure safety and efficiency. However, the challenging part is how to represent the social interactions between agents and output different possible trajectories with interpretability. In this paper, we introduce a neural prediction framework based on the Transformer structure to model the relationship among the interacting agents and extract the attention of the target agent on the map waypoints. Specifically, we organize the interacting agents into a graph and utilize the multi-head attention Transformer encoder to extract the relations between them. To address the multi-modality of motion prediction, we propose a multi-modal attention Transformer encoder, which modifies the multi-head attention mechanism to multi-modal attention, and each predicted trajectory is conditioned on an independent attention mode. The proposed model is validated on the Argoverse motion forecasting dataset and shows state-of-the-art prediction accuracy while maintaining a small model size and a simple training process. We also demonstrate that the multi-modal attention module can automatically identify different modes of the target agent's attention on the map, which improves the interpretability of the model.	https://doi.org/10.1109/ICRA46639.2022.9812060	Zhiyu Huang, Xiaoyu Mo, Chen Lv
Multi-robot Cooperative Pursuit via Potential Field-Enhanced Reinforcement Learning.	It is of great challenge, though promising, to coordinate collective robots for hunting an evader in a decentralized manner purely in light of local observations. In this paper, this challenge is addressed by a novel hybrid cooperative pursuit algorithm that combines reinforcement learning with the artificial potential field method. In the proposed algorithm, decentralized deep reinforcement learning is employed to learn cooperative pursuit policies that are adaptive to dynamic environments. The artificial potential field method is integrated into the learning process as predefined rules to improve the data efficiency and generalization ability. It is shown by numerical simulations that the proposed hybrid design outperforms the pursuit policies either learned from vanilla reinforcement learning or designed by the potential field method. Furthermore, experiments are conducted by transferring the learned pursuit policies into real-world mobile robots. Experimental results demonstrate the feasibility and potential of the proposed algorithm in learning multiple cooperative pursuit strategies.	https://doi.org/10.1109/ICRA46639.2022.9812083	Zheng Zhang, Xiaohan Wang, Qingrui Zhang, Tianjiang Hu
Multi-view object pose distribution tracking for pre-grasp planning on mobile robots.	The ability to track the 6D pose distribution of an object when a mobile manipulator robot is still approaching the object can enable the robot to pre-plan grasps that combine base and arm motion. However, tracking a 6D object pose distribution from a distance can be challenging due to the limited view of the robot camera. In this work, we present a framework that fuses observations from external stationary cameras with a moving robot camera and sequentially tracks it in time to enable 6D object pose distribution tracking from a distance. We model the object pose posterior as a multi-modal distribution which results in a better performance against uncertainties introduced by large camera-object distance, occlusions and object geometry. We evaluate the proposed framework on a simulated multi-view dataset using objects from the YCB data set. Results show that our framework enables accurate tracking even when the robot camera has poor visibility of the object.	https://doi.org/10.1109/ICRA46639.2022.9812339	Lakshadeep Naik, Thorbjørn Mosekjær Iversen, Aljaz Kramberger, Jakob Wilm, Norbert Krüger
MultiPath++: Efficient Information Fusion and Trajectory Aggregation for Behavior Prediction.	Predicting the future behavior of road users is one of the most challenging and important problems in autonomous driving. Applying deep learning to this problem requires fusing heterogeneous world state in the form of rich perception signals and map information, and inferring highly multi-modal distributions over possible futures. In this paper, we present MultiPath++, a future prediction model that achieves state-of-the-art performance on popular benchmarks. MultiPath++ improves the MultiPath architecture [34] by revisiting many design choices. The first key design difference is a departure from dense image-based encoding of the input world state in favor of a sparse encoding of heterogeneous scene elements: MultiPath++ consumes compact and efficient polylines to describe road features, and raw agent state information directly (e.g., position, velocity, acceleration). We propose a context-aware fusion of these elements and develop a reusable multi-context gating fusion component. Second, we reconsider the choice of pre-defined static anchors, and develop a way to learn latent anchor embeddings end-to-end in the model. Lastly, we explore ensembling and output aggregation techniques—common in other ML domains—and find effective variants for our probabilistic multimodal output representation. We perform an extensive ablation on these design choices, and show that our proposed model achieves state-of-the-art performance on the Argoverse Motion Forecasting Competition [10] and the Waymo Open Dataset Motion Prediction Challenge [13].	https://doi.org/10.1109/ICRA46639.2022.9812107	Balakrishnan Varadarajan, Ahmed Hefny, Avikalp Srivastava, Khaled S. Refaat, Nigamaa Nayakanti, Andre Cornman, Kan Chen, Bertrand Douillard, Chi-Pang Lam, Dragomir Anguelov, Benjamin Sapp
Multimodal Hydrostatic Actuators for Wearable Robots: A Preliminary Assessment of Mass-Saving and Energy-Efficiency Opportunities.	Wearable robots are limited by their actuators performances because they must bear the weight of their own power system and energy source. This paper explores the idea of leveraging hybrid modes to meet multiple operating points with a lightweight and efficient system by using hydraulic valves to dynamically reconfigure the connections of a hydrostatic actuator. The analyzed opportunities consist in 1) switching between a highly geared power source or a fast power source, 2) dynamically connecting an energy accumulator and 3) using a locking mechanism for holding. Based on a knee exoskeleton case study analysis, results show that switching between gearing ratio can lead to a lighter and more efficient actuator. Also, results show that using an accumulator to provide a preload continuous force has great mass-saving potential, but does not reduce mass significantly if used as a power booster for short transients. Finally, using a locking valve can slightly reduce battery mass if the work cycle includes frequent stops. The operating principles of the proposed multimodal schemes are demonstrated with a one-DOF prototype.	https://doi.org/10.1109/ICRA46639.2022.9812435	Jeff Denis, Alex Lecavalier, Jean-Sébastien Plante, Alexandre Girard
Multiple Consistency Supervision based Semi-supervised OCT Segmentation using Very Limited Annotations.	Optical Coherence Tomography (OCT) is a rapidly growing and promising imaging technique, enabling non-invasive high-resolution visualization of biological tissues. Segmentation of tissue structures from OCT scans is essen-tial for disease diagnosis but remains challenging for the blurry boundaries and large volumes. Deep learning-based OCT segmentation algorithms always require large numbers of annotations for satisfying performance, which is hard to meet since manually labeling is time-consuming and labor-intensive. Therefore, we propose a novel semi-supervised OCT segmentation framework utilizing very few labeled scans, i.e., 5 samples, and abundant unlabeled data. Specifically, our framework con-sists of one shared encoder and two different decoder branches. For the two branches, we design a strong augmentation-consistent supervision module and a scaling transformation-consistent supervision module respectively to improve their generalization ability. Besides, cross consistency supervision with feature perturbations between two branches is proposed to incorporate their advantages for further regularization. With such multiple consistency supervision, we aim to enrich the diversity of unsupervised information so as to make full use of labeled and unlabeled data. Experimental results on a public retinal OCT dataset demonstrate the effectiveness of our method, achieving an average dice score of 87.25% in the case of only 5 labeled samples used. It outperforms the supervised baseline by 3.46% and the best semi-supervised model by 1.42% in our experiments.	https://doi.org/10.1109/ICRA46639.2022.9812447	Ye Lu, Yantao Shen, Xiaohan Xing, Max Q.-H. Meng
Multirobot control with double-integrator dynamics and control barrier functions for deformable object transport.	In this paper, we propose a formation control system for deforming and transporting simultaneously a de-formable object with a team of robots, modeled with double-integrator dynamics. The goal is to reach a target configuration, defined as a combination of shape, scale, orientation and position of the formation. We augment this controller with a set of control barrier functions (CBFs). The CBFs allow us to satisfy fundamental constraints for the success of the task: avoidance of agent-to-agent, agent-to-obstacle and object-to-obstacle collisions, and of excessive stretching. We test the performance of our proposal in different simulation scenarios.	https://doi.org/10.1109/ICRA46639.2022.9812378	Rafael Herguedas, Miguel Aranda, Gonzalo López-Nicolás, Carlos Sagüés, Youcef Mezouar
MyoSim: Fast and physiologically realistic MuJoCo models for musculoskeletal and exoskeletal studies.	Owing to the restrictions of live experimentation, musculoskeletal simulation models play a key role in biological motor control studies and investigations. Successful results of which are then tried on live subjects to develop treatments as well as robot aided rehabilitation procedures for addressing neuromusculoskeletal anomalies ranging from limb loss, to tendinitis, from sarcopenia to brain and spinal injuries. Despite its significance, current musculoskeletal models are computationally expensive, and provide limited support for contact-rich interactions which are essential for studying motor behaviors in activities of daily living, during rehabilitation treatments, or in assistive robotic devices. To bridge this gap, this work proposes an automatic pipeline to generate physiologically accurate musculoskeletal, as well as hybrid musculoskeletal-exoskeletal models. Leveraging this pipeline we present MyoSim - a set of computationally efficient (over 2 orders of magnitude faster than state of the art) musculoskeletal models that support fully interactive contact rich simulation. We further extend MyoSim to support additional features that help simulate various real-life changes/diseases, such as muscle fatigue, and sarcopenia. To demonstrate the potential applications, several use cases, including interactive rehabilitation movements, tendon-reaffirmation, and the cosimulation with an exoskeleton, were developed and investigated for physiological correctness. Web-page: https://sites.google.com/view/myosuite	https://doi.org/10.1109/ICRA46639.2022.9811684	Huawei Wang, Vittorio Caggiano, Guillaume Durandau, Massimo Sartori, Vikash Kumar
N-QGN: Navigation Map from a Monocular Camera using Quadtree Generating Networks.	Monocular depth estimation has been a popu-lar area of research for several years, especially since self-supervised networks have shown increasingly good results in bridging the gap with supervised and stereo methods. However, these approaches focus their interest on dense 3D reconstruction and sometimes on tiny details that are superfluous for autonomous navigation. In this paper, we propose to address this issue by estimating the navigation map under a quad tree representation. The objective is to create an adaptive depth map prediction that only extract details that are essential for the obstacle avoidance. Other 3D space which leaves large room for navigation will be provided with approximate distance. Experiment on KITTI dataset shows that our method can significantly reduce the number of output information without major loss of accuracy.	https://doi.org/10.1109/ICRA46639.2022.9812362	Daniel Braun, Olivier Morel, Pascal Vasseur, Cédric Demonceaux
Narrowing the coordinate-frame gap in behavior prediction models: Distillation for efficient and accurate scene-centric motion forecasting.	Behavior prediction models have proliferated in recent years, especially in the popular real-world robotics application of autonomous driving, where representing the distribution over possible futures of moving agents is essential for safe and comfortable motion planning. In these models, the choice of coordinate frames to represent inputs and outputs has crucial trade offs which broadly fall into one of two categories. Agent-centric models transform inputs and perform inference in agent-centric coordinates. These models are intrinsically invari-ant to translation and rotation between scene elements, are best-performing on public leaderboards, but scale quadratically with the number of agents and scene elements. Scene-centric models use a fixed coordinate system to process all agents. This gives them the advantage of sharing representations among all agents, offering efficient amortized inference computation which scales linearly with the number of agents. However, these models have to learn invariance to translation and rotation between scene elements, and typically underperform agent-centric models. In this work, we develop knowledge distillation techniques between probabilistic motion forecasting models, and apply these techniques to close the gap in performance between agent-centric and scene-centric models. This improves scene-centric model performance by 13.2% on the public Argoverse benchmark, 7.8% on Waymo Open Dataset and up to 9.4% on a large In-House dataset. These improved scene-centric models rank highly in public leaderboards and are up to 15 times more efficient than their agent-centric teacher counterparts in busy scenes.	https://doi.org/10.1109/ICRA46639.2022.9812368	DiJia Andy Su, Bertrand Douillard, Rami Al-Rfou, Cheol Park, Benjamin Sapp
NeRF-Supervision: Learning Dense Object Descriptors from Neural Radiance Fields.	Thin, reflective objects such as forks and whisks are common in our daily lives, but they are particularly chal-lenging for robot perception because it is hard to reconstruct them using commodity RGB-D cameras or multi-view stereo techniques. While traditional pipelines struggle with objects like these, Neural Radiance Fields (NeRFs) have recently been shown to be remarkably effective for performing view synthesis on objects with thin structures or reflective materials. In this paper we explore the use of NeRF as a new source of supervision for robust robot vision systems. In particular, we demonstrate that a NeRF representation of a scene can be used to train dense object descriptors. We use an optimized NeRF to extract dense correspondences between multiple views of an object, and then use these correspondences as training data for learning a view-invariant representation of the object. NeRF's usage of a density field allows us to reformulate the correspondence problem with a novel distribution-of-depths formulation, as opposed to the conventional approach of using a depth map. Dense correspondence models supervised with our method significantly outperform off-the-shelf learned descriptors by 106% (PCK@3px metric, more than doubling performance) and outperform our baseline supervised with multi-view stereo by 29%. Furthermore, we demonstrate the learned dense descriptors enable robots to perform accurate 6-degree of freedom (6-DoF) pick and place of thin and reflective objects.	https://doi.org/10.1109/ICRA46639.2022.9812291	Yen-Chen Lin, Pete Florence, Jonathan T. Barron, Tsung-Yi Lin, Alberto Rodriguez, Phillip Isola
Nearest-Neighbor-based Collision Avoidance for Quadrotors via Reinforcement Learning.	Collision avoidance algorithms are of central interest to many drone applications. In particular, decentralized approaches may be the key to enabling robust drone swarm solutions in cases where centralized communication becomes computationally prohibitive. In this work, we draw biological inspiration from flocks of starlings (Sturnus vulgaris) and apply the insight to end-to-end learned decentralized collision avoidance. More specifically, we propose a new, scalable observation model following a biomimetic nearest-neighbor information constraint that leads to fast learning and good collision avoidance behavior. By proposing a general reinforcement learning approach, we obtain an end-to-end learning-based approach to integrating collision avoidance with arbitrary tasks such as package collection and formation change. To validate the generality of this approach, we successfully apply our methodology through motion models of medium complexity, modeling momentum and nonetheless allowing direct application to real world quadrotors in conjunction with a standard PID controller. In contrast to prior works, we find that in our sufficiently rich motion model, nearest-neighbor information is indeed enough to learn effective collision avoidance behavior. Our learned policies are tested in simulation and subsequently transferred to real-world drones to validate their real-world applicability.	https://doi.org/10.1109/ICRA46639.2022.9812221	Ramzi Ourari, Kai Cui, Ahmed Elshamanhory, Heinz Koeppl
Negative Stiffness Analysis and Regulation of In-Hand Manipulation with Underactuated Compliant Hands.	This paper addresses the generation mechanism and avoidance method of negative stiffness during in-Hand manipulation with underactuated compliant hands. Firstly, a planar hand with two three-jointed fingers manipulating a rectangular is set, and a quasi-static underactuated operation model is established. Secondly, based on this simulation model, we investigated the stiffness evolution during in-hand manipulation, and analyze the influence factors of system stiffness. Finally, a stiffness regulation method is developed to avoid negative stiffness during in-hand manipulation. The method is validated by simulation. The research results are beneficial to improve the performance of underactuated in-hand manipulation.	https://doi.org/10.1109/ICRA46639.2022.9811964	Wenrui Chen, Qiang Diao, Yaonan Wang, Xiaodong Zhou, Qiang Zhang, Cuo Yan, Zhiyong Li
Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation.	We present Neural Descriptor Fields (NDFs), an object representation that encodes both points and relative poses between an object and a target (such as a robot gripper or a rack used for hanging) via category-level descriptors. We employ this representation for object manipulation, where given a task demonstration, we want to repeat the same task on a new object instance from the same category. We propose to achieve this objective by searching (via optimization) for the pose whose descriptor matches that observed in the demonstration. NDFs are conveniently trained in a self-supervised fashion via a 3D auto-encoding task that does not rely on expert-labeled keypoints. Further, NDFs are SE(3)-equivariant, guaranteeing performance that generalizes across all possible 3D object translations and rotations. We demonstrate learning of manipulation tasks from few (∼5-10) demonstrations both in simulation and on a real robot. Our performance generalizes across both object instances and 6-DoF object poses, and significantly outperforms a recent baseline that relies on 2D descriptors. Project website: https://yilundu.github.io/ndf/	https://doi.org/10.1109/ICRA46639.2022.9812146	Anthony Simeonov, Yilun Du, Andrea Tagliasacchi, Joshua B. Tenenbaum, Alberto Rodriguez, Pulkit Agrawal, Vincent Sitzmann
Neural Implicit Event Generator for Motion Tracking.	We present a novel framework of motion tracking from event data using implicit expression. Our framework uses pre-trained event generation MLP called the implicit event generator (IEG) and carries out motion tracking by updating its state (position and velocity) based on the difference between the observed event and generated event from the current state estimation. The difference is computed implicitly by the IEG. Unlike the conventional explicit approach, which requires dense computation to evaluate the difference, our implicit approach realizes the update of the efficient state directly from sparse event data. Our sparse algorithm is especially suitable for mobile robotics applications in which computational resources and battery life are limited. To verify the effectiveness of our method on real-world data, we applied it to the AR marker tracking application. We have confirmed that our framework works well in real-world environments in the presence of noise and background clutter.	https://doi.org/10.1109/ICRA46639.2022.9812142	Mana Masuda, Yusuke Sekikawa, Ryo Fujii, Hideo Saito
Neural Style Transfer with Twin-Delayed DDPG for Shared Control of Robotic Manipulators.	"Neural Style Transfer (NST) refers to a class of algorithms able to manipulate an element, most often images, to adopt the appearance or style of another one. Each element is defined as a combination of Content and Style: the Content can be conceptually defined as the ""what"" and the Style as the ""how"" of said element. In this context, we propose a custom NST framework for transferring a set of styles to the motion of a robotic manipulator, e.g., the same robotic task can be carried out in an ""angry"", ""happy"", ""calm"", or ""sad"" way. An autoencoder architecture extracts and defines the Content and the Style of the target robot motions. A Twin Delayed Deep Deterministic Policy Gradient (TD3) network generates the robot control policy using the loss defined by the autoencoder. The proposed Neural Policy Style Transfer TD3 (NPST33) alters the robot motion by introducing the trained style. Such an approach can be implemented either offline, for carrying out autonomous robot motions in dynamic environments, or online, for adapting at runtime the style of a teleoperated robot. The considered styles can be learned online from human demonstrations. We carried out an evaluation with human subjects enrolling 73 volunteers, asking them to recognize the style behind some representative robotic motions. Results show a good recognition rate, proving that it is possible to convey different styles to a robot using this approach."	https://doi.org/10.1109/ICRA46639.2022.9812245	Raul Fernandez-Fernandez, Marco Aggravi, Paolo Robuffo Giordano, Juan G. Victores, Claudio Pacchierotti
NeuroErgo: A Deep Neural Network Method to Improve Postural Optimization for Ergonomic Human-Robot Collaboration.	Collaborative robots can help industry workers to improve their ergonomics. They can propose a safe and ergonomic posture to the workers to reduce the risk of musculoskeletal disorders. Proposing an ergonomic stance needs postural evaluation and optimization. To optimize the workers' posture, we need to run the optimization on a cost function representing the ergonomic status. The tabular ergonomic assessment methods are the most common methods used by ergonomists, but they are linear stepwise functions that are not differentiable and not suitable for optimization purposes. We propose NeuroErgo, a deep neural network model that can approximate the tabular ergonomic assessment methods more precisely than existing methods. By solving the task constraints optimization problem for any task in industry and NeuroErgo as posture cost function, a safe and ergonomic posture can be derived and recommended to the workers while accomplishing their job.	https://doi.org/10.1109/ICRA46639.2022.9812460	Atieh Merikh Nejadasl, Omid Gheibi, Greet Van de Perre, Bram Vanderborght
Next Steps: Learning a Disentangled Gait Representation for Versatile Quadruped Locomotion.	Quadruped locomotion is rapidly maturing to a degree where robots now routinely traverse a variety of unstructured terrains. However, while gaits can be varied typically by selecting from a range of pre-computed styles, current planners are unable to vary key gait parameters continuously while the robot is in motion. The synthesis, on-the-fly, of gaits with unexpected operational characteristics or even the blending of dynamic manoeuvres lies beyond the capabilities of the current state-of-the-art. In this work we address this limitation by learning a latent space capturing the key stance phases of a particular gait, via a generative model trained on a single trot style. This encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. In fact properties of this drive signal map directly to gait parameters such as cadence, footstep height and full stance duration. The use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on a real ANYmal quadruped robot and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations.	https://doi.org/10.1109/ICRA46639.2022.9811584	Alexander L. Mitchell, Wolfgang Merkt, Mathieu Geisert, Siddhant Gangapurwala, Martin Engelcke, Oiwi Parker Jones, Ioannis Havoutis, Ingmar Posner
Next-Best-View Prediction for Active Stereo Cameras and Highly Reflective Objects.	Depth acquisition with the active stereo camera is a challenging task for highly reflective objects. When setup permits, multi-view fusion can provide increased levels of depth completion. However, due to the slow acquisition speed of high-end active stereo cameras, collecting a large number of viewpoints for a single scene is generally not practical. In this work, we propose a next-best-view framework to strategically select camera viewpoints for completing depth data on reflective objects. In particular, we explicitly model the specular reflection of reflective surfaces based on the Phong reflection model and a photometric response function. Given the object CAD model and grayscale image, we employ an RGB-based pose estimator to obtain current pose predictions from the existing data, which is used to form predicted surface normal and depth hypotheses, and allows us to then assess the information gain from a subsequent frame for any candidate viewpoint. Using this formulation, we implement an active perception pipeline which is evaluated on a challenging real-world dataset. The evaluation results demonstrate that our active depth acquisition method outperforms two strong baselines for both depth completion and object pose estimation performance.	https://doi.org/10.1109/ICRA46639.2022.9811917	Jun Yang, Steven L. Waslander
Non-Gaussian Risk Bounded Trajectory Optimization for Stochastic Nonlinear Systems in Uncertain Environments.	We address the risk bounded trajectory optimization problem of stochastic nonlinear robotic systems. More precisely, we consider the motion planning problem in which the robot has stochastic nonlinear dynamics and uncertain initial locations, and the environment contains multiple dynamic uncertain obstacles with arbitrary probabilistic distributions. The goal is to plan a sequence of control inputs for the robot to navigate to the target while bounding the probability of colliding with obstacles. Existing approaches to address risk bounded trajectory optimization problems are limited to particular classes of models and uncertainties such as Gaussian linear problems. In this paper, we deal with stochastic nonlinear models, nonlinear safety constraints, and arbitrary probabilistic uncertainties, the most general setting ever considered. To address the risk bounded trajectory optimization problem, we first formulate the problem as an optimization problem with stochastic dynamics equations and chance constraints. We then convert probabilistic constraints and stochastic dynamics constraints on random variables into a set of deterministic constraints on the moments of state probability distributions. Finally, we solve the resulting deterministic optimization prob-lem using nonlinear optimization solvers and get a sequence of control inputs. To our best knowledge, it is the first time that the motion planning problem to such a general extent is considered and solved. To illustrate the performance of the proposed method, we provide several robotics examples.	https://doi.org/10.1109/ICRA46639.2022.9811363	Weiqiao Han, Ashkan Jasour, Brian C. Williams
Non-Penetration Iterative Closest Points for Single-View Multi-Object 6D Pose Estimation.	This paper presents a novel iterative closest points (ICP) variant, non-penetration iterative closest points (NPICP), which prevents interpenetration in 6DOF pose optimization and/or joint optimization of multiple object poses. This capability is particularly advantageous in cluttered scenarios, where there are many interactions between objects that constrain the space of valid poses. We use a semi-infinite programming approach to handle non-penetration constraints between complex, non-convex 3D geometries. NPICP is applied to a common use case for ICP as a post-processing method to improve the pose estimation accuracy of a rough guess. The results show that NPICP outperforms ICP, assists in outlier detection, and also outperforms the best result on the IC-BIN dataset in the Benchmark for 6D Object Pose Estimation.	https://doi.org/10.1109/ICRA46639.2022.9812043	Mengchao Zhang, Kris Hauser
Non-destructive Fruit Firmness Evaluation Using Vision-Based Tactile Information.	During postharvest storage, fruit firmness usually decreases due to respiration and bruise, the former of which indicates the fruit ripeness while the latter negatively influence consumers' taste preference. This paper presents a portable and low-cost device using vision-based tactile information to evaluate fruit firmness in a non-destructive manner. The device consists of a camera, LED lights, and a soft sensing layer with small bumps to capture detailed tactile information of the fruit. Two working modes are designed and a CNN-LSTM architecture is developed to relate the tactile information to fruit overall firmness or detect local firmness distortion. According to the experimental results, an R2 up to 92.9% was achieved for the evaluation of the overall firmness of Cuixiang kiwifruit, and accuracy of 98.0% was obtained for the detection of local firmness distortion of Fuji apples. These results demonstrate the efficacy of the proposed solution to evaluate fruit firmness featuring high precision, and its non-destructive and potable nature is also anticipated to be favorable by the fresh fruit market.	https://doi.org/10.1109/ICRA46639.2022.9811920	Yaohui Chen, Jiahao Lin, Xuan Du, Bin Fang, Fuchun Sun, Shanjun Li
Non-prehensile Planar Manipulation via Trajectory Optimization with Complementarity Constraints.	Contact adaptation is an essential capability when manipulating objects. Two key contact modes of non-prehensile manipulation are sticking and sliding. This paper presents a Trajectory Optimization (TO) method formulated as a Mathematical Program with Complementarity Constraints (MPCC), which is able to switch between these two modes. We show that this formulation can be applicable to both planning and Model Predictive Control (MPC) for planar manipulation tasks. We numerically compare: (i) our planner against a mixed integer alternative, showing that the MPCC planner converges faster, scales better with respect to the time horizon (TH), and can handle environments with obstacles; (ii) our controller against a state-of-the-art mixed integer approach, showing that the MPCC controller achieves improved tracking and more consistent computation times. Additionally, we experimentally validate both our planner and controller with the KUKA LWR robot on a range of planar manipulation tasks. See our accompanying video here: https://youtu.be/EkU6YHMhjto.	https://doi.org/10.1109/ICRA46639.2022.9811942	João Moura, Theodoros Stouraitis, Sethu Vijayakumar
Nonlinear Model Identification and Observer Design for Thrust Estimation of Small-scale Turbojet Engines.	Jet-powered vertical takeoff and landing (VTOL) drones require precise thrust estimation to ensure adequate stability margins and robust maneuvering. Small-scale turbojets have become good candidates for powering heavy aerial drones. However, due to limited instrumentation available in these turbojets, estimating the precise thrust using classical techniques is not straightforward. In this paper, we present a methodology to accurately estimate the online thrust for the small-scale turbojets used on the iRonCub - an aerial humanoid robot. We use a grey-box method to capture the turbojet system dynamics with a nonlinear state-space model based on the data acquired from a custom engine test bench. This model is then used to design an extended Kalman filter that estimates the turbojet thrust only from the angular speed measurements. We exploited the parameter estimation algorithm to ensure that the EKF gives smooth and accurate estimates even at engine failures. The designed EKF was validated on the test bench where the mean absolute error in estimated thrust was found to be within 2% of rated peak thrust.	https://doi.org/10.1109/ICRA46639.2022.9812283	Affaf Junaid Ahamad Momin, Gabriele Nava, Giuseppe L'Erario, Hosameldin Awadalla Omer Mohamed, Fabio Bergonti, Punith Reddy Vanteddu, Francesco Braghin, Daniele Pucci
Nonprehensile Object Transportation with a Legged Manipulator.	This paper tackles the problem of nonprehensile object transportation through a legged manipulator. A whole-body control architecture is devised to prevent sliding of the object placed on the tray at the manipulator's end-effector and retain the legged robot balance during walking. The controller solves a quadratic optimization problem to realize the sought transportation task while maintaining the contact forces between the tray and the object and between the legs and the ground within their respective friction cones, also considering limits on the input torques. An extensive simulation campaign confirmed the feasibility of the approach and evaluated the control performance through a thorough statistical analysis conducted varying mass, friction, and the dimension of the transported object.	https://doi.org/10.1109/ICRA46639.2022.9811810	Viviana Morlando, Mario Selvaggio, Fabio Ruggiero
OPIRL: Sample Efficient Off-Policy Inverse Reinforcement Learning via Distribution Matching.	Inverse Reinforcement Learning (IRL) is attractive in scenarios where reward engineering can be tedious. However, prior IRL algorithms use on-policy transitions, which require intensive sampling from the current policy for stable and optimal performance. This limits IRL applications in the real world, where environment interactions can become highly expensive. To tackle this problem, we present Off-Policy Inverse Reinforcement Learning (OPIRL), which (1) adopts off-policy data distribution instead of on-policy and enables significant reduction of the number of interactions with the environment, (2) learns a reward function that is transferable with high generalization capabilities on changing dynamics, and (3) leverages mode-covering behavior for faster convergence. We demonstrate that our method is considerably more sample efficient and generalizes to novel environments through the experiments. Our method achieves better or comparable results on policy performance baselines with significantly fewer interactions. Furthermore, we empirically show that the recovered reward function generalizes to different tasks where prior arts are prone to fail.	https://doi.org/10.1109/ICRA46639.2022.9811660	Hana Hoshino, Kei Ota, Asako Kanezaki, Rio Yokota
OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-Vehicle Communication.	Employing Vehicle-to-Vehicle communication to enhance perception performance in self-driving technology has attracted considerable attention recently; however, the absence of a suitable open dataset for benchmarking algorithms has made it difficult to develop and assess cooperative perception technologies. To this end, we present the first large-scale open simulated dataset for Vehicle-to-Vehicle perception. It contains over 70 interesting scenes, 11,464 frames, and 232,913 annotated 3D vehicle bounding boxes, collected from 8 towns in CARLA and a digital town of Culver City, Los Angeles. We then construct a comprehensive benchmark with a total of 16 implemented models to evaluate several information fusion strategies (i.e. early, late, and intermediate fusion) with state-of-the-art LiDAR detection algorithms. Moreover, we propose a new Attentive Intermediate Fusion pipeline to aggregate information from multiple connected vehicles. Our experiments show that the proposed pipeline can be easily integrated with existing 3D LiDAR detectors and achieve outstanding performance even with large compression rates. To encourage more researchers to investigate Vehicle-to-Vehicle perception, we will release the dataset, benchmark methods, and all related codes in https://mobility-lab.seas.ucla.edu/opv2v/.	https://doi.org/10.1109/ICRA46639.2022.9812038	Runsheng Xu, Hao Xiang, Xin Xia, Xu Han, Jinlong Li, Jiaqi Ma
ORFD: A Dataset and Benchmark for Off-Road Freespace Detection.	Freespace detection is an essential component of autonomous driving technology and plays an important role in trajectory planning. In the last decade, deep learning based freespace detection methods have been proved feasible. However, these efforts were focused on urban road environments and few deep learning based methods were specifically designed for off-road freespace detection due to the lack of off-road dataset and benchmark. In this paper, we present the ORFD dataset, which, to our knowledge, is the first off-road freespace detection dataset. The dataset was collected in different scenes (woodland, farmland, grassland and countryside), different weather conditions (sunny, rainy, foggy and snowy) and different light conditions (bright light, daylight, twilight, darkness), which totally contains 12,198 LiDAR point cloud and RGB image pairs with the traversable area, non-traversable area and unreachable area annotated in detail. We propose a novel network named OFF-Net, which unifies Transformer architecture to aggregate local and global information, to meet the requirement of large receptive fields for freespace detection task. We also propose the cross-attention to dynamically fuse LiDAR and RGB image information for accurate off-road freespace detection. Dataset and code are publicly available at https://github.com/chaytonmin/OFF-Net.	https://doi.org/10.1109/ICRA46639.2022.9812139	Chen Min, Weizhong Jiang, Dawei Zhao, Jiaolong Xu, Liang Xiao, Yiming Nie, Bin Dai
OSCAR: Data-Driven Operational Space Control for Adaptive and Robust Robot Manipulation.	Learning performant robot manipulation policies can be challenging due to high-dimensional continuous actions and complex physics-based dynamics. This can be alleviated through intelligent choice of action space. Operational Space Control (OSC) has been used as an effective task-space controller for manipulation. Nonetheless, its strength depends on the underlying modeling fidelity, and is prone to failure when there are modeling errors. In this work, we propose OSC for Adaptation and Robustness (OSCAR), a data-driven variant of OSC that compensates for modeling errors by inferring relevant dynamics parameters from online trajectories. OSCAR decomposes dynamics learning into task-agnostic and task-specific phases, decoupling the dynamics dependencies of the robot and the extrinsics due to its environment. This structure enables robust zero-shot performance under out-of-distribution and rapid adaptation to significant domain shifts through additional finetuning. We evaluate our method on a variety of simulated manipulation problems, and find substantial improvements over an array of controller baselines. For more results and information, please visit https://cremebrule.github.io/oscar-web/.	https://doi.org/10.1109/ICRA46639.2022.9811967	Josiah Wong, Viktor Makoviychuk, Anima Anandkumar, Yuke Zhu
Object Insertion Based Data Augmentation for Semantic Segmentation.	"Neural network used for the LiDAR semantic segmentation task needs the point-wise labeled point clouds for training, which is more expensive than bounding box annotations. Enhancing the diversity of training data through object insertion is an effective method to reduce labeling costs. The existing object insertion methods are mainly divided into two categories. First is ""copy"" the clusters from a LiDAR frame and ""paste"" it to other frames or positions. Second is inserting CAD models into the background then using LiDAR simulator to generate laser points of the inserted CAD models. ""Copy-paste"" method cannot generate realistic scanning lines and shadows, and the CAD models, especially the CAD models of flexible objects, are hard to obtain. We propose an object insertion based data augmentation method which can increase the performance of the semantic segmentation network remarkably. First, an object library is created by using the labeled LiDAR point clouds. Then, these objects are inserted into the LiDAR point clouds dynamically during the training. Finally, the realistic scanning lines and shadows are simulated according to the real LiDAR parameters. The experimental results show that the proposed augmentation method can increase the performance of different semantic segmentation frameworks remarkably."	https://doi.org/10.1109/ICRA46639.2022.9811816	Yuan Ren, Siyan Zhao, Bingbing Liu
Object Memory Transformer for Object Goal Navigation.	This paper presents a reinforcement learning method for object goal navigation (ObjNav) where an agent navigates in 3D indoor environments to reach a target object based on long-term observations of objects and scenes. To this end, we propose Object Memory Transformer (OMT) that consists of two key ideas: 1) Object-Scene Memory (OSM) that enables to store long-term scenes and object semantics, and 2) Transformer that attends to salient objects in the sequence of previously observed scenes and objects stored in OSM. This mechanism allows the agent to efficiently navigate in the indoor environment without prior knowledge about the environments, such as topological maps or 3D meshes. To the best of our knowledge, this is the first work that uses a long-term memory of object semantics in a goal-oriented navigation task. Experimental results conducted on the AI2-THOR dataset show that OMT outperforms previous approaches in navigating in unknown environments. In particular, we show that utilizing the long-term object semantics information improves the efficiency of navigation.	https://doi.org/10.1109/ICRA46639.2022.9812027	Rui Fukushima, Kei Ota, Asako Kanezaki, Yoko Sasaki, Yusuke Yoshiyasu
Object-based Visual-Inertial Navigation System on Matrix Lie Group.	In this paper, we propose a novel object-based visual-inertial navigation system fully embedded in a matrix Lie group and built upon the invariant Kalman filtering theory. Specifically, we focus on relative pose measurements of objects and derive an error equation at the associated tangent space. We prove that the observability property does not suffer from the filter inconsistency and nonlinear error terms are identically zero at the object initialization. A thorough Monte-Carlo simulation reveals that our approach yields consistent estimates and is very robust to a large initial state uncertainty. Further-more, we demonstrate a real-world application to the KITTI dataset with a deep neural network-based 3D object detector. Experimental results report that noises on pose measurements follow a Gaussian-like density matching our assumption. The proposed method improves the localization and object global mapping accuracy by probabilistically accounting for inertial readings and object pose uncertainties at multiple views.	https://doi.org/10.1109/ICRA46639.2022.9812443	Jae-Hyung Jung, Chan Gook Park
Off Environment Evaluation Using Convex Risk Minimization.	Applying reinforcement learning (RL) methods on robots typically involves training a policy in simulation and deploying it on a robot in the real world. Because of the model mismatch between the real world and the simulator, RL agents deployed in this manner tend to perform suboptimally. To tackle this problem, researchers have developed robust policy learning algorithms that rely on synthetic noise disturbances. However, such methods do not guarantee performance in the target environment. We propose a convex risk minimization algorithm to estimate the model mismatch between the simulator and the target domain using trajectory data from both environments. We show that this estimator can be used along with the simulator to evaluate performance of an RL agents in the target domain, effectively bridging the gap between these two environments. We also show that the convergence rate of our estimator to be of the order of n^{-1/4}, where n is the number of training samples. In simulation, we demonstrate how our method effectively approximates and evaluates performance on Gridworld, Cartpole, and Reacher environments on a range of policies. We also show that the our method is able to estimate performance of a 7 DOF robotic arm using the simulator and remotely collected data from the robot in the real world.	https://doi.org/10.1109/ICRA46639.2022.9812026	Pulkit Katdare, Shuijing Liu, Katherine Driggs-Campbell
Offline Learning of Counterfactual Predictions for Real-World Robotic Reinforcement Learning.	We consider real-world reinforcement learning (RL) of robotic manipulation tasks that involve both visuomotor skills and contact-rich skills. We aim to train a policy that maps multimodal sensory observations (vision and force) to a manipulator's joint velocities under practical considerations. We propose to use offline samples to learn a set of general value functions (GVFs) that make counterfactual predictions from the visual inputs. We show that combining the offline learned counterfactual predictions with force feedbacks in online policy learning allows efficient reinforcement learning given only a terminal (success/failure) reward. We argue that the learned counterfactual predictions form a compact and informative representation that enables sample efficiency and provides auxiliary reward signals that guide online explorations towards contact-rich states. Various experiments in simulation and real-world settings were performed for evaluation. Recordings of the real-world robot training can be found via https://sites.google.com/view/realrl.	https://doi.org/10.1109/ICRA46639.2022.9811963	Jun Jin, Daniel Graves, Cameron Haigh, Jun Luo, Martin Jägersand
Offline Meta-Reinforcement Learning for Industrial Insertion.	Reinforcement learning (RL) can in principle let robots automatically adapt to new tasks, but current RL methods require a large number of trials to accomplish this. In this paper, we tackle rapid adaptation to new tasks through the framework of meta-learning, which utilizes past tasks to learn to adapt with a specific focus on industrial insertion tasks. Fast adaptation is crucial because prohibitively large number of on-robot trials will potentially damage hardware pieces. Additionally, effective adaptation is also feasible in that experience among different insertion applications can be largely leveraged by each other. In this setting, we address two specific challenges when applying meta-learning. First, conventional meta-RL algorithms require lengthy online meta-training. We show that this can be replaced with appropriately chosen offline data, resulting in an offline meta- RL method that only requires demonstrations and trials from each of the prior tasks, without the need to run costly meta-RL procedures online. Second, meta-RL methods can fail to generalize to new tasks that are too different from those seen at meta-training time, which poses a particular challenge in industrial applications, where high success rates are critical. We address this by combining contextual meta-learning with direct online finetuning: if the new task is similar to those seen in the prior data, then the contextual meta-learner adapts immediately, and if it is too different, it gradually adapts through finetuning. We show that our approach is able to quickly adapt to a variety of different insertion tasks, with a success rate of 100% using only a fraction of the samples needed for learning the tasks from scratch. Experiment videos and details are available at //sites.google.com/view/offline-metarl-insertion.https:	https://doi.org/10.1109/ICRA46639.2022.9812312	Tony Z. Zhao, Jianlan Luo, Oleg Sushkov, Rugile Pevceviciute, Nicolas Heess, Jon Scholz, Stefan Schaal, Sergey Levine
Omni-Roach: A Legged Robot Capable of Traversing Multiple Types of Large Obstacles and Self-Righting.	Robots excel at avoiding obstacles but struggle to traverse complex 3-D terrain with cluttered large obstacles. By contrast, insects like cockroaches excel at doing so. Recent research in our lab elucidated how locomotor transitions emerge from locomotor-environment interaction for diverse locomotor challenges abstracted from complex 3-D terrain and the strategies to overcome them. Here we built on these fundamental insights to develop a cockroach-inspired legged robot, Omni-Roach, that integrated these strategies to achieve multi-modal locomotion and provide a robophysical model to study the tradeoff between multi-functionality and performance. The robot was based on the RHex design with six compliant legs and featured a rounded body with two wings that can open and a tail with pitch and yaw degrees of freedom. After two development and testing iterations, our robot was capable of overcoming all loco-motor challenges with a high performance and success rate. It traversed cluttered rigid pillars only 1.1× robot body width apart, a 2.5× hip height bump, a 0.75× body length gap, densely cluttered flexible beams only 65% body width apart, and self-righted within 4 seconds. Systematic beam traversal experiments further revealed that a downward-pointing tail oscillating laterally helps roll the body into beam gaps and break frictional and interlocking contact to traverse. Our work highlights the usefulness of multi-functional appendages and exaptation for large obstacle traversal.	https://doi.org/10.1109/ICRA46639.2022.9811372	Jonathan Mi, Yaqing Wang, Chen Li
On Wearable, Lightweight, Low-Cost Human Machine Interfaces for the Intuitive Collection of Robot Grasping and Manipulation Data.	Robot grasping and manipulation allow robots to interact with their environments and execute a plethora of complex tasks that require increased dexterity (e.g., open a door, push buttons, collect and transpose objects, etc.). Collecting data of such activities is of paramount importance as it allows roboticists to create new methods and models that will facilitate the execution of sophisticated tasks. In this paper, we propose new wearable, lightweight, low-cost human machine interfaces that improve the efficiency of the data collection process for both robotic grasping and manipulation by offering intuitive and simplified control of the employed robotic grippers and hands. In particular, two different types of interfaces are proposed: i) a handle-based forearm stabilized interface that uses a waist-linkage system to provide weight support for bulky and heavy robotic end-effectors and ii) a palm-mounted interface that can accommodate smaller and lightweight grippers and hands, offering more agility in the control and positioning of these devices. Both interfaces are equipped with appropriate sliders, joysticks, and buttons that facilitate the control of the multiple degrees of freedom of the employed end-effectors and appropriate cameras that allow for object detection, identification, and object pose estimation.	https://doi.org/10.1109/ICRA46639.2022.9812198	Che-Ming Chang, Jayden Chapman, Ke Wang, Patrick Jarvis, Minas V. Liarokapis
On a New 10-Millimeter Surgical Robot Wrist.	Presented is a new 10-mm diameter wrist designed for robotic surgery. Featuring greater dexterity than current designs, entirely new procedures may be possible. An innovative, parallel mechanism, it offers 180 degrees of singularity-free pitch/yaw motion. The wrist is also a new form of high angulation, constant velocity, universal joint and is capable of continuous 360 degrees of roll rotation at any angle to enable drilling, reaming, milling, filing, deburring, or inserting fasteners. Z-axis motion is incorporated into the wrist itself, a unique feature. In addition, a gripper, scissors, stapler or other open/close device may be added. A thru-hole allows for passing wires, fiber optics, or flexible tubes. Stainless steel rotary shafts drive the wrist and also enable force reflection useful for providing haptic feedback to the operator. Eliminating difficult to sterilize woven steel cables/pulleys and bearings, the wrist may be sterilized in an autoclave. A simple construction, the wrist lends itself to CNC machining and automated assembly.	https://doi.org/10.1109/ICRA46639.2022.9812073	Mark E. Rosheim
On nondeterminism in combinatorial filters.	The problem of combinatorial filter reduction arises from resource optimization in robots; it is one specific way in which automation can help to achieve minimalism, to build better robots. This paper contributes a new definition of filter minimization that is broader than its antecedents, allowing filters (input, output, or both) to be nondeterministic. This changes the problem considerably. Nondeterministic filters may re-use states to obtain more 'behavior' per vertex. We show that the gap in size can be significant (larger than polyno-mial), suggesting such cases will generally be more challenging than deterministic problems. Indeed, this is supported by the core complexity result established in this paper: producing nondeterministic minimizers is PSPACE-hard. The hardness separation for minimization existing between deterministic filter and automata, thus, fails to hold for the nondeterministic case.	https://doi.org/10.1109/ICRA46639.2022.9812371	Yulin Zhang, Dylan A. Shell
On the Convergence of Multi-robot Constrained Navigation: A Parametric Control Lyapunov Function Approach.	This paper studies the distributed multi-robot constrained navigation problem. While the multi-robot collision avoidance has been extensively studied in the literature with safety being the primary focus, the individual robot's destination convergence is not necessarily guaranteed. In particular, robots may get stuck in the local equilibria or periodic orbits of the multi-robot system, some of which are practically known as the deadlock and the livelock behaviors. Inspired by the combination of Control Lyapunov Function (CLF) and Control Barrier Function (CBF) for the nonlinear system's constrained stabilization, the authors present a guaranteed safe feedback control policy with improved convergence performance. The proposed Parametric CLF (PCLF) scheme adaptively determines the appropriate CLF parameterization within the in-stantaneous feasible action space. The algorithm also induces a conditional global asymptotic convergence guarantee for multi-robot system of single-integrator dynamics, and is empirically effective for nonlinear nonholonomic vehicle model. Empiri-cally, the proposed PCLF-CBF framework exhibits superior performance than state-of-the-art methods, including its de-generated counterpart of various CLF-CBF solutions.	https://doi.org/10.1109/ICRA46639.2022.9811807	Bowen Weng, Hua Chen, Wei Zhang
On the Feasibility of Learning Finger-gaiting In-hand Manipulation with Intrinsic Sensing.	Finger-gaiting manipulation is an important skill to achieve large-angle in-hand re-orientation of objects. However, achieving these gaits with arbitrary orientations of the hand is challenging due to the unstable nature of the task. In this work, we use model-free reinforcement learning (RL) to learn finger-gaiting only via precision grasps and demonstrate finger-gaiting for rotation about an axis using only on-board proprioceptive and tactile feedback. To tackle the inherent instability of precision grasping, we propose the use of initial state distributions that enable effective exploration of the state space. Our method can learn finger gaiting with better sample complexity than the state-of-the-art. The policies we obtain are robust to noise and perturbations, and transfer to novel objects. Videos can be found at https://roamlab.github.io/learnfg/	https://doi.org/10.1109/ICRA46639.2022.9812212	Gagan Khandate, Maximilian Haas-Heger, Matei T. Ciocarlie
On the Reliability of Inverse Optimal Control.	Inverse Optimal Control (IOC) is a popular method for human motion analysis. In the context of these methods it is necessary to pay attention to the reliability of the results. This paper proposes an approach based on the evaluation of Karush-Kuhn-Tucker conditions relying on a complete analysis with Singular Value Decomposition and provides a detailed analysis of reliability. With respect to a ground truth, our simulations illustrate how the proposed method analyzes the reliability of the resolution. After introducing a clear methodology, the properties of the matrices are studied with different noise levels and different experimental models and conditions. We show how to implement the method, step by step, by explaining the numerical difficulties encountered during the resolution and thus how to make the results of the IOC problem reliable.	https://doi.org/10.1109/ICRA46639.2022.9811847	Jessica Colombel, David Daney, François Charpillet
On the Role of Hyperdimensional Computing for Behavioral Prioritization in Reactive Robot Navigation Tasks.	Hyperdimensional computing (HDC) is a brain-inspired computing paradigm that operates on pseudo-random hypervectors, an information-rich, hardware-efficient representation that is robust to noise and facilitates learning with limited training data. This work explores how robot navigation tasks can leverage the high-capacity hypervector representation to enable behavioral prioritization through a weighted encoding of heterogeneous sensor information. Experiments over 100 trials in each of the 100 randomly generated obstacle maps demonstrate that the proposed weighted sensor encoding scheme boosts the success rate of the navigation task by over 30% compared to an unweighted sensor encoding. A hybrid scheme using the HDC weighted scheme at the input of a deep feed-forward neural network achieves the highest success rate. The hybrid scheme furthermore is more robust when reducing the HDC dimension by 50%. However, the simple HDC implementation remains the most hardware efficient, making it desirable for resource-constrained systems.	https://doi.org/10.1109/ICRA46639.2022.9811939	Alisha Menon, Anirudh Natarajan, Laura Isabel Galindez Olascoaga, Youbin Kim, Braeden C. Benedict, Jan M. Rabaey
On-chip Continuous Pairing, Separation and Electrofusion of Cells Using a Microdroplet.	Cell fusion has been widely applied in scientific research for cancer immunotherapy, antibody production, and nuclear reprogramming of somatic cells, and therefore the cell fusion technique that enable us to precisely control the fusion process with high throughput manner has been desired. Here, we present a novel microfluidic method for automatic cell pairing by microdroplets, separation of droplets containing cells, and electrofusion of cells inside a droplet. The proposed microfluidic device mainly composed of three sequential function parts for (i) encapsulation of cells into a droplet by microfluidic droplet generator, (ii) separation of droplets containing cells from empty droplets through a micropillar array, and (iii) electrofusion of cells inside the droplets by applying a voltage during the droplet passing over the pair of electrodes. In the microfluidic device, cell-encapsulated and empty droplets were generated at the upstream cross-junction; they then entered the micropillar array, separating the cell-encapsulated droplets from empty droplets continuously. After separation, they passed over the electrode pairs, and were collected the outside of the microchannel. This continuous process for cell fusion would enable us to observe and isolate the target fused cells for cell analysis.	https://doi.org/10.1109/ICRA46639.2022.9812390	Naotomo Tottori, Sora Sadamichi, Shinya Sakuma, Tomomi Tsubouchi, Yoko Yamanishi
Online Adaptive Identification and Switching of Soft Contact Model Based on ART-II Method.	In order to obtain a high-precision contact model that can properly describe the target soft tissue, this paper proposes a hybrid soft contact model based on a clustering algorithm ART-II, which selects the most suitable soft contact model according to the surgical environment. The least-square method is used to identify the parameters of the model online. In the experiments, different parts of animal tissues were used as the experimental objects. The hybrid model was used to identify and switch for the most appropriate soft contact model when dealing with a certain type of animal tissue. The performance of the hybrid model on force estimation was compared with several individual soft contact models. The results showed that the estimated/reconstructed force of the hybrid model was closer to the ground truth measured by the force sensor. In addition, a new reference soft contact model has been purposely added online to verify the expandability of the hybrid model.	https://doi.org/10.1109/ICRA46639.2022.9811740	Yi Liu, Di Wu, Fengtao Han, Jing Guo, Zhaoshui He, Chao Liu
Online Assistance Control of a Pneumatic Gait Assistive Suit Using Physical Reservoir Computing Exploiting Air Dynamics.	Wearable gait assistive devices have been im-proved by soft robotics in terms of safety and physical burden of the wearer. Currently, electrical sensors and computers around the wearer are bottlenecks in enhancing the wearer's activities. In this paper, we present a wearable gait assistive system using soft pneumatic system for all the actuation, sensing, and computation. Pneumatic artifical muscles (PAMs) on the thighs were used to generate assistance force, and thin PAMs on the whole legs were used for sensing the wearer's motion. All thin PAMs were connected to each other by tubes, and the pressure response in the tubes were exploited to compute the wearer's motion in manner of physical reservoir computing. The left thigh angular velocity estimated from the reservoir response was used for control the PAMs for actuation. Our experiment with the use of gait assistance showed that the system worked correctly. This paper shows that the pneumatic analog computation system for sensing soft body can help the functionality of soft wearable assistive devices.	https://doi.org/10.1109/ICRA46639.2022.9812377	Hiroyuki Hayashi, Toshihiro Kawase, Tetsuro Miyazaki, Maina Sogabe, Yoshikazu Nakajima, Kenji Kawashima
Online Learning of Centroidal Angular Momentum towards Enhancing DCM-based Locomotion.	Gait generation frameworks for humanoid robots typically assume a constant centroidal angular momentum (CAM) throughout the walking cycle, which induces undesirable contact torques in the feet and results in performance degradation. In this work, we present a novel algorithm to learn the CAM online and include the obtained knowledge within the closed-form solutions of the Divergent Component of Motion (DCM) locomotion framework. To ensure a reduction of the contact torques at the desired center of pressure position, a CAM trajectory is generated and explicitly tracked by a whole-body controller. Experiments with the humanoid robot TORO demonstrate that the proposed method significantly increases the maximum step length and walking speed during locomotion.	https://doi.org/10.1109/ICRA46639.2022.9811708	Robert Schuller, George Mesesan, Johannes Englsberger, Jinoh Lee, Christian Ott
Online Non-linear Centroidal MPC for Humanoid Robot Locomotion with Step Adjustment.	This paper presents a Non-Linear Model Predictive Controller for humanoid robot locomotion with online step adjustment capabilities. The proposed controller considers the Centroidal Dynamics of the system to compute the desired contact forces and torques and contact locations. Differently from bipedal walking architectures based on simplified models, the presented approach considers the reduced centroidal model, thus allowing the robot to perform highly dynamic movements while keeping the control problem still treatable online. We show that the proposed controller can automatically adjust the contact location both in single and double support phases. The overall approach is then tested with a simulation of one-leg and two-leg systems performing jumping and running tasks, respectively. We finally validate the proposed controller on the position-controlled Humanoid Robot iCub. Results show that the proposed strategy prevents the robot from falling while walking and pushed with external forces up to 40 Newton for 1 second applied at the robot arm.	https://doi.org/10.1109/ICRA46639.2022.9811670	Giulio Romualdi, Stefano Dafarra, Giuseppe L'Erario, Ines Sorrentino, Silvio Traversaro, Daniele Pucci
Online Object Model Reconstruction and Reuse for Lifelong Improvement of Robot Manipulation.	This work proposes a robotic pipeline for picking and constrained placement of objects without geometric shape priors. Compared to recent efforts developed for similar tasks, where every object was assumed to be novel, the proposed system recognizes previously manipulated objects and per-forms online model reconstruction and reuse. Over a lifelong manipulation process, the system keeps learning features of objects it has interacted with and updates their reconstructed models. Whenever an instance of a previously manipulated object reappears, the system aims to first recognize it and then register its previously reconstructed model given the current observation. This step greatly reduces object shape uncertainty allowing the system to even reason for parts of objects, which are currently not observable. This also results in better manipulation efficiency as it reduces the need for active perception of the target object during manipulation. To get a reusable reconstructed model, the proposed pipeline adopts: i) TSDF for object representation, and ii) a variant of the standard particle filter algorithm for pose estimation and tracking of the partial object model. Furthermore, an effective way to construct and maintain a dataset of manipulated objects is presented. A sequence of real-world manipulation experiments is performed. They show how future manipulation tasks become more effective and efficient by reusing reconstructed models of previously manipulated objects, which were generated during their prior manipulation, instead of treating objects as novel every time.	https://doi.org/10.1109/ICRA46639.2022.9812440	Shiyang Lu, Rui Wang, Yinglong Miao, Chaitanya Mitash, Kostas E. Bekris
Online Optimal Landing Control of the MIT Mini Cheetah.	Quadrupedal landing is a complex process involving large impacts, elaborate contact transitions, and is a crucial recovery behavior observed in many biological animals. This work presents a real-time, optimal landing controller that is free of pre-specified contact schedules. The controller determines optimal touchdown postures and reaction force profiles and is able to recover from a variety of falling configurations. The quadrupedal platform used, the MIT Mini Cheetah, recovered safely from drops of up to 8 m in simulation, as well as from a range of orientations and planar velocities. The controller is also tested on hardware, successfully recovering from drops of up to 2 m.	https://doi.org/10.1109/ICRA46639.2022.9811796	Se Hwan Jeon, Sangbae Kim, Donghyun Kim
Online Payload Identification for Tactile Robots Using the Momentum Observer.	Knowledge of the robot's load inertial parameters is indispensable for accurate and safe operation, especially in collaborative robotics. However, an intuitive method for online inertial payload identification, usable while the robot is executing another online generated task, is still lacking. In this work, we propose an online payload identification approach based on the momentum observer using proprioceptive sensors of tactile robots and a novel filter design of kinematic measure-ments. Furthermore, we introduce a novel calibration scheme, that allows circumventing constraints of current calibration methods for payload identification. Specifically, the requirement of performing exactly the same motion for calibration as well as for the identification process is released. This is achieved by introducing an average virtual calibration object that improves the robot model for the identification process. In experiments with a Franka Emika Panda robot, it is shown that the proposed methods surpass common methods in terms of identification error. Especially, the novel calibration approach shows high robustness against temporal and spatial misalignment of the motions.	https://doi.org/10.1109/ICRA46639.2022.9811691	Alexander Kurdas, Mazin Hamad, Jonathan Vorndamme, Nico Mansfeld, Saeed Abdolshah, Sami Haddadin
Online Prediction of Lane Change with a Hierarchical Learning-Based Approach.	In the foreseeable future, connected and auto-mated vehicles (CAVs) and human-driven vehicles will share the road networks together. In such a mixed traffic environment, CAVs need to understand and predict maneuvers of surrounding vehicles for safer and more efficient interactions, especially when human drivers bring in a wide range of uncertainties. In this paper, we propose a learning-based lane-change prediction algorithm that considers the driving behaviors of the target human driver. To provide accurate maneuver prediction, we adopt a hierarchical structure that seamlessly seals both the lane-change decision prediction and the vehicle trajectory pre-diction together. Specifically, we propose a lane-change decision prediction method based on a Long-Short Term Memory (LSTM) network, and a trajectories prediction considering driver preference and vehicular interactions based on Inverse Reinforcement Learning (IRL). To validate the performance of the proposed methodology, a case study of an on-ramp merging scenario is conducted on a uniquely built human-in-the-loop simulation platform that can provide an immersive driving environment, collect data of lane-change behaviors, and test drivers' reactions to the prediction results in real time. It is shown in the simulation results that we can predict the lane-change decision 3 seconds before the vehicle crosses the line to another lane, and the Mean Euclidean Distance between the predicted trajectory and ground truth is 0.39 meters within a 4-second prediction window.	https://doi.org/10.1109/ICRA46639.2022.9812269	Xishun Liao, Ziran Wang, Xuanpeng Zhao, Zhouqiao Zhao, Kyungtae Han, Prashant Tiwari, Matthew J. Barth, Guoyuan Wu
Online State-Time Trajectory Planning Using Timed-ESDF in Highly Dynamic Environments.	Online state-time trajectory planning in highly dynamic environments remains an unsolved problem due to the curse of dimensionality of the state-time space. Existing state-time planners are typically implemented based on randomized sampling approaches or path searching on discrete graphs. The smoothness, path clearance, or planning efficiency is sometimes not satisfying. In this work, we propose a gradient-based planner on the state-time space for online trajectory generation in highly dynamic environments. To enable the gradient-based optimization, we propose a Timed-ESDT that supports distance and gradient queries with state-time keys. Based on the Timed-ESDT, we also define a smooth prior and an obstacle likelihood function that are compatible with the state-time space. The trajectory planning is then formulated to a MAP problem and solved by an efficient numerical optimizer. Moreover, to improve the optimality of the planner, we also define a state-time graph and conduct path searching on it to find a better initialization for the optimizer. By integrating the graph searching, the planning quality is significantly improved. Experiments on simulated and benchmark datasets demonstrate the superior performance of our proposes method over conventional ones.	https://doi.org/10.1109/ICRA46639.2022.9812436	Delong Zhu, Tong Zhou, Jiahui Lin, Yuqi Fang, Max Q.-H. Meng
OpenSceneVLAD: Appearance Invariant, Open Set Scene Classification.	Scene classification is a well-established area of computer vision research that aims to classify a scene image into pre-defined categories such as playground, beach and airport. Recent work has focused on increasing the variety of pre-defined categories for classification, but so far failed to consider two major challenges: changes in scene appearance due to lighting and open set classification (the ability to classify unknown scene data as not belonging to the trained classes). Our first contribution, SceneVLAD, fuses scene classification and visual place recognition CNNs for appearance invariant scene classification that outperforms state-of-the-art scene classification by a mean F1 score of up to 0.1. Our second contribution, OpenSceneVLAD, extends the first to an open set classification scenario using intra-class splitting to achieve a mean increase in F1 scores of up to 0.06 compared to using state-of-the-art openmax layer. We achieve these results on three scene class datasets extracted from large scale outdoor visual localisation datasets, one of which we collected ourselves.	https://doi.org/10.1109/ICRA46639.2022.9812248	William H. B. Smith, Michael Milford, Klaus D. McDonald-Maier, Shoaib Ehsan, Robert B. Fisher
Optimal Control via Combined Inference and Numerical Optimization.	Derivative based optimization methods are efficient at solving optimal control problems near local optima. However, their ability to converge halts when derivative information vanishes. The inference approach to optimal control does not have strict requirements on the objective landscape. However, sampling, the primary tool for solving such problems, tends to be much slower in computation time. We propose a new method that combines second order methods with inference. We utilise the Kullback Leibler (KL) control framework to formulate an inference problem that computes the optimal controls from an adaptive distribution approximating the solution of the second order method. Our method allows for combining simple convex and non convex cost functions. This simplifies the process of cost function design and leverages the strengths of both inference and second order optimization. We compare our method to Model Predictive Path Integral (MPPI) and iterative Linear Quadratic Gaussian controller (iLQG), outperforming both in sample efficiency and quality on manipulation and obstacle avoidance tasks.	https://doi.org/10.1109/ICRA46639.2022.9811908	Daniel Layeghi, Steve Tonneau, Michael N. Mistry
Optimal Design and Control of an Aerial Manipulator with Elastic Suspension Using Unidirectional Thrusters.	Aerial Manipulators with Elastic Suspension (AMES) may be seen as a hybrid robot mixing properties of classical Aerial Manipulators (AMs) and Cable-Driven Parallel Robots (CDPRs). The optimal design and control of an AMES using unidirectional thrusters are considered in this paper. To maximize the workspace, an optimization algorithm is proposed. The position and orientation of the thrusters are optimized by adapting methods borrowed from both the AM and CDPR communities. The resulting design is used to build a prototype. Preliminary experimentations are carried out to validate the theoretical workspace and assess the trajectory tracking performance of this AMES. Experiments highlight the significant improvements with respect to a previous suboptimal prototype.	https://doi.org/10.1109/ICRA46639.2022.9811775	Miguel Arpa Perozo, Jean Dussine, Arda Yigit, Loïc Cuvillon, Sylvain Durand, Jacques Gangloff
Optimal Inverted Landing in a Small Aerial Robot with Varied Approach Velocities and Landing Gear Designs.	Inverted landing is a challenging feat to perform in aerial robots, especially without external positioning. However, it is routinely performed by biological fliers such as bees, flies, and bats. Our previous observations of landing behaviors in flies suggest an open-loop causal relationship between their putative visual cues and the kinematics of the aerial maneuvers executed. For example, the degree of rotational maneuver (the amount of body inversion prior to touchdown) and the amount of leg-assisted body swing both depend on the flies' initial body states while approaching the ceiling. In this work, inspired by the inverted landing behavior of flies, we used a physics-based simulation with experimental validation to systematically investigate how optimized inverted landing maneuvers depend on the initial approach velocities with varied magnitude and direction. This was done by analyzing the putative visual cues (that can be derived from onboard measurements) during optimal maneuvering trajectories. We identified a three-dimensional policy region, from which a mapping to a global inverted landing policy can be developed without the use of external positioning data. Through simulation, we also investigated the effects of an array of landing gear designs on the optimized landing performance and identified their advantages and disadvantages. The above results have been partially validated using limited experimental testing and will continue to inform and guide our future experiments, for example by applying the calculated global policy.	https://doi.org/10.1109/ICRA46639.2022.9812409	Bryan Habas, Bader AlAttar, Brian Davis, Jack W. Langelaan, Bo Cheng
Optimal Thrust Vector Control of an Electric Small-Scale Rocket Prototype.	Recent advances in Model Predictive Control (MPC) algorithms and methodologies, combined with the surge of computational power of available embedded platforms, allows the use of real-time optimization-based control of fast mechatronic systems. This paper presents an implementation of an optimal guidance, navigation and control (GNC) system for the motion control of a small-scale electric prototype of a thrust-vectored rocket. The aim of this prototype is to provide an inexpensive platform to explore GNC algorithms for automatic landing of sounding rockets. The guidance and trajectory tracking are formulated as continuous-time optimal control problems and are solved in real-time on embedded hardware using the PolyMPC library. An Extended Kalman Filter (EKF) is designed to estimate external disturbances and actuators offsets. Finally, indoor and outdoor flight experiments are performed to validate the architecture.	https://doi.org/10.1109/ICRA46639.2022.9811938	Raphaël Linsen, Petr Listov, Albéric de Lajarte, Roland Schwan, Colin N. Jones
Optimal and Bounded-Suboptimal Multi-Goal Task Assignment and Path Finding.	We formalize and study the multi-goal task assignment and path finding (MG-TAPF) problem from theoretical and algorithmic perspectives. The MG-TAPF problem is to compute an assignment of tasks to agents, where each task consists of a sequence of goal locations, and collision-free paths for the agents that visit all goal locations of their assigned tasks in sequence. Theoretically, we prove that the MG-TAPF problem is NP-hard to solve optimally. We present algorithms that build upon algorithmic techniques for the multi-agent path finding problem and solve the MG-TAPF problem optimally and bounded-suboptimally. We experimentally compare these algorithms on a variety of different benchmark domains.	https://doi.org/10.1109/ICRA46639.2022.9812020	Xinyi Zhong, Jiaoyang Li, Sven Koenig, Hang Ma
Optimal-Horizon Model Predictive Control with Differential Dynamic Programming.	We present an algorithm, based on the Differential Dynamic Programming framework, to handle trajectory optimization problems in which the horizon is determined online rather than fixed a priori. This algorithm exhibits exact one-step convergence for linear, quadratic, time-invariant problems and is fast enough for real-time nonlinear model-predictive control. We show derivations for the nonlinear algorithm in the discrete-time case, and apply this algorithm to a variety of nonlinear problems. Finally, we show the efficacy of the optimal-horizon model-predictive control scheme compared to a standard MPC controller, on an obstacle-avoidance problem with planar robots.	https://doi.org/10.1109/ICRA46639.2022.9812036	Kyle Stachowicz, Evangelos A. Theodorou
Optimizing Camera Placements for Overlapped Coverage with 3D Camera Projections.	This paper proposes a method to compute camera 6 DoF poses to achieve a user defined coverage. The camera placement problem is modeled as a combinatorial optimization where given the maximum number of cameras, a camera set is selected from a larger pool of possible camera poses. We propose to minimize the squared error between the desired and the achieved coverage, and formulate the non-linear cost function as a mixed integer linear programming problem. A camera lens model is utilized to project the camera's view on a 3D voxel map to compute a coverage score which makes the optimization problem in real environments tractable. Experimental results in two real retail store environments demonstrate the better performance of the proposed formulation in terms of coverage and overlap for triangulation compared to existing methods.	https://doi.org/10.1109/ICRA46639.2022.9812042	Akshay Malhotra, Dhananjay Singh, Tushar Dadlani, Luis Yoichi Morales
Optimizing Multi-Robot Placements for Wire Arc Additive Manufacturing.	Wire arc additive manufacturing is a metal additive manufacturing process in which the material is deposited using arc welding technology. It is gaining popularity due to high material deposition rates and faster build time. It is en-abled using robotic manipulators and can build relatively large-scale parts faster when compared with other metal additive manufacturing processes. However, the size of the large-scale parts is limited by the size of the industrial manipulator being used for the process. This limitation is overcome by using a fixed configuration multi-robot cell in which manipulators work cooperatively to build large-scale parts quickly. A fixed multi-robot cell with closely spaced industrial manipulators has high flexibility, but it restricts the part size that can be built. If the manipulators are spread out, the cell loses its flexibility but can build relatively larger parts. This issue can be avoided by using larger size manipulators, which are expensive, or by moving the modest size manipulators based on the part geometries. This paper presents a novel algorithm to generate multi-robot placements for different part geometries to be built using wire arc additive manufacturing. Furthermore, the algorithm hierarchically optimizes the build time and the inverse kinematics consistency in robot paths to improve the process efficiency and part quality. We compare the results with fixed multi-robot cells and provide insights to users to make an informed decision on whether to use a fixed or a flexible multi-robot cell for wire arc additive manufacturing.	https://doi.org/10.1109/ICRA46639.2022.9812318	Prahar M. Bhatt, Andrzej Nycz, Satyandra K. Gupta
Optimizing Space Utilization for More Effective Multi-Robot Path Planning.	We perform a systematic exploration of the principle of Space Utilization Optimization (SUO) as a heuristic for planning better individual paths in a decoupled multi-robot path planner, with applications to both one-shot and life-long multi-robot path planning problems. We show that the heuristic set, SU - I, preserves single path optimality and significantly reduces congestion that naturally happens when many paths are planned without coordination. Integration of SU - I into complete planners brings dramatic reductions in computation time due to the significantly reduced number of conflicts and leads to sizable solution optimality gains in diverse evaluation scenarios over medium and large maps, for both one-shot and life-long problem settings.	https://doi.org/10.1109/ICRA46639.2022.9812357	Shuai D. Han, Jingjin Yu
Optimizing Terrain Mapping and Landing Site Detection for Autonomous UAVs.	The next generation of Mars rotorcrafts requires on-board autonomous hazard avoidance landing. To this end, this work proposes a system that performs continuous multi-resolution height map reconstruction and safe landing spot detection. Structure-from-Motion measurements are aggregated in a pyramid structure using a novel Optimal Mixture of Gaus-sians formulation that provides a comprehensive uncertainty model. Our multiresolution pyramid is built more efficiently and accurately than past work by decoupling pyramid filling from the measurement updates of different resolutions. To detect the safest landing location, after an optimized hazard segmentation, we use a mean shift algorithm on multiple distance transform peaks to account for terrain roughness and uncertainty. The benefits of our contributions are evaluated on real and synthetic flight data.	https://doi.org/10.1109/ICRA46639.2022.9811789	Pedro F. Proença, Jeff Delaune, Roland Brockers
Optimizing Trajectories with Closed-Loop Dynamic SQP.	"Indirect trajectory optimization methods such as Differential Dynamic Programming (DDP) have found considerable success when only planning under dynamic feasibility constraints. Meanwhile, nonlinear programming (NLP) has been the state-of-the-art approach when faced with additional constraints (e.g., control bounds, obstacle avoidance). However, a naïve implementation of NLP algorithms, e.g., shooting-based sequential quadratic programming (SQP), may suffer from slow convergence – caused from natural instabilities of the underlying system manifesting as poor numerical stability within the optimization. Re-interpreting the DDP closed-loop rollout policy as a sensitivity-based correction to a second-order search direction, we demonstrate how to compute analogous closedloop policies (i.e., feedback gains) for constrained problems. Our key theoretical result introduces a novel dynamic programmingbased constraint-set recursion that augments the canonical ""cost-to-go"" backward pass. On the algorithmic front, we develop a hybrid-SQP algorithm incorporating DDP-style closedloop rollouts, enabled via efficient parallelized computation of the feedback gains. Finally, we validate our theoretical and algorithmic contributions on a set of increasingly challenging benchmarks, demonstrating significant improvements in convergence speed over standard open-loop SQP."	https://doi.org/10.1109/ICRA46639.2022.9811562	Sumeet Singh, Jean-Jacques E. Slotine, Vikas Sindhwani
Opto-electrotactile Feedback Enabled Text-line Tracking Control for A Finger-wearable Reading Aid for the Blind.	"In this paper, to achieve the goal of aiding the blind and visually impaired (BVI) to read any text not written in Braille, a custom-built, finger-wearable, and electro-tactile based Braille reading system with its Rapid Optical Character Recognition (R-OCR) method is developed. The R-OCR is capable of processing text information in real time using a miniature fish-eye imaging device mounted at the finger-wearable system. This allows real-time translation of printed text to electro-Braille along with natural movement of user's fingertip as if reading any Braille sign or book. An electro-tactile neuro-stimulation feedback mechanism is further proposed and incorporated with the reading system, which facilitates a new opto-electrotactile-feedback-based text line tracking control approach that enables text line following by user's fingertip during reading. Extensive experiments were designed and conducted to test the ability of blindfolded participants to read through and follow the printed text lines based on this optoelectrotactile-feedback method. The experimental results show that as the outcome of the opto-electrotactile-feedback, the users who involved in the feedback loop were able to maintain their fingertips within a 2mm distance of the text while ""reading"" through a printed text line. Our work is a significant step to aid the BVI users with a portable means to read any printed texts to Braille through the following and the translation, whether in the digital realm or physically, on any surface."	https://doi.org/10.1109/ICRA46639.2022.9811610	Mehdi Rahimi, Yantao Shen, Cong Peng, Zhiming Liu, Fang Jiang
Orientation to Pose: Continuum Robots Shape Reconstruction Based on the Multi-Attitude Solving Approach.	Continuum robots are typically slender and flexible with infinite freedoms in theory, which poses a challenge for their control and application. The shape reconstruction of continuum robots is vital to realize closed-loop control. This paper proposes a novel general real-time shape reconstruction framework of continuum robots based on the piecewise polynomial curvature (PPC) kinematics model. We illustrate the coupling between orientation and position at any given location of the continuum robots. Further, the coupling relation could be bridged by the PPC kinematics. Therefore, we propose to estimate the shape through multi-attitude solving, using the off-the-shelf orientation sensors, e.g., IMUs, mounted on certain locations. The approach gives a valuable framework to real-time shape reconstruction of continuum robots, which is general, accurate and convenient. The accuracy of our approach is verified in the experiments of distinct physical prototypes.	https://doi.org/10.1109/ICRA46639.2022.9812289	Hao Cheng, Hejie Xu, Hongji Shang, Xueqian Wang, Houde Liu, Bin Liang
Oriented Surface Reachability Maps for Robot Placement.	For a robot to perform a grasping and manipulation task, it has to determine possible robot placements in the workspace, from which target objects or environmental elements relevant to the given task are reachable. This work presents a novel approach for finding placements for the mobile base of a humanoid robot in an unknown environment with multiple support planes. We propose a novel type of reachability map - the Oriented Surface Reachability Map - that takes inclined surfaces in the environment into account and has the same complexity as reachability maps designed for flat surfaces. The resulting robot placements are not limited to SE(2) but can be applied to arbitrarily oriented planes in 3D space. The proposed method was evaluated in simulation and on the humanoid robot ARMAR-6 in real-world grasping experiments. The results show that a placement can be found for over 80% of the poses that are reachable in complicated, simulated environments, with only a small runtime overhead.	https://doi.org/10.1109/ICRA46639.2022.9811600	Timo Birr, Christoph Pohl, Tamim Asfour
PA-AWCNN: Two-stream Parallel Attention Adaptive Weight Network for RGB-D Action Recognition.	Due to overly relying on appearance information or adopting direct static feature fusion, most of the existing action recognition methods based on multi-modality have poor robustness and insufficient consideration of modality differences. To address these problems, we propose a two-stream adaptive weight integration network with a three-dimensional parallel attention module, PA-AWCNN. Firstly, a three-dimensional Parallel Attention (PA) module is proposed to effectively extract features of spatial, temporal and channel dimensions and reduce the cross-dimensional interference, to achieve better robustness. Secondly, a Common Feature-driven (CFD) feature integration module is proposed to dynamically integrate appearance and depth features with adaptive weights, utilizing modality differences to redeem the lack of each feature, thereby balance the influence of both. The proposed PA-AW CNN uses the representative integrated feature generated by attention enhancement and feature integration for action recognition; it can not only get higher recognition accuracy but also improve the performance of distinguishing similar actions. Experiments illustrate that the proposed method achieves com-parable performances to state-of-the-art methods and obtains the accuracy of 92.76% and 95.65% on NTU RGB+D Dataset and SBU Kinect Interaction Dataset, respectively. The code is publicly available at: https://github.com/Luu-Yao/PA-AWCNN.	https://doi.org/10.1109/ICRA46639.2022.9811995	Lu Yao, Sheng Liu, Chaonan Li, Siyu Zou, Shengyong Chen, Diyi Guan
PF-MOT: Probability Fusion Based 3D Multi-Object Tracking for Autonomous Vehicles.	3D Multi-Object Tracking (MOT) plays a crucial role in efficient and safe operation of automatic driving, especially in scenarios of occlusion or poor visibility. Most 3D MOT methods leverage only positional distance, which is insufficient for scenes with high density of objects or drastic changes in the motion state. In order to address this, we propose a new 3D MOT model which fuses information pertaining to positional distance and geometric similarity. Our proposed solution comprises of four parts: a) a feature extraction mechanism integrated into a commonly used detector to extract individual features for each detection, b) computation of two distance matrices based on Euclidean distance and feature similarity, c) conversion of the distance matrices to probability matrices by a cluster based Earth-Mover Distance (EMD) algorithm, and d) a data association method that fuses both sources to boost the tracking accuracy. Our proposed model demonstrates state-of-the-art performance on the nuScenes tracking dataset, with extensive experiments attesting to an improved tracking accuracy over baselines that operate solely on positional distance.	https://doi.org/10.1109/ICRA46639.2022.9811653	Tao Wen, Yanyong Zhang, Nikolaos M. Freris
Panoptic Multi-TSDFs: a Flexible Representation for Online Multi-resolution Volumetric Mapping and Long-term Dynamic Scene Consistency.	For robotic interaction in environments shared with other agents, access to volumetric and semantic maps of the scene is crucial. However, such environments are inevitably subject to long-term changes, which the map needs to account for. We thus propose panoptic multi-TSDFs as a novel representation for multi-resolution volumetric mapping in changing environments. By leveraging high-level information for 3D reconstruction, our proposed system allocates high resolution only where needed. Through reasoning on the object level, semantic consistency over time is achieved. This enables our method to maintain up-to-date reconstructions with high accuracy while improving coverage by incorporating previous data. We show in thorough experimental evaluation that our map can be efficiently constructed, maintained, and queried during online operation, and that the presented approach can operate robustly on real depth sensors using non-optimized panoptic segmentation as input.	https://doi.org/10.1109/ICRA46639.2022.9811877	Lukas Schmid, Jeffrey A. Delmerico, Johannes L. Schönberger, Juan I. Nieto, Marc Pollefeys, Roland Siegwart, César Cadena
Parametric Path Optimization for Wheeled Robots Navigation.	Collision risk and smoothness are the most important factors in global path planning. Currently, planning methods that reduce global path collision risk and improve its smoothness through numerical optimization have achieved good results. However, these methods cannot always optimize the path. The reason is all points on the path are considered as decision variables, which leads to the high dimensionality of the defined optimization problem. Therefore, we propose a novel global path optimization method. The method characterizes the path as a parametric curve and then optimizes the curve's parameters with a defined objective function, which successfully reduces the dimension of optimization problem. The proposed method is compared with baseline and state-of-the-art methods. Experimental results show the path optimized by our method is not only optimal in collision risk, but also in efficiency and smoothness. Furthermore, the proposed method is also implemented and tested in both simulation and real robots.	https://doi.org/10.1109/ICRA46639.2022.9812167	Zhiqiang Jian, Songyi Zhang, Jiahui Zhang, Shitao Chen, Nanning Zheng
PatchGraph: In-hand tactile tracking with learned surface normals.	We address the problem of tracking 3D object poses from touch during in-hand manipulations. Specifically, we look at tracking small objects using vision-based tactile sensors that provide high-dimensional tactile image measurements at the point of contact. While prior work has relied on a-priori information about the object being localized, we remove this requirement. Our key insight is that an object is composed of several local surface patches, each informative enough to achieve reliable object tracking. Moreover, we can recover the geometry of this local patch online by extracting local surface normal information embedded in each tactile image. We propose a novel two-stage approach. First, we learn a mapping from tactile images to surface normals using an image translation network. Second, we use these surface normals within a factor graph to both reconstruct a local patch map and use it to infer 3D object poses. We demonstrate reliable object tracking for over 100 contact sequences across unique shapes with four objects in simulation and two objects in the real-world.	https://doi.org/10.1109/ICRA46639.2022.9811953	Paloma Sodhi, Michael Kaess, Mustafa Mukadam, Stuart Anderson
Path-Aware Graph Attention for HD Maps in Motion Prediction.	The success of motion prediction for autonomous driving relies on integration of information from the HD maps. As maps are naturally graph-structured, investigation on graph neural networks (GNNs) for encoding HD maps is burgeoning in recent years. However, unlike many other applications where GNNs have been straightforwardly deployed, HD maps are heterogeneous graphs where vertices (lanes) are connected by edges (lane-lane interaction relationships) of various nature, and most graph-based models are not designed to understand the variety of edge types which provide crucial cues for predicting how the agents would travel the lanes. To overcome this challenge, we propose Path-Aware Graph Attention, a novel attention architecture that infers the attention between two vertices by parsing the sequence of edges forming the paths that connect them. Our analysis illustrates how the proposed attention mechanism can facilitate learning in a didactic problem where existing graph networks like GCN struggle. By improving map encoding, the proposed model surpasses previous state of the art on the Argoverse Motion Forecasting dataset, and won the first place in the 2021 Argoverse Motion Forecasting Competition.	https://doi.org/10.1109/ICRA46639.2022.9812100	Fang Da, Yu Zhang
Patient-tailored Adaptive Control for Robot-aided Orthopaedic Rehabilitation.	Robot-aided rehabilitation is pushing forward novel robotic architectures to provide physical therapy. This paper presents a patient-tailored control architecture for upper-limb robot-aided orthopaedic rehabilitation capable of i) adapting the robot workspace on the basis of patient Range of Motion (RoM); ii) generating a tunnel, around the desired path to be followed by the patient, which guarantees spatial autonomy; iii) introducing a back-wall inside the tunnel sliding with variable speed on the basis of patient performance to ensure temporal autonomy; iv) rehabilitating to working gestures, thanks to a DMP-based trajectory planner, with the aim of favoring an effective translation of the patient's motor recovery results to the occupational sphere; v) ensuring a patient-tailored assistance also thanks to the evaluation of performance indicators. The designed system was validated demonstrating the adaptability of the system to orthopaedic patient motor imnrovements.	https://doi.org/10.1109/ICRA46639.2022.9811791	Christian Tamantini, Francesca Cordella, Clemente Lauretti, Francesco Scotto di Luzio, Marco Bravi, Federica Bressi, Francesco Draicchio, Silvia Sterzi, Loredana Zollo
Pedestrian Stop and Go Forecasting with Hybrid Feature Fusion.	Forecasting pedestrians' future motions is essential for autonomous driving systems to safely navigate in urban areas. However, existing prediction algorithms often overly rely on past observed trajectories and tend to fail around abrupt dynamic changes, such as when pedestrians suddenly start or stop walking. We suggest that predicting these highly non-linear transitions should form a core component to improve the robustness of motion prediction algorithms. In this paper, we introduce the new task of pedestrian stop and go forecasting. Considering the lack of suitable existing datasets for it, we release TRANS, a benchmark for explicitly studying the stop and go behaviors of pedestrians in urban traffic. We build it from several existing datasets annotated with pedestrians' walking motions, in order to have various scenarios and behaviors. We also propose a novel hybrid model that leverages pedestrian-specific and scene features from several modalities, both video sequences and high-level attributes, and gradually fuses them to integrate multiple levels of context. We evaluate our model and several baselines on TRANS, and set a new benchmark for the community to work on pedestrian stop and go forecasting.	https://doi.org/10.1109/ICRA46639.2022.9811664	Dongxu Guo, Taylor Mordan, Alexandre Alahi
Perception Engine Using a Multi-Sensor Head to Enable High-level Humanoid Robot Behaviors.	For achieving significant levels of autonomy, legged robot behaviors require perceptual awareness of both the terrain for traversal, as well as structures and objects in their surroundings for planning, obstacle avoidance, and high-level decision making. In this work, we present a perception engine for legged robots that extracts the necessary information for developing semantic, contextual, and metric awareness of their surroundings. Our custom sensor configuration consists of (1) an active depth sensor, (2) two monocular cameras looking sideways, (3) a passive stereo sensor observing the terrain, (4) a forward facing active depth camera, and (5) a rotating 3D LIDAR with a large vertical field-of-view (FOV). The mutual overlap in the sensors' FOVs allows us to redundantly detect and track objects of both dynamic and static types. We fuse class masks generated by a semantic segmentation model with LIDAR and depth data to accurately identify and track individual instances of dynamically moving objects. In parallel, active depth and passive stereo streams of the terrain are also fused to map the terrain using the on-board GPU. We evaluate the engine using two different humanoid behaviors, (1) look-and-step and (2) track-and-follow, on the Boston Dynamics Atlas.	https://doi.org/10.1109/ICRA46639.2022.9812178	Bhavyansh Mishra, Duncan Calvert, Brendon Ortolano, Max Asselmeier, Luke Fina, Stephen McCrory, Hakki Erhan Sevil, Robert J. Griffin
Perception-Friendly Video Enhancement for Autonomous Driving under Adverse Weather Conditions.	Visual perception of an autonomous vehicle is a crucial component of autonomous driving technologies. While visual perception research has achieved promising performance in recent years, modern methods are mostly trained, applied, and tested on single clean images. Recently, deep learning-based perception methods have addressed multiple degrading effects to reflect real-world bad weather cases, but have achieved only limited success, mainly due to 1) less or no temporal information across adjacent frames and 2) poor correlation between image enhancement and visual perception performance. To solve these issues, in this paper we propose a simple and effective video enhancement network incorporating the perception module, one of the high-level vision tasks, which takes video degraded by adverse weather conditions as an input, and produces an enhanced image and a recognition result as output. Besides, this allows us to leverage temporal information across consecutive frames without flow estimation. We also introduce a new training strategy to robustly guide the high-level task model suitable for both high-quality restoration of images and highly accurate perception. Further, considering sequence-level discrimination, we propose a Sequential Contrastive Loss, called SCL, to maximize apparent discrimination over sequential input. By doing this, our algorithm achieves full interaction showing mutual influence between the enhancement and perception tasks. Further, we introduce a novel low memory network dropping out most of the layer connections of dense blocks to reduce memory usage and computational cost while maintaining high performance. Experiment results demonstrate that the proposed method significantly improves the performance on object detection, distance estimation, and memory usage under adverse weather.	https://doi.org/10.1109/ICRA46639.2022.9811870	Younkwan Lee, YeongMin Ko, Yechan Kim, Moongu Jeon
Performance Guarantees for Spectral Initialization in Rotation Averaging and Pose-Graph SLAM.	In this work we present the first initialization methods equipped with explicit performance guarantees that are adapted to the pose-graph simultaneous localization and mapping (SLAM) and rotation averaging (RA) problems. SLAM and rotation averaging are typically formalized as large-scale nonconvex point estimation problems, with many bad local minima that can entrap the smooth optimization methods typically applied to solve them; the performance of standard SLAM and RA algorithms thus crucially depends upon the quality of the estimates used to initialize this local search. While many initialization methods for SLAM and RA have appeared in the literature, these are typically obtained as purely heuristic approximations, making it difficult to determine whether (or under what circumstances) these techniques can be reliably deployed. In contrast, in this work we study the problem of initialization through the lens of spectral relaxation. Specifically, we derive a simple spectral relaxation of SLAM and RA, the form of which enables us to exploit classical linear-algebraic techniques (eigenvector perturbation bounds) to control the distance from our spectral estimate to both the (unknown) ground-truth and the global minimizer of the estimation prob lem as a function of measurement noise. Our results reveal the critical role that spectral graph-theoretic properties of the measurement network play in controlling estimation accuracy; moreover, as a by-product of our analysis we obtain new bounds on the estimation error for the maximum likelihood estimators in SLAM and RA, which are likely to be of independent interest. Finally, we show experimentally that our spectral estimator is very effective in practice, producing initializations of comparable or superior quality at lower computational cost compared to existing state-of-the-art techniques.	https://doi.org/10.1109/ICRA46639.2022.9811788	Kevin J. Doherty, David M. Rosen, John J. Leonard
Periodic SLAM: Using Cyclic Constraints to Improve the Performance of Visual-Inertial SLAM on Legged Robots.	Methods for state estimation that rely on visual information are challenging on legged robots due to rapid changes in the viewing angle of onboard cameras. In this work, we show that by leveraging structure in the way that the robot locomotes, the accuracy of visual-inertial SLAM in these challenging scenarios can be increased. We present a method that takes advantage of the underlying periodic predictability often present in the motion of legged robots to improve the performance of the feature tracking module within a visual-inertial SLAM system. Our method performs multi-session SLAM on a single robot, where each session is responsible for mapping during a distinct portion of the robot's gait cycle. Our method produces lower absolute trajectory error than several state-of-the-art methods for visual-inertial SLAM in both a simulated environment and on data collected on a quadrupedal robot executing dynamic gaits. On real-world bounding gaits, our median trajectory error was less than 35% of the error of the next best estimate provided by state-of-the-art methods.	https://doi.org/10.1109/ICRA46639.2022.9811634	Hans Kumar, J. Joe Payne, Matthew J. Travers, Aaron M. Johnson, Howie Choset
Persistent Homology for Effective Non-Prehensile Manipulation.	This work explores the use of topological tools for achieving effective non-prehensile manipulation in cluttered, constrained workspaces. In particular, it proposes the use of persistent homology as a guiding principle in identifying the appropriate non-prehensile actions, such as pushing, to clean a cluttered space with a robotic arm so as to allow the retrieval of a target object. Persistent homology enables the automatic identification of connected components of blocking objects in the space without the need for manual input or tuning of parameters. The proposed algorithm uses this information to push groups of cylindrical objects together and aims to minimize the number of pushing actions needed to reach to the target. Simulated experiments in a physics engine using a model of the Baxter robot show that the proposed topology-driven solution is achieving significantly higher success rate in solving such constrained problems relatively to state-of-the-art alternatives from the literature. It manages to keep the number of pushing actions low, is computationally efficient and the resulting decisions and motion appear natural for effectively solving such tasks.	https://doi.org/10.1109/ICRA46639.2022.9811848	Ewerton R. Vieira, Daniel Nakhimovich, Kai Gao, Rui Wang, Jingjin Yu, Kostas E. Bekris
Personalized Car Following for Autonomous Driving with Inverse Reinforcement Learning.	Driving automation is gradually replacing human driving maneuvers in different applications such as adaptive cruise control and lane keeping. However, contemporary driving automation applications based on expert systems or prede-fined control strategies are not in line with individual human driver's preference. To overcome this problem, we propose a Personalized Adaptive Cruise Control (P-ACC) system that can learn the driver's car-following preferences from historical data using model-based maximum entropy Inverse Reinforcement Learning (IRL). Once activated in real-time, the P-ACC system first classifies the driver type and the weather type (at that moment). The vehicle is then controlled using the pre-trained IRL model on the cloud of the associated class. The personalized IRL model on the cloud will be updated as more human driving data is collected from various scenarios. Numerical simulation with real-world naturalistic driving data shows that, the accuracy of reproducing the real-world driving profile improves up to 30.1% in terms of speed and 36.5% in terms of distance gap, when P-ACC is compared with the Intelligent Driver Model (IDM). Game engine-based human-in-the-loop simulation demonstrates that, the takeover frequency of the driver during the usage of P-ACC decreases up to 93.4%, compared with that during the usage of IDM-based ACC.	https://doi.org/10.1109/ICRA46639.2022.9812446	Zhouqiao Zhao, Ziran Wang, Kyungtae Han, Rohit Gupta, Prashant Tiwari, Guoyuan Wu, Matthew J. Barth
Physical Property Estimation and Knife Trajectory Optimization During Robotic Cutting.	Dexterous robotic cutting needs to demonstrate a skill level with smooth and efficient knife movements. The work performed by the knife mainly generates fracture and overcomes the blade-material friction. This paper presents a recursive least-squares method that repeatedly estimates relevant physical parameters such as Poisson's ratio, fracture toughness, and coefficient of friction, all varying with the knife's movement when cutting a natural food, from force sensor readings. Furthermore, we show that these estimates can be used for generating the knife's trajectory on the fly to either maximize the ease of fracturing or to minimize the rate of work.	https://doi.org/10.1109/ICRA46639.2022.9811894	Xiaoqian Mu, Yan-Bin Jia
PixSelect: Less but Reliable Pixels for Accurate and Efficient Localization.	Accurate camera pose estimation is a fundamental requirement for numerous applications, such as autonomous driving, mobile robotics, and augmented reality. In this work, we address the problem of estimating the global 6 DoF camera pose from a single RGB image in a given environment. Previous works consider every part of the image valuable for localization. However, many image regions such as the sky, occlusions, and repetitive non-distinguishable patterns cannot be utilized for localization. In addition to adding unnecessary computation efforts, extracting and matching features from such regions pro-duce many wrong matches which in turn degrades the localization accuracy and efficiency. Our work addresses this particular issue and shows by exploiting an interesting concept of sparse 3D models that we can exploit discriminatory environment parts and avoid useless image regions for the sake of a single image localization. Interestingly, through avoiding selecting keypoints from non-reliable image regions such as trees, bushes, cars, pedestrians, and occlusions, our work acts naturally as an outlier filter. This makes our system highly efficient in that minimal set of correspondences is needed and highly accurate as the number of outliers is low. Our work exceeds state-of-the-art methods on outdoor Cambridge Landmarks dataset. With only relying on single image at inference, it outweighs in terms of accuracy methods that exploit pose priors and/or reference 3D models while being much faster. By choosing as little as 100 correspondences, it surpasses similar methods that localize from thousands of correspondences, while being more efficient. In particular, it achieves, compared to these methods, an improvement of localization by 33% on OldHospital scene. Furthermore, It outstands direct pose regressors even those that learn from sequence of images. Our work will be publicly available.	https://doi.org/10.1109/ICRA46639.2022.9812345	Mohammad Altillawi
Planning Natural Locomotion for Articulated Soft Quadrupeds.	Embedding elastic elements into legged robots through mechanical design enables highly efficient oscillating patterns that resemble natural gaits. However, current trajectory planning techniques miss the opportunity of taking advantage of these natural motions. This work proposes a locomotion planning method that aims to unify traditional trajectory generation with modal oscillations. Our method utilizes task-space linearized modes for generating center of mass trajectories on the sagittal plane. We then use nonlinear optimization to find the gait timings that match these trajectories within the Divergent Component of Motion planning framework. This way, we can robustly translate the modes-aware centroidal motions into joint coordinates. We validate our approach with promising results and insights through experiments on a compliant quadrupedal robot.	https://doi.org/10.1109/ICRA46639.2022.9812416	Mathew Jose Pollayil, Cosimo Della Santina, George Mesesan, Johannes Englsberger, Daniel Seidel, Manolo Garabini, Christian Ott, Antonio Bicchi, Alin Albu-Schäffer
Planning and Control for Cable-routing with Dual-arm Robot.	In this paper, we propose a new framework for solving cable-routing problems with a dual-arm robot, where the objective is to clip a Deformable Linear Object (DLO) into several arbitrarily placed fixtures. The core of the framework is a task-space planner, which builds a roadmap from predefined tasks and employs a replanning strategy based on a genetic algorithm, if problems occur. The manipulation tasks are executed with either individual or coordinated control of the arms. Moreover, hierarchical quadratic programming is used to solve the inverse differential kinematics together with extra feasibility objectives. A vision system first identifies the desired fixture route and structure preserved registration estimates the state of the DLO in real-time. The framework is tested on real-world experiments with a YuMi robot, demonstrating a 90% success rate for 3 fixture problems.	https://doi.org/10.1109/ICRA46639.2022.9811765	Gabriel Arslan Waltersson, Rita Laezza, Yiannis Karayiannidis
Planning via model checking with decision-tree controllers.	"Planning problems can be solved not only by planners, but also by model checkers. While the former yield a plan that requires replanning as soon as any fault occurs, the latter provide a ""universal"" plan (a.k.a. strategy, policy, or controller) able to make decisions under all circumstances. One of the prohibitive aspects of the latter approach is stemming from this very advantage: since it is defined for all possible states of the system, it is typically so large that it does not fit into small memories of embedded devices. As another consequence of the size, its execution may be slow. In this paper, we provide a solution to this issue by linking the model checkers with decision-tree learners, resulting in decision-tree representations of the synthesized strategies. Not only are they dramatically smaller, but also more explainable and orders-of-magnitude faster to execute than plans with replanning. In addition, we describe a method for model validation and debugging via the model checker and the decision-tree learner in the loop. We illustrate the approach on our case study of a robotic arm for picking items in a real industrial setting."	https://doi.org/10.1109/ICRA46639.2022.9811980	Jonis Kiesbye, Kush Grover, Pranav Ashok, Jan Kretínský
PogoDrone: Design, Model, and Control of a Jumping Quadrotor.	We present a design, model, and control for a novel jumping-flying robot that is called PogoDrone. The robot is composed of a quadrotor with a passive mechanism for jumping. The robot can continuously jump in place or fly like a normal quadrotor. Jumping in place allows the robot to quickly move and operate very close to the ground. For instance, in agricultural applications, the jumping mechanism allows the robot to take samples of soil. We propose a hybrid controller that switches from attitude to position control to allow the robot to fall horizontally and recover to the original position. We compare the jumping mode with the hovering mode to analyze the energy consumption. In simulations, we evaluate the effect of different factors on energy consumption. In real experiments, we show that our robot can repeatedly impact the ground, jump, and fly in a physical environment.	https://doi.org/10.1109/ICRA46639.2022.9811970	Brian Zhu, Jiawei Xu, Andrew Charway, David Saldaña
Pose Estimation based on a Dual Quaternion Feedback Particle Filter.	Fast and accurate pose estimation is essential for many robotic applications such as SLAM, manipulation, and 3D point registration. Existing solutions to this problem suffer from either high computation overhead due to the nonlinear features or accuracy loss due to linear approximation. In this paper, we propose a dual quaternion feedback particle filter (DQFPF) that can capture the nonlinear factors in the observation model and use the optimal control theory to estimate the pose. To avoid particle degeneracy caused by sequential importance sampling and resampling, we present a feedback particle update formula to speed up the optimization with fewer particles being sampled. Simulation results show that in known corresponding cases our approach can converge to the correct pose more efficiently than the state-of-the-art. A similar conclusion can also be drawn in real applications of unknown corresponding cases, i.e., point cloud stitching and visual odometry estimation.	https://doi.org/10.1109/ICRA46639.2022.9812437	Wenjie Li, Wasif Naeem, Wenhao Ji, Jia Liu, Wei Hao, Lijun Chen
PoseSDF: Simultaneous 3D Human Shape Reconstruction and Gait Pose Estimation Using Signed Distance Functions.	Vision-based 3D human pose estimation and shape reconstruction play important roles in robot-assisted healthcare monitoring and personal assistance. However, 3D data captured from a single viewpoint always encounter occlusions and exhibit substantial heterogeneity across different views, resulting in significant challenges for both tasks. Extensive approaches have been proposed to perform each task separately, but few of them present a unified solution. In this paper, we propose a novel network based on signed distance functions, namely PoseSDF, to simultaneously reconstruct 3D lower limb shape and estimate gait pose by two dedicated branches. To promote multi-task learning, several strategies are developed to ensure that these two branches leverage the same latent shape code while exchanging information between them. More importantly, an auxiliary RotNet is incorporated into the inference phase, overcoming the inherent limitations of implicit neural functions under cross-view scenarios. Experimental results demonstrate that our proposed PoseSDF can achieve both high-quality shape reconstruction and precise pose estimation, generalizing well on the data from novel views, gait patterns, as well as real-world.	https://doi.org/10.1109/ICRA46639.2022.9812051	Jianxin Yang, Yuxuan Liu, Xiao Gu, Guang-Zhong Yang, Yao Guo
Post-Stall Navigation with Fixed-Wing UAVs using Onboard Vision.	Recent research has enabled fixed-wing unmanned aerial vehicles (UAVs) to maneuver in constrained spaces through the use of direct nonlinear model predictive control (NMPC) [1]. However, this approach has been limited to a priori known maps and ground truth state measurements. In this paper, we present a direct NMPC approach that leverages NanoMap [2], a light-weight point cloud mapping framework, to generate collision-free trajectories using onboard stereo vision. We first explore our approach in simulation and demonstrate that our algorithm is sufficient to enable vision-based navigation in urban environments. We then demonstrate our approach in hardware using a 42-inch fixed-wing UAV and show that our motion planning algorithm is capable of navigating around a building using a minimalistic set of goal-points. We also show that point cloud history is important for navigating in these types of constrained environments.	https://doi.org/10.1109/ICRA46639.2022.9812099	Adam Polevoy, Max Basescu, Luca Scheuer, Joseph L. Moore
Pouring by Feel: An Analysis of Tactile and Proprioceptive Sensing for Accurate Pouring.	As service robots begin to be deployed to assist humans, it is important for them to be able to perform a skill as ubiquitous as pouring. Specifically, we focus on the task of pouring an exact amount of water without any environmental instrumentation, that is, using only the robot's own sensors to perform this task in a general way robustly. In our approach we use a simple PID controller which uses the measured change in weight of the held container to supervise the pour. Unlike previous methods which use specialized force-torque sensors at the robot wrist, we use our robot joint torque sensors and investigate the added benefit of tactile sensors at the fingertips. We train three estimators from data which regress the poured weight out of the source container and show that we can accurately pour within 10 ml of the target on average while being robust enough to pour at novel locations and with different grasps on the source container.	https://doi.org/10.1109/ICRA46639.2022.9811898	Pedro Piacenza, Daewon Lee, Volkan Isler
Powerful and dexterous multi-finger hand using dynamical pulley mechanism.	A multi-fingered hand that can grasp and manipulate a variety of objects is an option for assisting people in their daily lives. However, the range of torque output that can be handled by the multi-fingered hand is very limited compared to the capability of the human hand. In this paper, we introduce a new multi-fingered hand consisting of a dynamic pulley and a linkage mechanism, aiming to achieve a human-like output torque with a human-like size. The proposed multi-fingered hand can achieve a fingertip force of 50N, which is equivalent to that of a human, and at the same time can perform delicate operations such as picking up a coin on a desk. In addition, we realized the stay-on-tab opening task of a can by utilizing fingertip strength.	https://doi.org/10.1109/ICRA46639.2022.9812112	Tadaaki Hasegawa, Hironori Waita, Tomohiro Kawakami, Yoshinari Takemura, Tetsuya Ishikawa, Yuta Kimura, Chiaki Tanaka, Kenichiro Sugiyama, Takahide Yoshiike
Precise 3D Reconstruction of Plants from UAV Imagery Combining Bundle Adjustment and Template Matching.	Monitoring individual plants and computing precise 3D reconstructions is highly relevant for crop breeding. In the conventional breeding approach, humans measure phenotypic traits by hand, requiring substantial manual labor. This paper addresses precise 3D plant reconstructions in a crop field or breeding plot based on UAV imagery. We explicitly address the challenges resulting from the thin structures of leaves and naturally occurring self-occlusions. We combine photogrammetric bundle adjustment with a template-based matching approach and produce accurate 3D models that allow us to derive common, geometric traits used by breeders to phenotype plants. We provide a thorough experimental evaluation on commercially used sugar beet breeding plots to illustrate the capabilities of our method as well as its real world applicability.	https://doi.org/10.1109/ICRA46639.2022.9811358	Elias Marks, Federico Magistri, Cyrill Stachniss
Precision fruit tree pruning using a learned hybrid vision/interaction controller.	Robotic tree pruning requires highly precise manipulator control in order to accurately align a cutting implement with the desired pruning point at the correct angle. Simultaneously, the robot must avoid applying excessive force to rigid parts of the environment such as trees, support posts, and wires. In this paper, we propose a hybrid control system that uses a learned vision-based controller to initially align the cutter with the desired pruning point, taking in images of the environment and outputting control actions. This controller is trained entirely in simulation, but transfers easily to real trees via a neural network which transforms raw images into a simplified, segmented representation. Once contact is established, the system hands over control to an interaction controller that guides the cutter pivot point to the branch while minimizing interaction forces. With this simple, yet novel, approach we demonstrate an improvement of over 30 percentage points in accuracy over a baseline controller that uses camera depth data.	https://doi.org/10.1109/ICRA46639.2022.9811628	Alexander You, Hannah Kolano, Nidhi Parayil, Cindy Grimm, Joseph R. Davidson
Predicting Like A Pilot: Dataset and Method to Predict Socially-Aware Aircraft Trajectories in Non-Towered Terminal Airspace.	Pilots operating aircraft in non-towered terminal airspace rely on their situational awareness and prior knowledge to predict the future trajectories of other agents. These predictions are conditioned on the past trajectories of other agents, agent-agent social interactions and environmental context such as airport location and weather. This paper provides a dataset, TrajAir, that captures this behaviour in non-towered terminal airspace around a regional airport. We also present a baseline socially-aware trajectory prediction algorithm, TrajAirNet, that uses the dataset to predict the trajectories of all agents. The dataset is collected for 111 days over 8 months and contains ADS-B transponder data along with the corresponding METAR weather data. The data is processed to be used as a benchmark with other publicly available social navigation datasets. To the best of the authors' knowledge, this is the first 3D social aerial navigation dataset, thus introducing social navigation for autonomous aviation. TrajAirNet combines state-of-the-art modules in social navigation to provide predictions in a static environment with a dynamic context. Both the TrajAir dataset and TrajAirNet prediction algorithm are open-source. [Dataset] 11Dataset: https://theairlab.org/trajair/ [Code]22Codebase: https://github.com/castacks/trajairnet [Video]33Video: https://youtu.be/e1AQXrxB2gw	https://doi.org/10.1109/ICRA46639.2022.9811972	Jay Patrikar, Brady G. Moon, Jean Oh, Sebastian A. Scherer
Predicting the effects of oscillator-based assistance on stride-to-stride variability of Parkinsonian walkers.	Parkinson's disease is a severe neurodegenerative disorder that affects sensorimotor control. In particular, several gait impairments are reported, including a decrease of long-range autocorrelations in stride duration time series. This complex statistics is potentially a biomarker of the risk of falling. This paper aims at developing model-based predictions about the loss of long-range autocorrelations in the gait of Parkinsonian patients, and how these autocorrelations can be restored by an oscillator-based walking assistance. Using a Super Central Pattern Generator model coupled with an adaptive oscillator, we show that this type of assistance has the potential to improve long-range autocorrelations in time series of Parkinsonian walkers. This requires however to tune the adaptive oscillator with slow learning gains, raising challenges for porting this method to an actual device.	https://doi.org/10.1109/ICRA46639.2022.9811822	Virginie Otlet, Renaud Ronsse
Prediction of Depth Camera Missing Measurements Using Deep Learning for Next Best View Planning.	Depth images usually contain pixels with invalid measurements. This paper presents a deep learning approach that receives as input a partially-known volumetric model of the environment and a camera pose, and it predicts the probability that a pixel would contain a valid depth measurement if a camera was placed at the given pose. The proposed network architecture consists of a 3D Convolutional Neural Network (CNN) module and a 2D CNN module, connected by a deep learning attention-based projection module. The method was integrated into a CNN-based probabilistic Next Best View plan-ner, resulting in a more realistic prediction of the information gain for each possible viewpoint with respect to state of the art approaches. Experiments were carried out in tabletop scenarios using a robot manipulator with an eye-in-hand depth camera.	https://doi.org/10.1109/ICRA46639.2022.9812358	Riccardo Monica, Jacopo Aleotti
Prediction of Metacarpophalangeal Joint Angles and Classification of Hand Configurations Based on Ultrasound Imaging of the Forearm.	With the advancement in computing and robotics, it is necessary to develop fluent and intuitive methods for inter-acting with digital systems, augmented/virtual reality (AR/VR) interfaces, and physical robotic systems. Hand movement recognition is widely used to enable such interaction. Hand configuration classification and metacarpophalangeal (MCP) joint angle detection are important for a comprehensive reconstruction of hand motion. Surface electromyography (sEMG) and other technologies have been used for the detection of hand motions. Ultrasound images of the forearm offer a way to visualize the internal physiology of the hand from a musculoskeletal perspective. Recent works have shown that these images can be classified using machine learning to predict various hand configurations. In this paper, we propose a Convolutional Neu-ral Network (CNN) based deep learning pipeline for predicting the MCP joint angles. We supplement our results by using a Support Vector Classifier (SVC) to classify the ultrasound information into several predefined hand configurations based on activities of daily living (ADL). Ultrasound data from the forearm were obtained from six subjects who were instructed to move their hands according to predefined hand configurations relevant to ADLs. Motion capture data was acquired as the ground truth for hand movements at three speeds (0.5 Hz, 1 Hz, and 2 Hz) for the index, middle, ring, and pinky fingers. We demonstrated the perfect prediction of hand configurations through SVC classification and a correspondence between the predicted MCP joint angles and the actual MCP joint angles for the fingers, with an average root mean square error of 7.35 degrees. A low latency (6.25 – 9.10 Hz) pipeline was implemented for the prediction of both MCP joint angles and hand configuration estimation aimed for real-time implementation.	https://doi.org/10.1109/ICRA46639.2022.9812287	Keshav Bimbraw, Christopher J. Nycz, Matthew J. Schueler, Ziming Zhang, Haichong K. Zhang
PredictionNet: Real-Time Joint Probabilistic Traffic Prediction for Planning, Control, and Simulation.	Predicting the future motion of traffic agents is crucial for safe and efficient autonomous driving. To this end, we present PredictionNet, a deep neural network (DNN) that predicts the motion of all surrounding traffic agents together with the ego-vehicle's motion. All predictions are probabilistic and are represented in a simple top-down rasterization that allows an arbitrary number of agents. Conditioned on a multi-layer map with lane information, the network outputs future positions, velocities, and backtrace vectors jointly for all agents including the ego-vehicle in a single pass. Trajectories are then extracted from the output. The network can be used to simulate realistic traffic, and it produces competitive results on popular benchmarks. More importantly, it has been used to successfully control a real-world vehicle for hundreds of kilometers, by combining it with a motion planning/control subsystem. The network runs faster than real-time on an embedded GPU, and the system shows good generalization (across sensory modalities and locations) due to the choice of input representation. Furthermore, we demonstrate that by extending the DNN with reinforcement learning (RL), it can better handle rare or unsafe events like aggressive maneuvers and crashes.	https://doi.org/10.1109/ICRA46639.2022.9812223	Alexey Kamenev, Lirui Wang, Ollin Boer Bohan, Ishwar Kulkarni, Bilal Kartal, Artem Molchanov, Stan Birchfield, David Nistér, Nikolai Smolyanskiy
Preemptive Motion Planning for Human-to-Robot Indirect Placement Handovers.	As technology advances, the need for safe, efficient, and collaborative human-robot-teams has become increasingly important. One of the most fundamental collaborative tasks in any setting is the object handover. Human-to-robot handovers can take either of two approaches: (1) direct hand-to-hand or (2) indirect hand-to-placement-to-pick-up. The latter approach ensures minimal contact between the human and robot but can also result in increased idle time due to having to wait for the object to first be placed down on a surface. To minimize such idle time, the robot must preemptively predict the human intent of where the object will be placed. Furthermore, for the robot to preemptively act in any sort of productive manner, predictions and motion planning must occur in real-time. We introduce a novel prediction-planning pipeline that allows the robot to preemptively move towards the human agent's intended placement location using gaze and gestures as model inputs. In this paper, we investigate the performance and drawbacks of our early intent predictor-planner as well as the practical benefits of using such a pipeline through a human-robot case study.	https://doi.org/10.1109/ICRA46639.2022.9811558	Andrew Choi, Mohammad Khalid Jawed, Jungseock Joo
Preliminary Investigation of Powered Knee Prosthesis with Small-Scale, Light-Weight, and Affordable Series-Elastic Actuator for Walking Rehabilitation of a Patient with Four-limb Deficiency.	"Powered knee prosthesis commonly improves locomotion of above-knee amputees by generating net positive mechanical work at the knee joint which is especially required for movements with active knee extension and flexion such as sit-to-stand maneuvers, level-ground walking with various walking speed, stair/slope ascent ambulation and so forth. These studies tend to refer and trace normal human locomotion, and have amputees move ""normally"", which is quite difficult for patients with severe disability such as four-limb deficiency. In this study, a powered knee prosthesis with small-scale, light-weight and affordable series elastic actuator (PKP-SEA) is developed and adopted to a walking rehabilitation of a patient with four-limb deficiency. A subject is 45 years old and has no experience to walk on prosthetic devices in his life. During the experiment, walking performance is investigated by turning PKP-SEA control parameters. As a result, the PKP-SEA shows capability of improving his walking performance in terms of walking speed and consistency not by replicating normal human walking, but suggesting an original walking gait based on his body condition and remaining functionality."	https://doi.org/10.1109/ICRA46639.2022.9811780	Ken Endo, Naoki Uchida, Ryusuke Morita, Tetsuo Tawara
Printable Origami Bistable Structures for Foldable Jumpers.	Origami/kirigami robotics are opening a path that leads to lightweight, compact, and expandable robots. However, it is generally challenging to design agile motions for origami/kirigami robots due to their size and the intrinsic limitation of the materials. In this paper, we propose to use the bistability of the waterbomb base structure to generate the swift motion of the robots. We evaluate the bistability of the waterbomb-based structure and build origami jumpers with different configurations of the body to help analyze the behavior of the waterbomb base bistable structure. The jumper is actuated by a phase change liquid pouch actuator. Our jumper is lightweight (0.3 g), flattenable, and able to jump to more than 12 times of its diameter and 112 times of its height.	https://doi.org/10.1109/ICRA46639.2022.9812002	Tung D. Ta, Zekun Chang, Koya Narumi, Takuya Umedachi, Yoshihiro Kawahara
Prioritized Planning for Cooperative Range-Only Localization in Multi-Robot Networks.	We present a novel path-planning algorithm to reduce localization error for a network of robots cooperatively localizing via inter-robot range measurements. The quality of localization with range measurements depends on the configuration of the network, and poor configurations can cause substantial localization errors. To reduce the effect of network configuration on localization error for moving networks we consider various optimality measures of the Fisher information matrix (FIM), which have well-known relationships with localization error. We pose a trajectory planning problem with constraints on the FIM optimality measures. By constraining these optimality measures we can control the statistical properties of the localization error. To efficiently generate trajectories which satisfy these FIM constraints we present a prioritized planner which leverages graph-based planning and properties of the range-only FIM. We demonstrate in simulations that the trajectories generated by our algorithm reduce worst-case localization error by up to 42% in comparison to existing planners and can scalably plan distance-efficient trajectories in complicated environments for large numbers of robots.	https://doi.org/10.1109/ICRA46639.2022.9812315	Alan Papalia, Nicole Thumma, John J. Leonard
Proactive And Smooth Maneuvering For Navigation Around Pedestrians.	Navigation in close proximity with pedestrians is a challenge on the way to fully automated vehicles. Pedestrian-friendly navigation requires an understanding of pedestrian reaction and intention. Merely safety based reactive systems can lead to sub-optimal navigation solutions resulting in the freezing of the vehicle in many scenarios. Moreover, a strictly reactive method can produce unnatural driving patterns which cannot guarantee the legibility or social acceptance of the automated vehicle. This work presents a proactive maneuvering method adapted to navigation in close interaction with pedestrians using a dynamic channel approach. The method allows to proactively explore the navigation options based on anticipating pedestrians cooperation. The navigation is tested in frontal and lateral crossing scenarios with variable space density. The system is implemented under ROS, and compared with the probabilistic Risk-RRT planning method. The results are evaluated based on the safety and comfort of the pedestrians, and the quality of the vehicle's trajectory.	https://doi.org/10.1109/ICRA46639.2022.9812255	Maria Kabtoul, Anne Spalanzani, Philippe Martinet
Probabilistic Inference of Simulation Parameters via Parallel Differentiable Simulation.	Reproducing real world dynamics in simulation is critical for the development of new control and perception methods. This task typically involves the estimation of simu-lation parameter distributions from observed rollouts through an inverse inference problem characterized by multi-modality and skewed distributions. We address this challenging problem through a novel Bayesian inference approach that approximates a posterior distribution over simulation parameters given real sensor measurements. By extending the commonly used Gaus-sian likelihood model for trajectories via the multiple-shooting formulation, our gradient-based particle inference algorithm, Stein Variational Gradient Descent, is able to identify highly nonlinear, underactuated systems. We leverage GPU code gen-eration and differentiable simulation to evaluate the likelihood and its gradient for many particles in parallel. Our algorithm infers nonparametric distributions over simulation parame-ters more accurately than comparable baselines and handles constraints over parameters efficiently through gradient-based optimization. We evaluate estimation performance on several physical experiments. On an underactuated mechanism where a 7-DOF robot arm excites an object with an unknown mass configuration, we demonstrate how the inference technique can identify symmetries between the parameters and provide highly accurate predictions. Website: https://uscresl.github.io/prob-diff-sim	https://doi.org/10.1109/ICRA46639.2022.9812293	Eric Heiden, Christopher E. Denniston, David Millard, Fabio Ramos, Gaurav S. Sukhatme
Promoting Quality and Diversity in Population-based Reinforcement Learning via Hierarchical Trajectory Space Exploration.	Quality Diversity (QD) algorithms in population-based reinforcement learning aim to optimize agents' returns and diversity among the population simultaneously. It is conducive to solving exploration problems in reinforcement learning and potentially getting multiple good and diverse strategies. However, previous methods typically define behavioral embedding in action space or outcome space, which neglect trajectory characteristics during the execution process. In this paper, we introduce a trajectory embedding model trained by Variational Autoencoder with similarity constraint to characterize trajectory features. Based on that, we propose a hierarchical trajectory-space exploration (HTSE) framework using Determinantal Point Processes (DPP) to generate high-quality and diverse solutions in the selection and mutation process. The experimental results show that our HTSE method effectively completes several simulated tasks, outperforming other Quality-Diversity Reinforcement Learning algorithms.	https://doi.org/10.1109/ICRA46639.2022.9811888	Jiayu Miao, Tianze Zhou, Kun Shao, Ming Zhou, Weinan Zhang, Jianye Hao, Yong Yu, Jun Wang
Propagating State Uncertainty Through Trajectory Forecasting.	Uncertainty pervades through the modern robotic autonomy stack, with nearly every component (e.g., sensors, detection, classification, tracking, behavior prediction) producing continuous or discrete probabilistic distributions. Trajectory forecasting, in particular, is surrounded by uncertainty as its inputs are produced by (noisy) upstream perception and its outputs are predictions that are often probabilistic for use in downstream planning. However, most trajectory forecasting methods do not account for upstream uncertainty, instead taking only the most-likely values. As a result, perceptual uncer-tainties are not propagated through forecasting and predictions are frequently overconfident. To address this, we present a novel method for incorporating perceptual state uncertainty in trajectory forecasting, a key component of which is a new statistical distance-based loss function which encourages predicting uncertainties that better match upstream perception. We evaluate our approach both in illustrative simulations and on large-scale, real-world data, demonstrating its efficacy in propagating perceptual state uncertainty through prediction and producing more calibrated predictions.	https://doi.org/10.1109/ICRA46639.2022.9811776	Boris Ivanovic, Yifeng Lin, Shubham Shrivastava, Punarjay Chakravarty, Marco Pavone
Prototype-Voxel Contrastive Learning for LiDAR Point Cloud Panoptic Segmentation.	LiDAR point cloud panoptic segmentation, including both semantic and instance segmentation, plays a critical role in meticulous scene understanding for autonomous driving. Existing 3D voxelized approaches either utilize 3D sparse convolution that only focuses on local scene understanding, or add extra and time-consuming PointNet branch to capture global feature structures. To address these limitations, we propose an end-to-end Prototype-Voxel Contrastive Learning (PVCL) framework for learning stable and discriminative semantic representations, which includes voxel-level and prototype-level contrastive learning (CL). The voxel-level CL decreases intra-class distance and increases inter-class distance among sample representations, while the prototype-level CL further reduces the dependence of CL on negative sampling and avoids the influence of outliers from the same class, enabling PVCL to be more effective for outdoor point cloud panoptic segmentation. Extensive experiments are conducted on the public point cloud panoptic segmentation datasets, Semantic-KITTI and nuScenes, where evaluations and ablation studies demonstrate PVCL achieves superior performance compared with the state-of-the-art. Our approach ranks the top on the public leaderboard of Semantic-KITTI at the time of submission, and surpasses the published 2nd rank, EfficientLPS, by 1.7% in PQ.	https://doi.org/10.1109/ICRA46639.2022.9811638	Minzhe Liu, Qiang Zhou, Hengshuang Zhao, Jianing Li, Yuan Du, Kurt Keutzer, Li Du, Shanghang Zhang
Provably Safe Deep Reinforcement Learning for Robotic Manipulation in Human Environments.	Deep reinforcement learning (RL) has shown promising results in the motion planning of manipulators. However, no method guarantees the safety of highly dynamic obstacles, such as humans, in RL-based manipulator control. This lack of formal safety assurances prevents the application of RL for manipulators in real-world human environments. Therefore, we propose a shielding mechanism that ensures ISO- verified human safety while training and deploying RL algorithms on manipulators. We utilize a fast reachability analysis of humans and manipulators to guarantee that the manipulator comes to a complete stop before a human is within its range. Our proposed method guarantees safety and significantly improves the RL performance by preventing episode-ending collisions. We demonstrate the performance of our proposed method in simulation using human motion capture data.	https://doi.org/10.1109/ICRA46639.2022.9811698	Jakob Thumm, Matthias Althoff
Providing Local Resilience to Vulnerable Areas in Robotic Networks.	"We study how information flows through a multi-robot network in order to better understand how to provide resilience to malicious information. While the notion of global resilience is well studied, one way existing methods provide global resilience is by bringing robots closer together to improve the connectivity of the network. However, large changes in network structure can impede the team from performing other functions such as coverage, where the robots need to spread apart. Our goal is to mitigate the trade-off between resilience and network structure preservation by applying resilience locally in areas of the network where it is needed most. We introduce a metric, Influence, to identify vulnerable regions in the network requiring resilience. We design a control law targeting local resilience to the vulnerable areas by improving the connectivity of robots within these areas so that each robot has at least 2F+1
vertex-disjoint communication paths between itself and the high influence robot in the vulnerable area. We demonstrate the performance of our local resilience controller in simulation and in hardware by applying it to a coverage problem and comparing our results with an existing global resilience strategy. For the specific hardware experiments, we show that our control provides local resilience to vulnerable areas in the network while only requiring 9.90% and 15.14% deviations from the desired team formation compared to the global strategy."	https://doi.org/10.1109/ICRA46639.2022.9812033	Matthew Cavorsi, Stephanie Gil
Push-to-See: Learning Non-Prehensile Manipulation to Enhance Instance Segmentation via Deep Q-Learning.	Efficient robotic manipulation of objects for sorting and searching often rely upon how well the objects are perceived and the available grasp poses. The challenge arises when the objects are irregular, have similar visual features (e.g., textureless objects) and the scene is densely cluttered. In such cases, non-prehensile manipulation (e.g., pushing) can facilitate grasping or searching by improving object perception and singulating the objects from the clutter via physical interaction. The current robotics literature in interactive segmentation focuses solely on isolated cases, where the central aim is on searching or singulating a single target object, or segmenting sparsely cluttered scenes, mainly through matching visual futures in successive scenes before and after the robotic interaction. On the other hand, in this paper, we introduce the first interactive segmentation model in the literature that can autonomously enhance the instance segmentation of such challenging scenes as a whole via optimising a Q-value function that predicts appropriate pushing actions for singulation. We achieved this by training a deep reinforcement learning model with reward signals generated by a Mask-RCNN trained solely on depth images. We evaluated our model in experiments by comparing its success on segmentation quality with a heuristic baseline, as well as the state-of-the-art Visual Pushing and Grasping (VPG) model [1]. Our model significantly outperformed both baselines in all benchmark scenarios. Furthermore, decreasing the segmentation error inherently enabled the autonomous singulation of the scene as a whole. Our evaluation experiments also serve as a benchmark for interactive segmentation research.	https://doi.org/10.1109/ICRA46639.2022.9811645	Baris Serhan, Harit Pandya, Ayse Küçükyilmaz, Gerhard Neumann
Put the Bear on the Chair! Intelligent Robot Interaction with Previously Unseen Chairs via Robot Imagination.	In this paper, we study the problem of autonomously seating a teddy bear on a previously unseen chair. To achieve this goal, we present a novel method for robots to imagine the sitting pose of the bear by physically simulating a virtual humanoid agent sitting on the chair. We also develop a robotic system which leverages motion planning to plan SE(2) motions for a humanoid robot to walk to the chair and whole-body motions to put the bear on it. Furthermore, to cope with cases where the chair is not in an accessible pose for placing the bear, a human assistance module is introduced for a human to follow language instructions given by the robot to rotate the chair and help make the chair accessible. We implement our method with a robot arm and a humanoid robot. We calibrate the proposed system with 3 chairs and test on 12 previously unseen chairs in both accessible and inaccessible poses extensively. Results show that our method enables the robot to autonomously seat the teddy bear on the 12 previously unseen chairs with a very high success rate. The human assistance module is also shown to be very effective in changing the accessibility of the chair. Video demos and more details are available at https://chirikjianlab.github.io/putbearonchair/.	https://doi.org/10.1109/ICRA46639.2022.9811619	Hongtao Wu, Xin Meng, Sipu Ruan, Gregory S. Chirikjian
PyROBOCOP: Python-based Robotic Control & Optimization Package for Manipulation.	PyROBOCOP is a Python-based package for control, optimization and estimation of robotic systems described by nonlinear Differential Algebraic Equations (DAEs). In particular, the package can handle systems with contacts that are described by complementarity constraints and provides a general framework for specifying obstacle avoidance constraints. The package performs direct transcription of the DAEs into a set of nonlinear equations by performing orthogonal collocation on finite elements. PyROBOCOP provides automatic reformulation of the complementarity constraints that are tractable to NLP solvers to perform optimization of robotic systems. The package is interfaced with ADOL-C [1] for obtaining sparse derivatives by automatic differentiation and IPOPT [2] for performing optimization. We evaluate PyROBOCOP on several manipulation problems for control and estimation.	https://doi.org/10.1109/ICRA46639.2022.9812069	Arvind U. Raghunathan, Devesh K. Jha, Diego Romeres
QuadRunner: A Transformable Quasi-Wheel Quadruped.	This paper presents QuadRunner, a transformable quasi-wheel legged robot that achieves both quadruped locomotion and wheel locomotion by exploiting a novel semicircular leg-wheel design with a Trotting Wheel gait. We built upon the Stanford Doggo open architecture platform and integrated it with a transformable leg-wheel design to enhance its locomotion capabilities. On its gait control, improvements were made to its trot gait kinematics with end-effector considerations as well as the design of a new trotting wheel gait. Our proposed locomotion strategy found that the robot's legged locomotion improves by an average speed of 10%. In addition, wheel to leg transition takes around 300 ms, and the speed of its wheel locomotion can reach more than five times its body-length/s (2.2 m/s) on flat terrain. Lastly, detailed experiments are conducted to observe the wheel-leg transition performance and gait verification under the absence of foot contact sensors.	https://doi.org/10.1109/ICRA46639.2022.9811839	Alper Yeldan, Abhimanyu Arora, Gim Song Soh
R-PCC: A Baseline for Range Image-based Point Cloud Compression.	In autonomous vehicles or robots, point clouds from LiDAR can provide accurate depth information of objects compared with 2D images, but they also suffer a large volume of data, which is inconvenient for data storage or transmission. In this paper, we propose a Range image-based Point Cloud Compression method, R-PCC, which can reconstruct the point cloud with uniform or non-uniform accuracy loss. We segment the original large-scale point cloud into small and compact regions for spatial redundancy and salient region classification. Our range image-based method can keep and align all points from the original point cloud in the reconstructed point cloud, and the setting of the quantization module restricts the maximum reconstruction error. In the experiments, we prove that our easier FPS-based segmentation method can achieve better performance than instance-based segmentation methods such as DBSCAN, and our non-uniform compression framework shows a great improvement on the downstream tasks compared with the state-of-the-art large-scale point cloud compression methods. Our real-time method can achieve 40 × compression ratio without affecting downstream tasks, to act as a baseline for range image-based point cloud compression. The code is available on https://github.com/StevenWang30/R-PCC.git.	https://doi.org/10.1109/ICRA46639.2022.9811880	Sukai Wang, Jianhao Jiao, Peide Cai, Lujia Wang
R2poweR: The Proof-of-Concept of a Backdrivable, High-Ratio Gearbox for Human-Robot Collaboration.	Robotic engineers face major challenges to solve the complex actuation needs of Human-Robot Collaboration with existing act robotic gearboxes. Available technologies comprise high-ratio Planetary Gearheads, Cycloid Drives and Harmonic Drives, inherited from conventional industrial robotics. Alternative approaches include Direct-Drive and Quasi Direct-Drive actuation strategies, which propose to cancel or substantially reduce gear ratio, in order to minimize reflected inertia and attain enough backdrivability for collaborative tasks. This paper presents the proof-of-concept validation of a novel high-ratio, Wolfrom-based, gearbox technology that follows a different approach to attain the same objective. Testing five different gearbox prototypes, we confirm the ability of the R2poweR technology to improve efficiency and backdrivability while retaining the weight and control advantages derived from the use of high reduction ratios. The result is a highly efficient, backdrivable, high-ratio gearbox with exciting Huma-Robot Collaboration potential.	https://doi.org/10.1109/ICRA46639.2022.9811923	Pablo López-García, Stein Crispel, A. Varadharajan, Elias Saerens, Tom Verstraten, Bram Vanderborght, Dirk Lefeber
R3LIVE: A Robust, Real-time, RGB-colored, LiDAR-Inertial-Visual tightly-coupled state Estimation and mapping package.	In this paper, we propose a novel LiDAR-Inertial-Visual sensor fusion framework termed R3LIVE, which takes advantage of measurement of LiDAR, inertial, and visual sensors to achieve robust and accurate state estimation. R3LIVE consists of two subsystems, a LiDAR-Inertial odometry (LIO) and a Visual-Inertial odometry (VIO). The LIO subsystem (FAST-LIO) utilizes the measurements from LiDAR and inertial sensors and builds the geometric structure (i.e., the positions of 3D points) of the map. The VIO subsystem uses the data of Visual-Inertial sensors and renders the map's texture (i.e., the color of 3D points). More specifically, the VIO subsystem fuses the visual data directly and effectively by minimizing the frame-to-map photometric error. The proposed system R3LIVE is developed based on our previous work R2LIVE, with a completely different VIO architecture design. The overall system is able to reconstruct the precise, dense, 3D, RGB-colored maps of the surrounding environment in real-time (see our attached video 11https://youtu.be/j5fT8NE5fdg). Our experiments show that the resultant system achieves higher robustness and accuracy in state estimation than its current counterparts. To share our findings and make contributions to the community, we open source R3LIVE on our Github 22https://github.com/hku-mars/r31ive	https://doi.org/10.1109/ICRA46639.2022.9811935	Jiarong Lin, Fu Zhang
RAPID-RL: A Reconfigurable Architecture with Preemptive-Exits for Efficient Deep-Reinforcement Learning.	Present-day Deep Reinforcement Learning (RL) systems show great promise towards building intelligent agents surpassing human-level performance. However, the computational complexity associated with the underlying deep neural networks (DNNs) leads to power-hungry implementations. This makes deep RL systems unsuitable for deployment on resource-constrained edge devices. To address this challenge, we propose a reconfigurable architecture with preemptive exits for effi-cient deep RL (RAPID-RL). RAPID-RL enables conditional activation of DNN layers based on the difficulty level of inputs. This allows to dynamically adjust the compute effort during inference while maintaining competitive performance. We achieve this by augmenting a deep Q-network (DQN) with side-branches capable of generating intermediate predictions along with an associated confidence score. We also propose a novel training methodology for learning the actions and branch confidence scores in a dynamic RL setting. Our experiments evaluate the proposed framework for Atari 2600 gaming tasks and a realistic Drone navigation task on an open-source drone simulator (PEDRA). We show that RAPID-RL incurs 0.34 × (0.25 ×) number of operations (OPS) while maintaining performance above 0.88 × (0.91 ×) on Atari (Drone navigation) tasks, compared to a baseline-DQN without any side-branches. The reduction in OPS leads to fast and efficient inference, proving to be highly beneficial for the resource-constrained edge where making quick decisions with minimal compute is essential.	https://doi.org/10.1109/ICRA46639.2022.9812320	Adarsh Kumar Kosta, Malik Aqeel Anwar, Priyadarshini Panda, Arijit Raychowdhury, Kaushik Roy
RE: BT-Espresso: Improving Interpretability and Expressivity of Behavior Trees Learned from Robot Demonstrations.	Behavior trees (BTs) are hierarchical agent control architectures popular for robot task-level planning that can be autonomously learned from robot demonstrations via decision tree (DT) intermediaries, making them accessible to non-expert users. Conversion algorithms from DTs to BTs, such as the BT-Espresso algorithm, focus on replicating DT logic in a BT format but do not exploit the strengths of the BT architecture. We introduce the Representation Exploitation of BT-Espresso (RE:BT-Espresso) algorithm, which builds on BT-Espresso and improves the learned BT's interpretability and expressivity. RE:BT-Espresso improves interpretability by removing logical redundancies in the generated BTs and improves expressivity by exploiting desired BT structures, such as adding Inverter nodes, Repeater sequences, and Parallel Selector Action nodes that gives the user a choice of actions for state spaces that did not resolve to a concise action in the DT. The RE:BT-Espresso algorithm was evaluated against BT-Espresso using demonstration data synthesized by BTs. When compared to the synthesized BTs using graph edit distance (GED), RE:BT-Espresso outscored BT-Espresso on 54 subtrees, tied on 178, and lost on 2. Further, the proposed reduction strategies reduced the number of nodes in a generated tree by a median of 7.82%. The results validate improved interpretability and expressivity of learned RE:BT-Espresso task-level BT policies from robot demonstration.	https://doi.org/10.1109/ICRA46639.2022.9812046	Adam Wathieu, Thomas R. Groechel, Haemin Jenny Lee, Chloe Kuo, Maja J. Mataric
RF-Annotate: Automatic RF-Supervised Image Annotation of Common Objects in Context.	Wireless tags are increasingly used to track and identify common items of interest such as retail goods, food, medicine, clothing, books, documents, keys, equipment, and more. At the same time, there is a need for labelled visual data featuring such items for the purpose of training object detection and recognition models for robots operating in homes, warehouses, stores, libraries, pharmacies, and so on. In this paper, we ask: can we leverage the tracking and identification capabilities of such tags as a basis for a large-scale automatic image annotation system for robotic perception tasks? We present RF-Annotate, a pipeline for autonomous pixel-wise image annotation which enables robots to collect labelled visual data of objects of interest as they encounter them within their environment. Our pipeline uses unmodified commodity RFID readers and RGB-D cameras, and exploits arbitrary small-scale motions afforded by mobile robotic platforms to spatially map RFIDs to corresponding objects in the scene. Our only assumption is that the objects of interest within the environment are pre-tagged with inexpensive battery-free RFIDs costing 3–15 cents each. We demonstrate the efficacy of our pipeline on several RGB-D sequences of tabletop scenes featuring common objects in a variety of indoor environments.	https://doi.org/10.1109/ICRA46639.2022.9812072	Emerson Sie, Deepak Vasisht
RMPs for Safe Impedance Control in Contact-Rich Manipulation.	Variable impedance control in operation-space is a promising approach to learning contact-rich manipulation behaviors. One of the main challenges with this approach is producing a manipulation behavior that ensures the safety of the arm and the environment. Such behavior is typically implemented via a reward function that penalizes unsafe actions (e.g. obstacle collision, joint limit extension), but that approach is not always effective and does not result in behaviors that can be reused in slightly different environments. We show how to combine Riemannian Motion Policies, a class of policies that dynamically generate motion in the presence of safety and collision constraints, with variable impedance operation-space control to learn safer contact-rich manipulation behaviors.	https://doi.org/10.1109/ICRA46639.2022.9811986	Seiji Shaw, Ben Abbatematteo, George Konidaris
RMS-FlowNet: Efficient and Robust Multi-Scale Scene Flow Estimation for Large-Scale Point Clouds.	The proposed RMS-FlowNet is a novel end-to-end learning-based architecture for accurate and efficient scene flow estimation which can operate on point clouds of high density. For hierarchical scene flow estimation, the existing methods depend on either expensive Farthest-Point-Sampling (FPS) or structure-based scaling which decrease their ability to handle a large number of points. Unlike these methods, we base our fully supervised architecture on Random-Sampling (RS) for multiscale scene flow prediction. To this end, we propose a novel flow embedding design which can predict more robust scene flow in conjunction with RS. Exhibiting high accuracy, our RMS-FlowNet provides a faster prediction than state-of-the-art methods and works efficiently on consecutive dense point clouds of more than 250K points at once. Our comprehensive experiments verify the accuracy of RMS-FlowNet on the established FlyingThings3D data set with different point cloud densities and validate our design choices. Additionally, we show that our model presents a competitive ability to generalize towards the real-world scenes of KITTI data set without fine-tuning.	https://doi.org/10.1109/ICRA46639.2022.9811981	Ramy Battrawy, René Schuster, Mohammad-Ali Nikouei Mahani, Didier Stricker
ROMAX: Certifiably Robust Deep Multiagent Reinforcement Learning via Convex Relaxation.	In a multirobot system, a number of cyber-physical attacks (e.g., communication hijack, observation per-turbations) can challenge the robustness of agents. This robust-ness issue worsens in multiagent reinforcement learning because there exists the non-stationarity of the environment caused by simultaneously learning agents whose changing policies affect the transition and reward functions. In this paper, we propose a minimax MARL approach to infer the worst-case policy update of other agents. As the minimax formulation is computationally intractable to solve, we apply the convex relaxation of neural networks to solve the inner minimization problem. Such convex relaxation enables robustness in interacting with peer agents that may have significantly different behaviors and also achieves a certified bound of the original optimization problem. We eval-uate our approach on multiple mixed cooperative-competitive tasks and show that our method outperforms the previous state of the art approaches on this topic.	https://doi.org/10.1109/ICRA46639.2022.9812321	Chuangchuang Sun, Dong-Ki Kim, Jonathan P. How
ROS2SWARM - A ROS 2 Package for Swarm Robot Behaviors.	Developing reusable software for mobile robots is still challenging. Even more so for swarm robots, despite the desired simplicity of the robot controllers. Prototyping and experimenting are difficult due to the multi-robot setting and often require robot-robot communication. Also, the diversity of swarm robot hardware platforms increases the need for hardware-independent software concepts. The main advantages of the commonly used robot software architecture ROS 2 are modularity and platform independence. We propose a new ROS 2 package, ROS2sWARM, for applications of swarm robotics that provides a library of ready-to-use swarm behavioral primitives. We show the successful application of our approach on three different platforms, the TurtleBot3 Burger, the TurtleBot3 Waffle Pi, and the Jackal UGV, and with a set of different behavioral primitives, such as aggregation, dispersion, and collective decision-making. The proposed approach is easy to maintain, extendable, and has good potential for simplifying swarm robotics experiments in future applications.	https://doi.org/10.1109/ICRA46639.2022.9812417	Tanja Katharina Kaiser, Marian Johannes Begemann, Tavia Plattenteich, Lars Schilling, Georg Schildbach, Heiko Hamann
ROW-SLAM: Under-Canopy Cornfield Semantic SLAM.	We study a semantic SLAM problem where a robot is tasked with autonomous weeding under the corn canopy. The goal is to detect corn stalks and localize them in a global coordinate frame. This is a challenging scenario for existing algorithms because there is very little space between the camera and the plants, and the camera motion is primarily restricted to be along the row. To overcome these challenges, we present a multi-camera system where a side camera (facing the plants) is used for detection, whereas front and back cameras are used for motion estimation. Next, we show how semantic features in the environment (corn stalks, ground, and crop planes) can be used to develop a robust semantic SLAM solution and present results from field trials performed throughout the growing season across various cornfields.	https://doi.org/10.1109/ICRA46639.2022.9811745	Jiacheng Yuan, Jungseok Hong, Junaed Sattar, Volkan Isler
ROZZ: Property-based Fuzzing for Robotic Programs in ROS.	ROS is popular in robotic-software development, and thus detecting bugs in ROS programs is important for modern robots. Fuzzing is a promising technique of runtime testing. But existing fuzzing approaches are limited in testing ROS programs, due to neglecting ROS properties, such as multi-dimensional inputs, temporal features of inputs and the distributed node model. In this paper, we develop a new fuzzing framework named ROZZ, to effectively test ROS programs and detect bugs based on ROS properties. ROZZ has three key techniques: (1) a multi-dimensional generation method to generate test cases of ROS programs from multiple dimensions, including user data, configuration parameters and sensor messages; (2) a distributed branch coverage to describe the overall code coverage of multiple ROS nodes in the robot task; (3) a temporal mutation strategy to generate test cases with temporal information. We evaluate ROZZ on 10 common robotic programs in ROS2, and it finds 43 real bugs. 20 of these bugs have been confirmed and fixed by related ROS developers. We compare ROZZ to existing approaches for testing robotic programs, and ROZZ finds more bugs with higher code coverage.	https://doi.org/10.1109/ICRA46639.2022.9811701	Kai-Tao Xie, Jia-Ju Bai, Yong-Hao Zou, Yu-Ping Wang
RTGNN: A Novel Approach to Model Stochastic Traffic Dynamics.	"Modeling stochastic traffic dynamics is critical to developing self-driving cars. Because it is difficult to develop first principle models of cars driven by humans, there is great potential for using data driven approaches in developing traffic dynamical models. While there is extensive literature on this subject, previous works mainly address the prediction accuracy of data-driven models. Moreover, it is often difficult to apply these models to common planning frameworks since they fail to meet the assumptions therein. In this work, we propose a new stochastic traffic model, Recurrent Traffic Graph Neural Network (RTGNN), by enforcing additional structures on the model so that the proposed model can be seamlessly integrated with existing motion planning algorithms. RTGNN is a Markovian model and is able to infer future traffic states conditioned on the motion of the ego vehicle. Specifically, RTGNN uses a definition of the traffic state that includes the state of all players in a local region and is therefore able to make joint predictions for all agents of interest. Meanwhile, we explicitly model the hidden states of agents, ""intentions,"" as part of the traffic state to reflect the inherent partial observability of traffic dynamics. The above mentioned properties are critical for integrating RTGNN with motion planning algorithms coupling prediction and decision making. Despite the additional structures, we show that RTGNN is able to achieve state-of-the-art accuracy through comparisons with other similar works."	https://doi.org/10.1109/ICRA46639.2022.9812104	Ke Sun, Stephen Chaves, Paul Martin, Vijay Kumar
RangeBird: Multi View Panoptic Segmentation of 3D Point Clouds with Neighborhood Attention.	Panoptic segmentation of point clouds is one of the key challenges of 3D scene understanding, requiring the simultaneous prediction of semantics and object instances. Tasks like autonomous driving strongly depend on these information to get a holistic understanding of their 3D environment. This work presents a novel proposal free framework for lidar-based panoptic segmentation, which exploits three different point cloud representations, leveraging their strengths and compensating their weaknesses. The efficient projection-based range view and bird's eye view are combined and further extended by a point-based network with a novel attention-based neighborhood aggregation for improved semantic features. Cluster-based object recognition in bird's eye view enables an efficient and high-quality instance segmentation. Semantic and instance segmentation are fused and further refined by a novel instance classification for the final panoptic segmentation. The results on two challenging large-scale datasets, nuScenes and SemanticKITTI, show the success of the proposed framework, which outperforms all existing approaches on nuScenes and achieves state-of-the-art results on SemanticKITTI.	https://doi.org/10.1109/ICRA46639.2022.9811998	Fabian Duerr, Hendrik Weigel, Jürgen Beyerer
Rapid and Reliable Quadruped Motion Planning with Omnidirectional Jumping.	Dynamic jumping with legged robots poses a challenging problem in planning and control. Formulating the jump optimization to allow fast online execution is difficult; efficiently using this capability to generate long-horizon motion plans further complicates the problem. In this work, we present a hierarchical planning framework to address this problem. We first formulate a real-time tractable trajectory optimization for performing omnidirectional jumping. We then embed the results of this optimization into a low dimensional jump feasibility classifier. This classifier is leveraged to produce geometric motion plans that select dynamically feasible jumps while mitigating the effects of the process noise. We deploy our framework on the Mini Cheetah Vision quadruped, demonstrating the robot's ability to generate and execute reliable, goal-oriented plans that involve forward, lateral, and rotational jumps onto surfaces as tall as the robot's nominal hip height. The ability to plan through omnidirectional jumping greatly expands the robot's mobility relative to planners that restrict jumping to the sagittal or frontal planes.	https://doi.org/10.1109/ICRA46639.2022.9812088	Matthew Chignoli, Savva Morozov, Sangbae Kim
ReDUCE: Reformulation of Mixed Integer Programs Using Data from Unsupervised Clusters for Learning Efficient Strategies.	Mixed integer convex and nonlinear programs, MICP and MINLP, are expressive but require long solving times. Recent work that combines learning methods on solver heuristics has shown potential to overcome this issue allowing for applications on larger scale practical problems. Gathering sufficient training data to employ these methods still present a challenge since getting data from traditional solvers are slow and newer learning approaches still require large amounts of data. In order to scale up and make these hybrid learning approaches more manageable we propose ReDUCE, a method that exploits structure within small to medium size datasets. We also introduce the bookshelf organization problem as an MINLP as a way to measure performance of solvers with ReDUCE. Results show that existing algorithms with ReDUCE can solve this problem within a few seconds, a significant improvement over the original formulation. ReDUCE is demonstrated as a high level planner for a robotic arm for the bookshelf problem.	https://doi.org/10.1109/ICRA46639.2022.9811566	Xuan Lin, Gabriel I. Fernandez, Dennis W. Hong
ReachBot: A Small Robot with Exceptional Reach for Rough Terrain.	ReachBot is a new concept for planetary exploration, consisting of a small body and long, lightweight extending arms loaded primarily in tension. The arms are equipped with spined grippers for anchoring on rock surfaces. The design and testing of a planar prototype is presented here. Experiments with rock grasping and coordinated locomotion illustrate the advantages of low inertia passive grippers, triggered by impact and using stored mechanical energy for the internal force. Gripper design involves a trade-off among the range of possible grasp angles, maximum grasp force, required triggering force, and required reset force. The current prototype can pull with up to 8N when gripping volcanic rock, limited only by the strength of the 3D printed components. Calculations predict a maximum pull of 26N for the same spines and stronger materials.	https://doi.org/10.1109/ICRA46639.2022.9811949	Tony G. Chen, Becky Miller, Crystal Winston, Stephanie Schneider, Andrew Bylard, Marco Pavone, Mark R. Cutkosky
Reactive Informative Planning for Mobile Manipulation Tasks under Sensing and Environmental Uncertainty.	In this paper we address mobile manipulation planning problems in the presence of sensing and environmental uncertainty. In particular, we consider mobile sensing manipulators operating in environments with unknown geometry and uncertain movable objects, while being responsible for accomplishing tasks requiring grasping and releasing objects in a logical fashion. Existing algorithms either do not scale well or neglect sensing and/or environmental uncertainty. To face these challenges, we propose a hybrid control architecture, where a symbolic controller generates high-level manipulation commands (e.g., grasp an object) based on environmental feedback, an informative planner designs paths to actively decrease the uncertainty of objects of interest, and a continuous reactive controller tracks the sparse waypoints comprising the informative paths while avoiding a priori unknown obstacles. The overall architecture can handle environmental and sensing uncertainty online, as the robot explores its workspace. Using numerical simulations, we show that the proposed architecture can handle tasks of increased complexity while responding to unanticipated adverse configurations.	https://doi.org/10.1109/ICRA46639.2022.9811642	Mariliza Tzes, Vasileios Vasilopoulos, Yiannis Kantaros, George J. Pappas
Reactive Locomotion Decision-Making and Robust Motion Planning for Real-Time Perturbation Recovery.	In this paper, we examine the problem of push recovery for bipedal robot locomotion and present a reactive decision-making and robust planning framework for locomotion resilient to external perturbations. Rejecting perturbations is an essential capability of bipedal robots and has been widely studied in the locomotion literature. However, adversarial disturbances and aggressive turning can lead to negative lateral step width (i.e., crossed-leg scenarios) with unstable motions and self-collision risks. These motion planning problems are computationally difficult and have not been explored under a hierarchically integrated task and motion planning method. We explore a planning and decision-making framework that closely ties linear-temporal-logic-based reactive synthesis with trajectory optimization incorporating the robot's full-body dynamics, kinematics, and leg collision avoidance constraints. Between the high-level discrete symbolic decision-making and the low-level continuous motion planning, behavior trees serve as a reactive interface to handle perturbations occurring at any time of the locomotion process. Our experimental results show the efficacy of our method in generating resilient recovery behaviors in response to diverse perturbations from any direction with bounded magnitudes.	https://doi.org/10.1109/ICRA46639.2022.9812068	Zhaoyuan Gu, Nathan Boyd, Ye Zhao
Real-Robot Deep Reinforcement Learning: Improving Trajectory Tracking of Flexible-Joint Manipulator with Reference Correction.	Flexible-joint manipulators are governed by complex nonlinear dynamics, defining a challenging control problem. In this work, we propose an approach to learn an outer-loop joint trajectory tracking controller with deep reinforcement learning. The controller represented by a stochastic policy is learned in under two hours directly on the real robot. This is achieved through bounded reference correction actions and use of a model-free off-policy learning method. In addition, an informed policy initialization is proposed, where the agent is pre-trained in a learned simulation. We test our approach on the 7 DOF manipulator of a Baxter robot. We demonstrate that the proposed method is capable of consistent learning across multiple runs when applied directly on the real robot. Our method yields a policy which significantly improves the trajectory tracking accuracy in comparison to the vendor-provided controller, generalizing to an unseen payload.	https://doi.org/10.1109/ICRA46639.2022.9812023	Dmytro Pavlichenko, Sven Behnke
Real-Time Multi-Contact Model Predictive Control via ADMM.	We propose a hybrid model predictive control algorithm, consensus complementarity control (C3), for systems that make and break contact with their environment. Many state-of-the-art controllers for tasks which require initiating contact with the environment, such as locomotion and manipulation, require a priori mode schedules or are so computationally complex that they cannot run at real-time rates. We present a method, based on the alternating direction method of multipliers (ADMM), capable of high-speed reasoning over potential contact events. Via a consensus formulation, our approach enables parallelization of the contact scheduling problem. We validate our results on three numerical examples, including two frictional contact problems, and physical experimentation on an underactuated multi-contact system.	https://doi.org/10.1109/ICRA46639.2022.9811957	Alp Aydinoglu, Michael Posa
Real-Time Trajectory Planning for Autonomous Driving with Gaussian Process and Incremental Refinement.	Real-time kinodynamic trajectory planning in dy-namic environments is critical yet challenging for autonomous driving. In this paper, we propose an efficient trajectory plan-ning system for autonomous driving in complex dynamic sce-narios through iterative and incremental path-speed optimization. Exploiting the decoupled structure of the planning prob-lem, a path planner based on Gaussian process first generates a continuous arc-length parameterized path in the Frenét frame, considering static obstacle avoidance and curvature constraints. We theoretically prove that it is a good generalization of the well-known jerk optimal solution. An efficient s-t graph search method is introduced to find a speed profile along the generated path to deal with dynamic environments. Finally, the path and speed are optimized incrementally and iteratively to ensure kinodynamic feasibility. Various simulated scenarios with both static obstacles and dynamic agents verify the effectiveness and robustness of our proposed method. Experimental results show that our method can run at 20 Hz. The source code is released as an open-source package.	https://doi.org/10.1109/ICRA46639.2022.9812405	Jie Cheng, Yingbing Chen, Qingwen Zhang, Lu Gan, Chengju Liu, Ming Liu
Real-time Full-stack Traffic Scene Perception for Autonomous Driving with Roadside Cameras.	"We propose a novel and pragmatic framework for traffic scene perception with roadside cameras. The proposed framework covers a full-stack of roadside perception pipeline for infrastructure-assisted autonomous driving, including object detection, object localization, object tracking, and multi-camera information fusion. Unlike previous vision-based perception frameworks rely upon depth offset or 3D annotation at training, we adopt a modular decoupling design and introduce a landmark-based 3D localization method, where the detection and localization can be well decoupled so that the model can be easily trained based on only 2D annotations. The proposed framework applies to either optical or thermal cameras with pinhole or fish-eye lenses. Our framework is deployed at a two-lane roundabout located at Ellsworth Rd. and State St., Ann Arbor, MI, USA, providing 7\times 24
real-time traffic flow monitoring and high-precision vehicle trajectory extraction. The whole system runs efficiently on a low-power edge computing device with all-component end-to-end delay of less than 20ms."	https://doi.org/10.1109/ICRA46639.2022.9812137	Zhengxia Zou, Rusheng Zhang, Shengyin Shen, Gaurav Pandey, Punarjay Chakravarty, Armin Parchami, Henry X. Liu
Real-time Inertial Parameter Identification of Floating-Base Robots Through Iterative Primitive Shape Division.	Dynamic models play a key role in robot motion generation and control and the identification of inertial parameters is a critical component for obtaining an accurate dynamic model of a robot. This paper presents a novel iterative primitive shape division method for the inertia parameter identification of floating-base robots. Describing a robot by a set of primitive shapes with uniform mass distributions, the method iteratively divides the primitive shapes into smaller ones and refines their masses, which quickly converges to yielding the true inertia parameters of the robot. This method guarantees the physical consistency of the obtained parameters, possesses a high computational efficiency for online deployment, and works without contact force measurement. Furthermore, it can be used to estimate the position and magnitude of an external load applied to the robot. Simulations and experiments on a quadruped robot have been conducted to verify the effectiveness and efficiency of the proposed method.	https://doi.org/10.1109/ICRA46639.2022.9812214	Jiafeng Xu, Yu Zheng, Xinyang Jiang, Sicheng Yang, Lingzhu Xiang, Zhengyou Zhang
Real2Sim2Real: Self-Supervised Learning of Physical Single-Step Dynamic Actions for Planar Robot Casting.	This paper introduces the task of Planar Robot Casting (PRC): where one planar motion of a robot arm holding one end of a cable causes the other end to slide across the plane toward a desired target. PRC allows the cable to reach points beyond the robot workspace and has applications for cable management in homes, warehouses, and factories. To efficiently learn a PRC policy for a given cable, we propose Real2Sim2Real, a self-supervised framework that automatically collects physical trajectory examples to tune parameters of a dynamics simulator using Differential Evolution, generates many simulated examples, and then learns a policy using a weighted combination of simulated and physical data. We evaluate Real2Sim2Real with three simulators, Isaac Gym-segmented, Isaac Gym-hybrid, and PyBullet, two function approximators, Gaussian Processes and Neural Networks (NNs), and three cables with differing stiffness, torsion, and friction. Results with 240 physical trials suggest that the PRC policies can attain median error distance (as % of cable length) ranging from 8 % to 14 %, outperforming baselines and policies trained on only real or only simulated examples. Code, data, and videos are available at https://tinyurl.com/robotcast.	https://doi.org/10.1109/ICRA46639.2022.9811651	Vincent Lim, Huang Huang, Lawrence Yunliang Chen, Jonathan Wang, Jeffrey Ichnowski, Daniel Seita, Michael Laskey, Ken Goldberg
Realtime Trajectory Smoothing with Neural Nets.	In order to safely and efficiently collaborate with humans, industrial robots need the ability to alter their motions quickly to react to sudden changes in the environment, such as an obstacle appearing across a planned trajectory. In Realtime Motion Planning, obstacles are detected in real time through a vision system, and new trajectories are planned with respect to the current positions of the obstacles, and immediately executed on the robot. Existing realtime motion planners, however, lack the smoothing post-processing step - which are crucial in sampling-based motion planning - resulting in the planned trajectories being jerky, and therefore inefficient and less human-friendly. Here we propose a Realtime Trajectory Smoother based on the shortcutting technique to address this issue. Leveraging fast clearance inference by a novel neural network, the proposed method is able to consistently smooth the trajectories of a 6-DOF industrial robot arm within 200 ms on a commercial GPU. We integrate the proposed smoother into a full Vision-Motion Planning-Execution loop and demonstrate a realtime, smooth, performance of an industrial robot subject to dynamic obstacles.	https://doi.org/10.1109/ICRA46639.2022.9812418	Shohei Fujii, Quang-Cuong Pham
Receding Horizon Tracking of an Unknown Number of Mobile Targets using a Bearings-Only Sensor.	Planning the motion of bearings-only sensors is critical for enabling accurate tracking of the positions of moving targets. In this paper, we demonstrate planning the observer's motion over horizons greater than one step for estimating an unknown and varying number of indistinguishable, maneuvering targets of interest using a probability hypothesis density (PHD) filter, with a Rériyi divergence reward for selecting actions. We describe approximations to make this approach computationally feasible, and we propose using Monte Carlo tree search (MCTS) to further reduce the cost. Finally, we present simulation results showing that longer planning horizons reduce the error in the estimates and that MCTS can reduce the cost of planning without sacrificing the quality of the estimates.	https://doi.org/10.1109/ICRA46639.2022.9811882	James D. Turner, James McMahon, Michael M. Zavlanos
Reconfigurable Underactuated Adaptive Gripper Designed by Morphological Computation.	Anthropomorphic robotic grippers are required for robots, prostheses, and orthosis to enable manipulation of a priori unknown and variable-shape objects. It has to meet a wide range of sometimes contradictory requirements in terms of adaptivity, dexterity, high payload to weight ratio, robustness, aesthetics, compactness, lightweight, etc. Within this paper, we utilize the morphological computation approach to introduce design for anthropomorphic re-configurable underactuated grippers. The key to fingers' adaptivity is embedded passive variable length links and elastic elements at input joints. Based on this concept, we designed a palm-size five-finger gripper, where 14 DoFs, including thumb, are controlled by just 4 motors, such that it can perform both precision pinch and encompassing power grasps of various objects. The paper describes synthesized linkages for digits, hand design overview, control strategy, and test results of a physical prototype.	https://doi.org/10.1109/ICRA46639.2022.9811738	Ivan I. Borisov, Evgenii E. Khornutov, Dmitriy V. Ivolga, Nikita A. Molchanov, Ivan A. Maksimov, Sergey A. Kolyubin
Recursive Feasibility Guided Optimal Parameter Adaptation of Differential Convex Optimization Policies for Safety-Critical Systems.	"Quadratic Program(QP) based state-feedback controllers, whose inequality constraints bound the rate of change of control barrier (CBFs) and lyapunov function with a class-\mathcal{K}
function of their values, are sensitive to the parameters of these class-\mathcal{K}
functions. The construction of valid CBFs, however, is not straightforward, and for arbitrarily chosen parameters of the QP, the system trajectories may enter states at which the QP either eventually becomes infeasible, or may not achieve desired performance. In this work, we pose the control synthesis problem as a differential policy whose parameters are optimized for performance over a time horizon at high level, thus resulting in a bi-level optimization routine. In the absence of knowledge of the set of feasible parameters, we develop a Recursive Feasibility Guided Gradient Descent approach for updating the parameters of QP so that the new solution performs at least as well as previous solution. By considering the dynamical system as a directed graph over time, this work presents a novel way of optimizing performance of a QP controller over a time horizon for multiple CBFs by (1) using the gradient of its solution with respect to its parameters by employing sensitivity analysis, and (2) backpropagating these as well as system dynamics gradients to update parameters while maintaining feasibility of QPs."	https://doi.org/10.1109/ICRA46639.2022.9812398	Hardik Parwana, Dimitra Panagou
Reducing Tactile Sim2Real Domain Gaps via Deep Texture Generation Networks.	Recently simulation methods have been developed for optical tactile sensors to enable the Sim2Real learning, i.e., first training models in simulation before deploying them on a real robot. However, some artefacts in real objects are unpredictable, such as imperfections caused by fabrication processes, or scratches by natural wear and tear, and thus cannot be represented in the simulation, resulting in a significant gap between the simulated and real tactile images. To address this Sim2Real gap, we propose a novel texture generation network to map the simulated images into photorealistic tactile images that resemble a real sensor contacting a real imperfect object. Each simulated tactile image is first divided into two types of regions: areas that are in contact with the object and areas that are not. The former is applied with generated textures learned from real textures in the real tactile images, whereas the latter maintains its appearance as when the sensor is not in contact with any object. This makes sure that the artefacts are only applied to deformed regions of the sensor. Our extensive experiments show that the proposed texture generation network can generate realistic artefacts on the deformed regions of the sensor, while avoiding leaking the textures into areas of no contact. Quantitative experiments further reveal that when using the adapted images generated by our proposed network for a Sim2Real classification task, the drop in accuracy caused by the Sim2Real gap is reduced from 38.43% to merely 0.81%. As such, this work has potential to accelerate the Sim2Real learning for robotic tasks requiring tactile sensing.	https://doi.org/10.1109/ICRA46639.2022.9811801	Tudor Jianu, Daniel Fernandes Gomes, Shan Luo
Refactoring ISP for High-Level Vision Tasks.	The image signal processing (ISP) pipeline, which transforms raw sensor measurement to a color image, is composed of a sequence of processing modules. Traditionally, the ISP pipeline is manually tuned by experts for human perception. The resulting handcrafted ISP configuration does not necessarily benefit the downstream high-level vision tasks. To mitigate these problems, this paper presents a simple yet effective framework based on Evolutionary Algorithm to search for a set of compact ISP configurations for high-level vision tasks. In particular, we encode ISP structure into a binary string and ISP parameters into a set of float numbers. Then we jointly optimize them with task-specific loss and ISP computation budgets (e.g., running time) through solving a nonlinear multi-objective optimization problem. By mutating the configurations of the ISP pipeline, we are able to remove redundant modules and design an ISP with both low cost and high accuracy. We validate the proposed method on extreme noisy and low-light raw images, and experimental results show that our framework can help find effective and efficient ISP configurations for both object detection and semantic segmentation tasks. We further provide a detailed analysis on the importance of different modules in the ISP configurations, which benefits the design of ISP for downstream tasks in the future.	https://doi.org/10.1109/ICRA46639.2022.9812052	Yongjie Shi, Songjiang Li, Xu Jia, Jianzhuang Liu
Regulations Aware Motion Planning for Autonomous Surface Vessels in Urban Canals.	In unstructured urban canals, regulation-aware interactions with other vessels are essential for collision avoidance and social compliance. In this paper, we propose a regulations aware motion planning framework for Autonomous Surface Vessels (ASVs) that accounts for dynamic and static obstacles. Our method builds upon local model predictive contouring control (LMPCC) to generate motion plans satisfying kino-dynamic and collision constraints in real-time while including regulation awareness. To incorporate regulations in the planning stage, we propose a cost function encouraging compliance with rules describing interactions with other vessels similar to COLlision avoidance REGulations at sea (COLREGs). These regulations are essential to make an ASV behave in a predictable and socially compliant manner with regard to other vessels. We compare the framework against baseline methods and show more effective regulation-compliant avoidance of moving obstacles with our motion planner. Additionally, we present experimental results in an outdoor environment.	https://doi.org/10.1109/ICRA46639.2022.9811608	Jitske de Vries, Elia Trevisan, Jules van der Toorn, Tuhin Das, Bruno Brito, Javier Alonso-Mora
Reinforcement Learning as a Method for Tuning CPG Controllers for Underwater Multi-Fin Propulsion.	CPG-Based oscillator networks are increasingly being used to drive multi-limbed robots. To produce effective gaits with these networks, the relationship between the CPG parameters and the characteristics of the gait must be determined. However, due to the nonlinear nature of the oscillators, this relationship is challenging to ascertain. In this work a reinforcement learning algorithm is used to determine the CPG parameters that produce propulsively beneficial kinematics in a multi-fin underwater robot. Due to the high computational cost in creating high fidelity simulations of underwater systems, an alternate method using a low fidelity simulation is explored. To better simulate the dynamics of a two-finned swimming robot a thorough force sweep is conducted on the subject robot in a controlled environment. The resulting force data is used as the dynamic information in a simple simulation. This method allows for the learning of CPG weight settings that produce desired kinematic operating conditions and their resulting forces in simulation. Using this method, when the learned CPG parameters were applied directly to the physical robot, the robot executed the same desired kinematics and forces as expected from simulation with no additional learning needed.	https://doi.org/10.1109/ICRA46639.2022.9812128	Anthony Drago, Gabe N. Carryon, James L. Tangorra
Reinforcement Learning for Picking Cluttered General Objects with Dense Object Descriptors.	Picking cluttered general objects is a challenging task due to the complex geometries and various stacking configurations. Many prior works utilize pose estimation for picking, but pose estimation is difficult on cluttered objects. In this paper, we propose Cluttered Objects Descriptors (CODs), a dense cluttered objects descriptor which can represent rich object structures, and use the pre-trained CODs network along with its intermediate outputs to train a picking policy. Additionally, we train the policy with reinforcement learning, which enable the policy to learn picking without supervision. We conduct experiments to demonstrate that our CODs is able to consistently represent seen and unseen cluttered objects, which allowed for the picking policy to robustly pick cluttered general objects. The resulting policy can pick 96.69% of unseen objects in our experimental environment that are twice as cluttered as the training scenarios.	https://doi.org/10.1109/ICRA46639.2022.9811911	Hoang-Giang Cao, Weihao Zeng, I-Chen Wu
Relative Distributed Formation and Obstacle Avoidance with Multi-agent Reinforcement Learning.	Multi-agent formation as well as obstacle avoid-ance is one of the most actively studied topics in the field of multi-agent systems. Although some classic controllers like model predictive control (MPC) and fuzzy control achieve a certain measure of success, most of them require precise global information which is not accessible in harsh environments. On the other hand, some reinforcement learning (RL) based approaches adopt the leader-follower structure to organize different agents' behaviors, which sacrifices the collaboration between agents thus suffering from bottlenecks in maneuver-ability and robustness. In this paper, we propose a distributed formation and obstacle avoidance method based on multi-agent reinforcement learning (MARL). Agents in our system only utilize local and relative information to make decisions and control themselves distributively, and will reorganize themselves into a new topology quickly in case that any of them is dis-connected. Our method achieves better performance regarding formation error, formation convergence rate and on-par success rate of obstacle avoidance compared with baselines (both classic control methods and another RL-based method). The feasibility of our method is verified by both simulation and hardware implementation with Ackermann-steering vehicles.	https://doi.org/10.1109/ICRA46639.2022.9812263	Yuzi Yan, Xiaoxiang Li, Xinyou Qiu, Jiantao Qiu, Jian Wang, Yu Wang, Yuan Shen
Rendering Virtual Inertia in Haptic Interfaces: Analysis and Limitations.	Virtual environments designed for haptic applications are usually rendered as a combination of spring and damper elements. The resulting haptic experience can be greatly enhanced by also adding virtual inertia, for example when interacting with mobile virtual objects. This paper analyzes the impact of implementing virtual inertia on haptic rendering stability. It describes the methodology followed to identify the physical inertia of a mechanism, to derive the acceleration from position, and the implications of this process on stability. Main results show how digital filtering and internal flexibility of the device affect the expected uncoupled stability region.	https://doi.org/10.1109/ICRA46639.2022.9812207	Jorge Juan Gil, Axier Ugartemendia, Iñaki Díaz
ReorientBot: Learning Object Reorientation for Specific-Posed Placement.	Robots need the capability of placing objects in arbitrary, specific poses to rearrange the world and achieve various valuable tasks. Object reorientation plays a crucial role in this as objects may not initially be oriented such that the robot can grasp and then immediately place them in a specific goal pose. In this work, we present a vision-based manipulation system, ReorientBot, which consists of 1) visual scene understanding with pose estimation and volumetric reconstruction using an onboard RGB-D camera; 2) learned waypoint selection for successful and efficient motion generation for reorientation; 3) traditional motion planning to generate a collision-free trajectory from the selected waypoints. We evaluate our method using the YCB objects in both simulation and the real world, achieving 93% overall success, 81% improvement in success rate, and 22% improvement in execution time compared to a heuristic approach. We demonstrate extended multi-object rearrangement showing the general capability of the system.	https://doi.org/10.1109/ICRA46639.2022.9811881	Kentaro Wada, Stephen James, Andrew J. Davison
RepAr-Net: Re-Parameterized Encoders and Attentive Feature Arsenals for Fast Video Denoising.	Real-time video denoising finds applications in several fields like mobile robotics, satellite television, and surveillance systems. Traditional denoising approaches are more common in such systems than their deep learning-based counterparts despite their inferior performance. The large size and heavy computational requirements of neural network-based denoising models pose a serious impediment to their deployment in real-time applications. In this paper, we propose RepAr-Net, a simple yet efficient architecture for fast video de noising. We propose to use temporally separable encoders to generate feature maps called arsenals that can be cached for reuse. We also incorporate re-parameterizable blocks that improve the representative power of the network without affecting the run-time. We benchmark our model on the Set-8 and 2017 DAVIS-Test datasets. Our model achieves state-of-the-art results with up to 29.62% improvement in PSNR and a 50% decrease in run times over existing methods. Our codes are open-sourced at: github.com/spider-tronix/RepAr-Net.	https://doi.org/10.1109/ICRA46639.2022.9812394	S. P. Sharan, Adithya K. Krishna, A. Siddharth Rao, Varun P. Gopi
Repeated Jumping with the REBOund: Self-Righting Jumping Robot Leveraging Bistable Origami-Inspired Design.	Repeated jumping is crucial to the mobility of jumping robots. In this paper, we extend upon the REBOund jumping robot design, an origami-inspired jumping robot that uses the Reconfigurable Expanding Bistable Origami (REBO) pattern as its body. The robot design takes advantage of the pattern's bistability to jump with controllable timing. For jump repeatedly, we also add self-righting legs that utilize a single motor actuation mechanism. We describe a dynamic model that captures the compression of the REBO pattern and the REBOund self-righting process and compared it to the physical robot. Our experiments show that the REBOund is able to successfully self-right and jump repeatedly over tens of jumps.	https://doi.org/10.1109/ICRA46639.2022.9812232	Yuchen Sun, Joanna Wang, Cynthia Sung
Repeated Robot-Assisted Unilateral Stiffness Perturbations Result in Significant Aftereffects Relevant to Post-Stroke Gait Rehabilitation.	Due to hemiparesis, stroke survivors frequently develop a dysfunctional gait that is often characterized by an overall decrease in walking speed and a unilateral decrease in step length. With millions currently affected by this dys-functional gait, robust and effective rehabilitation protocols are needed. Although robotic devices have been used in numerous rehabilitation protocols for gait, the lack of significant afteref-fects that translate to effective therapy makes their application still questionable. This paper proposes a novel type of robot-assisted intervention that results in significant aftereffects that last much longer than any other previous study. With the utilization of a novel robotic device, the Variable Stiffness Treadmill (VST), the stiffness of the walking surface underneath one leg is decreased for a number of steps. This unilateral stiffness perturbation results in a significant aftereffect that is both useful for stroke rehabilitation and often lasts for over 200 gait cycles after the intervention has concluded. More specifically, the aftereffect created is an increase in both left and right step lengths, with the unperturbed step length increasing significantly more than the perturbed. These effects may be helpful in correcting two of the most common issues in post-stroke gait: overall decrease in walking speed and a unilateral shortened step length. The results of this work show that a robot-assisted therapy protocol involving repeated unilateral stiffness perturbations can lead to a more permanent and effective solution to post-stroke gait.	https://doi.org/10.1109/ICRA46639.2022.9812323	Vaughn Chambers, Panagiotis Artemiadis
Reproduction of Human Demonstrations with a Soft-Robotic Arm based on a Library of Learned Probabilistic Movement Primitives.	In this paper we introduce a novel technique that aims to control a two-module bio-inspired soft-robotic arm in order to qualitatively reproduce human demonstrations. The main idea behind the proposed methodology is based on the assumption that a complex trajectory can be derived from the composition and asynchronous activation of learned parameterizable simple movements constituting a knowledge base. The present work capitalises on recent research progress in Movement Primitive (MP) theory in order to initially build a library of Probabilistic MPs (ProMPs), and subsequently to compute on the fly their proper combination in the task space resulting in the requested trajectory. At the same time, a model learning method is assigned with the task to approximate the inverse kinematics, while a replanning procedure handles the sequential and/or parallel ProMPs' asynchronous activation. Taking advantage of the mapping at the primitive-level that the ProMP framework provides, the composition is transferred into the actuation space for execution. The proposed control architecture is experimentally evaluated on a real soft-robotic arm, where its capability to simplify the trajectory control task for robots of complex unmodeled dynamics is exhibited.	https://doi.org/10.1109/ICRA46639.2022.9811627	Paris Oikonomou, Athanasios Dometios, Mehdi Khamassi, Costas S. Tzafestas
Resolution-Optimal Motion Planning for Steerable Needles.	Medical steerable needles can follow 3D curvilinear trajectories inside body tissue, enabling them to move around critical anatomical structures and precisely reach clinically significant targets in a minimally invasive way. Automating needle steering, with motion planning as a key component, has the potential to maximize the accuracy, precision, speed, and safety of steerable needle procedures. In this paper, we introduce the first resolution-optimal motion planner for steerable needles that offers excellent practical performance in terms of runtime while simultaneously providing strong theoretical guarantees on completeness and the global optimality of the motion plan in finite time. Compared to state-of-the-art steerable needle motion planners, simulation experiments on realistic scenarios of lung biopsy demonstrate that our proposed planner is faster in generating higher-quality plans while incorporating clinically relevant cost functions. This indicates that the theoretical guarantees of the proposed planner have a practical impact on the motion plan quality, which is valuable for computing motion plans that minimize patient trauma.	https://doi.org/10.1109/ICRA46639.2022.9811850	Mengyu Fu, Kiril Solovey, Oren Salzman, Ron Alterovitz
Rethinking LiDAR Object Detection in adverse weather conditions.	LiDAR sensors are becoming crucial for achieving higher levels of autonomy. With the current sensor technology, LiDAR sensors are still susceptible to erroneous measurements in adverse weather conditions due to weather artifacts observed in the point cloud data. In this work, we analyze the performance of deep learning LiDAR object detectors in adverse weather conditions. We study the under-researched albeit crucial aspect of deep learning - the size and the content of the training data, as we believe that efforts in data curation bring more benefit than often preferred complex algorithmic enhancements. We argue that with sufficient data, learning-based object detectors are inherently capable of distinguishing between points from a true object and weather-induced artifacts in an end-to-end manner, thus, making explicit, handcrafted and computationally expensive point cloud prefiltering steps obsolete. We corroborate our hypothesis by conducting experiments on a variety of LiDAR object detection architectures over two subsets of training data - one comprising of all weather conditions and the other one comprising of only clear conditions. Contrary to popular belief that object detectors need to be trained on data from adverse weather conditions to be performant in adverse weather, we show that training on datasets with a higher number of annotated objects, predominantly acquired in clear conditions, is sufficient to achieve almost similar or sometimes better KPIs across all weather conditions. This makes the data collection more accessible and convenient compared to adverse weather conditions that are often hardly accessible (e.g., heavy snow and fog). Finally, our proposed methodology streamlines the LiDAR perception pipeline in the direction of keeping well-known end-to-end trainable architectures, removing additional pre-processing blocks that are often handcrafted and bring an additional computational cost.	https://doi.org/10.1109/ICRA46639.2022.9812039	Teja Vattem, George Sebastian, Luka Lukic
Retriever: Point Cloud Retrieval in Compressed 3D Maps.	Most autonomous driving and robotic applications require retrieving map data around the vehicle's current location. Those maps can cover large areas and are often stored in a compressed form to save memory and allow for efficient transmission. In this paper, we address the problem of place recognition in a compressed point cloud map. To this end, we propose a novel deep neural network architecture that directly operates on a compressed feature representation produced by a compression encoder. This enables us to bypass compute-heavy decompression of the map and exploits the compact as well as descriptive nature of the compressed features. Additionally, we propose an alternative to the commonly used NetVLAD layer to aggregate local descriptors. Here, we utilize an attention mechanism between local features and a latent code. Our experiments suggest that this produces a more descriptive feature representation of the point clouds for place recognition. We experimentally validate all architectural choices we made by our ablation studies and compare our performance to other state-of-the-art baselines on two commonly used datasets.	https://doi.org/10.1109/ICRA46639.2022.9811785	Louis Wiesmann, Rodrigo Marcuzzi, Cyrill Stachniss, Jens Behley
Roboethics as a Design Challenge: Lessons Learned from the Roboethics to Design and Development Competition.	How do we make concrete progress towards de-signing robots that can navigate ethically sensitive contexts? Almost two decades after the word 'roboethics' was coined, translating interdisciplinary roboethics discussions into techni-cal design still remains a daunting task. This paper describes our first attempt at addressing these challenges through a roboethics-themed design competition. The design competition setting allowed us to (a) formulate ethical considerations as an engineering design task that anyone with basic programming skills can tackle; and (b) develop a prototype evaluation scheme that incorporates diverse normative perspectives of multiple stakeholders. The initial implementation of the competition was held online at the RO-MAN 2021 conference. The competition task involved programming a simulated mobile robot (TIAGo) that delivers items for individuals in the home environment, where many of these tasks involve ethically sensitive con-texts (e.g., an underage family member asks for an alcoholic drink). This paper outlines our experiences implementing the competition and the lessons we learned. We highlight design competitions as a promising mechanism to enable a new wave of roboethics research equipped with technical design solutions.	https://doi.org/10.1109/ICRA46639.2022.9812265	Jimin Rhim, Cheng Lin, Alexander Werner, Brandon J. DeHart, Vivian Qiang, Shalaleh Rismani, AJung Moon
Robot Grasping through a Joint-Initiative Supervised Autonomy Framework.	Robot grasping applications are faced with challenges and limitations leading to errors that affect their performance and accuracy. Although these errors are reduced in expensive industrial systems, low-cost robots are still prone to inaccurate perception and execution due to their limited hardware and software capabilities. To mitigate these challenges and limitations, this work develops a Joint-Initiative Supervised Autonomy (JISA) framework for robot grasping. In the proposed system, a human supervisor provides assistance to the robot's perception and planning modules, where the assistance is triggered by requests made by the robot based on its self confidence (SC) metric. Moreover, the human supervisor can also assist the robot in eliminating execution errors based on his/her situation awareness (SA). Through experimental validation, we show that including a human supervisor in the loop for grasping tasks in low-cost robots outperforms full autonomy. In fact, our proposed system showed a marked performance improvement by increasing the end-to-end success rate of the baseline approach, which we implemented JISA on, from 35.0% to 87.6%.	https://doi.org/10.1109/ICRA46639.2022.9811721	Abbas Sidaoui, Naseem A. Daher, Daniel C. Asmar
Robot Learning Physical Object Properties from Human Visual Cues: A novel approach to infer the fullness level in containers.	For collaborative tasks, involving handovers, humans are able to exploit visual, non-verbal cues, to infer physical object properties, like mass, to modulate their actions. In this paper, we investigate how the different levels of liquid inside a cup can be inferred from the observation of the movement of the person handling the cup. We model this mechanism from human experiments and incorporate it in an online human-to-robot handover. Finally, we provide a new dataset with human eye+head+hand motion data for human-to-human handovers and human pick-and-place of a cup with three levels of liquid: empty, half-full, and full of water. Our results show that it is possible to model (non-verbal) signals exchanged by humans during interaction and classify the level of water inside the cup being handed over.	https://doi.org/10.1109/ICRA46639.2022.9811725	Nuno Ferreira Duarte, Mirko Rakovic, José Santos-Victor
Robot Skill Adaptation via Soft Actor-Critic Gaussian Mixture Models.	"A
core challenge for an autonomous agent acting in the real world is to adapt its repertoire of skills to cope with its noisy perception and dynamics. To scale learning of skills to long-horizon tasks, robots should be able to learn and later refine their skills in a structured manner through trajectories rather than making instantaneous decisions individually at each time step. To this end, we propose the Soft Actor- Critic Gaussian Mixture Model (SAC-GMM), a novel hybrid approach that learns robot skills through a dynamical system and adapts the learned skills in their own trajectory distribution space through interactions with the environment. Our approach combines classical robotics techniques of learning from demonstration with the deep reinforcement learning framework and exploits their complementary nature. We show that our method utilizes sensors solely available during the execution of preliminarily learned skills to extract relevant features that lead to faster skill refinement. Extensive evaluations in both simulation and real-world environments demonstrate the effectiveness of our method in refining robot skills by leveraging physical interactions, high-dimensional sensory data, and sparse task completion rewards. Videos, code, and pre-trained models are available at http://sac-gmm.cs.uni-freiburg.de."	https://doi.org/10.1109/ICRA46639.2022.9811770	Iman Nematollahi, Erick Rosete-Beas, Adrian Röfer, Tim Welschehold, Abhinav Valada, Wolfram Burgard
Robotic Autonomous Trolley Collection with Progressive Perception and Nonlinear Model Predictive Control.	Autonomous mobile manipulation robots that can collect trolleys are widely used to liberate human resources and fight epidemics. Most prior robotic trolley collection solutions only detect trolleys with 2D poses or are merely based on spe-cific marks and lack the formal design of planning algorithms. In this paper, we present a novel mobile manipulation system with applications in luggage trolley collection. The proposed system integrates a compact hardware design and a progressive perception and planning framework, enabling the system to efficiently and robustly collect trolleys in dynamic and complex environments. For perception, we first develop a 3D trolley detection method that combines object detection and keypoint estimation. Then, a docking process in a short distance is achieved with an accurate point cloud plane detection method and a novel manipulator design. On the planning side, we formulate the robot's motion planning under a nonlinear model predictive control framework with control barrier functions to improve obstacle avoidance capabilities while maintaining the target in the sensors' field of view at close distances. We demonstrate our design and framework by deploying the system on actual trolley collection tasks, and their effectiveness and robustness are experimentally validated. (Video 11Video demonstration: https://youtu.be/6SwjgGvRtno.)	https://doi.org/10.1109/ICRA46639.2022.9812455	Anxing Xiao, Hao Luan, Ziqi Zhao, Yue Hong, Jieting Zhao, Weinan Chen, Jiankun Wang, Max Q.-H. Meng
Robotic Cell Manipulation for Blastocyst Biopsy.	Soft tissue cutting is used for incision, separation and removal of tissues or cells. Due to high deformation of soft tissues resulting from their viscosity and elasticity, it is challenging to accurately cut the tissue along a desired path and control the force applied to the tissue for reducing invasiveness, especially at the microscale. This paper presents a robotic biopsy system for cutting and collecting trophectoderm cells from a highly deformable blastocyst. The system, for the first time, enables TE cell junction detection for laser ablation throughout the blastocyst biopsy process by using a convolutional neural network. The overall detection error was 2.13% in every 1,000 cell junctions with position RMSE of 1.63\\ \\mu \\mathrm{m}\\pm 0.29\\ \\mu \\mathrm{m}\n. A dynamics model was developed to describe the motion of the trophectoderm cells inside a biopsy micropipette. Based on this model, an adaptive control method was developed for trophectoderm cell aspiration and positioning inside the biopsy micropipette. Experimental results revealed that the controller was capable of effectively compensating for the cell positioning error by updating the varying system parameters according to the adaptation law. The success rate was 100%, the cell aggregate positioning accuracy was \\pm 1\\ \\mu \\mathrm{m}\n, the average settling time was 2 s, and the largest overshoot was 4.3\\ \\mu \\mathrm{m}\n. Compared to manual blastocyst biopsy, the robotic biopsy system shortened the blastocyst's recovery time (35 min vs. 50 min) which indicates lower invasiveness.	https://doi.org/10.1109/ICRA46639.2022.9812246	Guanqiao Shan, Zhuoran Zhang, Changsheng Dai, Hang Liu, Xian Wang, Wenkun Dou, Yu Sun
Robotic Manipulators Performing Smart Sanding Operation: A Vibration Approach.	This paper presents the design of a novel expert system for robotic manipulators performing sanding tasks on work surfaces. The expert system adjusts the velocity of the robotic manipulator based on the observed surface quality. These observation are obtained by an analysis of the raw force data provided by a force-torque sensor at the end-effector level. The expert system consists of two governing control laws that act in parallel, a variable velocity generation law and a pose regulation-based law. The variable velocity law regulates the velocity of the manipulator along a set path, in the tangent direction, based on an analysis of the frequency and amplitude of the force signal generated during the sanding process. The pose regulation-based law drives the manipulator in the bi-normal and rotational direction, ensuring the manipulators remain on the sanding path with the desired orientation. The proposed strategy is experimentally evaluated using the UR5e collaborative robotic manipulator sanding wood and metal panels. The obtained results show that such an approach is beneficial to ensure accurate contact between the sanding tool and the working environment, robust path tracking, and smart sanding.	https://doi.org/10.1109/ICRA46639.2022.9812029	Joshua Nguyen, Manuel F. Bailey, Ignacio Carlucho, Corina Barbalata
Robotically-Aligned Optical Coherence Tomography with Gaze Tracking for Live Image Montaging of the Retina.	Optical coherence tomography (OCT) has revolutionized diagnostics in ophthalmology. However, it requires pa-tient cooperation to fixate on multiple targets and stabilize their head utilizing both chin and forehead rests. Patient cooperation is particularly important for image montaging, where patients are asked to fixate on multiple targets to sequentially image different regions of interest on the retina. These individual volumes are then combined into a single large field of view volume. To automate the OCT image acquisition process, we previously developed a robot-mounted OCT scanner that auto-aligned with the retinal region of interest while compensating for subject motion. We utilized this system to self-align at multiple regions-of-interest and acquire stabilized volumes. We then montaged volume projections into a larger field of view image. The system tracked the 3D location of the subject's eye as well as their gaze orientation using a combination of face and pupil tracking cameras. We demonstrated automated OCT acquisition for live image montaging on free-standing subjects and evaluated the consistency of our live volumetric mapping on human subject data. Our results demonstrate that the system not only stabilized images, but also provided sufficient control of region-of-interest specific alignment to automatically acquire and montage OCT images, synthetically increasing the system's field of view by\n20\n∘\n.	https://doi.org/10.1109/ICRA46639.2022.9812428	Pablo Ortiz, Mark Draelos, Amit Narawane, Ryan P. McNabb, Anthony N. Kuo, Joseph A. Izatt
Robust Control Under Uncertainty via Bounded Rationality and Differential Privacy.	The rapid development of affordable and compact high-fidelity sensors (e.g., cameras and LIDAR) allows robots to construct detailed estimates of their states and environments. However, the availability of such rich sensor information introduces two challenges: (i) the lack of analytic sensing models, which makes it difficult to design controllers that are robust to sensor failures, and (ii) the computational expense of processing the high-dimensional sensor information in real time. This paper addresses these challenges using the theory of differential privacy, which allows us to (i) design controllers with bounded sensitivity to errors in state estimates, and (ii) bound the amount of state information used for control (i.e., to impose decision-making under bounded rationality). The resulting framework approximates the separation principle and allows us to derive an upper-bound on the cost incurred with a faulty state estimator in terms of three quantities: the cost incurred using a perfect state estimator, the magnitude of state estimation errors, and the level of differential privacy. We demonstrate the efficacy of our framework numerically on different robotics problems, including nonlinear system stabilization and motion planning.	https://doi.org/10.1109/ICRA46639.2022.9811557	Vincent Pacelli, Anirudha Majumdar
Robust Impedance Control for Dexterous Interaction Using Fractal Impedance Controller with IK-Optimisation.	Robust dynamic interactions are required to move robots in daily environments alongside humans. Optimisation and learning methods have been used to mimic and reproduce human movements. However, they are often not robust and their generalisation is limited. This work proposed a hierarchical control architecture for robot manipulators and provided capabilities of reproducing human-like motions during unknown interaction dynamics. Our results show that the reproduced end-effector trajectories can preserve the main characteristics of the initial human motion recorded via a motion capture system, and are robust against external perturbations. The data indicate that some detailed movements are hard to reproduce due to the physical limits of the hardware that cannot reach the same velocity recorded in human movements. Nevertheless, these technical problems can be addressed by using better hardware and our proposed algorithms can still be applied to produce imitated motions.	https://doi.org/10.1109/ICRA46639.2022.9812013	Carlo Tiseo, Quentin Rouxel, Zhibin Li, Michael N. Mistry
Robust Monocular Localization in Sparse HD Maps Leveraging Multi-Task Uncertainty Estimation.	Robust localization in dense urban scenarios using a low-cost sensor setup and sparse HD maps is highly relevant for the current advances in autonomous driving, but remains a challenging topic in research. We present a novel monocular localization approach based on a sliding-window pose graph that leverages predicted uncertainties for increased precision and robustness against challenging scenarios and per-frame failures. To this end, we propose an efficient multi-task uncertainty-aware perception module, which covers semantic segmentation, as well as bounding box detection, to enable the localization of vehicles in sparse maps, containing only lane borders and traffic lights. Further, we design differentiable cost maps that are directly generated from the estimated uncertainties. This opens up the possibility to minimize the reprojection loss of amorphous map elements in an association-free and uncertainty-aware manner. Extensive evaluation on the Lyft 5 dataset shows that, despite the sparsity of the map, our approach enables robust and accurate 6D localization in challenging urban scenarios using only monocular camera images and vehicle odometry.	https://doi.org/10.1109/ICRA46639.2022.9812266	Kürsat Petek, Kshitij Sirohi, Daniel Büscher, Wolfram Burgard
Robust Pivoting: Exploiting Frictional Stability Using Bilevel Optimization.	Generalizable manipulation requires that robots be able to interact with novel objects and environment. This requirement makes manipulation extremely challenging as a robot has to reason about complex frictional interaction with uncertainty in physical properties of the object. In this paper, we study robust optimization for control of pivoting manipulation in the presence of uncertainties. We present insights about how friction can be exploited to compensate for the inaccuracies in the estimates of the physical properties during manipulation. In particular, we derive analytical expressions for stability margin provided by friction during pivoting manipulation. This margin is then used in a bilevel trajectory optimization algorithm to design a controller that maximizes this stability margin to provide robustness against uncertainty in physical properties of the object. We demonstrate our proposed method using a 6 DoF manipulator for manipulating several different objects.	https://doi.org/10.1109/ICRA46639.2022.9811812	Yuki Shirai, Devesh K. Jha, Arvind U. Raghunathan, Diego Romeres
Robust Reinforcement Learning via Genetic Curriculum.	Achieving robust performance is crucial when applying deep reinforcement learning (RL) in safety critical systems. Some of the state of the art approaches try to address the problem with adversarial agents, but these agents often require expert supervision to fine tune and prevent the adversary from becoming too challenging to the trainee agent. While other approaches involve automatically adjusting environment setups during training, they have been limited to simple environments where low-dimensional encodings can be used. Inspired by these approaches, we propose genetic curriculum, an algorithm that automatically identifies scenarios in which the agent currently fails and generates an associated curriculum to help the agent learn to solve the scenarios and acquire more robust behaviors. As a non-parametric optimizer, our approach uses a raw, non-fixed encoding of scenarios, reducing the need for expert supervision and allowing our algorithm to adapt to the changing performance of the agent. Our empirical studies show improvement in robustness over the existing state of the art algorithms, providing training curricula that result in agents being 2 - 8x times less likely to fail without sacrificing cumulative reward. We include an ablation study and share insights on why our algorithm outperforms prior approaches.	https://doi.org/10.1109/ICRA46639.2022.9812420	Yeeho Song, Jeff Schneider
Robust Semantic Mapping and Localization on a Free-Flying Robot in Microgravity.	We propose a system that uses semantic object detections to localize a microgravity free-flyer. Many applications require absolute localization in a known reference frame, such as the execution of waypoint trajectories defined by human operators. Classical geometric methods build a map of point features, which may not be able to be associated after lighting or environmental changes. By contrast, semantics remain invariant to changes up to the robustness of the detection algorithm and motion of the semantic objects. In this work, we describe our approaches for both offline semantic map generation as well as online localization against a semantic map, intended to run in real-time on the robot. We additionally demonstrate how our semantic localizer outperforms image-feature matching in some cases, and show the robustness of the algorithm to environmental changes. Crucially, we show in our experiments that when semantics are used to supplement point features, localization is always improved. To our knowledge, these experiments demonstrate the first use of learned semantics for localization on a free-flying robot in microgravity.	https://doi.org/10.1109/ICRA46639.2022.9811862	Ian D. Miller, Ryan Soussan, Brian Coltin, Trey Smith, Vijay Kumar
Robust and Accurate Multi-Agent SLAM with Efficient Communication for Smart Mobiles.	In a long-term large-scenario application, the multi-agent collaborative SLAM is expected to improve the robustness and efficiency of executing tasks for mobile agents. In this paper, a multi-agent collaborative visual-inertial SLAM system is proposed based on a centralized client-server (CS) architecture, where the clients run on smart mobiles. In general, multi-agent collaborative SLAM relies on robust and precise experience sharing and efficient communication among agents. The experience sharing requires the place recognition with a high recall and accuracy, the precise estimation of transformation between looping frames, and the map fusion with globally consistency. To this end, we devise an enhanced geometric verification, a re-projection optimization based on the error-aware weighting strategy, and a strategy of flexible fusion to meet these requirements. In addition, the multi-agent collaborative SLAM needs to exchange abundant information, which requires the efficient communication. Therefore, we design a CS collaborative loop detection mechanism which is more robust to network transmission. We perform extensive experiments on the EuRoc dataset and in real environments. Experimental results show that the proposed system achieves better results than state-of-the-art methods. Furthermore, we demonstrate the stability of the proposed collaborative SLAM in real environments with a bandwidth of 7.55Mbps.	https://doi.org/10.1109/ICRA46639.2022.9812366	Jialing Liu, Kaiqi Chen, Ruyu Liu, Yanhong Yang, Zhenhua Wang, Jianhua Zhang
Robust-by-Design Plans for Multi-Robot Pursuit-Evasion.	This paper studies a multi-robot visibility-based pursuit-evasion problem in which a group of pursuer robots are tasked with detecting an evader within a two dimensional polygonal environment. The primary contribution is a novel formulation of the pursuit-evasion problem that modifies the pursuers' objective by requiring that the evader still be de-tected, even in spite of the failure of any single pursuer robot. This novel constraint, whereby two pursuers are required to detect an evader, has the benefit of providing redundancy to the search, should any member of the team become unresponsive, suffer temporary sensor disruption/failure, or otherwise become incapacitated. Existing methods, even those that are designed to respond to failures, rely on the pursuers to replan and update their search pattern to handle such occurrences. In contrast, the proposed formulation produces plans that are inherently tolerant of some level of disturbance. Building upon this new formulation, we introduce an augmented data structure for encoding the problem state and a novel sampling technique to ensure that the generated plans are robust to failures of any single pursuer robot. An implementation and simulation results illustrating the effectiveness of this approach are described.	https://doi.org/10.1109/ICRA46639.2022.9812333	Trevor Olsen, Nicholas M. Stiffler, Jason M. O'Kane
Runtime Detection of Executional Errors in Robot-Assisted Surgery.	Despite significant developments in the design of surgical robots and automated techniques for objective evaluation of surgical skills, there are still challenges in ensuring safety in robot-assisted minimally-invasive surgery (RMIS). This paper presents a runtime monitoring system for the detection of executional errors during surgical tasks through the analysis of kinematic data. The proposed system incorporates dual Siamese neural networks and knowledge of surgical context, including surgical tasks and gestures, their distributional similarities, and common error modes, to learn the differences between normal and erroneous surgical trajectories from small training datasets. We evaluate the performance of the error detection using Siamese networks compared to single CNN and LSTM networks trained with different levels of contextual knowledge and training data, using the dry-lab demonstrations of the Suturing and Needle Passing tasks from the JIGSAWS dataset. Our results show that gesture specific task nonspecific Siamese networks obtain micro F1 scores of 0.94 (Siamese-CNN) and 0.95 (Siamese-LSTM), and perform better than single CNN (0.86) and LSTM (0.87) networks. These Siamese networks also outperform gesture nonspecific task specific Siamese-CNN and Siamese-LSTM models for Suturing and Needle Passing.	https://doi.org/10.1109/ICRA46639.2022.9812034	Zongyu Li, Kay Hutchinson, Homa Alemzadeh
Runtime Safety Assurance for Learning-enabled Control of Autonomous Driving Vehicles.	Providing safety guarantees for Autonomous Vehicle (AV) systems with machine-learning based controllers remains a challenging issue. In this work, we propose Simplex-Drive, a framework that can achieve runtime safety assurance for machine-learning enabled controllers of AVs. The proposed Simplex-Drive consists of an unverified Deep Reinforcement Learning (DRL)-based advanced controller (AC) that achieves desirable performance in complex scenarios, a Velocity-Obstacle (VO) based baseline safe controller (BC) with provably safety guarantees, and a verified mode management unit that monitors the operation status and switches the control authority between AC and BC based on safety-related conditions. We provide a formal correctness proof of Simplex-Drive and conduct a lane-changing case study in dense traffic scenarios. The simulation experiment results demonstrate that Simplex-Drive can always ensure the operation safety without sacrificing control performance, even if the DRL policy may lead to deviations from the safe status.	https://doi.org/10.1109/ICRA46639.2022.9812177	Shengduo Chen, Yaowei Sun, Dachuan Li, Qiang Wang, Qi Hao, Joseph Sifakis
SAFIT: Segmentation-Aware Scene Flow with Improved Transformer.	Scene flow prediction is a challenging task that aims at jointly estimating the 3D structure and 3D motion of dynamic scenes. The previous methods concentrate more on point-wise estimation instead of considering the correspondence between objects as well as lacking the sensation of high-level semantic knowledge. In this paper, we propose a concise yet effective method for scene flow prediction. The key idea is to extend the view of all points for computing point cloud features into object-level, thus simultaneously modeling the relationships of the object-level and point-level via an improved transformer. In addition, we introduce a novel unsupervised loss called segmentation-aware loss, which can model semanticaware details to help predict scene flow more accurately and robustly. Since this loss can be trained without any ground truth, it can be used in both supervised training and self-supervised training. Experiments on both supervised training and self-supervised training demonstrate the effectiveness of our method. On supervised training, 3.8%, 22.58%, 10.90% and 21.82 % accuracy boosts than FLOT [23] can be observed on FT3Ds, KITTIs, FT3Do and KITTIo datasets. On self-supervised scheme, 48.23% and 48.96% accuracy boost than PointPWC-Net [40] can be observed on KITTIo and KITTIs datasets.	https://doi.org/10.1109/ICRA46639.2022.9811747	Yukang Shi, Kaisheng Ma
SAGCI-System: Towards Sample-Efficient, Generalizable, Compositional, and Incremental Robot Learning.	Building general-purpose robots to perform a diverse range of tasks in a large variety of environments in the physical world at the human level is extremely challenging. According to [1], it requires the robot learning to be sample-efficient, generalizable, compositional, and incremental. In this work, we introduce a systematic learning framework called SAGCI-system towards achieving these above four requirements. Our system first takes the raw point clouds gathered by the camera mounted on the robot's wrist as the inputs and produces initial modeling of the surrounding environment represented as a file of Unified Robot Description Format (URDF). Our system adopts a learning-augmented differentiable simulation that loads the URDF. The robot then utilizes the interactive perception to interact with the environment to online verify and modify the URDF. Leveraging the differentiable simulation, we propose a model-based learning algorithm combining object-centric and robot-centric stages to efficiently produce policies to accomplish manipulation tasks. We apply our system to perform articulated object manipulation tasks, both in the simulation and the real world. Extensive experiments demonstrate the effectiveness of our proposed learning framework. Supplemental materials and videos are available on our project webpage https://sites.google.com/view/egci.	https://doi.org/10.1109/ICRA46639.2022.9811859	Jun Lv, Qiaojun Yu, Lin Shao, Wenhai Liu, Wenqiang Xu, Cewu Lu
SAGE: SLAM with Appearance and Geometry Prior for Endoscopy.	In endoscopy, many applications (e.g., surgical navigation) would benefit from a real-time method that can simultaneously track the endoscope and reconstruct the dense 3D geometry of the observed anatomy from a monocular endoscopic video. To this end, we develop a Simultaneous Localization and Mapping system by combining the learning-based appearance and optimizable geometry priors and factor graph optimization. The appearance and geometry priors are explicitly learned in an end-to-end differentiable training pipeline to master the task of pair-wise image alignment, one of the core components of the SLAM system. In our experiments, the proposed SLAM system is shown to robustly handle the challenges of texture scarceness and illumination variation that are commonly seen in endoscopy. The system generalizes well to unseen endoscopes and subjects and performs favorably compared with a state-of-the-art feature-based SLAM system. The code repository is available at https://github.com/lppllpp1920/SAGE-SLAM.git.	https://doi.org/10.1109/ICRA46639.2022.9812257	Xingtong Liu, Zhaoshuo Li, Masaru Ishii, Gregory D. Hager, Russell H. Taylor, Mathias Unberath
SEHLNet: Separate Estimation of High- and Low-Frequency components for Depth Completion.	Depth completion refers to inferring the dense depth map from a sparse depth map with or without corre-sponding color image. Numerous neural networks have been proposed to accomplish this task. However, insufficient uti-lization of heteromorphic data and the fact that predicted dense depth prefers a sparse depth enormously damage the performance of approaches. To reduce data preference and fully utilize two modalities, this paper proposes a novel network that predicts high- and low-frequency components of dense depth separately. Specifically, the framework consists of a Low-Frequency(LF) branch and a High-Frequency(HF) branch. In the LF branch, we recover the low-frequency depth component from sparse depth through an Adaptive Graph-Generate Graph Attention Network, which can be seen as a low-pass filter. In the HF branch, we model the high-frequency component, e.g. boundaries, as residuals to mitigate the impact of data preferences. Moreover, in this branch, we propose an Attention-based Self-Fusion mechanism to efficiently fuse multi-scale features extracted from the sparse depth and color image. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on the KITTI benchmark and ranks 1st in root mean squared error among other published approaches.	https://doi.org/10.1109/ICRA46639.2022.9811840	Qiang Liu, Haosong Yue, Zhanggang Lyu, Wei Wang, Zhong Liu, Weihai Chen
SEMI: Self-supervised Exploration via Multisensory Incongruity.	Efficient exploration is a long-standing problem in reinforcement learning since extrinsic rewards are usually sparse or missing. A popular solution to this issue is to feed an agent with novelty signals as intrinsic rewards. In this work, we introduce SEMI, a self-supervised exploration policy by incentivizing the agent to maximize a new novelty signal: multisensory incongruity, which can be measured in two aspects, perception incongruity and action incongruity. The former represents the misalignment of the multisensory inputs, while the latter represents the variance of an agent's policies under different sensory inputs. Specifically, an alignment predictor is learned to detect whether multiple sensory inputs are aligned, the error of which is used to measure perception incongruity. A policy model takes different combinations of the multisensory observations as input, and outputs actions for exploration. The variance of actions is further used to measure action incongruity. Using both incongruities as intrinsic rewards, SEMI allows an agent to learn skills by exploring in a self-supervised manner without any external rewards. We further show that SEMI is compatible with extrinsic rewards and it improves sample efficiency of policy learning. The effectiveness of SEMI is demonstrated across a variety of benchmark environments including object manipulation and audio-visual games.	https://doi.org/10.1109/ICRA46639.2022.9811979	Jianren Wang, Ziwen Zhuang, Hang Zhao
SMAC-Seg: LiDAR Panoptic Segmentation via Sparse Multi-directional Attention Clustering.	Panoptic segmentation aims to address semantic and instance segmentation simultaneously in a unified framework. However, an efficient solution of panoptic segmentation in applications like autonomous driving is still an open research problem. In this work, we propose a novel LiDAR-based panoptic system, called SMAC-Seg. We present a learnable sparse multi-directional attention clustering to segment multi-scale foreground instances. SMAC-Seg is a real-time clustering-based approach, which removes the complex proposal network to segment instances. Most existing clustering-based methods use the difference of the predicted and ground truth center offset as the only loss to supervise the instance centroid regression. However, this loss function only considers the centroid of the current object, but its relative position with respect to the neighbouring objects is not considered when learning to cluster. Thus, we propose to use a novel centroid-aware repel loss as an additional term to effectively supervise the network in order to differentiate each object cluster with its neighbours. Our experimental results show that SMAC-Seg achieves state-of-the-art performance among all real-time deployable networks on both large-scale public SemanticKITTI and nuScenes panoptic segmentation datasets.	https://doi.org/10.1109/ICRA46639.2022.9812408	Enxu Li, Ryan Razani, Yixuan Xu, Bingbing Liu
SMORS: A soft multirotor UAV for multimodal locomotion and robust interaction.	We present SMORS, the first Soft fully actuated MultirOtoR System for multimodal locomotion. Unlike conventional hexarotors, SMORS is equipped with three rigid and three continuously soft arms, with each arm hosting a propeller. We create a bridge between the fields of soft and aerial robotics by mechanically coupling the actuation of a fully actuated flying platform with the actuation of a soft robotic manipulator. Each rotor is slightly tilted, allowing for full actuation of the platform. The soft components combined with the platform's full actuation allow for a robust interaction, in the form of efficient multimodal locomotion. In this work, we present the dynamical model of the platform, derive a closed-loop control, and present simulation results fortifying the robustness of the platform under a jumping-flying maneuver. We demonstrate in simulations that our multimodal locomotion approach can be more energy-efficient than the flight with a hexarotor.	https://doi.org/10.1109/ICRA46639.2022.9812044	Markus Ryll, Robert K. Katzschmann
SPIN Road Mapper: Extracting Roads from Aerial Images via Spatial and Interaction Space Graph Reasoning for Autonomous Driving.	Road extraction is an essential step in building autonomous navigation systems. Detecting road segments is challenging as they are of varying widths, bifurcated throughout the image, and are often occluded by terrain, cloud, or other weather conditions. Using just convolution neural networks (ConvNets) for this problem is not effective as it is inefficient at capturing distant dependencies between road segments in the image which is essential to extract road connectivity. To this end, we propose a Spatial and Interaction Space Graph Reasoning (SPIN) module which when plugged into a ConvNet performs reasoning over graphs constructed on spatial and interaction spaces projected from the feature maps. Reasoning over spatial space extracts dependencies between different spatial regions and other contextual information. Reasoning over a projected interaction space helps in appropriate delineation of roads from other topographies present in the image. Thus, SPIN extracts long-range dependencies between road segments and effectively delineates roads from other semantics. We also introduce a SPIN pyramid which performs SPIN graph reasoning across multiple scales to extract multi-scale features. We propose a network based on stacked hourglass modules and SPIN pyramid for road segmentation which achieves better performance compared to existing methods. Moreover, our method is computationally efficient and significantly boosts the convergence speed during training, making it feasible for applying on large-scale high-resolution aerial images. Code available at: https://github.com/wgcban/SPIN_RoadMapper.git.	https://doi.org/10.1109/ICRA46639.2022.9812134	Wele Gedara Chaminda Bandara, Jeya Maria Jose Valanarasu, Vishal M. Patel
ST-RRT*: Asymptotically-Optimal Bidirectional Motion Planning through Space-Time.	We present a motion planner for planning through space-time with dynamic obstacles, velocity constraints, and unknown arrival time. Our algorithm, Space-Time RRT*(ST-RRT*), is a probabilistically complete, bidirectional motion planning algorithm, which is asymptotically optimal with respect to the shortest arrival time. We experimentally evaluate ST-RRT* in both abstract (2D disk, 8D disk in cluttered spaces, and on a narrow passage problem), and simulated robotic path planning problems (sequential planning of 8DoF mobile robots, and 7DoF robotic arms). The proposed planner outperforms RRT-Connect and RRT* on both initial solution time, and attained final solution cost. The code for ST-RRT* is available in the Open Motion Planning Library (OMPL).	https://doi.org/10.1109/ICRA46639.2022.9811814	Francesco Grothe, Valentin N. Hartmann, Andreas Orthey, Marc Toussaint
SaRA: A Tool for Safe Human-Robot Coexistence and Collaboration through Reachability Analysis.	Current safety mechanisms implementing industry standards for human-robot coexistence separate humans and robots through caging. Other approaches allowing humans to enter the workspace of manipulators do not provide formal safety guarantees. Thus, this study aims to facilitate the widespread adoption of collaborative robots by presenting SaRA, an extensible tool that performs set-based reachability analysis and formally guarantees safety. Our experimental results show that the set-based prediction of a human can be computed in a few microseconds, using SaRA, allowing for real-time consideration of many surrounding humans in an environment.	https://doi.org/10.1109/ICRA46639.2022.9811952	Sven R. Schepp, Jakob Thumm, Stefan B. Liu, Matthias Althoff
Safe endoscope holding in minimally invasive surgery: zero stiffness and adaptive weight compensation.	One of the major functions brought by robots in Minimally Invasive Surgery is endoscope holding. This consists, for the user, in placing the camera at a desired location which the robot will maintain still once he/she releases it. This behavior is usually achieved with rigid position servoing, leading to possibly high forces generated and safety issues. Model-based weight compensation is an alternative solution. However, endoscopic cameras' weight is difficult to model as their gravity parameters can change during the same surgery. In this paper, an algorithm is presented as an option to cope with this variability in the gravity model without using rigid position servoing. The surgeon first positions the camera in a comanipulation mode (gravity compensation). When he/she releases the camera, if the gravity model is not accurate, the endoscope presents a drift. In this case, a controller brings the endoscope back to its release position by combining low gain position control and model adaptation. Once stabilized, the system is switched back to a zero-stiffness mode. Two in-vitro experiments were performed in which a user manipulates an endoscope whose configuration of mass is changed. In one case, the mass in the gravity model was set to half of the actual one. In the second case, a variable weight was attached to the endoscope. The algorithm successfully updated the model for each experiment reducing position errors by 95% and 57%, respectively.	https://doi.org/10.1109/ICRA46639.2022.9811359	Jesus Mago, François Louveau, Marie-Aude Vitrani, Guillaume Morel
Safe multi-agent motion planning via filtered reinforcement learning.	We study the problem of safe multi-agent motion planning in cluttered environments. Existing multi-agent reinforcement learning-based motion planners only provide approximate safety enforcement. We propose a safe reinforcement learning algorithm that leverages single-agent reinforcement learning for target regulation and a subsequent convex optimization-based filtering that ensures the collective safety of the system. Our approach yields a safe, real-time implementable multi-agent motion planner that is simpler to train and enforces safety as hard constraints. Our approach can handle state and control constraints on the agents, and enforce collision avoidance among themselves and with static obstacles in the environment. Numerical simulations and hardware experiments show the efficacy of the approach.	https://doi.org/10.1109/ICRA46639.2022.9812259	Abraham P. Vinod, Sleiman Safaoui, Ankush Chakrabarty, Rien Quirynen, Nobuyuki Yoshikawa, Stefano Di Cairano
SafePicking: Learning Safe Object Extraction via Object-Level Mapping.	Robots need object-level scene understanding to manipulate objects while reasoning about contact, support, and occlusion among objects. Given a pile of objects, object recognition and reconstruction can identify the boundary of object instances, giving important cues as to how the objects form and support the pile. In this work, we present a system, SafePicking, that integrates object-level mapping and learning-based motion planning to generate a motion that safely extracts occluded target objects from a pile. Planning is done by learning a deep Q-network that receives observations of predicted poses and a depth-based heightmap to output a motion trajectory, trained to maximize a safety metric reward. Our results show that the observation fusion of poses and depth-sensing gives both better performance and robustness to the model. We evaluate our methods using the YCB objects in both simulation and the real world, achieving safe object extraction from piles.	https://doi.org/10.1109/ICRA46639.2022.9812009	Kentaro Wada, Stephen James, Andrew J. Davison
Safety Assurances for Human-Robot Interaction via Confidence-aware Game-theoretic Human Models.	An outstanding challenge with safety methods for human-robot interaction is reducing their conservatism while maintaining robustness to variations in human behavior. In this work, we propose that robots use confidence-aware game-theoretic models of human behavior when assessing the safety of a human-robot interaction. By treating the influence between the human and robot as well as the human's rationality as unobserved latent states, we succinctly infer the degree to which a human is following the game-theoretic interaction model. We leverage this model to restrict the set of feasible human controls during safety verification, enabling the robot to confidently modulate the conservatism of its safety monitor online. Evaluations in simulated human-robot scenarios and ablation studies demonstrate that imbuing safety monitors with confidence-aware game-theoretic models enables both safe and efficient human-robot interaction. Moreover, evaluations with real traffic data show that our safety monitor is less conservative than traditional safety methods in real human driving scenarios.	https://doi.org/10.1109/ICRA46639.2022.9812048	Ran Tian, Liting Sun, Andrea Bajcsy, Masayoshi Tomizuka, Anca D. Dragan
Safety-Critical Control and Planning for Obstacle Avoidance between Polytopes with Control Barrier Functions.	Obstacle avoidance between polytopes is a chal-lenging topic for optimal control and optimization-based tra-jectory planning problems. Existing work either solves this problem through mixed-integer optimization, relying on simpli-fication of system dynamics, or through model predictive control with dual variables using distance constraints, requiring long horizons for obstacle avoidance. In either case, the solution can only be applied as an offline planning algorithm. In this paper, we exploit the property that a smaller horizon is sufficient for obstacle avoidance by using discrete-time control barrier function (DCBF) constraints and we propose a novel optimization formulation with dual variables based on DCBFs to generate a collision-free dynamically-feasible trajectory. The proposed optimization formulation has lower computational complexity compared to existing work and can be used as a fast online algorithm for control and planning for general nonlinear dynamical systems. We validate our algorithm on different robot shapes using numerical simulations with a kinematic bicycle model, resulting in successful navigation through maze environments with polytopic obstacles.	https://doi.org/10.1109/ICRA46639.2022.9812334	Akshay Thirugnanam, Jun Zeng, Koushil Sreenath
SafetyNet: Safe Planning for Real-World Self-Driving Vehicles Using Machine-Learned Policies.	In this paper we present the first safe system for full control of self-driving vehicles trained from human demonstrations and deployed in challenging, real-world, urban environments. Current industry-standard solutions use rule-based systems for planning. Although they perform reasonably well in common scenarios, the engineering complexity renders this approach incompatible with human-level performance. On the other hand, the performance of machine-learned (ML) planning solutions can be improved by simply adding more exemplar data. However, ML methods cannot offer safety guarantees and sometimes behave unpredictably. To combat this, our approach uses a simple yet effective rule-based fallback layer that performs sanity checks on an ML planner's decisions (e.g. avoiding collision, assuring physical feasibility). This allows us to leverage ML to handle complex situations while still assuring the safety, reducing ML planner-only collisions by 95%. We train our ML planner on 300 hours of expert driving demonstrations using imitation learning and deploy it along with the fallback layer in downtown San Francisco, where it takes complete control of a real vehicle and navigates a wide variety of challenging urban driving scenarios.	https://doi.org/10.1109/ICRA46639.2022.9811576	Matt Vitelli, Yan Chang, Yawei Ye, Ana Ferreira, Maciej Wolczyk, Blazej Osinski, Moritz Niendorf, Hugo Grimmett, Qiangui Huang, Ashesh Jain, Peter Ondruska
Sampling Over Riemannian Manifolds Using Kernel Herding.	Kernel herding is a deterministic sampling algorithm designed to draw 'super samples' from probability distributions when provided with their kernel mean embeddings in a reproducing kernel Hilbert space (RKHS). Empirical expectations of functions in the RKHS formed using these super samples tend to converge even faster than random sampling from the true distribution itself. Standard implementations of kernel herding have been restricted to sampling over flat Euclidean spaces, which is not ideal for applications such as robotics where more general Riemannian manifolds may be appropriate. We propose to adapt kernel herding to Riemannian manifolds by (1) using geometry-aware kernels that incorporate the appropriate distance metric for the manifold and (2) using Riemannian optimization to constrain herded samples to lie on the manifold. We evaluate our approach on problems involving various manifolds commonly used in robotics including the SO(3) manifold of rotation matrices, the spherical manifold used to encode unit quaternions, and the manifold of symmetric positive definite matrices. We demonstrate that our approach outperforms existing alternatives on the task of resampling from empirical distributions of weighted particles, a problem encountered in applications such as particle filtering. We also demonstrate how Riemannian kernel herding can be used as part of the kernel recursive approximate Bayesian computation algorithm to estimate parameters of black-box simulators, including inertia matrices of an Adroit robot hand simulator. Our results confirm that exploiting geometric information through our approach to kernel herding yields better results than alternatives including standard kernel herding with heuristic projections.	https://doi.org/10.1109/ICRA46639.2022.9811951	Sandesh Adhikary, Byron Boots
Scalable Gradient Ascent for Controllers in Constrained POMDPs.	This paper presents a novel gradient ascent al-gorithm and nonlinear programming algorithm for finite state controller policies in constrained partially observable Markov decision processes (CPOMDPs). A key component of the gradient ascent algorithm is a constraint projection to ensure constraints are satisfied. Both an optimal and an approximate projection are formally defined. A theoretical analysis of the algorithm and its projections is presented, formally proving aspects of projection correctness and algorithm convergence. Experiments evaluate the baseline and novel algorithms, as well as both constraint projections, on seven CPOMDP benchmark domains. The proposed novel algorithm is demonstrated on an actual robot performing a navigation task in a real household environment.	https://doi.org/10.1109/ICRA46639.2022.9812262	Kyle Hollins Wray, Kenneth Czuprynski
Scalable Minimally Actuated Leg Extension Bipedal Walker Based on 3D Passive Dynamics.	We present simplified 2D dynamic models of the 3D, passive dynamic inspired walking gait of a physical quasi-passive walking robot. Quasi-passive walkers are robots that integrate passive walking principles and some form of actuation. Our ultimate goal is to better understand the dynamics of actuated walking in order to create miniature, untethered, bipedal walking robots. At these smaller scales there is limited space and power available, and so in this work we leverage the passive dynamics of walking to reduce the burden on the actuators and controllers. Prior quasi-passive walkers are much larger than our intended scale, have more complicated mechanical designs, and require more precise feedback control and/or learning algorithms. By leveraging the passive 3D dynamics, carefully designing the spherical feet, and changing the actuation scheme, we are able to produce a very simple 3D bipedal walking model that has a total of 5 rigid bodies and a single actuator per leg. Additionally, the model requires no feedback as each actuator is controlled by an open-loop sinusoidal profile. We validate this model in 2D simulations in which we measure the stability properties while varying the leg length/amplitude ratio, the frequency of actuation, and the spherical foot profile. These results are also validated experimentally on a 3D walking robot (15cm leg length) that implements the modeled walking dynamics. Finally, we experimentally investigate the ability to control the heading of the robot by changing the open-loop control parameters of the robot.	https://doi.org/10.1109/ICRA46639.2022.9812053	Sharfin Islam, Kamal Carter, Justin K. Yim, James Kyle, Sarah Bergbreiter, Aaron M. Johnson
Scalable Simulation and Demonstration of Jumping Piezoelectric 2-D Soft Robots.	"Soft robots have drawn great interest due to their ability to take on a rich range of shapes and motions, compared to traditional rigid robots. However, the motions, and underlying statics and dynamics, pose significant challenges to forming well-generalized and robust models necessary for robot design and control. In this work, we demonstrate a five-actuator soft robot capable of complex motions and develop a scalable simulation framework that reliably predicts robot motions. The simulation framework is validated by comparing its predictions to experimental results, based on a robot constructed from piezoelectric layers bonded to a steel-foil substrate. The simulation framework exploits the physics engine PyBullet, and employs discrete rigid-link elements connected by motors to model the actuators. We perform static and AC analyses to validate a single-unit actuator cantilever setup and observe close agreement between simulation and experiments for both the cases. The analyses are extended to the five-actuator robot, where simulations accurately predict the static and AC robot motions, including shapes for applied DC voltage inputs, nearly-static ""inchworm"" motion, and jumping (in vertical as well as vertical and horizontal directions). These motions exhibit complex non-linear behavior, with forward robot motion reaching ̴1 cm/s. Our open-source code can be found at: https://github.com/zhiwuz/sfers."	https://doi.org/10.1109/ICRA46639.2022.9811927	Zhiwu Zheng, Prakhar Kumar, Yenan Chen, Hsin Cheng, Sigurd Wagner, Minjie Chen, Naveen Verma, James C. Sturm
Search-Based Task Planning with Learned Skill Effect Models for Lifelong Robotic Manipulation.	Robots deployed in many real-world settings need to be able to acquire new skills and solve new tasks over time. Prior works on planning with skills often make assumptions on the structure of skills and tasks, such as subgoal skills, shared skill implementations, or task-specific plan skeletons, which limit adaptation to new skills and tasks. By contrast, we propose doing task planning by jointly searching in the space of parameterized skills using high-level skill effect models learned in simulation. We use an iterative training procedure to efficiently generate relevant data to train such models. Our approach allows flexible skill parameterizations and task specifications to facilitate lifelong learning in general-purpose domains. Experiments demonstrate the ability of our planner to integrate new skills in a lifelong manner, finding new task strategies with lower costs in both train and test tasks. We additionally show that our method can transfer to the real world without further fine-tuning.	https://doi.org/10.1109/ICRA46639.2022.9811575	Jacky Liang, Mohit Sharma, Alex LaGrassa, Shivam Vats, Saumya Saxena, Oliver Kroemer
Secure Multi-Robot Information Sampling with Periodic and Opportunistic Connectivity.	Multi-robot teams are becoming an increasingly popular approach for information gathering in large geographic areas, with applications in precision agriculture, surveying the aftermath of natural disasters or tracking pollution. These robot teams are often assembled from untrusted devices not owned by the user, making the maintenance of the integrity of the collected samples an important challenge. Furthermore, such robots often operate under conditions of opportunistic, or periodic connectivity and are limited in their energy budget and computational power. In this paper, we propose algorithms that build on blockchain technology to address the data integrity problem, but also take into account the limitations of the robots' resources and communication. We evaluate the proposed algorithms along the perspective of the tradeoffs between data integrity, model accuracy, and time consumption.	https://doi.org/10.1109/ICRA46639.2022.9812211	Tamim Samman, Ayan Dutta, O. Patrick Kreidl, Swapnoneel Roy, Ladislau Bölöni
See Yourself in Others: Attending Multiple Tasks for Own Failure Detection.	Autonomous robots deal with unexpected scenarios in real environments. Given input images, various visual perception tasks can be performed, e.g., semantic segmentation, depth estimation and normal estimation. These different tasks provide rich information for the whole robotic perception system. All tasks have their own characteristics while sharing some latent correlations. However, some of the task predictions may suffer from the unreliability dealing with complex scenes and anomalies. We propose an attention-based failure detection approach by exploiting the correlations among multiple tasks. The proposed framework infers task failures by evaluating the individual prediction, across multiple visual perception tasks for different regions in an image. The formulation of the evaluations is based on an attention network supervised by multi-task uncertainty estimation and their corresponding prediction errors. Our proposed framework11Code link https://github.com/ethz-asl/uncertainty_with_multiple_tasks. generates more accurate estimations of the prediction error for the different task's predictions.	https://doi.org/10.1109/ICRA46639.2022.9812310	Boyang Sun, Jiaxu Xing, Hermann Blum, Roland Siegwart, César Cadena
Seeking Visual Discomfort: Curiosity-driven Representations for Reinforcement Learning.	Vision-based reinforcement learning (RL) is a promising approach to solve control tasks involving images as the main observation. State-of-the-art RL algorithms still struggle in terms of sample efficiency, especially when using image observations. This has led to increased attention on integrating state representation learning (SRL) techniques into the RL pipeline. Work in this field demonstrates a substantial improvement in sample efficiency among other benefits. However, to take full advantage of this paradigm, the quality of samples used for training plays a crucial role. More importantly, the diversity of these samples could affect the sample efficiency of vision-based RL, but also its generalization capability. In this work, we present an approach to improve sample diversity for state representation learning. Our method enhances the exploration capability of RL algorithms, by taking advantage of the SRL setup. Our experiments show that our proposed approach boosts the visitation of problematic states, improves the learned state representation, and outperforms the baselines for all tested environments. These results are most apparent for environments where the baseline methods struggle. In simple environments, our method contributes to stabilizing the training, reducing the reward variance, and improving sample efficiency.	https://doi.org/10.1109/ICRA46639.2022.9811663	Elie Aljalbout, Maximilian Ulmer, Rudolph Triebel
Segmentation and Shape Estimation of Multiple Deformed Cloths Using a CNN-Based Landmark Detector and Clustering.	In this paper, we propose a method for segmentation and shape estimation of multiple deformed cloths stacked on a floor from an image using a CNN-based landmark detector and clustering. The proposed method first estimates landmark positions from the heatmaps generated from the landmark detector and then clusters them using their attributes also given from the landmark detector. The contributions of the proposed method are twofold: (1) it can perform segmentation and shape estimation of multiple cloths of the same type or different types simultaneously by modeling a cloth as a grid of landmarks and estimating their positions and attributes, (2) it can correctly segment severely occluded or seemingly disjointed cloths by estimating and classifying landmark attributes including grid index, cloth position, cloth orientation, and cloth type. We evaluate the proposed method on both synthetic and real image datasets and show that the proposed method outperforms three baseline methods. We also show that the proposed method enables our humanoid robot to pick up the desired type of cloth from a pile of cloths.	https://doi.org/10.1109/ICRA46639.2022.9811551	Daiki Sonegawa, Koichi Ogawara
Self-Reconfiguring Robotic Gantries Powered by Modular Magnetic Lead Screws.	This paper outlines the design, specifications, and algorithms for a new modular self-reconfigurable robotic system; at its foundation is a novel modular magnetically geared linear actuator paired with a kinematic coupling connector. Motivating this work is the core idea that high performance actuators as well as inexpensive, precise and repeatable connectors are the key ingredients required for useful real-world self-reconfiguring machines. This work builds upon existing research in the areas of modular self-reconfigurable robots, magnetic lead screws, modular machine tools and kinematic couplings. Magnetic lead screws (MLS) have many desirable characteristics applicable to modular robots, including a tolerance for slight misalignments, high efficiency, zero backlash, robustness, inherent series elasticity, high force capability, and the ability to gracefully separate and reattach. Due to their high mechanical efficiency, MLS actuators are able to be combined in parallel to provide for increased forces and stiffness. Our system implements a MLS through two separable elements: brushless motor powered actuators called carts which pair with modular passive tracks which constrain the carts' movement to a line. This paper also explores the design for a connector which is able to precisely align modules through the use of a 4-way symmetric kinematic coupling.	https://doi.org/10.1109/ICRA46639.2022.9811863	John Romanishin, James M. Bern, Daniela Rus
Self-Supervised Camera Self-Calibration from Video.	Camera calibration is integral to robotics and computer vision algorithms that seek to infer geometric properties of the scene from visual input streams. In practice, calibration is a laborious procedure requiring specialized data collection and careful tuning. This process must be repeated whenever the parameters of the camera change, which can be a frequent occurrence for mobile robots and autonomous vehicles. In contrast, self-supervised depth and ego-motion estimation approaches can bypass explicit calibration by in-ferring per-frame projection models that optimize a view-synthesis objective. In this paper, we extend this approach to explicitly calibrate a wide range of cameras from raw videos in the wild. We propose a learning algorithm to regress per-sequence calibration parameters using an efficient family of general camera models. Our procedure achieves self-calibration results with sub-pixel reprojection error, outperforming other learning-based methods. We validate our approach on a wide variety of camera geometries, including perspective, fisheye, and catadioptric. Finally, we show that our approach leads to improvements in the downstream task of depth estimation, achieving state-of-the-art results on the EuRoC dataset with greater computational efficiency than contemporary methods. The project page: https://sites.google.com/ttic.edu/self-sup-self-calib	https://doi.org/10.1109/ICRA46639.2022.9811784	Jiading Fang, Igor Vasiljevic, Vitor Guizilini, Rares Ambrus, Greg Shakhnarovich, Adrien Gaidon, Matthew R. Walter
Self-Supervised Ego-Motion Estimation Based on Multi-Layer Fusion of RGB and Inferred Depth.	In existing self-supervised depth and ego-motion estimation methods, ego-motion estimation is usually limited to only leveraging RGB information. Recently, several methods have been proposed to further improve the accuracy of self-supervised ego-motion estimation by fusing information from other modalities, e.g., depth, acceleration, and angular velocity. However, they rarely focus on how different fusion strategies affect performance. In this paper, we investigate the effect of different fusion strategies for ego-motion estimation and pro-pose a new framework for self-supervised learning of depth and ego-motion estimation, which performs ego-motion estimation by leveraging RGB and inferred depth information in a Multi-Layer Fusion manner. As a result, we have achieved state-of-the-art performance among learning-based methods on the KITTI odometry benchmark. Detailed studies on the design choices of leveraging inferred depth information and fusion strategies have also been carried out, which clearly demonstrate the advantages of our proposed framework.3	https://doi.org/10.1109/ICRA46639.2022.9811842	Zijie Jiang, Hajime Taira, Naoyuki Miyashita, Masatoshi Okutomi
Self-Supervised Online Learning for Safety-Critical Control using Stereo Vision.	With the increasing prevalence of complex vision-based sensing methods for use in obstacle identification and state estimation, characterizing environment-dependent measurement errors has become a difficult and essential part of modern robotics. This paper presents a self-supervised learning approach to safety-critical control. In particular, the uncertainty associated with stereo vision is estimated, and adapted online to new visual environments, wherein this estimate is leveraged in a safety-critical controller in a robust fashion. To this end, we propose an algorithm that exploits the structure of stereo-vision to learn an uncertainty estimate without the need for ground-truth data. We then robustify existing Control Barrier Function-based controllers to provide safety in the presence of this uncertainty estimate. We demonstrate the efficacy of our method on a quadrupedal robot in a variety of environments. When not using our method safety is violated. With offline training alone we observe the robot is safe, but overly-conservative. With our online method the quadruped remains safe and conservatism is reduced.	https://doi.org/10.1109/ICRA46639.2022.9812183	Ryan K. Cosner, Ivan D. Jimenez Rodriguez, Tamás G. Molnár, Wyatt Ubellacker, Yisong Yue, Aaron D. Ames, Katherine L. Bouman
Self-supervised Monocular Multi-robot Relative Localization with Efficient Deep Neural Networks.	Relative localization is an important ability for multiple robots to perform cooperative tasks in GPS-denied environments. This paper presents a novel autonomous positioning framework for monocular relative localization of multiple tiny flying robots. This approach does not require any groundtruth data from external systems or manual labeling. Instead, the proposed framework is able to label real-world images with 3D relative positions between robots based on another onboard relative estimation technology, using ultra-wideband (UWB). After training in this self-supervised manner, the proposed deep neural network (DNN) can predict relative positions of peer robots by purely using a monocular camera. This deep learning-based visual relative localization is scalable, distributed, and autonomous. We also built an open-source and lightweight simulation pipeline by using Blender for 3D rendering, which allows synthetic image generation of other robots, and generalized training of the neural network. The proposed localization framework is tested on two real-world Crazyflie2 quadrotors by running the DNN on the onboard AIdeck (a tiny AI chip and monocular camera). All results demonstrate the effectiveness of the self-supervised multi-robot localization method. Video: https://youtu.be/7arkaIblPps	https://doi.org/10.1109/ICRA46639.2022.9812150	Shushuai Li, Christophe De Wagter, Guido C. H. E. de Croon
Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies.	"Data augmentation can be a simple yet powerful tool for autonomous robots to fully utilise available data for self-supervised identification of atypical scenes or objects. State-of-the-art augmentation methods arbitrarily embed ""structural"" peculiarity on typical images so that classifying these artefacts can provide guidance for learning representations for the detection of anomalous visual signals. In this paper, however, we argue that learning such structure-sensitive representations can be a suboptimal approach to some classes of anomaly (e.g., unhealthy fruits) which could be better recognised by a different type of visual element such as ""colour"". We thus propose Channel Randomisation as a novel data augmentation method for restricting neural networks to learn encoding of ""colour irregularity"" whilst predicting channel-randomised images to ultimately build reliable fruit-monitoring robots identifying atypical fruit qualities. Our experiments show that (1) this colour-based alternative can better learn representations for consistently accurate identification of fruit anomalies in various fruit species, and also, (2) unlike other methods, the validation accuracy can be utilised as a criterion for early stopping of training in practice due to positive correlation between the performance in the self-supervised colour-differentiation task and the subsequent detection rate of actual anomalous fruits. Also, the proposed approach is evaluated on a new agricultural dataset, Riseholme-2021, consisting of 3.5K strawberry images gathered by a mobile robot, which we share online to encourage active agri-robotics research."	https://doi.org/10.1109/ICRA46639.2022.9811954	Taeyeong Choi, Owen Would, Adrian Salazar Gomez, Grzegorz Cielniak
Self-supervised Transparent Liquid Segmentation for Robotic Pouring.	Liquid state estimation is important for robotics tasks such as pouring; however, estimating the state of transparent liquids is a challenging problem. We propose a novel segmentation pipeline that can segment transparent liquids such as water from a static, RGB image without requiring any manual annotations or heating of the liquid for training. Instead, we use a generative model that is capable of translating images of colored liquids into synthetically generated transparent liquid images, trained only on an unpaired dataset of colored and transparent liquid images. Segmentation labels of colored liquids are obtained automatically using background subtraction. Our experiments show that we are able to accurately predict a segmentation mask for transparent liquids without requiring any manual annotations. We demonstrate the utility of transparent liquid segmentation in a robotic pouring task that controls pouring by perceiving the liquid height in a transparent cup. Accompanying video and supplementary materials can be found at https://sites.google.com/view/transparentliquidpouring.	https://doi.org/10.1109/ICRA46639.2022.9812000	Gautham Narayan Narasimhan, Kai Zhang, Ben Eisner, Xingyu Lin, David Held
SelfTune: Metrically Scaled Monocular Depth Estimation through Self-Supervised Learning.	Monocular depth estimation in the wild inherently predicts depth up to an unknown scale. To resolve scale ambiguity issue, we present a learning algorithm that leverages monocular simultaneous localization and mapping (SLAM) with proprioceptive sensors. Such monocular SLAM systems can provide metrically scaled camera poses. Given these metric poses and monocular sequences, we propose a self-supervised learning method for the pre-trained supervised monocular depth networks to enable metrically scaled depth estimation. Our approach is based on a teacher-student formulation which guides our network to predict high-quality depths. We demonstrate that our approach is useful for various applications such as mobile robot navigation and is applicable to diverse environments. Our full system shows improvements over recent self-supervised depth estimation and completion methods on EuRoC, OpenLORIS, and ScanNet datasets.	https://doi.org/10.1109/ICRA46639.2022.9811639	Jaehoon Choi, Dongki Jung, Yonghan Lee, Deokhwa Kim, Dinesh Manocha, Donghwan Lee
SemLoc: Accurate and Robust Visual Localization with Semantic and Structural Constraints from Prior Maps.	Semantic information and geometrical structures of a prior map can be leveraged in visual localization to bound drift errors and improve accuracy. In this paper, we propose SemLoc, a pure visual localization system, for accurate localization in a prior semantic map. To tightly couple semantic and structure information from prior maps, a hybrid constraint is presented by using the Dirichlet distribution. Then, with the local landmarks and their semantic states tracked in the frontend, the camera poses and data associations are jointly optimized through Expectation-Maximization (EM) algorithm. We validate the effectiveness of our approach in both monocular and stereo modes on the public KITTI dataset. Experimental results demonstrate that our system can greatly reduce drift errors with an satisfying real-time performance. Compared with several state-of-the-art visual localization systems, the proposed framework achieves a competitive localization performance.	https://doi.org/10.1109/ICRA46639.2022.9811925	Shiwen Liang, Yunzhou Zhang, Rui Tian, Delong Zhu, Linghao Yang, Zhenzhong Cao
Semantic-aware Texture-Structure Feature Collaboration for Underwater Image Enhancement.	Underwater image enhancement has become an attractive topic as a significant technology in marine engi-neering and aquatic robotics. However, the limited number of datasets and imperfect hand-crafted ground truth weaken its robustness to unseen scenarios, and hamper the application to high-level vision tasks. To address the above limitations, we develop an efficient and compact enhancement network in collaboration with a high-level semantic-aware pretrained model, aiming to exploit its hierarchical feature representation as an auxiliary for the low-level underwater image enhance-ment. Specifically, we tend to characterize the shallow layer features as textures while the deep layer features as structures in the semantic-aware model, and propose a multi-path Contextual Feature Refinement Module (CFRM) to refine features in multiple scales and model the correlation between different features. In addition, a feature dominative network is devised to perform channel-wise modulation on the aggregated texture and structure features for the adaptation to different feature patterns of the enhancement network. Extensive experiments on benchmarks demonstrate that the proposed algorithm achieves more appealing results and outperforms state-of-the-art meth-ods by large margins. We also apply the proposed algorithm to the underwater salient object detection task to reveal the favorable semantic-aware ability for high-level vision tasks.	https://doi.org/10.1109/ICRA46639.2022.9812457	Di Wang, Long Ma, Risheng Liu, Xin Fan
Semantically Grounded Object Matching for Robust Robotic Scene Rearrangement.	Object rearrangement has recently emerged as a key competency in robot manipulation, with practical solutions generally involving object detection, recognition, grasping and high-level planning. Goal-images describing a desired scene configuration are a promising and increasingly used mode of instruction. A key outstanding challenge is the accurate inference of matches between objects in front of a robot, and those seen in a provided goal image, where recent works have struggled in the absence of object-specific training data. In this work, we explore the deterioration of existing methods' ability to infer matches between objects as the visual shift between observed and goal scenes increases. We find that a fundamental limitation of the current setting is that source and target images must contain the same instance of every object, which restricts practical deployment. We present a novel approach to object matching that uses a large pre-trained vision-language model to match objects in a cross-instance setting by leveraging semantics together with visual features as a more robust, and much more general, measure of similarity. We demonstrate that this provides considerably improved matching performance in cross-instance settings, and can be used to guide multi-object rearrangement with a robot manipulator from an image that shares no object instances with the robot's scene. Our code is available at https://github.com/applied-ai-lab/object_matching.	https://doi.org/10.1109/ICRA46639.2022.9811817	Walter Goodwin, Sagar Vaze, Ioannis Havoutis, Ingmar Posner
Semi-Autonomous Teleoperation via Learning Non-Prehensile Manipulation Skills.	In this paper, we present a semi-autonomous teleoperation framework for a pick-and-place task using an RGB-D sensor. In particular, we assume that the target object is located in a cluttered environment where both prehensile grasping and non-prehensile manipulation are combined for efficient teleoperation. A trajectory-based reinforcement learning is utilized for learning the non-prehensile manipulation to rearrange the objects for enabling direct grasping. From the depth image of the cluttered environment and the location of the goal object, the learned policy can provide multiple options of non-prehensile manipulation to the human operator. We carefully design a reward function for the rearranging task where the policy is trained in a simulational environment. Then, the trained policy is transferred to a real-world and evaluated in a number of real-world experiments with the varying number of objects where we show that the proposed method outperforms manual keyboard control in terms of the time duration for the grasping.	https://doi.org/10.1109/ICRA46639.2022.9811823	Sangbeom Park, Yoonbyung Chai, Sunghyun Park, Jeongeun Park, Kyungjae Lee, Sungjoon Choi
Semi-Supervised Learning with Mutual Distillation for Monocular Depth Estimation.	We propose a semi-supervised learning framework for monocular depth estimation. Compared to existing semi-supervised learning methods, which inherit limitations of both sparse supervised and unsupervised loss functions, we achieve the complementary advantages of both loss functions, by building two separate network branches for each loss and distilling each other through the mutual distillation loss function. We also present to apply different data augmentation to each branch, which improves the robustness. We conduct experiments to demonstrate the effectiveness of our framework over the latest methods and provide extensive ablation studies.	https://doi.org/10.1109/ICRA46639.2022.9811802	Jongbeom Baek, Gyeongnyeon Kim, Seungryong Kim
Sen-Glove: A Lightweight Wearable Glove for Hand Assistance with Soft Joint Sensing.	Perception and portability are critical issues for wearable gloves in hand assistive engineering. However, available wearable gloves either lack flexible sensing or are bulky. In this paper, we present a tendon-driven lightweight wearable glove with soft joint sensing, Sen-Glove. Sen-Glove is equipped with 14 soft strain sensors, which enables full bending motion monitoring of 14 joints of five fingers and greatly reduces the weight of the glove. Besides, modular design makes Sen-Glove more compact and weighs 161g in total, reducing the burden on hand. A series of mechanical tests are conducted to evaluate the characteristics of Sen-Glove. Experimental results show that Sen-Glove can withstand 500 bending cycles, assist the subject in grasping 21 multi-scale objects, and recognize 11 gestures. The classification accuracy of 11 different gestures reaches 98.6 %, which verifies the efficacy of the strain sensors.	https://doi.org/10.1109/ICRA46639.2022.9812412	Linan Deng, Yi Shen, Yang Hong, Yunlong Dong, Xin He, Ye Yuan, Zhi Li, Han Ding
SenSnake: A snake robot with contact force sensing for studying locomotion in complex 3-D terrain.	Despite advances in a diversity of environments, snake robots are still far behind snakes in traversing complex 3-D terrain with large obstacles. This is due to a lack of understanding of how to control 3-D body bending to push against terrain features to generate and control propulsion. Biological studies suggested that generalist snakes use contact force sensing to adjust body bending in real time to do so. However, studying this sensory-modulated force control in snakes is challenging, due to a lack of basic knowledge of how their force sensing organs work. Here, we take a robophysics approach to make progress, starting by developing a snake robot capable of 3-D body bending with contact force sensing to enable systematic locomotion experiments and force measurements. Through two development and testing iterations, we created a 12-segment robot with 36 piezo-resistive sheet sensors distributed on all segments with compliant shells with a sampling frequency of 30 Hz. The robot measured contact forces while traversing a large obstacle using vertical bending with high repeatability, achieving the goal of providing a platform for systematic experiments. Finally, we explored model-based calibration considering the viscoelastic behavior of the piezo-resistive sensor, which will for useful for future studies.	https://doi.org/10.1109/ICRA46639.2022.9812159	Divya Ramesh, Qiyuan Fu, Chen Li
Sequential Joint Shape and Pose Estimation of Vehicles with Application to Automatic Amodal Segmentation Labeling.	Shape and pose estimation is a critical perception problem for a self-driving car to fully understand its surrounding environment. One fundamental challenge in solving this problem is the incomplete sensor signal (e.g., LiDAR scans), especially for faraway or occluded objects. In this paper, we propose a novel algorithm to address this challenge, which explicitly leverages the sensor signal captured over consecutive time: the consecutive signals can provide more information about an object, including different viewpoints and its motion. By encoding the consecutive signals via a recurrent neural network, not only our algorithm improves the shape and pose estimates, but also produces a labeling tool that can benefit other tasks in autonomous driving research. Specifically, building upon our algorithm, we propose a novel pipeline to automatically annotate high-quality labels for amodal segmentation on images, which are hard and laborious to annotate manually. Our code and data will be made publicly available.	https://doi.org/10.1109/ICRA46639.2022.9812202	Josephine Monica, Wei-Lun Chao, Mark E. Campbell
Shape Control of Deformable Linear Objects with Offline and Online Learning of Local Linear Deformation Models.	The shape control of deformable linear objects (DLOs) is challenging, since it is difficult to obtain the deformation models. Previous studies often approximate the models in purely offline or online ways. In this paper, we propose a scheme for the shape control of DLOs, where the unknown model is estimated with both offline and online learning. The model is formulated in a local linear format, and approximated by a neural network (NN). First, the NN is trained offline to provide a good initial estimation of the model, which can directly migrate to the online phase. Then, an adaptive controller is proposed to achieve the shape control tasks, in which the NN is further updated online to compensate for any errors in the offline model caused by insufficient training or changes of DLO properties. The simulation and real-world experiments show that the proposed method can precisely and efficiently accomplish the DLO shape control tasks, and adapt well to new and untrained DLOs.	https://doi.org/10.1109/ICRA46639.2022.9812244	Mingrui Yu, Hanzhong Zhong, Xiang Li
ShapeMap 3-D: Efficient shape mapping through dense touch and vision.	Knowledge of 3-D object shape is of great importance to robot manipulation tasks, but may not be readily available in unstructured environments. While vision is often occluded during robot-object interaction, high-resolution tactile sensors can give a dense local perspective of the object. However, tactile sensors have limited sensing area and the shape representation must faithfully approximate non-contact areas. In addition, a key challenge is efficiently incorporating these dense tactile measurements into a 3-D mapping framework. In this work, we propose an incremental shape mapping method using a GelSight tactile sensor and a depth camera. Local shape is recovered from tactile images via a learned model trained in simulation. Through efficient inference on a spatial factor graph informed by a Gaussian process, we build an implicit surface representation of the object. We demonstrate visuo-tactile mapping in both simulated and real-world experiments, to incrementally build 3-D reconstructions of household objects.	https://doi.org/10.1109/ICRA46639.2022.9812040	Sudharshan Suresh, Zilin Si, Joshua G. Mangelson, Wenzhen Yuan, Michael Kaess
SiamX: An Efficient Long-term Tracker Using Cross-level Feature Correlation and Adaptive Tracking Scheme.	Siamese network based trackers have achieved significant progress in visual object tracking. For the sake of speed, they mainly rely on offline training to learn a mono-level feature correlation between a target template and a search region. During the tracking period, they use a fixed strategy to infer target positions over sequences regardless of target states. However, such approaches are vulnerable in case of long-term challenges e.g. large variance, presence of distractors, fast motion, or target disappearing and the like. In this paper, we propose a new tracking framework, referred to as SiamX, by exploiting cross-level Siamese features to learn robust correlations between the target template and search regions, and also adaptive inference strategies to prevent tracking loss and realize fast target re-localization. Extensive experiments on four benchmarks including VOT-2019, LaSOT, GOT-10k, and TrackingNet show our method significantly enhances the tracker's ability to resist variance and interference, and achieve state-of-the-art results at around 50 FPS.	https://doi.org/10.1109/ICRA46639.2022.9812327	Huajian Huang, Sai-Kit Yeung
Sim-to-Real Learning for Bipedal Locomotion Under Unsensed Dynamic Loads.	Recent work on sim-to-real learning for bipedal locomotion has demonstrated new levels of robustness and agility over a variety of terrains. However, that work, and most prior bipedal locomotion work, have not considered locomotion under a variety of external loads that can significantly influence the overall system dynamics. In many applications, robots will need to maintain robust locomotion under a wide range of potential dynamic loads, such as pulling a cart or carrying a large container of sloshing liquid, ideally without requiring additional load-sensing capabilities. In this work, we explore the capabilities of reinforcement learning (RL) and sim-to-real transfer for bipedal locomotion under dynamic loads using only proprioceptive feedback. We show that prior RL policies trained for unloaded locomotion fail for some loads and that simply training in the context of loads is enough to result in successful and improved policies. We also compare training specialized policies for each load versus a single policy for all considered loads and analyze how the resulting gaits change to accommodate different loads. Finally, we demonstrate sim-to-real transfer, which is successful but shows a wider sim-to-real gap than prior unloaded work, which points to interesting future research.	https://doi.org/10.1109/ICRA46639.2022.9811783	Jeremy Dao, Kevin Green, Helei Duan, Alan Fern, Jonathan W. Hurst
Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking.	Recently, work on reinforcement learning (RL) for bipedal robots has successfully learned controllers for a variety of dynamic gaits with robust sim-to-real demonstrations. In order to maintain balance, the learned controllers have full freedom of where to place the feet, resulting in highly robust gaits. In the real world however, the environment will often impose constraints on the feasible footstep locations, typically identified by perception systems. Unfortunately, most demonstrated RL controllers on bipedal robots do not allow for specifying and responding to such constraints. This missing control interface greatly limits the real-world application of current RL controllers. In this paper, we aim to maintain the robust and dynamic nature of learned gaits while also respecting footstep constraints imposed externally. We develop an RL formulation for training dynamic gait controllers that can respond to specified touchdown locations. We then successfully demonstrate simulation and sim-to-real performance on the bipedal robot Cassie. In addition, we use supervised learning to induce a transition model for accurately predicting the next touchdown locations that the controller can achieve given the robot's proprioceptive observations. This model paves the way for integrating the learned controller into a full-order robot locomotion planner that robustly satisfies both balance and environmental constraints.	https://doi.org/10.1109/ICRA46639.2022.9812015	Helei Duan, Ashish Malik, Jeremy Dao, Aseem Saxena, Kevin Green, Jonah Siekmann, Alan Fern, Jonathan W. Hurst
Simulation and Fabrication of Soft Robots with Embedded Skeletons.	Soft robots can be incredibly robust and safe but typically fail to match the strength and precision of rigid robots. This dichotomy between soft and rigid is recently starting to break down, with emerging research interest in hybrid soft-rigid robots. In this work, we draw inspiration from Nature, which achieves the best of both worlds by coupling soft and rigid tissues-like muscle and bone-to produce biological systems capable of both robustness and strength. We present foundational, general-purpose pipelines to simulate and fabricate cable-driven soft-rigid robots with embedded skeletons. We show that robots built using these methods can fluidly mimic biological systems while achieving greater force output and external load resistance than purely soft robots. Finally, we show how our simulation and fabrication pipelines can be leveraged to create more complex robots and do model-based control.	https://doi.org/10.1109/ICRA46639.2022.9811844	James M. Bern, Fatemeh Zargarbashi, Annan Zhang, Josie Hughes, Daniela Rus
Simultaneous Control and Trajectory Estimation for Collision Avoidance of Autonomous Robotic Spacecraft Systems.	We propose factor graph optimization for simultaneous planning, control, and trajectory estimation for collision-free navigation of autonomous systems in environments with moving objects. The proposed online probabilistic motion planning and trajectory estimation navigation technique generates optimal collision-free state and control trajectories for autonomous vehicles when the obstacle motion model is both unknown and known. We evaluate the utility of the algorithm to support future autonomous robotic space missions.	https://doi.org/10.1109/ICRA46639.2022.9811875	Matthew King-Smith, Panagiotis Tsiotras, Frank Dellaert
Single User WiFi Structure from Motion in the Wild.	"This paper proposes a novel motion estimation algorithm using WiFi networks and IMU sensor data in large uncontrolled environments, dubbed ""WiFi Structure-from-Motion"" (WiFi SfM). Given smartphone sensor data through day-to-day activities from a single user over a month, our WiFi SfM algorithm estimates smartphone motion tra-jectories and the structure of the environment represented as a WiFi radio map. The approach 1) establishes frame-to-frame correspondences based on WiFi fingerprints while exploiting our repetitive behavior patterns; 2) aligns trajectories via bundle adjustment; and 3) trains a self-supervised neural network to extract further motion constraints. We have col-lected 235 hours of smartphone data, spanning 38 days of daily activities in a university campus. Our experiments demonstrate the effectiveness of our approach over the competing methods with qualitative evaluations of the estimated motions and quantitative evaluations of indoor localization accuracy based on the reconstructed WiFi radio map. The WiFi SfM technology will potentially allow digital mapping companies to build better radio maps automatically by asking users to share WiFi/IMU sensor data in their daily activities."	https://doi.org/10.1109/ICRA46639.2022.9812340	Yiming Qian, Hang Yan, Sachini Herath, Pyojin Kim, Yasutaka Furukawa
Single-Stage Keypoint- Based Category-Level Object Pose Estimation from an RGB Image.	Prior work on 6-DoF object pose estimation has largely focused on instance-level processing, in which a textured CAD model is available for each object being detected. Category-level 6- DoF pose estimation represents an important step toward developing robotic vision systems that operate in unstructured, real-world scenarios. In this work, we propose a single-stage, keypoint-based approach for category-level object pose estimation that operates on unknown object instances within a known category using a single RGB image as input. The proposed network performs 2D object detection, detects 2D keypoints, estimates 6- DoF pose, and regresses relative bounding cuboid dimensions. These quantities are estimated in a sequential fashion, leveraging the recent idea of convGRU for propagating information from easier tasks to those that are more difficult. We favor simplicity in our design choices: generic cuboid vertex coordinates, single-stage network, and monocular RGB input. We conduct extensive experiments on the challenging Objectron benchmark, outperforming state-of-the-art methods on the 3D IoU metric (27.6% higher than the MobilePose single-stage approach and 7.1 % higher than the related two-stage approach).	https://doi.org/10.1109/ICRA46639.2022.9812299	Yunzhi Lin, Jonathan Tremblay, Stephen Tyree, Patricio A. Vela, Stan Birchfield
Skeletal Feature Compensation for Imitation Learning with Embodiment Mismatch.	"Learning from demonstrations in the wild (e.g. YouTube videos) is a tantalizing goal in imitation learning. However, for this goal to be achieved, imitation learning algorithms must deal with the fact that the demonstrators and learners may have bodies that differ from one another. This condition — ""embodiment mismatch"" — is ignored by many recent imitation learning algorithms. Our proposed imitation learning technique, SILEM (Skeletal feature compensation for Imitation Learning with Embodiment Mismatch), addresses a particular type of embodiment mismatch by introducing a learned affine transform to compensate for differences in the skeletal features obtained from the learner and expert. We create toy domains based on PyBullet's HalfCheetah and Ant to assess SILEM's benefits for this type of embodiment mismatch. We also provide qualitative and quantitative results on more realistic problems — teaching simulated humanoid agents, including Atlas from Boston Dynamics, to walk by observing human demonstrations."	https://doi.org/10.1109/ICRA46639.2022.9812127	Eddy Hudson, Garrett Warnell, Faraz Torabi, Peter Stone
Sliding Mode Controller for Positioning of an Underwater Vehicle Subject to Disturbances and Time Delays.	Unmanned underwater vehicles are crucial for deep-sea exploration and inspection without imposing any danger to human life due to extreme environmental conditions. But, designing a robust controller that can cope with model uncertainties, external disturbances, and time delays for such vehicles is a challenge. This paper implements a sliding mode position control algorithm with a time-delay estimation term to a remotely operated underwater vehicle to deal with disturbances, such as waves, and time delays. The controller is implemented on an underwater vehicle (BlueRov) and compared with a proportional-integral-derivative (PID) controller in a wave tank with different disturbances and when there exist delays within the communication channel. The experimental results show that the proposed control method provides better performance than the conventional PID in the presence of extreme disturbances with less control efforts.	https://doi.org/10.1109/ICRA46639.2022.9812005	Harun Tugal, Kamil Cetin, Xiaoran Han, Ibrahim B. Küçükdemiral, Joshua Roe, Yvan R. Petillot, Mustafa Suphi Erden
Smoothing Away From The Edge For Mesh Estimation in Urban Outdoor Environments.	3D meshes offer a computationally efficient but still quite accurate path to the understanding of a robot's environment. While mesh reconstructions are often employed in indoor regions where regular planar surfaces dominate the scene, their use in urban outdoor environments has been under-explored. This is as outdoor urban environments produce a significant contrast between preserving discontinuities between different objects and maintaining smoothness in the solution. When coupled with the natural sparse nature of meshes this presents a significant challenge to their optimisation. Motivated by these challenges and leveraging insights from computer graphics, we firstly balance previously introduced real-time definitions of variational smoothing on meshes with their 'canonical' definitions. In doing so we introduce a novel Delaunay-Voronoi formulation for real-time mesh smoothing that allows for the accumulation of information away from the triangular edges. This allows for the use of more powerful non-convex regularisers that are able to more finely balance smoothness and object discontinuities and showcase more faithful reconstructions of the urban outdoor scene. In doing so the benefits of non-convex regularisers promised in the 'every-pixel' scenarios can now be inherited by sparse mesh formulations.	https://doi.org/10.1109/ICRA46639.2022.9811563	Jason Pilbrough, Paul Amayo
SnailBot: A Continuously Dockable Modular Self-reconfigurable Robot Using Rocker-bogie Suspension.	"This paper proposes a novel modular self-assembling, self-reconfiguring robot with the 3D continuous dock called ""SnailBot"". SnailBot mainly consists of a spherical ferromagnetic shell and a six-wheel rocker chassis with embedded magnets. Unlike many other existing modular self-reconfigurable robots with fixed docking locations, SnailBot uses the 3D continuous dock to attach to its peers regardless of alignment. This freeform docking mechanism can greatly improve the efficiency of self-reconfiguration and reduce docking failures because there is nearly no constraint in the location of the connector. Compared with the existing freeform MSRR, SnailBot can form a more structurally stable connection to its peers without loss of connection efficiency. Owing to the excellent obstacle crossing ability of the rocker-bogie suspension, the robot can freely crawl on other modules in the form of a sliding sphere. Experiments demonstrate the basic actions of a single module and some applications of SnailBots, such as a manipulator."	https://doi.org/10.1109/ICRA46639.2022.9811779	Da Zhao, Tin Lun Lam
Soft-Jig: A Flexible Sensing Jig for Simultaneously Fixing and Estimating Orientation of Assembly Parts.	For assembly tasks, it is essential to fix target parts firmly and accurately estimate their poses. Several rigid jigs for individual parts are frequently used in assembly factories to achieve a precise and time-efficient product assembly. However, providing customized jigs is time-consuming. In this study, to address the lack of versatility in the shapes for which jigs can be used, we developed a flexible jig with a soft membrane including transparent beads and oil with a tuned refractive index. The bead-based jamming transition was accomplished by discharging only the oil, enabling the part to be firmly fixed. Because the two cameras under the jig can capture membrane shape changes, we proposed a sensing method to estimate the orientation of the part based on the behaviors of markers created on the jig's inner surface. Through estimation experiments, the proposed system can estimate the orientation of a cylindrical object with a diameter larger than 50 mm and an RMSE of less than 3°.	https://doi.org/10.1109/ICRA46639.2022.9812094	Tatsuya Sakuma, Takuya Kiyokawa, Jun Takamatsu, Takahiro Wada, Tsukasa Ogasawara
Spatial Acoustic Projection for 3D Imaging Sonar Reconstruction.	In this work we present a novel method for reconstructing 3D surfaces using a multi-beam imaging sonar. We integrate the intensities measured by the sonar from different viewpoints for fixed cell positions in a 3D grid. For each cell we integrate a feature vector that holds the mean intensity for a discretized range of viewpoints. Based on the feature vectors and independent sparse range measurements that act as ground truth information, we train convolutional neural networks that allow us to predict the signed distance and direction to the nearest surface for each cell. The predicted signed distances can be projected into a truncated signed distance field (TSDF) along the predicted directions. Utilizing the marching cubes algorithm, a polygon mesh can be rendered from the TSDF. Our method allows a dense 3D reconstruction from a limited set of viewpoints and was evaluated on three real-world datasets.	https://doi.org/10.1109/ICRA46639.2022.9812277	Sascha Arnold, Bilal Wehbe
SpecTac: A Visual-Tactile Dual-Modality Sensor Using UV Illumination.	Perceiving the dynamical environment both visually and tactilely is crucial for the survival of animals, and therefore, is considered of importance in robotics research. Recently, there has been an increasing interest in vision-based tactile sensors due to their high sensing resolution and robustness to environmental changes. However, almost all vision-based tactile sensors make only partial use of the camera, specifically, only when contact occurs, and stay idle at other times, which results in a waste of the camera information bandwidth. In this paper, we propose a new visual-tactile dual-modality sensor called SpecTac, which can visually inspect the environment and make tactile observations. The main novelty of the sensor is the use of ultraviolet (UV) LEDs and randomly distributed UV fluorescent markers. When the LEDs are on, those markers will be bright and can easily be distinguished and tracked from the background. Besides, by controlling the on and off of the UV LEDs, due to the switchable visibility of those markers, the sensor will switch between visual and tactile sensing mode. The qualities of tactile and visual perception are evaluated quantitatively by force estimation, visual triangulation and visual feature matching. By combining both modalities into one compact sensor, the information from the camera is better utilized, and it is hoped that the sensor will achieve more flexibility in the motion of the robot arm, especially in tasks where the workspace is narrow.	https://doi.org/10.1109/ICRA46639.2022.9812348	Qi Wang, Yipai Du, Michael Yu Wang
Speed Planning in Dynamic Environments over a Fixed Path for Autonomous Vehicles.	In this paper, we present a novel convex optimization approach to address the minimum-time speed planning problem over a fixed path with dynamic obstacle constraints and point-wise speed and acceleration constraints. The contributions of this paper are three-fold. First, we formulate the speed planning as an iterative convex optimization problem based on space discretization. Our formulation allows imposing dynamic obstacle constraints and point-wise speed and acceleration constraints simultaneously. Second, we propose a modified vertical cell decomposition method to handle dynamic obstacles. It divides the freespace into channels, where each channel represents a homotopy of free paths and defines convex constraints for dynamic obstacles. Third, we demonstrate significant improvement over previous work on speed planning for typical driving scenarios such as following, merging, and crossing.	https://doi.org/10.1109/ICRA46639.2022.9812136	Wenda Xu, John M. Dolan
Speeding up deep neural network-based planning of local car maneuvers via efficient B-spline path construction.	This paper demonstrates how an efficient repre-sentation of the planned path using B-splines, and a construction procedure that takes advantage of the neural network's inductive bias, speed up both the inference and training of a DNN-based motion planner. We build upon our recent work on learning local car maneuvers from past experience using a DNN architecture, introducing a novel B-spline path construction method, making it possible to generate local maneuvers in almost constant time of about 11 ms, respecting a number of constraints imposed by the environment map and the kinematics of a car-like vehicle. We evaluate thoroughly the new planner employing the recent Bench-MR framework to obtain quantitative results showing that our method outperforms state-of-the-art planners by a large margin in the considered task.	https://doi.org/10.1109/ICRA46639.2022.9812313	Piotr Kicki, Piotr Skrzypczynski
Stable 3D Human Pose Estimation in Low- Resolution Videos with a Few Views.	We discuss the problem of 3D pose estimation for multi-view videos. With previous frame-by-frame multi-view methods, it has been difficult to achieve stable estimation under challenging settings such as low-resolution or with only a few views. Temporal approaches are effective ways of addressing such problems, but enforcing temporal consistency with neigh-boring frames sometimes damages the precision of the results. We propose a temporal approach with selective corrections based on the observation that errors in the frame-by-frame approach are concentrated under certain adverse conditions. Our method evaluates the confidence of the frame-by-frame results and compensates for the inaccurate keypoints with temporal information while retaining the accurate keypoints. In our experiments on the CMU Panoptic dataset customized for low-resolution and a few views, we reported 32.98 mm for MPJPE and 98.64% for 3D-PCK@150. Compared to the state-of-the-art method, our method improved MPJPE by 1.14 mm and corrected 16 % of incorrect keypoints.	https://doi.org/10.1109/ICRA46639.2022.9812382	Chihiro Nakatsuka, Satoshi Komorita
Stable Object Reorientation using Contact Plane Registration.	We present a system for accurately predicting stable orientations for diverse rigid objects. We propose to overcome the critical issue of modelling multimodality in the space of rotations by using a conditional generative model to accurately classify contact surfaces. Our system is capable of operating from noisy and partially-observed pointcloud observations captured by real world depth cameras. Our method substantially outperforms the current state-of-the-art systems on a simulated stacking task requiring highly accurate rotations, and demonstrates strong sim2real zero-shot transfer results across a variety of unseen objects on a real world reorientation task.	https://doi.org/10.1109/ICRA46639.2022.9811655	Richard Li, Carlos Esteves, Ameesh Makadia, Pulkit Agrawal
Stable and Efficient Shapley Value-Based Reward Reallocation for Multi-Agent Reinforcement Learning of Autonomous Vehicles.	With the development of sensing and communication technologies in networked cyber-physical systems (CPSs), multi-agent reinforcement learning (MARL)-based methodologies are integrated into the control process of physical systems and demonstrate prominent performance in a wide array of CPS domains, such as connected autonomous vehicles (CAVs). However, it remains challenging to mathematically characterize the improvement of the performance of CAVs with communication and cooperation capability. When each individual autonomous vehicle is originally self-interest, we can not assume that all agents would cooperate naturally during the training process. In this work, we propose to reallocate the system's total reward efficiently to motivate stable cooperation among autonomous vehicles. We formally define and quantify how to reallocate the system's total reward to each agent under the proposed transferable utility game, such that communication-based cooperation among multi-agents increases the system's total reward. We prove that Shapley value-based reward reallocation of MARL locates in the core if the transferable utility game is a convex game. Hence, the cooperation is stable and efficient and the agents should stay in the coalition or the cooperating group. We then propose a cooperative policy learning algorithm with Shapley value reward reallocation. In experiments, compared with several literature algorithms, we show the improvement of the mean episode system reward of CAV systems using our proposed algorithm.	https://doi.org/10.1109/ICRA46639.2022.9811626	Songyang Han, He Wang, Sanbao Su, Yuanyuan Shi, Fei Miao
Stackelberg Strategic Guidance for Heterogeneous Robots Collaboration.	In this study, we explore the application of game theory, in particular Stackelberg games, to address the issue of effective coordination strategy generation for heterogeneous robots with one-way communication. To that end, focusing on the task of multi-object rearrangement, we develop a theoretical and algorithmic framework that provides strategic guidance for a pair of robot arms, a leader and a follower where the leader has a model of the follower's decision-making process, through the computation of a feedback Stackelberg equilibrium. With built-in tolerance of model uncertainty, the strategic guidance generated by our planning algorithm not only improves the overall efficiency in solving the rearrangement tasks, but is also robust to common pitfalls in collaboration, e.g., chattering.	https://doi.org/10.1109/ICRA46639.2022.9811678	Yuhan Zhao, Baichuan Huang, Jingjin Yu, Quanyan Zhu
Stair Ascent Phase-Variable Control of a Powered Knee-Ankle Prosthesis.	Passive prostheses cannot provide the net positive work required at the knee and ankle for step-over stair ascent. Powered prostheses can provide this net positive work, but user synchronization of joint motion and power input are critical to enabling natural stair ascent gaits. In this work, we build on previous phase variable-based control methods for walking and propose a stair ascent controller driven by the motion of the user's residual thigh. We use reference kinematics from an able-bodied dataset to produce knee and ankle joint trajectories parameterized by gait phase. We redefine the gait cycle to begin at the point of maximum hip flexion instead of heel strike to improve the phase estimate. Able-bodied bypass adapter experiments demonstrate that the phase variable controller replicates normative able-bodied kinematic trajectories with a root mean squared error of 12.66° and 2.64° for the knee and ankle, respectively. The knee and ankle joints provided on average 0.39 J/kg and 0.21 J/kg per stride, compared to the normative averages of 0.34 J/kg and 0.21 J/kg, respectively. Thus, this controller allows powered knee-ankle prostheses to perform net positive mechanical work to assist stair ascent.	https://doi.org/10.1109/ICRA46639.2022.9811578	Ross J. Cortino, Edgar A. Bolívar-Nieto, T. Kevin Best, Robert D. Gregg
Star-Convex Constrained Optimization for Visibility Planning with Application to Aerial Inspection.	The visible capability is critical in many robot applications, such as inspection and surveillance, etc. Without the assurance of the visibility to targets, some tasks end up not being complete or even failing. In this paper, we propose a visibility guaranteed planner by star-convex constrained optimization. The visible space is modeled as star convex polytope (SCP) by nature and is generated by finding the visible points directly on point cloud. By exploiting the properties of the SCP, the visibility constraint is formulated for trajectory optimization. The trajectory is confined in the safe and visible flight corridor which consists of convex polytopes and SCPs. We further make a relaxation to the visibility constraints and transform the constrained trajectory optimization problem into an unconstrained one that can be reliably and efficiently solved. To validate the capability of the proposed planner, we present the practical application in site inspection. The experimental results show that the method is efficient, scalable, and visibility guaranteed, presenting the prospect of application to various other applications in the future.	https://doi.org/10.1109/ICRA46639.2022.9812158	Tianyu Liu, Qianhao Wang, Xingguang Zhong, Zhepei Wang, Chao Xu, Fu Zhang, Fei Gao
Star-Convolution for Image-Based 3D Object Detection.	3D object detection with only image inputs is an interesting and important problem in computer vision and autonomous driving. Nowadays, most existing monocular 3D object detection algorithms rely solely on the approximation power of convolutional neural networks to learn a mapping from pixels to 3D predictions without knowing the projection matrix of the camera. To endow the networks with camera projection knowledge, we propose the Star-Convolution module for application to image-based 3D detection. The introduced module increases the receptive field of the detector and embeds the camera's projection geometry inside the network while keeping the network end-to-end trainable. We test the module with different baselines in both monocular and stereo 3D object detection, and we achieve significant improvements on both tasks. The code will be published at https://github.com/Owen-Liuyuxuan/visualDet3D.	https://doi.org/10.1109/ICRA46639.2022.9811612	Yuxuan Liu, Zhenhua Xu, Ming Liu
Stein Variational Probabilistic Roadmaps.	Efficient and reliable generation of global path plans are necessary for safe execution and deployment of autonomous systems. In order to generate planning graphs which adequately resolve the topology of a given environment, many sampling-based motion planners resort to coarse, heuristically-driven strategies which often fail to generalize to new and varied surroundings. Further, many of these approaches are not designed to contend with partial-observability. We posit that such uncertainty in environment geometry can, in fact, help drive the sampling process in generating feasible, and probabilistically-safe planning graphs. We propose a method for Probabilistic Roadmaps which relies on particle-based Variational Inference to efficiently cover the posterior distribution over feasible regions in configuration space. Our approach, Stein Variational Probabilistic Roadmap (SV-PRM), results in sample-efficient generation of planning-graphs and large improvements over traditional sampling approaches. We demonstrate the approach on a variety of challenging planning problems, including real-world probabilistic occupancy maps and high-dof manipulation problems common in robotics. Video, additional material and results can be found here: https://sites.google.com/view/stein-prm.	https://doi.org/10.1109/ICRA46639.2022.9811656	Alexander Lambert, Brian Hou, Rosario Scalise, Siddhartha S. Srinivasa, Byron Boots
StopNet: Scalable Trajectory and Occupancy Prediction for Urban Autonomous Driving.	We introduce a motion forecasting (behavior prediction) method that meets the latency requirements for autonomous driving in dense urban environments without sacrificing accuracy. A whole-scene sparse input representation allows StopNet to scale to predicting trajectories for hundreds of road agents with reliable latency. In addition to predicting trajectories, our scene encoder lends itself to predicting whole-scene probabilistic occupancy grids, a complementary output representation suitable for busy urban environments. Occupancy grids allow the AV to reason collectively about the behavior of groups of agents without processing their individual trajectories. We demonstrate the effectiveness of our sparse input representation and our model in terms of computation and accuracy over three datasets. We further show that co-training consistent trajectory and occupancy predictions improves upon state-of-the-art performance under standard metrics.	https://doi.org/10.1109/ICRA46639.2022.9811830	Jinkyu Kim, Reza Mahjourian, Scott Ettinger, Mayank Bansal, Brandyn White, Ben Sapp, Dragomir Anguelov
Strawberry picking point localization ripeness and weight estimation.	Labour shortage, difficulties in labour management, the digitalization of fruit production pipeline to reduce the fruit production costs have made robotic systems for selective harvesting of strawberries an important industry and academic research. One of the important components of such technologies yet to be developed is fruit picking perception. For picking strawberries, a robot needs to infer the location of picking points from the images of strawberries. Moreover, the size and weight of strawberries to be picked can help the robot to place the picked strawberries in proper punnets directly to be delivered to customers in supermarkets. This can save significant time and packing costs in packhouses. Geometry-based approaches are the most common approach to determine the picking point but they suffer from inaccuracies due to noise, occlusion, and varying shape and orientation of the berries. In contrast, we present two novel datasets of strawberries annotated with picking points, key-points (such as the shoulder points, the contact point between the calyx and flesh, and the point on the flesh farthest from the calyx), and the weight and size of the berries. We performed experiments with Detectron-2, which is an extended version of Mask-RCNN with key-points detection capability. The results show that the key-points detection approach works well for picking and grasping point localization. The second dataset also presents the dimensions and weight of strawberries. Our novel baseline model for weight estimation outperforms many state-of-the-art deep networks. The datasets and annotations are available at https://github.com/imanlab/strawberry-pp-w-r-dataset.	https://doi.org/10.1109/ICRA46639.2022.9812303	Alessandra Tafuro, Adeayo Adewumi, Soran Parsa, Ghalamzan E. Amir, Bappaditya Debnath
Striking the Right Balance: Recall Loss for Semantic Segmentation.	Class imbalance is a fundamental problem in computer vision applications such as semantic segmentation. Specifically, uneven class distributions in a training dataset often result in unsatisfactory performance on under-represented classes. Many works have proposed to weight the standard cross entropy loss function with pre-computed weights based on class statistics, such as the number of samples and class margins. There are two major drawbacks to these methods: 1) constantly up-weighting minority classes can introduce excessive false positives in semantic segmentation; 2) a minority class is not necessarily a hard class. The consequence is low precision due to excessive false positives. In this regard, we propose a hard-class mining loss by reshaping the vanilla cross entropy loss such that it weights the loss for each class dynamically based on instantaneous recall performance. We show that the novel recall loss changes gradually between the standard cross entropy loss and the inverse frequency weighted loss. Recall loss also leads to improved mean accuracy while offering competitive mean Intersection over Union (IoU) performance. On Synthia dataset11Synthia-Sequence Summer split, recall loss achieves 9% relative improvement on mean accuracy with competitive mean IoU using DeepLab-ResNet18 compared to the cross entropy loss. Code available at https://github.com/PotatoTian/recall-semseg.	https://doi.org/10.1109/ICRA46639.2022.9811702	Junjiao Tian, Niluthpol Chowdhury Mithun, Zachary Seymour, Han-Pang Chiu, Zsolt Kira
Stronger Generalization Guarantees for Robot Learning by Combining Generative Models and Real-World Data.	We are motivated by the problem of learning policies for robotic systems with rich sensory inputs (e.g., vision) in a manner that allows us to guarantee generalization to environments unseen during training. We provide a framework for providing such generalization guarantees by leveraging a finite dataset of real-world environments in combination with a (potentially inaccurate) generative model of environments. The key idea behind our approach is to utilize the generative model in order to implicitly specify a prior over policies. This prior is updated using the real-world dataset of environments by minimizing an upper bound on the expected cost across novel environments derived via Probably Approximately Correct (PAC)-Bayes generalization theory. We demonstrate our approach on two simulated systems with nonlinear/hybrid dynamics and rich sensing modalities: (i) quadrotor navigation with an onboard vision sensor, and (ii) grasping objects using a depth sensor. Comparisons with prior work demonstrate the ability of our approach to obtain stronger generalization guarantees by utilizing generative models. We also present hardware experiments for validating our bounds for the grasping task.	https://doi.org/10.1109/ICRA46639.2022.9811565	Abhinav Agarwal, Sushant Veer, Allen Z. Ren, Anirudha Majumdar
StructFormer: Learning Spatial Structure for Language-Guided Semantic Rearrangement of Novel Objects.	Geometric organization of objects into semantically meaningful arrangements pervades the built world. As such, assistive robots operating in warehouses, offices, and homes would greatly benefit from the ability to recognize and rearrange objects into these semantically meaningful structures. To be useful, these robots must contend with previously unseen objects and receive instructions without significant programming. While previous works have examined recognizing pairwise semantic relations and sequential manipulation to change these simple relations none have shown the ability to arrange objects into complex structures such as circles or table settings. To address this problem we propose a novel transformer-based neural network, StructFormer, which takes as input a partial-view point cloud of the current object arrangement and a structured language command encoding the desired object configuration. We show through rigorous experiments that StructFormer enables a physical robot to rearrange novel objects into semantically meaningful structures with multi-object relational constraints inferred from the language command.	https://doi.org/10.1109/ICRA46639.2022.9811931	Weiyu Liu, Chris Paxton, Tucker Hermans, Dieter Fox
Superpoint-guided Semi-supervised Semantic Segmentation of 3D Point Clouds.	3D point cloud semantic segmentation is a challenging topic in the computer vision field. Most of the existing methods in literature require a large amount of fully labeled training data, but it is extremely time-consuming to obtain these training data by manually labeling massive point clouds. Addressing this problem, we propose a superpoint-guided semi-supervised segmentation network for 3D point clouds, which jointly utilizes a small portion of labeled scene point clouds and a large number of unlabeled point clouds for network training. The proposed network is iteratively updated with its predicted pseudo labels, where a superpoint generation module is introduced for extracting superpoints from 3D point clouds, and a pseudo-label optimization module is explored for automatically assigning pseudo labels to the unlabeled points under the constraint of the extracted superpoints. Additionally, there are some 3D points without pseudo-label supervision. We propose an edge prediction module to constrain features of edge points. A superpoint feature aggregation module and a superpoint feature consistency loss function are introduced to smooth superpoint features. Extensive experimental results on two 3D public datasets demonstrate that our method can achieve better performance than several state-of-the-art point cloud segmentation networks and several popular semi-supervised segmentation methods with few labeled scenes.	https://doi.org/10.1109/ICRA46639.2022.9811904	Shuang Deng, Qiulei Dong, Bo Liu, Zhanyi Hu
Symbolic State Estimation with Predicates for Contact-Rich Manipulation Tasks.	Manipulation tasks often require a robot to adjust its sensorimotor skills based on the state it finds itself in. Taking peg-in-hole as an example: once the peg is aligned with the hole, the robot should push the peg downwards. While high level execution frameworks such as state machines and behavior trees are commonly used to formalize such decision-making problems, these frameworks require a mechanism to detect the high-level symbolic state. Handcrafting heuristics to identify symbolic states can be brittle, and using data-driven methods can produce noisy predictions, particularly when working with limited datasets, as is common in real-world robotic scenarios. This paper proposes a Bayesian state estimation method to predict symbolic states with predicate classifiers. This method requires little training data and allows fusing noisy observations from multiple sensor modalities. We evaluate our framework on a set of real-world peg-in-hole and connector-socket insertion tasks, demonstrating its ability to classify symbolic states and to generalize to unseen tasks, outperforming baseline methods. We also demonstrate the ability of our method to improve the robustness of manipulation policies on a real robot.	https://doi.org/10.1109/ICRA46639.2022.9811675	Toki Migimatsu, Wenzhao Lian, Jeannette Bohg, Stefan Schaal
Symphony: Learning Realistic and Diverse Agents for Autonomous Driving Simulation.	Simulation is a crucial tool for accelerating the development of autonomous vehicles. Making simulation realistic requires models of the human road users who interact with such cars. Such models can be obtained by applying learning from demonstration (LfD) to trajectories observed by cars already on the road. However, existing LfD methods are typically insufficient, yielding policies that frequently collide or drive off the road. To address this problem, we propose Symphony, which greatly improves realism by combining conventional policies with a parallel beam search. The beam search refines these policies on the fly by pruning branches that are unfavourably evaluated by a discriminator. However, it can also harm diversity, i.e., how well the agents cover the entire distribution of realistic behaviour, as pruning can encourage mode collapse. Symphony addresses this issue with a hierarchical approach, factoring agent behaviour into goal generation and goal conditioning. The use of such goals ensures that agent diversity neither disappears during adversarial training nor is pruned away by the beam search. Experiments on both proprietary and open Waymo datasets confirm that Symphony agents learn more realistic and diverse behaviour than several baselines.	https://doi.org/10.1109/ICRA46639.2022.9811990	Maximilian Igl, Daewoo Kim, Alex Kuefler, Paul Mougin, Punit Shah, Kyriacos Shiarlis, Dragomir Anguelov, Mark Palatucci, Brandyn White, Shimon Whiteson
Synergistic Scheduling of Learning and Allocation of Tasks in Human-Robot Teams.	We consider the problem of completing a set of n tasks with a human-robot team using minimum effort. In many domains, teaching a robot to be fully autonomous can be counterproductive if there are finitely many tasks to be done. Rather, the optimal strategy is to weigh the cost of teaching a robot and its benefit- how many new tasks it allows the robot to solve autonomously. We formulate this as a planning problem where the goal is to decide what tasks the robot should do autonomously (act), what tasks should be delegated to a human (delegate) and what tasks the robot should be taught (learn) so as to complete all the given tasks with minimum effort. This planning problem results in a search tree that grows expo-nentially with n - making standard graph search algorithms intractable. We address this by converting the problem into a mixed integer program that can be solved efficiently using off-the-shelf solvers with bounds on solution quality. To predict the benefit of learning, we use an approximate simulation model of the tasks to train a precondition model that is parameterized by the training task. Finally, we evaluate our approach on peg insertion and Lego stacking tasks- both in simulation and real-world, showing substantial savings in human effort.	https://doi.org/10.1109/ICRA46639.2022.9812328	Shivam Vats, Oliver Kroemer, Maxim Likhachev
Systematic Development of a Novel, Dynamic, Reduced Complexity Quadruped Robot Platform for Robotic Tail Research.	This paper presents a systematical approach to develop a novel reduced complexity quadruped (RCQ) robot designed for serpentine robotic tail research purposes. The critical design requirements are determined based on careful dynamic analysis and synthesis results. Guided by formulated design requirements and principles, a robot prototype was designed and built. The robot has an overall weight of 5 Kg and the body size of a domestic cat. The existing electronic system allows a control frequency of up to 1 kHz and accepts both torque and position commands. These features guarantee that the platform could be used to explore the dynamic usages of robotic tails on legged locomotion. The preliminary tests show that the hardware can lift itself off the ground up to 112 mm (46.7% of its body height) and stay in the air for at least 0.3 seconds.	https://doi.org/10.1109/ICRA46639.2022.9811871	Yujiong Liu, Pinhas Ben-Tzvi
TERP: Reliable Planning in Uneven Outdoor Environments using Deep Reinforcement Learning.	We present a novel method for reliable robot navigation in uneven outdoor terrains. Our approach employs a fully-trained Deep Reinforcement Learning (DRL) network that uses elevation maps of the environment, robot pose, and goal as inputs to compute an attention mask of the environment. The attention mask is used to identify reduced stability regions in the elevation map and is computed using channel and spatial attention modules and a novel reward function. We continuously compute and update a navigation cost-map that encodes the elevation information or the level-of-flatness of the terrain using the attention mask. We then generate locally least-cost waypoints on the cost-map and compute the final dynamically feasible trajectory using another DRL-based method. Our approach guarantees safe, locally least-cost paths and dynamically feasible robot velocities in uneven terrains. We observe an increase of 35.18% in terms of success rate and, a decrease of 26.14% in the cumulative elevation gradient of the robot's trajectory compared to prior navigation methods in high-elevation regions. We evaluate our method on a Husky robot in real-world uneven terrains (∼\n4m\nof elevation gain) and demonstrate its benefits.	https://doi.org/10.1109/ICRA46639.2022.9812238	Kasun Weerakoon, Adarsh Jagan Sathyamoorthy, Utsav Patel, Dinesh Manocha
TOPP-MPC-Based Dual-Arm Dynamic Collaborative Manipulation for Multi-Object Nonprehensile Transportation.	This paper presents a unified controller for dual-arm robot dynamic multi-object nonprehensile transportation. The controller is composed of time-optimal path parameteri-zation (TOPP) and model predictive control (MPC) and aimed at efficiently and dynamically transporting objects using the dual-arm robot under physical constraints while avoiding the slippage of the objects. A force tracking controller without using the force sensor is also proposed to achieve accurate contact force control between the arms and objects. Experiments on the real robot show the effectiveness of the proposed TOPP-MPC-based controller.	https://doi.org/10.1109/ICRA46639.2022.9812424	Cheng Zhou, Maolin Lei, Longfei Zhao, Zunran Wang, Yu Zheng
TP-AE: Temporally Primed 6D Object Pose Tracking with Auto-Encoders.	Fast and accurate tracking of an object's motion is one of the key functionalities of a robotic system for achieving reliable interaction with the environment. This paper focuses on the instance-level six-dimensional (6D) pose tracking problem with a symmetric and textureless object under occlusion. We propose a Temporally Primed 6D pose tracking framework with Auto-Encoders (TP-AE) to tackle the pose tracking problem. The framework consists of a prediction step and a temporally primed pose estimation step. The prediction step aims to quickly and efficiently generate a guess on the object's real-time pose based on historical information about the target object's motion. Once the prior prediction is obtained, the temporally primed pose estimation step embeds the prior pose into the RGB-D input, and leverages auto-encoders to reconstruct the target object with higher quality under occlusion, thus improving the framework's performance. Extensive experiments show that the proposed 6D pose tracking method can accurately estimate the 6D pose of a symmetric and textureless object under occlusion, and significantly outperforms the state-of-the-art on T-LESS dataset while running in real-time at 26 FPS.	https://doi.org/10.1109/ICRA46639.2022.9811890	Linfang Zheng, Ales Leonardis, Tze Ho Elden Tse, Nora Horanyi, Hua Chen, Wei Zhang, Hyung Jin Chang
TaTa: A Universal Jamming Gripper with High-Quality Tactile Perception and Its Application to Underwater Manipulation.	Large-area and high-precision tactile sensing information can not only improve the stability of robot grasping but also compensate for the lack of visual information in specific environments such as turbid underwater, dimness, and smoke. In this paper, we devise a universal jamming gripper with high-quality tactile sensing capability. The gripper adopts the particle jamming mechanism for grasping, and simultaneously uses a built-in camera to detect the deformation of its surface to obtain tactile information. To make the inside of the gripper transparent, glass beads and liquid with the same refractive index are applied as the internal filling. Besides, special treatments are taken to improve the tactile perception resolution of the gripper. The design perfectly merges visual-based tactile sensing into the traditional universal jamming gripper without changing its original gripping performance, making it possible for simultaneous grasping and sensing. To verify the tactile perception and grasping ability of the gripper in specific environments, we design two underwater experiments for grasping and pipe leak detection based on tactile information. Both have achieved a success rate not less than 95%, which demonstrates the effectiveness of the proposed gripper for manipulation in low visibility environments.	https://doi.org/10.1109/ICRA46639.2022.9811806	Shoujie Li, Xianghui Yin, Chongkun Xia, Linqi Ye, Xueqian Wang, Bin Liang
Tactile Classification of Object Materials for Virtual Reality based Robot Teleoperation.	This work presents a method for tactile classification of materials for virtual reality (VR) based robot teleoperation. In our system, a human-operator uses a remotely controlled robot-manipulator with an optical fibre-based tactile and proximity sensor to scan surfaces of objects in a remote environment. Tactile and proximity data and the robot's end-effector state feedback are used for the classification of objects' materials which are then visualized in the VR reconstruction of the remote environment for each object. Machine learning techniques such as random forest, convolutional neural and multi-modal convolutional neural networks were used for material classification. The proposed system and methods were tested with five different materials and classification accuracy of 90 % and more was achieved. The results of material classification were successfully exploited for visualising the remote scene in the VR interface to provide more information to the human-operator.	https://doi.org/10.1109/ICRA46639.2022.9811825	Bukeikhan Omarali, Francesca Palermo, Kaspar Althoefer, Maurizio Valle, Ildar Farkhatdinov
Targeted Attack on Deep RL-based Autonomous Driving with Learned Visual Patterns.	Recent studies demonstrated the vulnerability of control policies learned through deep reinforcement learning against adversarial attacks, raising concerns about the application of such models to risk-sensitive tasks such as autonomous driving. Threat models for these demonstrations are limited to (1) targeted attacks through real-time manipulation of the agent's observation, and (2) untargeted attacks through manipulation of the physical environment. The former assumes full access to the agent's states/observations at all times, while the latter has no control over attack outcomes. This paper investigates the feasibility of targeted attacks through visually learned patterns placed on physical objects in the environment, a threat model that combines the practicality and effectiveness of the existing ones. Through analysis, we demonstrate that a pre-trained policy can be hijacked within a time window, e.g., performing an unintended self-parking, when an adversarial object is present. To enable the attack, we adopt an assumption that the dynamics of both the environment and the agent can be learned by the attacker. Lastly, we empirically show the effectiveness of the proposed attack on different driving scenarios, perform a location robustness test, and study the tradeoff between the attack strength and its effectiveness Code is available at https://github.com/ASU-APG/ Targeted-Physical-Adversarial-Attacks-on-AD	https://doi.org/10.1109/ICRA46639.2022.9811574	Prasanth Buddareddygari, Travis Zhang, Yezhou Yang, Yi Ren
TartanDrive: A Large-Scale Dataset for Learning Off-Road Dynamics Models.	We present TartanDrive, a large scale dataset for learning dynamics models for off-road driving. We collected a dataset of roughly 200,000 off-road driving interactions on a modified Yamaha Viking ATV with seven unique sensing modalities in diverse terrains. To the authors' knowledge, this is the largest real-world multi-modal off-road driving dataset, both in terms of number of interactions and sensing modalities. We also benchmark several state-of-the-art methods for model-based reinforcement learning from high-dimensional observations on this dataset. We find that extending these models to multi-modality leads to significant performance on off-road dynamics prediction, especially in more challenging terrains. We also identify some shortcomings with current neural network architectures for the off-road driving task. Our dataset is available at https://github.com/castacks/tartan_drive.	https://doi.org/10.1109/ICRA46639.2022.9811648	Samuel Triest, Matthew Sivaprakasam, Sean J. Wang, Wenshan Wang, Aaron M. Johnson, Sebastian A. Scherer
Task Allocation with Load Management in Multi-Agent Teams.	In operations of multi-agent teams ranging from homogeneous robot swarms to heterogeneous human-autonomy teams, unexpected events might occur. While efficiency of operation for multi-agent task allocation problems is the primary objective, it is essential that the decision-making framework is intelligent enough to manage unexpected task load with limited resources. Otherwise, operation effectiveness would drastically plummet with overloaded agents facing unforeseen risks. In this work, we present a decision-making framework for multiagent teams to learn task allocation with the consideration of load management through decentralized reinforcement learning, where idling is encouraged and unnecessary resource usage is avoided. We illustrate the effect of load management on team performance and explore agent behaviors in example scenarios. Furthermore, a measure of agent importance in collaboration is developed to infer team resilience when facing handling potential overload situations.	https://doi.org/10.1109/ICRA46639.2022.9811374	Haochen Wu, Amin Ghadami, Alparslan Emrah Bayrak, Jonathon M. Smereka, Bogdan I. Epureanu
Task Persistification for Robots with Control-Dependent Energy Dynamics.	This paper presents a solution to the problem of executing robotic tasks over time horizons that exceed the robot's total battery capacity. In the presented robotics application, the robot's mission is to satisfy two tasks: environmental exploration and environmental monitoring, both of which need to be executed over long time periods. These tasks need therefore to be persistified. Ensuring the longevity of the system requires to consider a maximum energy consumption at all times. Including a dependency of battery voltage dynamics on the control input introduces a quadratic term in the battery's dynamic equation, making previous persistification approaches no longer directly applicable, as they used control-affine dynamics. In this paper an alternative task persistification approach is formulated. The control strategy used is based on Control Barrier Functions (CBFs). Using which, the generated controller renders the system state variables, position and battery voltage, to remain within the boundaries of their safe sets. This generated safe controller minimally modifies the nominal controller, which commands the robot to satisfy its environmental mission. Once the CBFs are selected, the minimization problem that results is one with a quadratic cost and two nested scalar constraints: one of which is quadratic and the other is linear. This new class of problems is noted as Quadratic Cost Scalar Linear and Quadratically Constrained (QCSLQC) problems. An analytical solution to the general QCSLQC problem is presented.	https://doi.org/10.1109/ICRA46639.2022.9812208	Carmen Jimenez Cortes, Magnus Egerstedt
Task-Oriented Generation of Stable Motions for Wheeled Inverted Pendulum Robots.	We present a whole-body control architecture for the generation of stable task-oriented motions in Wheeled Inverted Pendulum (WIP) robots. Controlling WIP systems is challenging because the successful execution of tasks is subordinate to the ability to maintain balance. Our feedback control approach relies both on partial feedback linearization and Model Predictive Control (MPC). The partial feedback linearization reshapes the system into a convenient form, while the MPC computes inputs to execute the desired task by solving a constrained optimization problem. Input constraints account for actuation limits and a stability constraint is in charge of stabilizing the unstable body pitch angle dynamics. The proposed approach is validated by simulations on an ALTER-EGO robot performing navigation and loco-manipulation tasks.	https://doi.org/10.1109/ICRA46639.2022.9812317	Marco Kanneworff, Tommaso Belvedere, Nicola Scianca, Filippo M. Smaldone, Leonardo Lanari, Giuseppe Oriolo
Task-Specific Design Optimization and Fabrication for Inflated-Beam Soft Robots with Growable Discrete Joints.	Soft robot serial chain manipulators with the capability for growth, stiffness control, and discrete joints have the potential to approach the dexterity of traditional robot arms, while improving safety, lowering cost, and providing an increased workspace, with potential application in home environments. This paper presents an approach for design optimization of such robots to reach specified targets while minimizing the number of discrete joints and thus construction and actuation costs. We define a maximum number of allowable joints, as well as hardware constraints imposed by the materials and actuation available for soft growing robots, and we formulate and solve an optimization problem to output a planar robot design, i.e., the total number of potential joints and their locations along the robot body, which reaches all the desired targets, avoids known obstacles, and maximizes the workspace. We demonstrate a process to rapidly construct the resulting soft growing robot design. Finally, we use our algorithm to evaluate the ability of this design to reach new targets and demonstrate the algorithm's utility as a design tool to explore robot capabilities given various constraints and objectives.	https://doi.org/10.1109/ICRA46639.2022.9811611	Ioannis Exarchos, Karen Wang, Brian H. Do, Fabio Stroppa, Margaret M. Coad, Allison M. Okamura, C. Karen Liu
Telerobotically Controlled Magnetic Soft Continuum Robots for Neurovascular Interventions.	Despite the recent advances in continuum robots for minimally invasive surgery or interventions, their applications to endovascular neurosurgery have remained technically challenging due to the difficulty of miniaturization. Aimed at enabling robotic applications to neurovascular interventions for endovascular treatments of stroke or brain aneurysms, we present a telerobotically controlled magnetic soft continuum robot capable of active steering and navigation under externally applied magnetic fields. For magnetic steering, a seven-degree-of-freedom (7-DOF) serial manipulator is employed to place an actuating magnet that can be manipulated via real-time teleoperation of the robot arm. A motorized linear drive is used to advance or retract the magnetic soft continuum robot, the distal tip of which is steered by the actuating magnet to enable endovascular navigation in the complex cerebral vasculature. We demonstrate the system's ability to guide selective navigation in different branches of cerebral arteries using anatomical models under visual feedback. We also compare the navigational performance of our system with that of a manually controlled passive guidewire and a conventional magnet-tipped guidewire. We found that the telerobotically controlled magnetic soft continuum robot allows for safer and quicker access to hard-to-reach areas in clinically challenging anatomies by enabling smooth navigation in narrow and winding pathways.	https://doi.org/10.1109/ICRA46639.2022.9812168	Yoonho Kim, Emily Genevriere, Pablo Harker, Jaehun Choe, Marcin Balicki, Aman B. Patel, Xuanhe Zhao
Temporal Logic Guided Motion Primitives for Complex Manipulation Tasks with User Preferences.	"Dynamic movement primitives (DMPs) are a flexible trajectory learning scheme widely used in motion generation of robotic systems. However, existing DMP-based methods mainly focus on simple go-to-goal tasks. Motivated to handle tasks beyond point-to-point motion planning, this work presents temporal logic guided optimization of motion primitives, namely \mathbf{PI}^{\mathbf{BB}-\mathbf{TL}}
algorithm, for complex manipulation tasks with user preferences. In particular, weighted truncated linear temporal logic (wTLTL) is incorporated in the \mathbf{PI}^{\mathbf{BB}-\mathbf{TL}}
algorithm, which not only enables the encoding of complex tasks that involve a sequence of logically organized action plans with user preferences, but also provides a convenient and efficient means to design the cost function. The black-box optimization is then adapted to identify optimal shape parameters of DMPs to enable motion planning of robotic systems. The effectiveness of the \mathbf{PI}^{\mathbf{BB}-\mathbf{TL}}
algorithm is demonstrated via simulation and experiment."	https://doi.org/10.1109/ICRA46639.2022.9811707	Hao Wang, Haoyuan He, Weiwei Shang, Zhen Kan
Temporally-Aggregating Multiple-Discontinuous-Image Saliency Prediction with Transformer-Based Attention.	In this paper, we aim to apply deep saliency prediction to automatic drone exploration, which should consider not only one single image, but multiple images from different view angles or localizations in order to determine the exploration direction. However, little attention has been paid to such saliency prediction problem over multiple-discontinuous-image and none of existing methods take temporal information into consideration, which may mean that the current predicted saliency map is not consistent with the previous predicted results. For this purpose, we propose a method named Temporally-Aggregating Multiple-Discontinuous-Image Saliency Prediction Network (TA-MSNet). It utilizes a transformer-based attention module to correlate relative saliency information among multiple discontinuous images and, furthermore, applies the ConvLSTM module to capture the temporal information. Experiments show that the proposed TA-MSNet can estimate better and more consistent results than previous works for time series data.	https://doi.org/10.1109/ICRA46639.2022.9811544	Pin-Jie Huang, Chi-An Lu, Kuan-Wen Chen
Tenodesis Grasp Emulator: Kinematic Assessment of Wrist-Driven Orthotic Control.	Wrist-driven orthotics have been designed to assist people with C6-7 spinal cord injury, however, the kinematic constraint imposed by such a control strategy can impede mobility and lead to abnormal body motion. This study characterizes body compensation using the novel Tenodesis Grasp Emulator, an adaptor orthotic that allows for the investigation of tenodesis grasping in subjects with unimpaired hand function. Subjects perform a series of grasp-and-release tasks in order to compare normal (test control) and constrained wrist-driven modes, showing significant compensation as a result of the constraint. A motor-augmented mode is also compared against traditional wrist-driven operation, to explore the potential role of hybrid human-robot control. We find that both the passive wrist-driven and motor-augmented modes fulfill different roles throughout various tasks tested. Thus, we conclude that a flexible control scheme that can alter intervention based on the task at hand holds the potential to reduce compensation in future work.	https://doi.org/10.1109/ICRA46639.2022.9812175	Erin Y. Chang, Raghid Mardini, Andrew I. W. McPherson, Yuri Gloumakov, Hannah S. Stuart
The Design of Stretch: A Compact, Lightweight Mobile Manipulator for Indoor Human Environments.	Mobile manipulators for indoor human environments can serve as versatile devices that perform a variety of tasks, yet adoption of this technology has been limited. Reducing size, weight, and cost could facilitate adoption, but risks restricting capabilities. We present a novel design that reduces size, weight, and cost, while supporting a variety of tasks. The core design consists of a two-wheeled differential-drive mobile base, a lift, and a telescoping arm configured to achieve Cartesian motion at the end of the arm. Design extensions include a 1 degree-of-freedom (DOF) wrist to stow a tool, a 2-DOF dexterous wrist to pitch and roll a tool, and a compliant gripper. We justify our design with anthropometry and mathematical models of static stability. We also provide empirical support from teleoperating and autonomously controlling a commercial robot based on our design (the Stretch RE1 from Hello Robot Inc.) to perform tasks in real homes.	https://doi.org/10.1109/ICRA46639.2022.9811922	Charles C. Kemp, Aaron Edsinger, Henry M. Clever, Blaine Matulevich
The Feedback Trajectory Control of a SMA-Driven Miniature Jumping Robot.	Jumping motion is an effective way to overcome large obstacles, especially for the miniature robots. However, controlling of the jumping trajectory on a centimeter scale robot is not easy due to the limitation of size and payload. None of the jumping robots lighter than 90 g achieved the feedback control of their jumping height and take-off angle independently. In this work, we proposed a miniature 6 g jumping robot that ensured the feedback control of jumping trajectory. Two simple PD controllers were used in take-off angle and jumping height control, respectively. The robot can control its jumping height from 0 to 73cm, take-off angle from −20° to +20° with respect to the vertical direction. The control errors of the jumping height and the take-off angle were less than 5 cm and 2°, respectively. The robot can hop upon different obstacles exactly, greatly increased the controllability of the micro jumping robot.	https://doi.org/10.1109/ICRA46639.2022.9811370	Lingqi Tang, Xuelin Wu, Peng Liu, Yao Li, Bing Li
The Second Generation (G2) Fingertip Sensor for Near-Distance Ranging and Material Sensing in Robotic Grasping.	To continuously improve robotic grasping, we are interested in developing a contactless fingertip-mounted sensor for near-distance ranging and material sensing. Previously, we demonstrated a dual-modal and dual sensing mechanisms (DMDSM) pretouch sensor prototype based on pulse-echo ultrasound and optoacoustics. However, the complex system, the bulky and expensive pulser-receiver, and the omni-directionally sensitive microphone block the sensor from practical applications in real robotic fingers. To address these issues, we report the second generation (G2) DMDSM sensor without the pulser-receiver and microphone, which is made possible by redesigning the ultrasound transmitter and receiver to gain much wider acoustic bandwidth. To verify our design, a prototype of the G2 DMDSM sensor has been fabricated and tested. The testing results show that the G2 DMDSM sensor can achieve better ranging and similar material/structure sensing performance, but with much-simplified configuration and operation. The primary results indicate that the G2 DMDSM sensor could provide a promising solution for fingertip pretouch sensing in robotic grasping.	https://doi.org/10.1109/ICRA46639.2022.9811902	Cheng Fang, Di Wang, Dezhen Song, Jun Zou
The ThreeDWorld Transport Challenge: A Visually Guided Task-and-Motion Planning Benchmark Towards Physically Realistic Embodied AI.	We introduce a visually-guided task-and-motion planning benchmark, which we call the ThreeDWorld Trans-port Challenge. In this challenge, an embodied agent is spawned randomly in a simulated physical home environment and required to transport a small set of objects scattered around the house with containers. We build this benchmark challenge using the ThreeDWorld simulation: a virtual 3D environment where all objects respond to physics, and a robot agent can be controlled using a fully physics-driven navigation and interaction API. We evaluate several existing agents on this benchmark. Experimental results suggest that: 1) a pure RL model struggles on this challenge; 2) state-of-the-art hierarchical planning-based agents can transport some objects but are still far from solving this task. We anticipate that this benchmark will empower researchers to develop more intelligent physics-aware robot learning algorithms.	https://doi.org/10.1109/ICRA46639.2022.9812329	Chuang Gan, Siyuan Zhou, Jeremy Schwartz, Seth Alter, Abhishek Bhandwaldar, Dan Gutfreund, Daniel L. K. Yamins, James J. DiCarlo, Josh H. McDermott, Antonio Torralba, Joshua B. Tenenbaum
The Visual-Inertial- Dynamical Multirotor Dataset.	Recently, the community has witnessed numerous datasets built for developing and testing state estimators. However, for some applications such as aerial transportation or search-and-rescue, the contact force or other disturbance must be perceived for robust planning and control, which is beyond the capacity of these datasets. This paper introduces a Visual-Inertial-Dynamical (VID) dataset, not only focusing on traditional six degrees of freedom (6-DOF) pose estimation but also providing dynamical characteristics of the flight platform for external force perception or dynamics-aided estimation. The VID dataset contains hardware synchronized imagery and inertial measurements, with accurate ground truth trajectories for evaluating common visual-inertial estimators. Moreover, the proposed dataset highlights rotor speed and motor current measurements, control inputs, and ground truth 6-axis force data to evaluate external force estimation. To the best of our knowledge, the proposed VID dataset is the first public dataset containing visual-inertial and complete dynamical information in the real world for pose and external force evaluation. The dataset1and related files2 are open-sourced.	https://doi.org/10.1109/ICRA46639.2022.9811956	Kunyi Zhang, Tiankai Yang, Ziming Ding, Sheng Yang, Teng Ma, Mingyang Li, Chao Xu, Fei Gao
The Wavejoints: A Novel Methodology to Design Soft-Rigid Grippers Made by Monolithic 3D Printed Fingers with Adjustable Joint Stiffness.	"In this paper, we present a methodology to design soft-rigid grippers able to perform different manipulation tasks. The main idea is the introduction of wave-shaped hinges whose geometrical parameters can be designed to achieve different three-dimensional impedance characteristics. This allows one to use the same tendon-driven actuation to perform different tasks including grasping objects with different shapes and in-hand manipulation of small objects. We report all design procedures and an experimental evaluation of two different prototypes exploiting two possible tasks, the first one is designed to grasp objects adapting to different shapes and dimensions, the second one performs an in-hand manipulation task consisting in object rotation with respect to an axis perpendicular to hand palm, resembling a ""screw"" movement. Obtained results confirm the feasibility and potentialities of the proposed methodology, that can be applied to obtain 3D printed monolithic fingers able to move in predefined directions when activated through a tendon-driven system, paving the way toward a new task-specific realization of compliant grippers."	https://doi.org/10.1109/ICRA46639.2022.9811548	Mihai Dragusanu, Gabriele Maria Achilli, Maria Cristina Valigi, Domenico Prattichizzo, Monica Malvezzi, Gionata Salvietti
The World Is Its Own Best Model: Robust Real-World Manipulation Through Online Behavior Selection.	Robotic manipulation behavior should be robust to disturbances that violate high-level task-structure. Such robustness can be achieved by constantly monitoring the environment to observe the discrete high-level state of the task. This is possible because different phases of a task are characterized by different sensor patterns and by monitoring these patterns a robot can decide which controllers to execute in the moment. This relaxes assumptions about the temporal sequence of those controllers and makes behavior robust to unforeseen disturbances. We implement this idea as probabilistic filter over discrete states where each state is direcly associated with a controller. Based on this framework we present a robotic system that is able to open a drawer and grasp tennis balls from it in a surprisingly robust way.	https://doi.org/10.1109/ICRA46639.2022.9811845	Manuel Baum, Oliver Brock
Tightly-coupled GNSS-aided Visual-Inertial Localization.	A navigation system which can output drift-free global trajectory estimation with local consistency holds great potential for autonomous vehicles and mobile devices. We propose a tightly-coupled GNSS-aided visual-inertial navigation system (GAINS) which is able to leverage the complementary sensing modality from a visual-inertial sensing pair, which provides high-frequency local information, and a Global Navigation Satellite System (GNSS) receiver with low-frequency global observations. Specifically, the raw GNSS measurements (including pseudorange, carrier phase changes, and Doppler frequency shift) are carefully leveraged and tightly fused within a visual-inertial framework. The proposed GAINS can accurately model the raw measurement uncertainties by canceling the atmospheric effects (e.g., ionospheric and tropospheric delays) which requires no prior model information. A robust state initialization procedure is presented to facilitate the fusion of global GNSS information with local visual-inertial odometry, and the spatiotemporal calibration between IMU-GNSS are also optimized in the estimator. The proposed GAINS is evaluated on extensive Monte-Carlo simulations on a trajectory generated from a large-scale urban driving dataset with specific verification for each component (i.e., online calibration and system initialization). GAINS also demonstrates competitive performance against existing state-of-the-art methods on a publicly available dataset with ground truth.	https://doi.org/10.1109/ICRA46639.2022.9811362	Woosik Lee, Patrick Geneva, Yulin Yang, Guoquan Huang
Topologically-Informed Atlas Learning.	We present a new technique that enables manifold learning to accurately embed data manifolds that contain holes, without discarding any topological information. Manifold learning aims to embed high-dimensional data into a lower dimensional Euclidean space by learning a coordinate chart, but it requires that the entire manifold can be embedded in a single chart. This is impossible for manifolds with holes. In such cases, it is necessary to learn an atlas: a collection of charts that collectively cover the entire manifold. We begin with many small charts, and combine them in a bottom-up approach, where charts are only combined if doing so will not introduce problematic topological features. When it is no longer possible to combine any charts, each chart is individually embedded with standard manifold learning techniques, completing the construction of the atlas. We show the efficacy of our method by constructing atlases for challenging synthetic manifolds; learning human motion embeddings from motion capture data; and learning kinematic models of articulated objects.	https://doi.org/10.1109/ICRA46639.2022.9812311	Thomas Cohn, Nikhil Devraj, Odest Chadwicke Jenkins
Toward Physical Human-Robot Interaction Control with Aerial Manipulators: Compliance, Redundancy Resolution, and Input Limits.	In this paper we introduce a comprehensive framework to control an aerial manipulator, i.e., an aerial vehicle with a robotic arm, in physical interaction with a human operator or co-worker. The framework uses an admittance control paradigm in order to attain human ergonomy and safety; an interaction supervisor to automatically shape the compliance based on the interaction regions defined around the human co-worker; a projected gradient redundancy resolution scheme to exploit the multiple degrees of freedom of the aerial robot to accommodate for possible additional secondary tasks; and a quadratic programming optimization-based inner loop to cope with real world input saturation and increase the safety level of the human co-worker. The control framework is demonstrated and validated through numerical simulations with a human-in-the loop.	https://doi.org/10.1109/ICRA46639.2022.9812451	Amr Afifi, Mark van Holland, Antonio Franchi
Towards 6DoF Bilateral Teleoperation of an Omnidirectional Aerial Vehicle for Aerial Physical Interaction.	Bilateral teleoperation offers an intriguing solution towards shared autonomy with aerial vehicles in contact-based inspection and manipulation tasks. Omnidirectional aerial robots allow for full pose operations, making them particularly attractive in such tasks. Naturally, the question arises whether standard bilateral teleoperation methodologies are suitable for use with these vehicles. In this work, a fully decoupled 6DoF bilateral teleoperation framework for aerial physical interaction is designed and tested for the first time. The method is based on the well established rate control, recentering and interaction force feedback policy. However, practical experiments evince the difficulty of performing de-coupled motions in a single axis only. As such, this work shows that the trivial extension of standard methods is insufficient for omnidirectional teleoperation, due to the operator's physical inability to properly decouple all input DoFs. This suggests that further studies on enhanced haptic feedback are necessary.	https://doi.org/10.1109/ICRA46639.2022.9812346	Mike Allenspach, Nicholas R. J. Lawrance, Marco Tognon, Roland Siegwart
Towards Accurate Positioning of Underwater Vehicles Using Low-cost Acoustic Modems.	Navigating autonomous underwater vehicles (AUVs) in shallow and harbor waters is challenging and typically has higher accuracy requirements than navigation in the open sea. We investigate enhancements to underwater localization techniques based on Two-Way Ranging (TWR) using acoustic modems, which have great potential to meet localization accuracy requirements at lower cost and complexity than current systems. By modifying the Extended Kalman Filter, we account for dynamic positioning errors that occur during the movement of the localization target, i.e., the underwater vehicle, and the fact that distance measurements with acoustic modems are delayed in time. The method is evaluated numerically and experimentally showing an accuracy improvement of about 20 cm compared to the traditional EKF scheme. In real-world tests at ranges below 30 m, the absolute localization accuracy is assessed using an RTK-GPS reference, showing that a positioning error below 35 cm can be achieved in a quasi-static test, while in a dynamic test the tracking error is mostly below 75 cm.	https://doi.org/10.1109/ICRA46639.2022.9811851	Christian Busse, Bernd-Christian Renner
Towards Artefact Aware Human Motion Capture using Inertial Sensors Integrated into Loose Clothing.	Inertial motion capture has become an attractive alternative to optical motion capture for human joint angle estimation outside the laboratory. Usually inertial sensors are assumed to be tightly fixed to the body segments, which can be cumbersome regarding setup-time and ease-of-use. However, integrating the sensors directly into loose clothing, usually, results in additional clothing motion relative to the motion of the underlying bones that should be captured. In this work we propose the Difference Mapping distributions approach that corrects the segment orientations of a given inertial motion capture system that assumes tightly coupled sensors. The approach allows to reduce the joint angle errors due to clothing artefacts by at least 77.2% for people with similar morphology performing a similar task as seen in the training data, including an ergonomic assessments scenario at work places with ten participants. Moreover, we show that the uncertainty of the distribution can be used to measure the reliability of the predicted map if e.g. the motion is further away from the training data to allow for an artefact aware inertial motion tracking approach. The experimental data for this study is available online under [1].	https://doi.org/10.1109/ICRA46639.2022.9811933	Michael Lorenz, Gabriele Bleser, Takayuki Akiyama, Takehiro Niikura, Didier Stricker, Bertram Taetz
Towards Broad Learning Networks on Unmanned Mobile Robot for Semantic Segmentation.	This article investigates the real-time semantic segmentation in robot engineering applications based on the Broad Learning System (BLS), and a novel Multi-level Enhancement Layers Network (MELNet) based on BLS framework is proposed for real-time vision tasks in a complex street scene on the unmanned mobile robot. This network mainly solves two problems: (1) mitigating the contradiction between accuracy and speed while maintaining low model complexity, and (2) accurately describing objects based on their shape despite their different sizes. Firstly, the BLS architecture is expanded to the deep network with trainable parameters. This trainable network could adjust its weights in a complex environment, and mitigate the adverse impact of the environment on the complex tasks. Secondly, enhancement layers with the extended enhancement layers could extract both detailed information and semantic information. Moreover, an Upsampling Atrous Spatial Pyramid Pooling (UPASPP) is designed to fuse detail and semantic information to describe object features properly. Finally, in the case of the MNIST dataset and Cityscapes dataset, we get high accuracy with 8.01M parameters and quicker inference speed on a single GTX 1070 Ti card. At the same time, the unmanned mobile robot (BIT-NAZA) is employed to evaluate semantic performance in real-world situations. This reveals that MELNet could be run adequately on the embedded device and effectively operate in the real-robot system.	https://doi.org/10.1109/ICRA46639.2022.9812204	Jiehao Li, Yingpeng Dai, Junzheng Wang, Xiaohang Su, Ruijun Ma
Towards Dynamic Visual Servoing for Interaction Control and Moving Targets.	In this work we present our results on dynamic visual servoing for the case of moving targets while also exploring the possibility of using such a controller for interaction with the environment. We illustrate the derivation of a feature space impedance controller for tracking a moving object as well as an Extended Kalman Filter based on the visual servoing kinematics for increasing the rate of the visual information and estimating the target velocity for both the cases of PBVS and IBVS with image point features. Simulations are carried out to validate the estimator performance during a Peg-in-Hole insertion task with a moving part. Experiments are also conducted on a real redundant manipulator with a low-cost wrist-mounted camera. Details on several implementation issues encountered during implementation are also discussed.	https://doi.org/10.1109/ICRA46639.2022.9812081	Alexander Antonio Oliva, Erwin Aertbeliën, Joris De Schutter, Paolo Robuffo Giordano, François Chaumette
Towards Efficient 3D Human Motion Prediction using Deformable Transformer-based Adversarial Network.	Human motion prediction is a crucial step for achieving human-robot interactions. While recent transformer-based methods have shown great potentials in 3D human motion prediction, they still suffer from mode collapse to non-plausible poses and quadratically computational complexity with respect to the increasing length of input sequences. In this paper, we propose a novel spatio-temporal deformable transformer-based adversarial network (STDTA) for 3D human motion prediction. First, we design a spatio-temporal deformable transformer module to capture the correlations between human joints while reducing the computational costs. Second, we introduce the adversarial training mechanism and design fidelity and continuity discriminators to maintain smoothness and stability for the long-term prediction. Finally, extensive experiments on Human 3.6M and AMASS benchmarks demonstrate that the proposed STDTA achieves state-of-the-art performance.	https://doi.org/10.1109/ICRA46639.2022.9812325	Hua Yu, Xuanzhe Fan, Yaqing Hou, Yi Liu, Cai Kang, Dongsheng Zhou, Qiang Zhang
Towards More Generalizable One-shot Visual Imitation Learning.	A general-purpose robot should be able to master a wide range of tasks and quickly learn a novel one by leveraging past experiences. One-shot imitation learning (OSIL) approaches this goal by training an agent with (pairs of) expert demonstrations, such that at test time, it can directly execute a new task from just one demonstration. However, so far this framework has been limited to training on many variations of one task, and testing on other unseen but similar variations of the same task. In this work, we push for a higher level of generalization ability by investigating a more ambitious multi-task setup. We introduce a diverse suite of vision-based robot manipulation tasks, consisting of 7 tasks, a total of 61 variations, and a continuum of instances within each variation. For consistency and comparison purposes, we first train and evaluate single-task agents (as done in prior few-shot imitation work). We then study the multi-task setting, where multi-task training is followed by (i) one-shot imitation on variations within the training tasks, (ii) one-shot imitation on new tasks, and (iii) fine-tuning on new tasks. Prior state-of-the-art, while performing well within some single tasks, struggles in these harder multi-task settings. To address these limitations, we propose MOSAIC (Multi-task One-Shot Imitation with self-Attention and Contrastive learning), which integrates a self-attention model architecture and a temporal contrastive module to enable better task disambiguation and more robust representation learning. Our experiments show that MOSAIC outperforms prior state of the art in learning efficiency, final performance, and learns a multi-task policy with promising generalization ability via fine-tuning on novel tasks.	https://doi.org/10.1109/ICRA46639.2022.9812450	Mandi Zhao, Fangchen Liu, Kimin Lee, Pieter Abbeel
Towards Optimal Correlational Object Search.	In realistic applications of object search, robots will need to locate target objects in complex environments while coping with unreliable sensors, especially for small or hard-to-detect objects. In such settings, correlational information can be valuable for planning efficiently. Previous approaches that consider correlational information typically resort to ad-hoc, greedy search strategies. We introduce the Correlational Object Search POMDP (COS-POMDP), which models correlations while preserving optimal solutions with a reduced state space. We propose a hierarchical planning algorithm to scale up COS-POMDPs for practical domains. Our evaluation, conducted with the AI2-THOR household simulator and the YOLOv5 object detector, shows that our method finds objects more successfully and efficiently compared to baselines, particularly for hard-to-detect objects such as srub brush and remote control.	https://doi.org/10.1109/ICRA46639.2022.9812252	Kaiyu Zheng, Rohan Chitnis, Yoonchang Sung, George Konidaris, Stefanie Tellex
Towards Robust Part-aware Instance Segmentation for Industrial Bin Picking.	Industrial bin picking is a challenging task that requires accurate and robust segmentation of individual object instances. Particularly, industrial objects can have irregular shapes, that is, thin and concave, whereas in bin-picking scenarios, objects are often closely packed with strong occlusion. To address these challenges, we formulate a novel part-aware instance segmentation pipeline. The key idea is to decompose industrial objects into correlated approximate convex parts and enhance the object-level segmentation with part-level segmentation. We design a part-aware network to predict part masks and part-to-part offsets, followed by a part aggregation module to assemble the recognized parts into instances. To guide the network learning, we also propose an automatic label decoupling scheme to generate ground-truth part-level labels from instance-level labels. Finally, we contribute the first instance segmentation dataset, which contains a variety of industrial objects that are thin and have non-trivial shapes. Extensive experimental results on various industrial objects demonstrate that our method can achieve the best segmentation results compared with the state-of-the-art approaches.	https://doi.org/10.1109/ICRA46639.2022.9811728	Yidan Feng, Biqi Yang, Xianzhi Li, Chi-Wing Fu, Rui Cao, Kai Chen, Qi Dou, Mingqiang Wei, Yun-Hui Liu, Pheng-Ann Heng
Towards Safe, Realistic Testbed for Robotic Systems with Human Interaction.	Simulation has been a necessary, safe testbed for robotics systems (RS). However, testing in simulation alone is not enough for robotic systems operating in close proximity, or interacting directly with, humans, because simulated humans are very limited. Furthermore, testing with real humans can be unsafe and costly. As recent advances in machine learning are being brought to physical robotic systems, how to collect data as well as evaluate them with human interactions safely yet realistically is a critical question. This paper presents a Mixed-Reality (MR) system toward human-centered development of robotic systems emphasizing benefits as a data collection and testbed tool. MR testbeds allow humans to interact with various levels of virtuality to maintain both realism and safety. We detail the advantages and limitations of these different levels of realism or virtualization, and report our MR-based RS testbed implemented using off-the-shelf MR devices with the Unity game engine and ROS. We demonstrate our testbed in a multi-robot, multi-person tracking and monitoring application. We share our vision and insights earned during the development and data collection.	https://doi.org/10.1109/ICRA46639.2022.9811766	Bhoram Lee, Jonathan Brookshire, Rhys Yahata, Supun Samarasekera
Towards Scale Consistent Monocular Visual Odometry by Learning from the Virtual World.	Monocular visual odometry (VO) has attracted extensive research attention by providing real-time vehicle motion from cost-effective camera images. However, state-of-the-art optimization-based monocular VO methods suffer from the scale inconsistency problem for long-term predictions. Deep learning has recently been introduced to address this issue by leveraging stereo sequences or ground-truth motions in the training dataset. However, it comes at an additional cost for data collection, and such training data may not be available in all datasets. In this work, we propose VRVO, a novel framework for retrieving the absolute scale from virtual data that can be easily obtained from modern simulation environments, whereas in the real domain no stereo or ground-truth data are required in either the training or inference phases. Specifically, we first train a scale-aware disparity network using both monocular real images and stereo virtual data. The virtual-to-real domain gap is bridged by using an adversarial training strategy to map images from both domains into a shared feature space. The resulting scale-consistent disparities are then integrated with a direct VO system by constructing a virtual stereo objective that ensures the scale consistency over long trajectories. Additionally, to address the suboptimality issue caused by the separate optimization backend and the learning process, we further propose a mutual reinforcement pipeline that allows bidirectional information flow between learning and optimization, which boosts the robustness and accuracy of each other. We demonstrate the effectiveness of our framework on the KITTI and vKITTI2 datasets.	https://doi.org/10.1109/ICRA46639.2022.9812347	Sen Zhang, Jing Zhang, Dacheng Tao
Towards Sensor Autonomy in Sub-Gram Flying Insect Robots: A Lightweight and Power-Efficient Avionics System.	Flying insect robots weighing less than a gram (FIRs) have advantages over their larger counterparts due to their low materials cost, small size, and low weight, allowing for deployment in large numbers. Control autonomy in such aircraft introduces challenges arising from their small size such as high-speed dynamics, limited power and payload capacity. Previous work has produced and characterized sensors with compatible mass and power specifications, many of which are biologically-inspired. And controlled flight has been demon-strated using feedback from external motion capture cameras. But to date, no avionics system has been reported that is light enough and capable of providing the feedback necessary to perform controlled hovering flight using only components carried on-board. Here we present such a system. It consists a sensor package consisting of an inertial measurement unit, a laser rangefinder and an optical flow sensor, and an associated estimator based on the nonlinear Extended Kalman Filter (EKF). The sensor suite weighs 187 mg and consumes 21 mW. We implemented a low-latency wireless link to transmit this data at 1 kHz without cumbersome wires. The EKF estimates attitude, altitude and lateral velocities. We estimate that computation power usage is <400 µW using floating-point operations on a standard microcontroller. Our system's RMSE attitude and position error are less than 4° and 1 cm relative to motion capture estimates.	https://doi.org/10.1109/ICRA46639.2022.9811918	Yash P. Talwekar, Andrew Adie, Vikram Iyer, Sawyer B. Fuller
Towards Time-Optimal Tunnel-Following for Quadrotors.	Minimum-time navigation within constrained and dynamic environments is of special relevance in robotics. Seeking time-optimality, while guaranteeing the integrity of time-varying spatial bounds, is an appealing trade-off for agile vehicles, such as quadrotors. State-of-the-art approaches, either assume bounds to be static and generate time-optimal trajectories offline, or compromise time-optimality for constraint satisfaction. Leveraging nonlinear model predictive control and a path parametric reformulation of the quadrotor model, we present a real-time control that approximates time-optimal behavior and remains within dynamic corridors. The efficacy of the approach is evaluated by simulated results, showing itself capable of performing extremely aggressive maneuvers as well as stop-and-go and backward motions. Video: https://youtu.be/Apc8MCu7Yvo	https://doi.org/10.1109/ICRA46639.2022.9811764	Jon Arrizabalaga, Markus Ryll
Towards a Microfluidic Microcontroller Circuit Library for Soft Robots.	Soft robotics has seen an exponential growth in the past decade, in part because the transition to soft materials has made a wider range of applications possible. Tasks involving contact with fragile objects or unstructured environments are particularly amenable to devices based on soft materials. To date, research has primarily focused on the development of soft analogs to traditional sensors and actuators while controllers for soft robots have tended to rely on common rigid electronic components. We aspire to create a library of elastomer-based devices that can evolve soft controllers beyond component-level demonstrations and towards system-level completeness taking inspiration from electronic microcontrollers. Our approach combines microfluidic circuit designs with soft robotic fabrication techniques to create fluidic microcontroller components that are composed of soft materials and are of minimal size. We have identified the shift register, oscillator, and demultiplexer as key circuit elements for both individual functionality and for multi-component systems that can mimic microcontroller behaviors. In this paper, we present a review of fluidic circuits, fabrication processes, and implementation of these circuits into soft robotic platforms. In this work, we demonstrate a shift register, demultiplexer, and oscillator. They contain characteristics such as memory storage, data communication, and timing capabilities.	https://doi.org/10.1109/ICRA46639.2022.9812219	Elizabeth Gallardo Hevia, Louis De La Rochefoucauld, Robert J. Wood
TraSeTR: Track-to-Segment Transformer with Contrastive Query for Instance-level Instrument Segmentation in Robotic Surgery.	Surgical instrument segmentation - in general a pixel classification task - is fundamentally crucial for promoting cognitive intelligence in robot-assisted surgery (RAS). However, previous methods are struggling with discriminating instrument types and instances. To address above issues, we explore a mask classification paradigm that produces per-segment predictions. We propose TraSeTR, a novel Track-to-Segment Transformer that wisely exploits tracking cues to assist surgical instrument segmentation. TraSeTR jointly reasons about the instrument type, location, and identity with instance-level predictions i.e., a set of class-bbox-mask pairs, by decoding query embeddings. Specifically, we introduce the prior query that encoded with previous temporal knowledge, to transfer tracking signals to current instances via identity matching. A contrastive query learning strategy is further applied to reshape the query feature space, which greatly alleviates the tracking difficulty caused by large temporal variations. The effectiveness of our method is demonstrated with state-of-the-art instrument type segmentation results on three public datasets, including two RAS benchmarks from EndoVis Challenges and one cataract surgery dataset CaDIs.	https://doi.org/10.1109/ICRA46639.2022.9811873	Zixu Zhao, Yueming Jin, Pheng-Ann Heng
Tracking Fast Trajectories with a Deformable Object using a Learned Model.	We propose a method for robotic control of deformable objects using a learned nonlinear dynamics model. After collecting a dataset of trajectories from the real system, we train a recurrent neural network (RNN) to approximate its input-output behavior with a latent state-space model. The RNN internal state is low-dimensional enough to enable realtime nonlinear control methods. We demonstrate a closed-loop control scheme with the RNN model using a standard nonlinear state observer and model-predictive controller. We apply our method to track a highly dynamic trajectory with a point on the deformable object, in real time and on real hardware. Our experiments show that the RNN model captures the true system's frequency response and can be used to track trajectories outside the training distribution. In an ablation study, we find that the full method improves tracking accuracy compared to an open-loop version without the state observer.	https://doi.org/10.1109/ICRA46639.2022.9812189	James A. Preiss, David Millard, Tao Yao, Gaurav S. Sukhatme
Traffic Context Aware Data Augmentation for Rare Object Detection in Autonomous Driving.	Detection of rare objects (e.g., traffic cones, traffic barrels and traffic warning triangles) is an important perception task to improve the safety of autonomous driving. Training of such models typically requires a large number of annotated data which is expensive and time consuming to obtain. To address the above problem, an emerging approach is to apply data augmentation to automatically generate cost-free training samples. In this work, we propose a systematic study on simple Copy-Paste data augmentation for rare object detection in autonomous driving. Specifically, local adaptive instance-level image transformation is introduced to generate realistic rare object masks from source domain to the target domain. Moreover, traffic scene context is utilized to guide the placement of masks of rare objects. To this end, our data augmentation generates training data with high quality and realistic characteristics by leveraging both local and global consistency. In addition, we build a new dataset named NM10k consisting 10k training images, 4k validation images and the corresponding labels with a diverse range of scenarios in autonomous driving. Experiments on NM10k show that our method achieves promising results on rare object detection. We also present a thorough study to illustrate the effectiveness of our local-adaptive and global constraints based Copy-Paste data augmentation for rare object detection. The data, development kit and more information of NM10k dataset are available online at: https://nullmax-vision.github.io.	https://doi.org/10.1109/ICRA46639.2022.9811724	Naifan Li, Fan Song, Ying Zhang, Pengpeng Liang, Erkang Cheng
Trajectory Distribution Control for Model Predictive Path Integral Control using Covariance Steering.	This paper presents a novel control approach for autonomous systems operating under uncertainty. We combine Model Predictive Path Integral (MPPI) control with Covariance Steering (CS) theory to obtain a robust controller for general nonlinear systems. The proposed Covariance-Controlled Model Predictive Path Integral (CC-MPPI) controller addresses the performance degradation observed in some MPPI implementations owing to unexpected disturbances and uncertainties. Namely, in cases where the environment changes too fast or the simulated dynamics during the MPPI rollouts do not capture the noise and uncertainty in the actual dynamics, the baseline MPPI implementation may lead to divergence. The proposed CC-MPPI controller avoids divergence by controlling the dispersion of the rollout trajectories at the end of the prediction horizon. Furthermore, the CC-MPPI has adjustable trajectory sampling distributions that can be changed according to the environment to achieve efficient sampling. Numerical examples using a ground vehicle navigating in challenging environments demonstrate the proposed approach.	https://doi.org/10.1109/ICRA46639.2022.9811615	Ji Yin, Zhiyuan Zhang, Evangelos A. Theodorou, Panagiotis Tsiotras
Trajectory Optimization Formulation with Smooth Analytical Derivatives for Track-leg and Wheel-leg Ground Robots.	Tracks, wheels, and legs are all useful locomotion modes for Unmanned Ground Vehicles (UGVs), and ground robots that combine these mechanisms have the potential to climb over large obstacles. As robot morphologies include more degrees of freedom and obstacles become increasingly large and complex, UGVs will need to rely on automatic motion planning to compute the joint trajectories for traversal. This article presents a trajectory optimization formulation for multibody UGVs with combined wheel-leg and track-leg designs. We derive the dynamics and constraints for rolling wheels and circulating elliptical tracks. Using direct collocation, we formulate a model-based trajectory optimization where all constraints and objectives are written in closed-form with smooth and exact derivatives for tractable computation times with existing large-scale nonlinear optimization solvers (<1 minute). We demonstrate the trajectory optimization on numerous simulated planar wheel-leg and track-leg morphologies completing locomotion tasks, demonstrating full body dynamic coupling for the multibody system. Future work will extend this formulation to 3D and include contact planning.	https://doi.org/10.1109/ICRA46639.2022.9812199	Adwait Mane, Dylan Swart, Jason White, Christian Hubicki
Trajectory Planning for Sensors and Payloads Moving Through Mixed and Uncertain Media.	Heterogeneous robotic systems in the field often encounter bodies of water with unknown traversability properties. One approach to measuring depth, current, soil composition, etc. is via an in situ underwater sensor being dragged by cable attached to a maneuvering airborne multicopter - which entails a novel motion planning and control problem with mixed resistive media. In this work we propose a framework to plan trajectories for future characterization sensors and payloads moving through mixed (air-water) media while considering uncertainty in the depth of the underwater ground surface. The methodology is applied to example underactuated systems with suspended payloads of increasing levels of complexity, including a cable robot and 4- and 8-DOF multicopter systems. Simulation studies employing trajectory optimization indicate that under certain payload configurations and task constraints, there are maneuvers in which it is more efficient to drag the payloads through water than through air. The paper also includes preliminary experiments with a testbed cable robot platform.	https://doi.org/10.1109/ICRA46639.2022.9811773	Camilo Ordonez, David Jay, Christian Hubicki
Trajectory Prediction for Autonomous Driving with Topometric Map.	State-of-the-art autonomous driving systems rely on high definition (HD) maps for localization and navigation. However, building and maintaining HD maps is time-consuming and expensive. Furthermore, the HD maps assume structured environment such as the existence of major road and lanes, which are not present in rural areas. In this work, we propose an end-to-end transformer networks based approach for map-less autonomous driving. The proposed model takes raw LiDAR data and noisy topometric map as input and produces precise local trajectory for navigation. We demonstrate the effectiveness of our method in real-world driving data, including both urban and rural areas. The experimental results show that the proposed method outperforms state-of-the-art multimodal methods and is robust to the perturbations of the topometric map. The code of the proposed method is publicly available at https://github.com/Jiaolong/trajectory-prediction.	https://doi.org/10.1109/ICRA46639.2022.9811712	Jiaolong Xu, Liang Xiao, Dawei Zhao, Yiming Nie, Bin Dai
Trajectory Prediction with Linguistic Representations.	Language allows humans to build mental models that interpret what is happening around them resulting in more accurate long-term predictions. We present a novel trajectory prediction model that uses linguistic intermediate representations to forecast trajectories, and is trained using trajectory samples with partially-annotated captions. The model learns the meaning of each of the words without direct per-word supervision. At inference time, it generates a linguistic description of trajectories which captures maneuvers and interactions over an extended time interval. This generated description is used to refine predictions of the trajectories of multiple agents. We train and validate our model on the Argoverse dataset, and demonstrate improved accuracy results in trajectory prediction. In addition, our model is more interpretable: it presents part of its reasoning in plain language as captions, which can aid model development and can aid in building confidence in the model before deploying it.	https://doi.org/10.1109/ICRA46639.2022.9811928	Yen-Ling Kuo, Xin Huang, Andrei Barbu, Stephen G. McGill, Boris Katz, John J. Leonard, Guy Rosman
Trajectory Scaling for Reactive Motion Planning.	Trajectory scaling has long been used to address velocity and acceleration constraints in robotic motion planning. In later years, reactive motion planning based on dynamical systems has become popular. The traditional scaling techniques are not always suitable to adopt directly when online modifications of the trajectories are made leading to feasibility problems. In this paper, we propose an approach which scales trajectories modelled as dynamical systems for improved feasibility. This is achieved by proactively scaling the trajectory as the acceleration limits are approached. Performance is illustrated by means of simulations and experiments on a UR10 robot.	https://doi.org/10.1109/ICRA46639.2022.9811657	Albin Dahlin, Yiannis Karayiannidis
TransGrasp: A Multi-Scale Hierarchical Point Transformer for 7-DoF Grasp Detection.	Robotic grasping pose detection that predicts the configuration of the robotic gripper for object grasping is fundamental in robot manipulation. Based on point clouds, most of the existing methods predict grasp pose with the hierarchical PointNet++ backbone, while the non-local geometric information is underexplored. In this work, we address the 7-DoF (6- DoF with the grasp width) grasp detection by introducing a one- stage Transformer-based hierarchical multi-scale model dubbed TransGrasp. Empowered by TransGrasp, the point features are enhanced via acquiring multi-scale shape awareness in the whole scene. By directly modeling the long-range relevance, our pipeline is aware of object contour to avoid collisions and able to apply analogy reasoning for long-distance geometric structures. The evaluation results on the large scale GraspNet- 1Billion dataset demonstrate the effectiveness of the proposed TransGrasp. The real robot experiments on an ABB YUMI robot with an Azure Kinect DK camera and an ABB Smart two-finger gripper show high success rates in both single object and cluttered scenes.	https://doi.org/10.1109/ICRA46639.2022.9812001	Zhixuan Liu, Zibo Chen, Shangjin Xie, Wei-Shi Zheng
Translating Images into Maps.	We approach instantaneous mapping, converting images to a top-down view of the world, as a translation problem. We show how a novel form of transformer network can be used to map from images and video directly to an overhead map or bird's-eye-view (BEV) of the world, in a single end-to-end network. We assume a 1–1 correspondence between a vertical scanline in the image, and rays passing through the camera location in an overhead map. This lets us formulate map generation from an image as a set of sequence-to-sequence translations. Posing the problem as translation allows the network to use the context of the image when interpreting the role of each pixel. This constrained formulation, based upon a strong physical grounding of the problem, leads to a restricted transformer network that is convolutional in the horizontal direction only. The structure allows us to make efficient use of data when training, and obtains state-of-the-art results for instantaneous mapping of three large-scale datasets, including a 15% and 30% relative gain against existing best performing methods on the nuScenes and Argoverse datasets, respectively.	https://doi.org/10.1109/ICRA46639.2022.9811901	Avishkar Saha, Oscar Mendez, Chris Russell, Richard Bowden
Translation Invariant Global Estimation of Heading Angle Using Sinogram of LiDAR Point Cloud.	Global point cloud registration is an essential module for localization, of which the main difficulty exists in estimating the rotation globally without initial value. With the aid of gravity alignment, the degree of freedom in point cloud registration could be reduced to 4DoF, in which only the heading angle is required for rotation estimation. In this paper, we propose a fast and accurate global heading angle estimation method for gravity-aligned point clouds. Our key idea is that we generate a translation invariant representation based on Radon Transform, allowing us to solve the decoupled heading angle globally with circular cross-correlation. Besides, for heading angle estimation between point clouds with different distributions, we implement this heading angle estimator as a differentiable module to train a feature extraction network end-to-end. The experimental results validate the effectiveness of the proposed method in heading angle estimation and show better performance compared with other methods.	https://doi.org/10.1109/ICRA46639.2022.9811750	Xiaqing Ding, Xuecheng Xu, Sha Lu, Yanmei Jiao, Mengwen Tan, Rong Xiong, Huanjun Deng, Mingyang Li, Yue Wang
TridentNetV2: Lightweight Graphical Global Plan Representations for Dynamic Trajectory Generation.	We present a framework for dynamic trajectory generation for autonomous navigation, which does not rely on HD maps as the underlying representation. High Definition (HD) maps have become a key component in most autonomous driving frameworks, which include complete road network information annotated at a centimeter-level that include traversable waypoints, lane information, and traffic signals. Instead, the presented approach models the distributions of feasible ego-centric trajectories in real-time given a nominal graph-based global plan and a lightweight scene representation. By embedding contextual information, such as crosswalks, stop signs, and traffic signals, our approach achieves low errors across multiple urban navigation datasets that include diverse intersection maneuvers, while maintaining real-time performance and reducing network complexity. Underlying datasets introduced are available online.	https://doi.org/10.1109/ICRA46639.2022.9811591	David Paz, Hao Xiang, Andrew Liang, Henrik I. Christensen
TrussBot: Modeling, Design, and Control of a Compliant, Helical Truss of Tetrahedral Modules.	Modular and truss robots offer the potential of high reconfigurability and great functional flexibility, but common implementations relying on rigid components often lead to highly complex actuation and control requirements. This paper introduces a new type of modular, compliant robot: TrussBot. TrussBot is composed of 3D-printed tetrahedral modules connected at the corners with compliant joints. We propose a truss geometry, analyze its deformation modes, and provide a simulation framework for predicting its behavior under applied loads and actuation. The TrussBot is geometrically constrained, thus requiring compliant joints to move. The TrussBot can be actuated through a network of tendons which pinch vertices together and apply a twisting motion due to the structure's connectivity. The truss was demonstrated in a physical prototype and compared to simulation results.	https://doi.org/10.1109/ICRA46639.2022.9812295	Yuhong Qin, Linda Ting, Celestina Saven, Yumika Amemiya, Michael Tanis, Randall D. Kamien, Cynthia Sung
UFO Depth: Unsupervised learning with flow-based odometry optimization for metric depth estimation.	We propose an efficient method for unsupervised learning of metric depth estimation from a single image in the context of unconstrained videos captured from UAVs. We combine the accuracy of an analytical solution based on odometry with the power of deep learning. First, we show how to correct the noisy odometric measurements by optimizing the alignment between the derotated optical flow and the projected linear speed in the image. Then, we detail an analytical depth estimation method based on optical flow and corrected camera velocities. Subsequently, the improved depth and camera veloc-ities obtained analytically are used, as additional cost terms, for training our novel unsupervised learning architecture for metric depth estimation. We extensively test on a recent UAV dataset, which we significantly extend by adding completely novel scenes. We outperform by significant margins different kinds of state-of-the-art approaches, ranging from analytical and unsupervised solutions to transformer-based architectures that require heavy computation and pre-training. The resulting algorithm could be deployed on embedded devices, being a good candidate for practical robotics use cases, such as obstacle avoidance and safe landing for UAV s.	https://doi.org/10.1109/ICRA46639.2022.9812374	Vlad Licaret, Victor Robu, Alina Marcu, Dragos Costea, Emil Slusanschi, Rahul Sukthankar, Marius Leordeanu
UnDAF: A General Unsupervised Domain Adaptation Framework for Disparity or Optical Flow Estimation.	Disparity and optical flow estimation are respectively 1D and 2D dense correspondence matching (DCM) tasks in nature. Unsupervised domain adaptation (UDA) is crucial for their success in new and unseen scenarios, enabling networks to draw inferences across different domains without manually-labeled ground truth. In this paper, we propose a general UDA framework (UnDAF) for disparity or optical flow estimation. Unlike existing approaches based on adversarial learning that suffers from pixel distortion and dense correspondence mismatch after domain alignment, our UnDAF adopts a straightforward but effective coarse-to-fine strategy, where a co-teaching strategy (two networks evolve by complementing each other) refines DCM estimations after Fourier transform initializes domain alignment. The simplicity of our approach makes it extremely easy to guide adaptation across different domains, or more practically, from synthetic to real-world domains. Extensive experiments carried out on the KITTI and MPI Sintel benchmarks demonstrate the accuracy and robustness of our UnDAF, advancing all other state-of-the-art UDA approaches for disparity or optical flow estimation. Our project page is available at https://sites.google.com/view/undaf.	https://doi.org/10.1109/ICRA46639.2022.9811811	Hengli Wang, Rui Fan, Peide Cai, Ming Liu, Lujia Wang
Uncertainty from Motion for DNN Monocular Depth Estimation.	Deployment of deep neural networks (DNNs) for monocular depth estimation in safety-critical scenarios on resource-constrained platforms requires well-calibrated and efficient uncertainty estimates. However, many popular uncertainty estimation techniques, including state-of-the-art ensembles and popular sampling-based methods, require multiple inferences per input, making them difficult to deploy in latency-constrained or energy-constrained scenarios. We propose a new algorithm, called Uncertainty from Motion (UfM), that requires only one inference per input. UfM exploits the temporal redundancy in video inputs by merging incrementally the per-pixel depth prediction and per-pixel aleatoric uncertainty prediction of points that are seen in multiple views in the video sequence. When UfM is applied to ensembles, we show that UfM can retain the uncertainty quality of ensembles at a fraction of the energy by running only a single ensemble member at each frame and fusing the uncertainty over the sequence of frames. In a set of representative experiments using FCDenseNet and eight indistribution and out-of-distribution video sequences, UfM offers comparable uncertainty quality to an ensemble of size 10 while consuming only 11.3% of the ensemble's energy and running 6.4× faster on a single Nvidia RTX 2080 Ti GPU, enabling near ensemble uncertainty quality for resource-constrained, real-time scenarios.	https://doi.org/10.1109/ICRA46639.2022.9812222	Soumya Sudhakar, Vivienne Sze, Sertac Karaman
Uncertainty-based Exploring Strategy in Densely Cluttered Scenes for Vacuum Cup Grasping.	Grasping a wide range of novel objects in densely cluttered scenes is difficult due to irregular shapes of objects and the uncertainty in sensing. In this paper, a novel vacuum cup grasping method, based on uncertainty modeling of perception data and grasp geometric heuristics, is proposed to grasp unknown objects in densely cluttered scenes. The probabilistic signed distance function is proposed to both reconstruct the point cloud of a scene and explicitly model the uncertainty from depth images captured from a low-cost stereo camera. The quasi-static spring model is used to approximate seal formation between the suction cup and the reconstructed point cloud. A coarse-to-fine exploration procedure is proposed to refine the estimated point cloud, reduce uncertainties during the movement of the robot and redetermine the target grasp pose iteratively. Extensive experiments show that our proposed method achieves state-of-the-art performance on real-world grasping and outperforms existing methods by a large margin.	https://doi.org/10.1109/ICRA46639.2022.9811599	Kimwa Tung, Jingcheng Su, Junhao Cai, Zhaoliang Wan, Hui Cheng
Uncertainty-driven Planner for Exploration and Navigation.	We consider the problems of exploration and pointgoal navigation in previously unseen environments, where the spatial complexity of indoor scenes and partial observability constitute these tasks challenging. We argue that learning occupancy priors over indoor maps provides significant advantages towards addressing these problems. To this end, we present a novel planning framework that first learns to generate occupancy maps beyond the field-of-view of the agent, and second leverages the model uncertainty over the generated areas to formulate path selection policies for each task of interest. For pointgoal navigation the policy chooses paths with an upper confidence bound policy for efficient and traversable paths, while for exploration the policy maximizes model uncertainty over candidate paths. We perform experiments in the visually realistic environments of Matterport3D using the Habitat simulator and demonstrate: 1) Improved results on exploration and map quality metrics over competitive methods, and 2) The effectiveness of our planning module when paired with the state-of-the-art DD-PPO method for the point-goal navigation task.	https://doi.org/10.1109/ICRA46639.2022.9812423	Georgios Georgakis, Bernadette Bucher, Anton Arapin, Karl Schmeckpeper, Nikolai Matni, Kostas Daniilidis
Understanding Xacro Misunderstandings.	The Xacro XML macro language can be used to augment the Universal Robot Description Format (URDF) and is part of a critical toolchain from geometric representations to simulation, visualization, and system execution. However, mem-bers of the robotics community, especially newcomers, struggle to troubleshoot and understand the interplay between systems and the Xacro preprocessing pipeline. To better understand how system developers struggle with Xacros, we manually examine 712 Xacro-related questions from the question and answer site answers.ros.org and find Xacro misunderstandings fit into eight key categories using a systematic, qualitative approach called Open Coding. By examining the 'tags' applied to questions, we further find that Xacro problems manifest in a befuddlingly broad set of contexts. This hinders onboarding and complicates system developers' understanding of representations and tools in the Robot Operating System. We aim to provide an empirical grounding that identifies and prioritizes impediments to users of open robotics systems, so that tool designers, teachers, and robotics practitioners can devise ways of improving robot software tooling and education.	https://doi.org/10.1109/ICRA46639.2022.9812349	Nicholas Albergo, Vivek Rathi, John-Paul Ore
Underwater Dock Detection through Convolutional Neural Networks Trained with Artificial Image Generation.	Autonomous Underwater Vehicles (AUVs) are a vital element for ocean exploration in various applications; however, energy sustainability still limits long-term operations. An option to overcome this problem is using underwater docking for power and data transfer. To robustly guide an AUV into a docking station, we propose an underwater vision algorithm for short-distance detection. In this paper, we present a Convolutional Neural Network architecture to accurately estimate the dock position during the terminal homing stage of the docking. Additionally, to alleviate the lack of available underwater datasets, two methods are proposed to generate synthetic datasets, one using a CycleGAN network, and another using Artistic Style transfer network. Both methods are used to train the same CNN architecture to compare the results. Finally, implementation details of the CNN are presented under the backseat architecture and ROS framework, running on an IVER3 AUV.	https://doi.org/10.1109/ICRA46639.2022.9812143	Jalil Chavez-Galaviz, Nina Mahmoudian
Unfreezing Social Navigation: Dynamical Systems based Compliance for Contact Control in Robot Navigation.	Large efforts have focused on ensuring that the controllers for mobile service robots follow proxemics and other social rules to ensure both safe and socially acceptable distance to pedestrians. Nonetheless, involuntary contact may be unavoidable when the robot travels in crowded areas or when encountering adversarial pedestrians. Freezing the robot in response to contact might be detrimental to bystanders' safety and prevents it from achieving its task. Unavoidable contacts must hence be controlled to ensure the safe and smooth travelling of robots in pedestrian alleys. We present a force-limited and obstacle avoidance controller integrated into a time-invariant dynamical system (DS) in a closed-loop force controller that let the robot react instantaneously to contact or to the sudden appearance of pedestrians. Mitigating the risk of collision is done by modulating the velocity commands upon detecting a contact and by absorbing part of the contact force through active compliant control when the robot bumps inad-vertently against a pedestrian. We evaluated our method with a personal mobility robot -Qolo- showing contact mitigation with passive and active compliance. We showed the robot able to overcome an adversarial pedestrian within 9 N of the set limit contact force for speeds under 1 m/s. Moreover, we evaluated integrated obstacle avoidance proving the ability to advance without Incurring any other collision.	https://doi.org/10.1109/ICRA46639.2022.9811772	Diego Paez-Granados, Vaibhav Gupta, Aude Billard
Unified Data Collection for Visual-Inertial Calibration via Deep Reinforcement Learning.	Visual-inertial sensors have a wide range of applications in robotics. However, good performance often requires different sophisticated motion routines to accurately calibrate camera intrinsics and inter-sensor extrinsics. This work presents a novel formulation to learn a motion policy to be executed on a robot arm for automatic data collection for calibrating intrinsics and extrinsics jointly. Our approach models the calibration process compactly using model-free deep reinforcement learning to derive a policy that guides the motions of a robotic arm holding the sensor to efficiently collect measurements that can be used for both camera intrinsic calibration and camera-IMU extrinsic calibration. Given the current pose and collected measurements, the learned policy generates the subsequent transformation that optimizes sensor calibration accuracy. The evaluations in simulation and on a real robotic system show that our learned policy generates favorable motion trajectories and collects enough measurements efficiently that yield the desired intrinsics and extrinsics with short path lengths. In simulation, we are able to perform calibrations 10× faster than hand-crafted policies, which transfers to a real-world speed up of 3× over a human expert. The code of this work is publicly available at: https://github.com/ethz-asl/Learn-to-Calibrate.	https://doi.org/10.1109/ICRA46639.2022.9811629	Yunke Ao, Le Chen, Florian Tschopp, Michel Breyer, Roland Siegwart, Andrei Cramariuc
Unified Representation of Geometric Primitives for Graph-SLAM Optimization Using Decomposed Quadrics.	In Simultaneous Localization And Mapping (SLAM) problems, high-level landmarks have the potential to build compact and informative maps compared to traditional point-based landmarks. In this work, we focus on the param-eterization of frequently used geometric primitives including points, lines, planes, ellipsoids, cylinders, and cones. We first present a unified representation based on quadrics, an algebraic representation of quadratic surfaces in 3D. Then we propose a decomposed model of quadrics that discloses the symmetry and degeneration properties of a primitive. Based on the decomposition, we develop geometrically meaningful quadrics factors for the graph-SLAM problem. Then in simulation, it is shown that the decomposed formulation has better efficiency and robustness to observation noises than baseline parame-terizations. Finally, in real-world experiments, the proposed back-end framework is demonstrated to be capable of building compact and regularized maps.	https://doi.org/10.1109/ICRA46639.2022.9812162	Weikun Zhen, Huai Yu, Yaoyu Hu, Sebastian A. Scherer
Unseen Object Amodal Instance Segmentation via Hierarchical Occlusion Modeling.	Instance-aware segmentation of unseen objects is essential for a robotic system in an unstructured environment. Although previous works achieved encouraging results, they were limited to segmenting the only visible regions of unseen objects. For robotic manipulation in a cluttered scene, amodal perception is required to handle the occluded objects behind others. This paper addresses Unseen Object Amodal Instance Segmentation (UOAIS) to detect 1) visible masks, 2) amodal masks, and 3) occlusions on unseen object instances. For this, we propose a Hierarchical Occlusion Modeling (HOM) scheme designed to reason about the occlusion by assigning a hierarchy to a feature fusion and prediction order. We evaluated our method on three benchmarks (tabletop, indoors, and bin environments) and achieved state-of-the-art (SOTA) performance. Robot demos for picking up occluded objects, codes, and datasets are available at https://sites.google.com/view/uoais.	https://doi.org/10.1109/ICRA46639.2022.9811646	Seunghyeok Back, Joosoon Lee, Taewon Kim, Sangjun Noh, Raeyoung Kang, Seongho Bak, Kyoobin Lee
Unsupervised Depth Completion and Denoising for RGB-D Sensors.	Depth information is considered valuable as it describes geometric structures, which benefits various robotic tasks. However, the depth acquired by RGB-D sensors still suffers from two deficiencies, i.e., incompletion and noises. Previous methods complete depth by exploring hand-tuned models or raising surface assumptions, while nowadays, deep approaches intend to solve this problem with rendered image pairs. For depth denoising, as a consequence of different sensor mechanisms, most methods can only work under specific devices. With existing methods, three challenges emerge: the onerous training set collecting process, the mismatch between existing models and present RGB-D sensors, and the non-real-time computation. In this paper, we first state depth completion and denoising are inherently different and without the need to collect or render complete and noiseless ground truths. We address all mentioned challenges with two separate un-supervised learning procedures. The completion network takes color and incomplete depth as input and predicts values to the unobserved area, which combines prior knowledge and color-depth correlations. The denoising step exploits image sequences to construct noise models in a self-supervised manner with the ability to cater to different sensors. Experimental comparisons and ablation studies demonstrate that even without human-labeled ground truths, the proposed method could produce better completion results and also reduce noises in real-time.	https://doi.org/10.1109/ICRA46639.2022.9812392	Lei Fan, Yunxuan Li, Chen Jiang, Ying Wu
Unsupervised Domain Adaptation in LiDAR Semantic Segmentation with Self-Supervision and Gated Adapters.	In this paper, we focus on a less explored, but more realistic and complex problem of domain adaptation in LiDAR semantic segmentation. There is a significant drop in performance of an existing segmentation model when training (source domain) and testing (target domain) data originate from different LiDAR sensors. To overcome this shortcoming, we propose an unsupervised domain adaptation framework that leverages unlabeled target domain data for self-supervision, coupled with an unpaired mask transfer strategy to mitigate the impact of domain shifts. Furthermore, we introduce the gated adapter module with a small number of parameters into the network to account for target domain-specific information. Experiments adapting from both real-to-real and synthetic-to-real LiDAR semantic segmentation benchmarks demonstrate the significant improvement over prior arts.	https://doi.org/10.1109/ICRA46639.2022.9811654	Mrigank Rochan, Shubhra Aich, Eduardo R. Corral-Soto, Amir Nabatchian, Bingbing Liu
Unsupervised Learning of Terrain Representations for Haptic Monte Carlo Localization.	Haptic sensing has recently been used effectively for legged robot localization in extreme scenarios where cam-eras and LiDAR might fail, such as dusty mines and foggy sewers. However, existing haptic sensing mainly relies on supervised classification, with training and evaluation executed over explicit terrain classes. Defining classes is a significant limitation to real-world applications, where prior labelling and handcrafted classes are often impractical. This paper proposes a novel haptic localization system based on a fully unsupervised terrain representation learned solely from the force/torque sensors located in the quadruped robot's feet. Instead of using the detected terrain class for localization, we propose an improved autoencoder architecture to generate a sparse map of encodings on the first run and to localize against this sparse map during subsequent runs. We compare our approach to a haptic localization system based on supervised terrain classification, showing that the unsupervised method has comparable or better performance than the supervised one for the same trajectories while clearly outperforming the proprioceptive odometry estimator available on the robot. Therefore, the proposed approach is well-suited for a routine maintenance application, increasing the platform's robustness.	https://doi.org/10.1109/ICRA46639.2022.9812296	Mikolaj Lysakowski, Michal R. Nowicki, Russell Buchanan, Marco Camurri, Maurice F. Fallon, Krzysztof Walas
Using Arm Swing Movements to Maintain the Walking State in a Self-Balanced Lower-Limb Exoskeleton.	This work investigates how arm swing movements measured by Inertial Motion Unit (IMU) sensors can be used to identify and maintain the walking state in a self-balanced lower-limb exoskeleton for medical use. When an exoskeleton is in a dynamical state during gait, short patterns in IMU signals (e.g. a braking movement) can be hard to extract. Therefore, by relying on a threshold-based classifier constructed upon descriptive features of actively maintained arm swing movements, it is possible to build a gait termination detection method in which the transition between the walking and standstill states occurs whenever arm movements cease, and the corresponding patterns in the IMU signals disappear. Analysis of arm IMU signals were used to identify three amplitude and coordination-based features for the classification architecture. An online implementation of this novel detection interface for maintaining the walking state was validated with 11 unimpaired participants using the Atalante exoskeleton, leading to high accuracy with less than 2% of false negatives when the arms were swinging at a high amplitude, and less than 15% when they were swinging at a medium amplitude.	https://doi.org/10.1109/ICRA46639.2022.9811824	Omar Mounir Alaoui, Fabien Expert, Guillaume Morel, Nathanaël Jarrassé
Using Eye Gaze to Forecast Human Pose in Everyday Pick and Place Actions.	Collaborative robots that operate alongside humans require the ability to understand their intent and forecast their pose. Among the various indicators of intent, the eye gaze is particularly important as it signals action towards the gazed object. By observing a person's gaze, one can effectively predict the object of interest and subsequently, forecast the person's pose. We leverage this and present a method that forecasts the human pose using gaze information for everyday pick and place actions in a home environment. Our method first attends to fixations to locate the coordinates of the object of interest before inputting said coordinates to a pose forecasting network. Experiments on the MoGaze dataset show that our gaze network lowers the errors of existing pose forecasting methods and that incorporating prior in the form of textual instructions further lowers the errors by a significant amount. Furthermore, the use of eye gaze now allows a simple multilayer perceptron network to directly forecast the keypose.aaCode available at www.imperial.ac.uk/personal-robotics/software	https://doi.org/10.1109/ICRA46639.2022.9812079	Haziq Razali, Yiannis Demiris
Using Language to Generate State Abstractions for Long-Range Planning in Outdoor Environments.	"Robots that process navigation instructions in large outdoor environments will need to operate at different levels of abstraction. For example, a land-surveying aerial robot receiving the instruction ""go to Boston and go through the state forest on the way"" must reason about a long-range goal like ""go to Boston"" while also processing a finer-grained constraint like ""go through the state forest."" Existing approaches struggle to plan such commands because of the immense number of locations and constraints that can be expressed in language. We introduce a hierarchical representation of outdoor environments and a planning approach that dynamically compacts the robot's state space to enable tractable planning in city and state-scale environments. Our approach leverages natural abstractions in real-world map data, coupled with abstractions generated from users' instructions, to generate filtered environment views that accelerate planning while supporting a robot's ability to obey complex temporal goals and constraints at different levels of abstraction. We evaluate our approach on seven templates of LTLJ formulas and in an 80 kilometer-radius environment containing over 250,000 locations downloaded from OpenStreetMap. The results show our approach enables planning in seconds or minutes in a large outdoor environment while still satisfying the task specification."	https://doi.org/10.1109/ICRA46639.2022.9812355	Matthew Berg, George Konidaris, Stefanie Tellex
Using Monocular Vision and Human Body Priors for AUVs to Autonomously Approach Divers.	Direct communication between humans and autonomous underwater vehicles (AUVs) is a relatively under-explored area in human-robot interaction research, although many tasks (e.g., surveillance, inspection, and search-and-rescue) require close diver-robot collaboration. Suboptimal AUV positioning relative to its human collaborators can lead to poor quality interaction and lead to excessive cognitive and physical load for divers. In this paper, we introduce a novel method for AUVs to autonomously navigate and achieve diver-relative positioning to begin interaction. Our method is based only on monocular vision, requires no global localization, and is computationally efficient. We present our algorithm and its implementation on board a physical AUV, performing extensive evaluations in the form of closed-water tests in a controlled pool. Our results show that the proposed monocular vision-based algorithm performs reliably and efficiently, operating entirely on-board the AUV.	https://doi.org/10.1109/ICRA46639.2022.9811905	Michael Fulton, Jungseok Hong, Junaed Sattar
VIP-SLAM: An Efficient Tightly-Coupled RGB-D Visual Inertial Planar SLAM.	In this paper, we propose a tightly-coupled SLAM system fused with RGB, Depth, IMU and structured plane information. Traditional sparse points based SLAM systems always maintain a mass of map points to model the environment. Huge number of map points bring us a high computational complexity, making it difficult to be deployed on mobile devices. On the other hand, planes are common structures in man-made environment especially in indoor environments. We usually can use a small number of planes to represent a large scene. So the main purpose of this article is to decrease the high complexity of sparse points based SLAM. We build a lightweight back-end map which consists of a few planes and map points to achieve efficient bundle adjustment (BA) with an equal or better accuracy. We use homography constraints to eliminate the parameters of numerous plane points in the optimization and reduce the complexity of BA. We separate the parameters and measurements in homography and point-to-plane constraints and compress the measurements part to further effectively im-prove the speed of BA. We also integrate the plane information into the whole system to realize robust planar feature extraction, data association, and global consistent planar reconstruction. Finally, we perform an ablation study and compare our method with similar methods in simulation and real environment data. Our system achieves obvious advantages in accuracy and efficiency. Even if the plane parameters are involved in the optimization, we effectively simplify the back-end map by using planar structures. The global bundle adjustment is nearly 2 times faster than the sparse points based SLAM algorithm.	https://doi.org/10.1109/ICRA46639.2022.9812354	Danpeng Chen, Shuai Wang, Weijian Xie, Shangjin Zhai, Nan Wang, Hujun Bao, Guofeng Zhang
VIRDO: Visio-tactile Implicit Representations of Deformable Objects.	Deformable object manipulation requires computationally efficient representations that are compatible with robotic sensing modalities. In this paper, we present VIRDO: an implicit, multi-modal, and continuous representation for deformable-elastic objects. VIRDO operates directly on visual (point cloud) and tactile (reaction forces) modalities and learns rich latent embeddings of contact locations and forces to predict object deformations subject to external contacts. Here, we demonstrate VIRDOs ability to: i) produce high-fidelity cross-modal reconstructions with dense unsupervised correspondences, ii) generalize to unseen contact formations, and iii) state-estimation with partial visio-tactile feedback. https://github.com/MMintLab/VIRDO	https://doi.org/10.1109/ICRA46639.2022.9812097	Youngsun Wi, Pete Florence, Andy Zeng, Nima Fazeli
VISTA 2.0: An Open, Data-driven Simulator for Multimodal Sensing and Policy Learning for Autonomous Vehicles.	Simulation has the potential to transform the development of robust algorithms for mobile agents deployed in safety-critical scenarios. However, the poor photorealism and lack of diverse sensor modalities of existing simulation engines remain key hurdles towards realizing this potential. Here, we present VISTA††Full code release for the VISTA data-driven simulation engine is available here: vista.csail.mit.edu., an open source, data-driven simulator that integrates multiple types of sensors for autonomous vehicles. Using high fidelity, real-world datasets, VISTA represents and simulates RGB cameras, 3D LiDAR, and event-based cameras, enabling the rapid generation of novel viewpoints in simulation and thereby enriching the data available for policy learning with corner cases that are difficult to capture in the physical world. Using VISTA, we demonstrate the ability to train and test perception-to-control policies across each of the sensor types and showcase the power of this approach via deployment on a full scale autonomous vehicle. The policies learned in VISTA exhibit sim-to-real transfer without modification and greater robustness than those trained exclusively on real-world data.	https://doi.org/10.1109/ICRA46639.2022.9812276	Alexander Amini, Tsun-Hsuan Wang, Igor Gilitschenski, Wilko Schwarting, Zhijian Liu, Song Han, Sertac Karaman, Daniela Rus
VOILA: Visual-Observation-Only Imitation Learning for Autonomous Navigation.	While imitation learning for vision-based au-tonomous mobile robot navigation has recently received a great deal of attention in the research community, existing approaches typically require state-action demonstrations that were gathered using the deployment platform. However, what if one cannot easily outfit their platform to record these demonstration signals or-worse yet-the demonstrator does not have access to the platform at all? Is imitation learning for vision-based autonomous navigation even possible in such scenarios? In this work, we hypothesize that the answer is yes and that recent ideas from the Imitation from Observation (IfO) literature can be brought to bear such that a robot can learn to navigate using only ego-centric video collected by a demonstrator, even in the presence of viewpoint mismatch. To this end, we introduce a new algorithm, Visual-Observation-only Imitation Learning for Autonomous navigation (VOILA), that can successfully learn navigation policies from a single video demonstration collected from a physically different agent. We evaluate VOILA in the AirSim simulator and show that VOILA not only successfully imitates the expert, but that it also learns navigation policies that can generalize to novel environments. Further, we demonstrate the effectiveness of VOILA in a real-world setting by showing that it allows a wheeled Jackal robot to successfully imitate a human walking in an environment while recording video with a handheld mobile phone camera.	https://doi.org/10.1109/ICRA46639.2022.9812316	Haresh Karnan, Garrett Warnell, Xuesu Xiao, Peter Stone
Validate on Sim, Detect on Real - Model Selection for Domain Randomization.	A practical approach to learning robot skills, often termed sim2real, is to train control policies in simulation and then deploy them on a real robot. Popular sim2real techniques build on domain randomization (DR) - training the policy on diverse randomly generated domains for better generalization to the real world. Due to the large number of hyper-parameters in both the policy learning and DR algorithms, one often ends up with a large number of trained policies, where choosing the best policy among them demands costly evaluation on the real robot. In this work we ask - can we rank the policies without running them in the real world? Our main idea is that a predefined set of real world data can be used to evaluate all policies, using out-of-distribution detection (OOD) techniques. In a sense, this approach can be seen as a 'unit test' to evaluate policies before any real world execution. However, we find that by itself, the OOD score can be inaccurate and very sensitive to the particular OOD method. Our main contribution is a simple-yet-effective policy score that combines OOD with an evaluation in simulation. We show that our score - VSDR - can significantly improve the accuracy of policy ranking without requiring additional real world data. We evaluate the effectiveness of VSDR on sim2real transfer in a robotic grasping task with image inputs. We extensively evaluate different DR parameters and OOD methods, and show that VSDR improves policy selection across the board. More importantly, our method achieves significantly better ranking, and uses significantly less data compared to baselines. Project website is at https://sites.google.com/view/vsdr/home	https://doi.org/10.1109/ICRA46639.2022.9811621	Gal Leibovich, Guy Jacob, Shadi Endrawis, Gal Novik, Aviv Tamar
Value learning from trajectory optimization and Sobolev descent: A step toward reinforcement learning with superlinear convergence properties.	The recent successes in deep reinforcement learning largely rely on the capabilities of generating masses of data, which in turn implies the use of a simulator. In particular, current progress in multi body dynamic simulators are under-pinning the implementation of reinforcement learning for end-to-end control of robotic systems. Yet simulators are mostly considered as black boxes while we have the knowledge to make them produce a richer information. In this paper, we are proposing to use the derivatives of the simulator to help with the convergence of the learning. For that, we combine model-based trajectory optimization to produce informative trials using 1st- and 2nd-order simulation derivatives. These locally-optimal runs give fair estimates of the value function and its derivatives, that we use to accelerate the convergence of the critics using Sobolev learning. We empirically demonstrate that the algorithm leads to a faster and more accurate estimation of the value function. The resulting value estimate is used in model-predictive controller as a proxy for shortening the preview horizon. We believe that it is also a first step toward superlinear reinforcement learning algorithm using simulation derivatives, that we need for end-to-end legged locomotion.	https://doi.org/10.1109/ICRA46639.2022.9811993	Amit Parag, Sébastien Kleff, Léo Saci, Nicolas Mansard, Olivier Stasse
Variable Rate Compression for Raw 3D Point Clouds.	In this paper, we propose a novel variable rate deep compression architecture that operates on raw 3D point cloud data. The majority of learning-based point cloud compression methods work on a downsampled representation of the data. Moreover, many existing techniques require training multiple networks for different compression rates to generate consolidated point clouds of varying quality. In contrast, our network is capable of explicitly processing point clouds and generating a compressed description at a comprehensive range of bitrates. Furthermore, our approach ensures that there is no loss of information as a result of the voxelization process and the density of the point cloud does not affect the encoder/decoder performance. An extensive experimental evaluation shows that our model obtains state-of-the-art results, it is computationally efficient, and it can work directly with point cloud data thus avoiding an expensive voxelized representation.	https://doi.org/10.1109/ICRA46639.2022.9812239	Md Ahmed Al Muzaddid, William J. Beksi
Variable Stiffness Control via External Torque Estimation Using LSTM.	Stable contact and safe responses to the collision have been studied to develop interactive robots such as service and collaborative robots. Stable and safe interactions are usually achieved through the inherent compliance of a motion controller with external torque estimation. However, a fixed control gain would sacrifice either compliance or position tracking performance. Additionally, external torque estimation is susceptible to model errors. In this study, a novel variable stiffness control approach is proposed to achieve a high position tracking performance in free motion and compliant behavior in the contact state. For this purpose, a precise estimation of the external torque and control gains that change based on the external torque are required. To estimate the external torque precisely, a collision detecting learning algorithm that uses long short-term memory (LSTM) is adopted. Although this method uses only proprioceptive sensors, its torque estimation capability is comparable to that of methods that use additional sensors. Then, the stiffness of a motion controller is adjusted based on the external torque in the stable region. Moreover, by adopting the Operational Space Formulation considering joint elasticity for a motion controller, high position tracking performance can be achieved with only proprioceptive sensors. The performance of the proposed method was validated through comparative experiments with two degrees of freedom (DoF) manipulator.	https://doi.org/10.1109/ICRA46639.2022.9811955	Jaesug Jung, Seungbin You, Donghyeon Kim, Jaeheung Park
Vision-Aided Dynamic Quadrupedal Locomotion on Discrete Terrain Using Motion Libraries.	In this paper, we present a framework rooted in control and planning that enables quadrupedal robots to traverse challenging terrains with discrete footholds using visual feedback. Navigating discrete terrain is challenging for quadrupeds because the motion of the robot can be aperiodic, highly dynamic, and blind for the hind legs of the robot. Additionally, the robot needs to reason over both the feasible footholds as well as the base velocity in order to speed up or slow down at different parts of the discrete terrain. To address these challenges, we build an offline library of periodic gaits which span two trotting steps, and switch between different motion primitives to achieve aperiodic motions of different step lengths on a quadrupedal robot. The motion library is used to provide targets to a geometric model predictive controller which outputs the contact forces at the stance feet. To incorporate visual feedback, we use terrain mapping tools and a forward facing depth camera to build a local height map of the terrain around the robot, and extract feasible foothold locations around both the front and hind legs of the robot. Our experiments show a small scale quadruped robot navigating multiple unknown, challenging and discrete terrains in the real world.	https://doi.org/10.1109/ICRA46639.2022.9811373	Ayush Agrawal, Shuxiao Chen, Akshara Rai, Koushil Sreenath
Vision-Based Large-scale 3D Semantic Mapping for Autonomous Driving Applications.	In this paper, we present a complete pipeline for 3D semantic mapping solely based on a stereo camera system. The pipeline comprises a direct sparse visual odometry frontend as well as a back-end for global optimization including GNSS integration, and semantic 3D point cloud labeling. We propose a simple but effective temporal voting scheme which improves the quality and consistency of the 3D point labels. Qualitative and quantitative evaluations of our pipeline are performed on the KITTI-360 dataset. The results show the effectiveness of our proposed voting scheme and the capability of our pipeline for efficient large-scale 3D semantic mapping. The large-scale mapping capabilities of our pipeline is furthermore demonstrated by presenting a very large-scale semantic map covering 8000 km of roads generated from data collected by a fleet of vehicles.	https://doi.org/10.1109/ICRA46639.2022.9811368	Qing Cheng, Niclas Zeller, Daniel Cremers
Vision-based Ascending Staircase Detection with Interpretable Classification Model for Stair Climbing Robots.	Robots capable of traversing flights of stairs play an important role in both indoor and outdoor applications. The capability of accurately identifying a staircase is one of the vital technical functions in these robots. This paper presents a vision-based ascending stair detection algorithm using RGB-Depth (RGB-D) data based on an interpretable model. The method follows the four steps: 1) pre-processing of RGB images for line extraction by applying the dilatation and Canny filters followed by the probabilistic Hough line transform, 2) defining the regions of interests (ROIs) via K- mean clustering, 3) training the initial model based on a support vector machine (SVM) using three extracted features (i.e., gradient, continuity factor, and deviation cost), and 4) building an interpretable model for stair classification by determining the decision boundary conditions. The developed method was evaluated for its performance using our dataset, and the results showed 85% sensitivity and 94% specificity. When the same model was tested on a different test set, the sensitivity and specificity slightly decreased to 80% and 90%, respectively. By shifting the boundary conditions using only a small subset of the new dataset without rebuilding the model, performance was improved to 90% sensitivity and 96% specificity. The presented method is also compared with existing SVM- and neural- network- based methods.	https://doi.org/10.1109/ICRA46639.2022.9812456	Kangneoung Lee, Vishnu Kalyanram, Chuanqi Zheng, Siddharth Sane, Kiju Lee
Visual Navigation Using Sparse Optical Flow and Time-to-Transit.	"Drawing inspiration from biology, we describe the way in which visual sensing with a monocular camera can provide a reliable signal for navigation of mobile robots. The work takes inspiration from the classic paper [3] which described a behavioral strategy pursued by diving sea birds based on a visual cue called time-to-contact. A closely related concept of time-to-transit, \tau
, is defined, and it is shown that steering laws based on monocular camera perceptions of \tau
can reliably steer a mobile vehicle. The contribution of the paper is two-fold. It provides a simple theory of robust vision-based steering control. It goes on to show how the theory guides the implementation of robust visual navigation using ROS-Gazebo simulations as well as deployment and experiments with a camera-equipped Jackal robot. As will be noted, there is an extensive literature on how animals use optical flow to guide their movements. The novelty of the work below is the introduction of the concepts of Eulerian optical flow and time-to-transit, \tau
and the demonstration that control laws based on the \tau
-values associated with an aggregated set of features in the field of view can be used to reliably steer a laboratory robot."	https://doi.org/10.1109/ICRA46639.2022.9812032	Chiara Boretti, Philippe Bich, Yanyu Zhang, John Baillieul
Visual Perception of Robot Appearance Attributes in the Peripheral Field of View Depends on Human Observer Eye-Movement Behaviors.	This paper presents results from a study on the perception of robot attributes by human observers in their peripheral field of view depending on types of eye-movements of the latter. A between-subjects design is used, where a picture of a robot head is presented on a screen in the peripheral field of view of the participants with two conditions of eye-movements: static and pursuit. The two conditions are realized by a dot to be tracked by the participants, which is placed either in the center of the screen or moving linearly between left and right screen margins. As a subjective measure for appearance attributes, anthropomorphism is used using the multi-component Human-Robot Interaction Evaluation Scale (HRIES). Significant differences are revealed in the sociability and agency sub-scales of HRIES with respect to eye-movement behaviors. The results show, that humans perceive robot appearance attributes differently depending on whether or not pursuit eye-movements are conducted supporting the main hypothesis. Further, for pursuit movements, the scale center is rated for these sub-scales, which may indicate, that the particular robot characteristic is perceived less distinctively. No significant interactions are found for animacy and disturbance, which may be due to less applicability of these sub-scales to static images. The findings may have an impact on close interaction between humans and robots and potential anthropomorphism-related influences on task accomplishment to be considered in interaction design.	https://doi.org/10.1109/ICRA46639.2022.9811763	Kolja Kühnlenz, Barbara Kühnlenz
Visual Representation Learning for Preference-Aware Path Planning.	Autonomous mobile robots deployed in outdoor environments must reason about different types of terrain for both safety (e.g., prefer dirt over mud) and deployer preferences (e.g., prefer dirt path over flower beds). Most existing solutions to this preference-aware path planning problem use semantic segmentation to classify terrain types from camera images, and then ascribe costs to each type. Unfortunately, there are three key limitations of such approaches - they 1) require preenumeration of the discrete terrain types, 2) are unable to handle hybrid terrain types (e.g., grassy dirt), and 3) require expensive labelled data to train visual semantic segmentation. We introduce Visual Representation Learning for Preference-Aware Path Planning (VRL-PAP), an alternative approach that overcomes all three limitations: VRL-PAP leverages un-labelled human demonstrations of navigation to autonomously generate triplets for learning visual representations of terrain that are viewpoint invariant and encode terrain types in a continuous representation space. The learned representations are then used along with the same unlabelled human navigation demonstrations to learn a mapping from the representation space to terrain costs. At run time, VRL-PAP maps from images to representations and then representations to costs to perform preference-aware path planning. We present empirical results from challenging outdoor settings that demonstrate VRL-PAP 1) is successfully able to pick paths that reflect demonstrated preferences, 2) is comparable in execution to geometric navigation with a highly detailed manually annotated map (without requiring such annotations), 3) is able to generalize to novel terrain types with minimal additional unlabeled demonstrations.	https://doi.org/10.1109/ICRA46639.2022.9811828	Kavan Singh Sikand, Sadegh Rabiee, Adam Uccello, Xuesu Xiao, Garrett Warnell, Joydeep Biswas
Visually Grounded Task and Motion Planning for Mobile Manipulation.	Task and motion planning (TAMP) algorithms aim to help robots achieve task-level goals, while maintaining motion-level feasibility. This paper focuses on TAMP domains that involve robot behaviors that take extended periods of time (e.g., long-distance navigation). In this paper, we develop a visual grounding approach to help robots probabilistically evaluate action feasibility, and introduce a TAMP algorithm, called GROP, that optimizes both feasibility and efficiency. We have collected a dataset that includes 96, 000 simulated trials of a robot conducting mobile manipulation tasks, and then used the dataset to learn to ground symbolic spatial relationships for action feasibility evaluation. Compared with competitive TAMP baselines, GROP exhibited a higher task-completion rate while maintaining lower or comparable action costs. In addition to these extensive experiments in simulation, GROP is fully implemented and tested on a real robot system.	https://doi.org/10.1109/ICRA46639.2022.9812055	Xiaohan Zhang, Yifeng Zhu, Yan Ding, Yuke Zhu, Peter Stone, Shiqi Zhang
Visually Grounding Language Instruction for History-Dependent Manipulation.	This paper emphasizes the importance of a robot's ability to refer to its task history, especially when it exe-cutes a series of pick-and-place manipulations by following language instructions given one by one. The advantage of referring to the manipulation history can be categorized into two folds: (1) the language instructions omitting details but using expressions referring to the past can be interpreted, and (2) the visual information of objects occluded by previous manipulations can be inferred. For this, we introduce a history-dependent manipulation task which objective is to visually ground a series of language instructions for proper pick-and-place manipulations by referring to the past. We also suggest a relevant dataset and model which can be a baseline, and show that our model trained with the proposed dataset can also be applied to the real world based on the CycleGAN. Our dataset and code are publicly available on the project website: https://sites.google.com/view/history-dependent-manipulation.	https://doi.org/10.1109/ICRA46639.2022.9812279	Hyemin Ahn, Obin Kwon, Kyungdo Kim, Jaeyeon Jeong, Howoong Jun, Hongjung Lee, Dongheui Lee, Songhwai Oh
Visuotactile-RL: Learning Multimodal Manipulation Policies with Deep Reinforcement Learning.	Manipulating objects with dexterity requires timely feedback that simultaneously leverages the senses of vision and touch. In this paper, we focus on the problem setting where both visual and tactile sensors provide pixel-level feedback for Visuotactile reinforcement learning agents. We investigate the challenges associated with multimodal learning and propose several improvements to existing RL methods; including tactile gating, tactile data augmentation, and visual degradation. When compared with visual-only and tactile-only baselines, our Visuotactile-RL agents showcase (1) significant improvements in contact-rich tasks; (2) improved robustness to visual changes (lighting/camera view) in the workspace; and (3) resilience to physical changes in the task environment (weight/friction of objects).	https://doi.org/10.1109/ICRA46639.2022.9812019	Johanna Hansen, Francois Robert Hogan, Dmitriy Rivkin, David Meger, Michael Jenkin, Gregory Dudek
Watch and Learn: Learning to control feedback linearizable systems from expert demonstrations.	"In this paper, we revisit the problem of learning a stabilizing controller from a finite number of demonstrations by an expert. By focusing on feedback linearizable systems, we show how to combine expert demonstrations into a stabilizing controller, provided that demonstrations are sufficiently long and there are at least n+1
of them, where n
is the number of states of the system being controlled. The results are experimentally demonstrated on a CrazyFlie 2.0 quadrotor."	https://doi.org/10.1109/ICRA46639.2022.9812054	Alimzhan Sultangazin, Luigi Pannocchi, Lucas Fraile, Paulo Tabuada
WeakLabel3D-Net: A Complete Framework for Real-Scene LiDAR Point Clouds Weakly Supervised Multi-Tasks Understanding.	Existing state-of-the-art 3D point clouds understanding methods only perform well in a fully supervised manner. To the best of our knowledge, there exists no unified framework which simultaneously solves the downstream high-level understanding tasks, especially when labels are extremely limited. This work presents a general and simple framework to tackle point clouds understanding when labels are limited. We propose a novel unsupervised region expansion based clustering method for generating clusters. More importantly, we innovatively propose to learn to merge the over-divided clusters based on the local low-level geometric property similarities and the learned high-level feature similarities supervised by weak labels. Hence, the true weak labels guide pseudo labels merging taking both geometric and semantic feature correlations into consideration. Finally, the self-supervised data augmentation optimization module is proposed to guide the propagation of labels among semantically similar points within a scene. Experimental Results demonstrate that our framework has the best performance among the three most important weakly supervised point clouds understanding tasks including semantic segmentation, instance segmentation, and object detection even when limited points are labeled.	https://doi.org/10.1109/ICRA46639.2022.9811959	Kangcheng Liu, Yuzhi Zhao, Zhi Gao, Ben M. Chen
Weakly Supervised Correspondence Learning.	Correspondence learning is a fundamental problem in robotics, which aims to learn a mapping between state, action pairs of agents of different dynamics or embodiments. However, current correspondence learning methods either leverage strictly paired data-which are often difficult to collect-or learn in an unsupervised fashion from unpaired data using regularization techniques such as cycle-consistency-which suffer from severe misalignment issues. We propose a weakly supervised correspondence learning approach that trades off between strong supervision over strictly paired data and unsupervised learning with a regularizer over unpaired data. Our idea is to leverage two types of weak supervision: i) temporal ordering of states and actions to reduce the compounding error, and ii) paired abstractions, instead of paired data, to alleviate the misalignment problem and learn a more accurate correspondence. The two types of weak supervision are easy to access in real-world applications, which simultaneously reduces the high cost of annotating strictly paired data and improves the quality of the learned correspondence. We show the videos of the experiments on our website.	https://doi.org/10.1109/ICRA46639.2022.9811729	Zihan Wang, Zhangjie Cao, Yilun Hao, Dorsa Sadigh
When Being Soft Makes You Tough: A Collision-Resilient Quadcopter Inspired by Arthropods' Exoskeletons.	Flying robots are usually rather delicate and require protective enclosures when facing the risk of collision, while high complexity and reduced payload are recurrent problems with collision-resilient flying robots. Inspired by arthropods' exoskeletons, we design a simple, open source, easily manufactured, semi-rigid structure with soft joints that can withstand high-velocity impacts. With an exoskeleton, the protective shell becomes part of the main robot structure, thereby minimizing its loss in payload capacity. Our design is simple to build and customize using cheap components (e.g. bamboo skewers) and consumer-grade 3D printers. The result is CogniFly, a sub-250 g autonomous quadcopter that survives multiple collisions at speeds up to 7 m s−1. In addition to its collision-resilience, CogniFly carries sensors that allow it to fly for approx. 17 min without the need of GPS or an external motion capture system, and it has enough computing power to run deep neural network models on-board. This structure becomes an ideal platform for high-risk activities, such as flying in a cluttered environment or reinforcement learning training, by dramatically reducing the risks of damaging its own hardware or the environment. Source code, 3D files, instructions and videos are available (open source license) through the project's website: https://thecognifly.github.io.	https://doi.org/10.1109/ICRA46639.2022.9811841	Ricardo de Azambuja, Hassan Fouad, Yann Bouteiller, Charles Sol, Giovanni Beltrame
Where to Look Next: Learning Viewpoint Recommendations for Informative Trajectory Planning.	Search missions require motion planning and navigation methods for information gathering that continuously replan based on new observations of the robot's surroundings. Current methods for information gathering, such as Monte Carlo Tree Search, are capable of reasoning over long horizons, but they are computationally expensive. An alternative for fast online execution is to train, offline, an information gathering policy, which indirectly reasons about the information value of new observations. However, these policies lack safety guarantees and do not account for the robot dynamics. To overcome these limitations we train an information-aware policy via deep reinforcement learning, that guides a receding-horizon trajectory optimization planner. In particular, the policy continuously recommends a reference viewpoint to the local planner, such that the resulting dynamically feasible and collision-free trajectories lead to observations that maximize the information gain and reduce the uncertainty about the environment. In simulation tests in previously unseen environments, our method consistently outperforms greedy next-best-view policies and achieves competitive performance compared to Monte Carlo Tree Search, in terms of information gains and coverage time, with a reduction in execution time by three orders of magnitude.	https://doi.org/10.1109/ICRA46639.2022.9812190	Max Lodel, Bruno Brito, Álvaro Serra-Gómez, Laura Ferranti, Robert Babuska, Javier Alonso-Mora
Whole-Body Control of Series-Parallel Hybrid Robots.	Parallel mechanisms are becoming increasingly popular as subsystems in various robots due to their superior stiffness, payload-to-weight ratio, and dynamic properties. The serial connection of parallel subsystems leads to series-parallel hybrid robots, which are more difficult to model and control than serial or tree-type systems. At the same time, Whole-Body Control (WBC) has become the method of choice in the control of robots with redundant degrees of freedom, e.g., legged robots. However, most state-of-the-art WBC frameworks can only deal with serial or tree-type robot topologies. In this paper, we describe a computationally efficient framework for Whole-Body Control of series-parallel hybrid robots subjected to a large number of holonomic constraints. In contrast to existing WBC frameworks, our approach describes the optimization problem in the actuation space of a series-parallel robot, which provides better exploitation of the feasible workspace, higher accuracy, and more transparent behavior near singularities. We evaluate the proposed framework on two different humanoids with series-parallel architecture and compare its performance to a WBC approach for tree-type robots.	https://doi.org/10.1109/ICRA46639.2022.9811616	Dennis Mronga, Shivesh Kumar, Frank Kirchner
Whole-Body MPC and Dynamic Occlusion Avoidance: A Maximum Likelihood Visibility Approach.	This paper introduces a novel approach for whole-body motion planning and dynamic occlusion avoidance. The proposed approach reformulates the visibility constraint as a likelihood maximization of visibility probability. In this formulation, we augment the primary cost function of a whole-body model predictive control scheme through a relaxed log barrier function yielding a relaxed log-likelihood maximization formulation of visibility probability. The visibility probability is computed through a probabilistic shadow field that quantifies point light source occlusions. We provide the necessary algorithms to obtain such a field for both 2D and 3D cases. We demonstrate 2D implementations of this field in simulation and 3D implementations through real-time hardware experiments. We show that due to the linear complexity of our shadow field algorithm to the map size, we can achieve high update rates, which facilitates onboard execution on mobile platforms with limited computational power. Lastly, we evaluate the performance of the proposed MPC reformulation in simulation for a quadrupedal mobile manipulator.	https://doi.org/10.1109/ICRA46639.2022.9811536	Ibrahim Ibrahim, Farbod Farshidian, Jan Preisig, Perry Franklin, Paolo Rocco, Marco Hutter
dSEDA: a Differential Series Elastic Damped Actuator.	Compliant actuation bestows robots with the ability to cope with unstructured environments, move with agility, and interact safely with humans at the expense of reduced tracking accuracy. The inclusion of dampening components aims to reduce oscillatory dynamics and partially restore precision without sacrificing the previously obtained characteristics. This paper introduces the concept and design of a novel damped compliant actuator suitable for building multi-degree of freedom systems. The proposed unit has a unique actuator topology that has never been seen before in the literature. The gearbox is used as a differential component, allowing the design of compact units without giving up safety and accuracy enhancements. We present and analyze the actuator's model and experimentally characterize the actuator prototype and the elastic and damping component.	https://doi.org/10.1109/ICRA46639.2022.9811727	Simone Monteleone, Francesca Negrello, Giorgio Grioli, Manuel G. Catalano
f-Cal: Aleatoric uncertainty quantification for robot perception via calibrated neural regression.	"While modern deep neural networks are performant perception modules, performance (accuracy) alone is insufficient, particularly for safety-critical robotic applications such as self-driving vehicles. Robot autonomy stacks also require these otherwise blackbox models to produce reliable and calibrated measures of confidence on their predictions. Existing approaches estimate uncertainty from these neural network perception stacks by modifying network architectures, inference procedure, or loss functions. However, in general, these methods lack calibration, meaning that the predictive uncertainties do not faithfully represent the true underlying uncertainties (process noise). Our key insight is that calibration is only achieved by imposing constraints across multiple examples, such as those in a mini-batch; as opposed to existing approaches which only impose constraints per-sample, often leading to overconfident (thus miscalibrated) uncertainty estimates. By enforcing the distribution of outputs of a neural network to resemble a target distribution by minimizing an f
-divergence, we obtain significantly better-calibrated models compared to prior approaches. Our approach, f-Cal, outperforms existing uncertainty calibration approaches on robot perception tasks such as object detection and monocular depth estimation over multiple real-world benchmarks."	https://doi.org/10.1109/ICRA46639.2022.9811903	Dhaivat Bhatt, Kaustubh Mani, Dishank Bansal, Krishna Murthy Jatavallabhula, Hanju Lee, Liam Paull
