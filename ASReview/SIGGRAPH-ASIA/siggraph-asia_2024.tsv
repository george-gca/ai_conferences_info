title	abstract	url	authors
'Colorblind Game' Can Enhances Awareness of Color Blindness	This study investigates whether awareness of color blindness can be enhanced through . We conducted two user studies—one with undergraduates and one with working adults—using 'colorblind' color schemes in a digital game to explore whether such an experience enhances their assessment of their own knowledge about color blindness and awareness of its associated disadvantages in society, workplaces, and private life. The results with undergraduates showed increases in general, but not much in workplace disadvantages. In contrast, the results with working adults showed a significant improvement in the assessment of knowledge but not in other aspects. Thus, a virtual colorblind gaming experience can enhance awareness of color blindness, yet the interpretation of the experience may vary significantly depending on the players' backgrounds.	https://dl.acm.org/doi/abs/10.1145/3681756.3697945	Taiju Kimura, Hiroki Nishino
3D Human Pose Estimation Using Ultra-low Resolution Thermal Images	Can we estimate 3D human pose from ultra-low resolution thermal images (e.g., 8 × 8 pixels)? This study explores this possibility. Thermal images capture radiation intensity, minimizing personal information exposure, and are commonly used in devices like air conditioners. We propose a framework that uses 8 × 8 thermal images for 3D human pose estimation, enhancing privacy and efficiency. To overcome challenges from subject and ambient temperature variations, we employ adversarial learning with discriminators for subject and temperature, ensuring robust and invariant feature extraction.	https://dl.acm.org/doi/abs/10.1145/3681756.3697916	Tatsuki Arai, Mariko Isogawa, Kuniharu Sakurada, Maki Sugimoto
3D Reconstruction of a Soft Object Surface and Contact Areas in Hand-Object Interactions	In Hand-Object Interactions (HOIs), contact information between the hand and the object can be utilized to estimate the area of deformation area and to improve the relative position of the hand and the object. However, mapping contact information to unknown and deformable objects is still challenging due to their shape transformation. In this study, we present a preliminary attempt to reconstruct the surface of a soft object and identify the contact area on that surface in HOIs. By using our system composed of multiple RGB cameras and a single thermal camera, our proposed method successfully visualizes the areas on the object's surface.	https://dl.acm.org/doi/abs/10.1145/3681756.3697895	Kohei Miura, Daisuke Iwai, Kosuke Sato
3D Scene Reconstruction of Point Cloud Data: A Lightweight Procedural Approach	In this paper, we present an approach that takes point cloud data of a scene and automatically produces a lightweight 3D reconstruction of the buildings and their facade details found in the scene. Our 3D reconstructions are described using a procedural grammar to allow for light-weight storage and processing, as well as scalability. The preliminary evaluation of our approach considers the terrestrial laser scan dataset semantic3d.net that includes a wide range of outdoor scenes and feature considerably variety in terms of the density of the point clouds. Our results show that our approach is able to extract most of the buildings and correctly detect most of the facade openings.	https://dl.acm.org/doi/abs/10.1145/3681756.3697934	Vivica Wirth, Max Mühlhäuser, Alejandro Sanchez Guinea
3D Texture Representation in Projection Mapping onto a Surface with Micro-Vibration	In projection mapping, it is not possible to adequately represent fine, three-dimensional surface textures such as fur. To solve this problem, we propose a method to add minute high-speed vibrations in the depth direction to the projection target and to project images at high speed synchronized with the depth position of the projection target at each instant. In this paper, we report on the proposed method and its projection results.	https://dl.acm.org/doi/abs/10.1145/3681756.3697944	Hayase Nishi, Daisuke Iwai, Kosuke Sato
3D-to-2D Animation Smear Effect Technique Based on Japanese Hand-Drawn Animation Style	"Smear effects are a visualization of 2D motion blur. In Japanese animation, because each keyframe of fast-moving objects might remain on the screen for more than one frame, significant differences often appear between consecutive frames, resulting in a choppy effect. To eliminate this, smear effects play an important role. In Japanese hand-drawn animation, this technique creates jagged outlines at the edges of fast-moving objects. This not only eliminates the choppy effect but also emphasizes the intensity and speed of the object's movement. The proposed method is specifically designed to accommodate the common hand-drawn technique of ""Animating on Ones, Twos, and Threes"" [Ryan ], which often appears alongside the smear effect. Our method is based on skeletal animation techniques, combined with a hierarchical processing mechanism to displace model vertices. Unlike other methods that only displace vertices in a specific direction, our method includes a bending mechanism to represent curved motion trajectories. Additionally, our method allows users to freely choose which vertices in the model to apply the effects to. Finally, the deformed model is rendered from 3D to 2D, achieving this Japanese animation-style smear effect."	https://dl.acm.org/doi/abs/10.1145/3681756.3697891	Shu-Ting Lin, Ming-Te Chi
A Collaborative Multimodal XR Physical Design Environment	Traditional design processes for physical prototypes can be time-consuming and costly due to iterations of prototyping, testing, and refinement. Extended Reality (XR) technology with video passthrough offers unique benefits for alleviating these issues by providing instant visual feedback. We have developed an XR system with multimodal input capability that provides annotations and enables interactive visual modifications by superimposing and aligning visual counterparts to physical objects. This system can help designers to quickly experiment with and visualize a wide range of design options, keep track of design iterations, and explore innovative solutions without the constraints of physical prototyping. As a result, it can significantly speed up the iterative design process, while requiring fewer physical modifications in each iteration.	https://dl.acm.org/doi/abs/10.1145/3681759.3688914	Keru Wang, Pincun Liu, Yushen Hu, Xiaoan Liu, Zhu Wang, Ken Perlin
A Lava Well of Reflexivity: Exploring Speculative Ambient Media	This work explores the idea of speculative ambient media, which integrates reflexive and speculative elements into environmental objects. Unlike traditional ambient media that provides background information, speculative ambient media subtly promotes reflexivity on societal and environmental issues. Through the case, we illustrate how such media might inspire contemplation without being intrusive. The installation features slow-changing projections from plastic waste to implicate and raise environmental awareness and challenge perceptions of human impact on nature. Speculative ambient media enhances environmental consciousness and fosters dialogue. Future research will investigate its application in various contexts to further assess its potential for stimulating discussion and reflection.	https://dl.acm.org/doi/abs/10.1145/3681756.3697889	Ting Han Daniel Chen
A Multi-flash Stereo Camera for Photo-realistic Capture of Small Scenes	Synthesizing accurate geometry and photo-realistic appearance of small scenes is an active area of research with compelling use cases in gaming, content creation, virtual reality, and robotics. When applying scene geometry and appearance estimation techniques to robotics, we found that the narrow cone of possible viewpoints due to the limited range of robot motion and scene clutter caused current estimation techniques to produce poor quality estimates or even fail. On the other hand, in robotic applications, dense metric depth can often be measured directly using robot mounted stereo cameras and light and camera positions can be accurately controlled. Depth can provide a good initial estimate of the object geometry to improve reconstruction, while multi-illumination images can help recover appearance to facilitate relighting. In this work we demonstrate a robot-mountable multi-flash stereo camera system developed in-house to capture the necessary data for synthesizing relightable assets from small scenes with a few training views.	https://dl.acm.org/doi/abs/10.1145/3681758.3698018	Arkadeep Narayan Chaudhury, Igor Vasiljevic, Sergey Zakharov, Vitor Guizilini, Rares Ambrus, Srinivasa Narasimhan, Christopher G. Atkeson
A Multimodal LLM-based Assistant for User-Centric Interactive Machine Learning	This paper proposes a system based on a multimodal large language model (MLLM) to assist non-expert users without prior experience in machine learning (ML) development. The MLLM assistant in our system interactively helps users compile their requirements and create appropriate training data while building an ML model. It has been reported that users often struggle to define training data that comprehensively covers all samples or aligns with their needs. To prevent such failures, the MLLM assistant monitors the user's interaction process and translates users' vague needs into concrete ML formulations through chat, ultimately facilitating the creation of appropriate training data.	https://dl.acm.org/doi/abs/10.1145/3681756.3697880	Wataru Kawabe, Yusuke Sugano
A Novel Projection Screen using the Crystalline Film of a Frozen Soap Bubble	This study proposes a novel screen that focuses on the freezing phenomenon of soap films. Although soap films are thin and transparent, in low-temperature environments, beautiful ice crystals form on the surface, reducing transparency and enabling image projection onto the film. This study explores the application of soap films as multi-layered projection screens that leverage the aesthetic qualities of the freezing process, and discusses potential expansion technologies. We also explore the possibility of applying frozen soap films as a novel screen.	https://dl.acm.org/doi/abs/10.1145/3681756.3697978	Shinichiro Terasawa, Oki Hasegawa, Toshiki Sato
A Practical Style Transfer Pipeline for 3D Animation: Insights from Production R&D	Our animation studio has developed a practical pipeline for creating stylized 3D animation, which is suitable for complex real-world production. This paper presents the insights from our development process, where we explored various options to balance quality, artist control, and workload, leading to several key decisions. For example, we chose patch-based texture synthesis over machine learning for better control and to avoid training data issues. We also addressed specifying style exemplars, managing multiple colors within a scene, controlling outlines and shadows, and reducing temporal noise. These insights were used to further refine our pipeline, ultimately enabling us to produce an experimental short film showcasing various styles.	https://dl.acm.org/doi/abs/10.1145/3681758.3698000	Hideki Todo, Yuki Koyama, Kunihiro Sakai, Akihiro Komiya, Jun Kato
A Relighting Method for Single Terrain Image based on Two-stage Albedo Estimation Model	This paper proposes a method for relighting a single terrain image to match user-specified times of day or weather conditions by estimating albedo and depth using deep learning. By employing a two-stage network to remove fog and lighting effects, our method enables accurate albedo estimation even for terrain images containing fog, which has been difficult for previous methods. We validate the effectiveness of our approach by demonstrating several examples and comparisons with an existing method.	https://dl.acm.org/doi/abs/10.1145/3681756.3697886	Shun Tatsukawa, Syuhei Sato
A Sentient Space Using Light Sensing with Particle Life	In interactive environments, the notion of space as a cognitive entity with the ability to autonomously perceive and explore its surroundings has yet to be fully developed. This paper presents a lightweight real-time interactive projection system that utilizes Particle Life algorithms and grid computing to enable spatial awareness and understanding of the internal environment, allowing for immediate projection adjustments in response to changes. The results show that interactive environments created by light as an information medium possess flexibility and broad application potential.	https://dl.acm.org/doi/abs/10.1145/3681756.3697898	Pan-Pan Shiung, June-Hao Hou
A Study of 3D Character Control Methods_Keyboard, Speech, Hand Gesture, and Mixed Interfaces	One popular form of a tele-presence guidance VR/MR system features local trainees utilizing immersive interfaces (such as headset and controllers), while the remote trainer employs the desktop interface, for the sake of familiarity, efficiency and convenience, to control the presence and actions of one's avatar in the third person perspective. Nowadays, the desktop (or non-VR) interfaces may extend from the mere keyboard/mouse to include speech and upper body/arm/hand gestures as well. Given this, however, it is not clear whether there exist any guideline in terms of what kind of interfaces might offer the best usability for effective avatar control. This poster presents a pilot study investigating such a problem with regards to using the keyboard, speech, and hand gestures (and properly mixing them) for a MR-based military training environment where the user controlled a squad leader character for making tactical signals to following squad members. Results indicated that appropriately mixing the interfaces by the characteristics of the subtask produced the highest usability and preference, reduced world load, and even the sense of embodiment with their avatar.	https://dl.acm.org/doi/abs/10.1145/3681756.3697868	JunSeo Park, Hanseob Kim, Gerard Jounghyun Kim
A Theory of Stabilization by Skull Carving	Accurate stabilization of facial motion is essential for applications in photoreal avatar construction for 3D games, virtual reality, movies, and training data collection. For the latter, stabilization must work automatically for the general population with people of varying morphology. Distinguishing rigid skull motion from facial expressions is critical since misalignment between skull motion and facial expressions can lead to animation models that are hard to control and can not fit natural motion. Existing methods struggle to work with sparse sets of very different expressions, such as when combining multiple units from the Facial Action Coding System (FACS). Certain approaches are not robust enough, some depend on motion data to find stable points, while others make one-for-all invalid physiological assumptions. In this paper, we leverage recent advances in neural signed distance fields and differentiable isosurface meshing to compute skull stabilization rigid transforms directly on unstructured triangle meshes or point clouds, significantly enhancing accuracy and robustness. We introduce the concept of a stable hull as the surface of the boolean intersection of stabilized scans, analogous to the visual hull in shape-from-silhouette and the photo hull from space carving. This hull resembles a skull overlaid with minimal soft tissue thickness, upper teeth are automatically included. Our skull carving algorithm simultaneously optimizes the stable hull shape and rigid transforms to get accurate stabilization of complex expressions for large diverse sets of people, outperforming existing methods.	https://dl.acm.org/doi/abs/10.1145/3681758.3697982	Mathieu Lamarre, Patrick Anderson, Étienne Danvoye
A Vocal Landscape	In A Vocal Landscape our aim has been to create a VR experience that feels familiar and relatable—both visually and in the way the story's narrative unfolds. Our approach in storytelling has been minimalistic, instead of using big theatrical dialogues or trying to save the world with a VR film. Instead, we focus on a more niche and complex subject matter: human communication. We have kept the dialogue naturalistic and sounding like everyday words— something we rarely see in VR, and the story has a simple structure: it's a late-night conversation between two people and each person's association arising from what's said and what's heard.	https://dl.acm.org/doi/abs/10.1145/3681759.3688910	Omid Zarei, Anne Jeppesen
ARAP-Based Shape Editing to Manipulate the Center of Mass	We propose an algorithm to align the center of mass of an input shape to a prescribed point. Unlike previous approaches that rely on hollowing the inner structure, our method deforms the outer shape by incorporating As-Rigid-As-Possible (ARAP) energy. Our method provides two editing modes: one prioritizing speed and the other focusing on accuracy. Combining these two modes, users can interactively explore the design space of shapes while achieving the desired center of mass positioning.	https://dl.acm.org/doi/abs/10.1145/3681756.3697901	Shunsuke Hirata, Yuta Noma, Koya Narumi, Yoshihiro Kawahara
Affective Wings: Exploring Affectionate Behaviors in Close-Proximity Interactions with Soft Floating Robots	"This study presents ""Affective Wings,"" a concept involving a soft floating robot designed to enable proximal interactions and direct physical contact with humans to support emotional connection in an indoor environment. Leveraging the capabilities of lighter-than-air robots combined with a controllable wing mechanism, we provide a novel approach to human-robot interaction prioritizing safety and rich dynamic movements. The robot, designed to fly freely within human living spaces, can engage in both physical contact and non-physical contact behaviors, such as hugging, tapping, perching, mimicking, and waving."	https://dl.acm.org/doi/abs/10.1145/3681756.3697951	Mingyang Xu, Yulan Ju, Yunkai Qi, Xiaru Meng, Qing Zhang, Matthias Hoppe, Kouta Minamizawa, Giulia Barbareschi, Kai Kunze
Alive Yi: Interactive Preservation of Yi Minority Embroidery Patterns through Digital Innovation	"By integrating heritage, design, and technology, ""Alive Yi"" innovatively empowers intangible cultural heritage through interactive generative design. Using our extensive pattern database, we visualize traditional Yi minority embroidery by applying particle and 3D effects in TouchDesigner with Leap Motion, emphasizing their symbolic meanings. This interactivity allows users to transform heritage visuals in real-time, fostering deeper engagement and appreciation. Future plans include using AI tools to create designs appealing to youth. Despite technical challenges, this approach promises cultural resilience in the digital age, offering a blueprint for leveraging computational creativity to preserve and sustain intangible culture."	https://dl.acm.org/doi/abs/10.1145/3681756.3697919	Zhiwei Wang, Yuzhe Xia, Kexin Nie, Mengyao Guo
An Augmented Reality Experience for Climate Justice: Using Spatial Animation to Enhance Perceived Togetherness	This project focuses on designing an Augmented Reality (AR) application for climate justice communication. It examines ways to use spatial graphics/animation/sound for multi-user simulations with strategies regarding economic and environmental conflicts.	https://dl.acm.org/doi/abs/10.1145/3681756.3697964	Ching-Hua Chuan, Wan-Hsiu Tsai, Xueer Xia
An Efficient and Smooth Volume Shell Mapping by Nonlinear Ray Traversal of Hierarchical Structures	Shell mapping is a method of representing microstructures on surfaces by mapping a three-dimensional texture space bijectively into a shell space. This paper introduces a volumetric texture to the texture space for the purpose of representing implicit surfaces and translucent materials. However, conventional approaches often generate artifacts at the boundaries of neighboring tetrahedra due to piecewise-linear approximate mapping. To achieve smooth mapping, we present an approach of mapping rays nonlinearly into the texture space, and we also address efficient sampling by using hierarchical volumetric textures.	https://dl.acm.org/doi/abs/10.1145/3681758.3697994	Mayuka Kuwana, Issei Fujishiro
An Empirical Analysis of GPT-4V's Performance on Fashion Aesthetic Evaluation	Fashion aesthetic evaluation is the task of estimating how well the outfits worn by individuals in images suit them. In this work, we examine the zero-shot performance of GPT-4V on this task for the first time. We show that its predictions align fairly well with human judgments on our datasets, and also find that it struggles with ranking outfits in similar colors. The code is available at https://github.com/st-tech/gpt4v-fashion-aesthetic-evaluation.	https://dl.acm.org/doi/abs/10.1145/3681758.3698022	Yuki Hirakawa, Takashi Wada, Kazuya Morishita, Ryotaro Shimizu, Takuya Furusawa, Sai Htaung Kham, Yuki Saito
An Evaluation Metric for Single Image-to-3D Models Based on Object Detection Perspective	"In this paper, we propose a novel evaluation metric for ""single image-to-3D"" models based on object detection perspective. Unlike conventional metrics that require the original 3D model or a lot of multi-view images of the model as reference, the proposed metric allows evaluations of the ""single image-to-3D"" models with just one input image. The proposed evaluation metric can be calculated by comparing the object detection results of the input image and novel-view images rendered from the generated object. Therefore, this metric enables evaluations that consider semantic information and focus especially on objects in the rendered images. The proposed evaluation metric is validated by the rank correlation coefficient between the order of its values and the order of the ""single image-to-3D"" models' publication dates. The experimental results show that our proposed metric enables semantically accurate evaluations using only one input image. The code of this work is available at https://github.com/EvalSingleImg23D/EvalSingleImg23D."	https://dl.acm.org/doi/abs/10.1145/3681758.3697992	Yuiko Uchida, Ren Togo, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama
An Exploratory Study on Fabricating of Unobtrusive Edible Tags	Previous work in Human-Food Interaction has investigated how to embed tags into food. One promising approach involves controlling the internal structure using food 3D printers. However, this method is not widely accessible due to the current limitations of food 3D printers. This paper explores alternative fabrication techniques, molding and stamping, for embedding unobtrusive tags inside foods. Our preliminary evaluations showed that the proposed methods can embed tags and have the potential to employ a wide range of materials with lower costs compared with the food 3D printing technique. These findings suggest that low-cost edible tagging technologies could become more accessible and versatile.	https://dl.acm.org/doi/abs/10.1145/3681756.3697910	Yamato Miyatake, Parinya Punpongsanon
An immersive interface for remote collaboration with multiple telepresence robots through digital twin spaces	"A human-robot collaboration system ""Telecobot"" is proposed, in which a remote user allocates tasks to multiple telepresence robots via digital twin spaces. The digital twin spaces of local sites where robots work is used as a medium to observe the real spaces from a remote site and to give instructions to the smart robots on the local site. Telecobot supports a remote user understanding the real-time status of local sites distributed geographically and allocating tasks to each of the robots. We assume that the robots are smart enough to execute the series of tasks assigned by the remote user. This division of roles is a major characteristic of Telecobot, where a remote user is responsible for judging the situation and building a series of tasks via the digital twin space, while multiple robots working in each of the local sites executes the individual tasks following the information built by the remote user in the digital twins of the local sites. An experiment assuming telecollaboration with smart robots working at nursing care sites demonstrated the division of roles for the care works and showed the potential of increasing the productivity of the work by using the Telecobot interface."	https://dl.acm.org/doi/abs/10.1145/3681756.3697940	Sawa Yoshioka, Shinichi Fukushige, Kohta Seki, Mizuki Kawakami
Analyzing and Visualizing the Correlation between Ecosystems and Environmental Sustainability : Focusing on Search API Data	This study aims to analyze public awareness of environmental sustainability, particularly focusing on the ecological importance of bees and their impact on human food production. Real-time search query data were collected and analyzed to identify trends related to bees and environmental keywords. Artificial intelligence techniques and data visualization methods were employed to create new forms of media art. The results of the study emphasize the importance of bees and can be used as a tool to promote a shift in public awareness regarding environmental issues.	https://dl.acm.org/doi/abs/10.1145/3681756.3697876	JungIn Lee, ChanKeun Park, Sooyeon Lim
AnimateLCM: Computation-Efficient Personalized Style Video Generation without Personalized Video Data	This paper introduces an effective method for computation-efficient personalized style video generation without requiring access to any personalized video data. The method's effectiveness lies in its dual-level decoupling learning approach: 1) separating the learning of video style from video generation acceleration, which allows for personalized style video generation without any personalized style video data, and 2) separating the acceleration of image generation from the acceleration of video motion generation, enhancing training efficiency and mitigating the negative effects of low-quality video data.	https://dl.acm.org/doi/abs/10.1145/3681758.3698013	Fu-Yun Wang, Zhaoyang Huang, Weikang Bian, Xiaoyu Shi, Keqiang Sun, Guanglu Song, Yu Liu, Hongsheng Li
Anime line art colorization by region matching using region shape	The coloring process in anime (Japanese animation) production constitutes a critical yet time-consuming aspect of creating animated works. This study introduces a colorization system for anime line art using a reference image. The proposed system colors line art based on the features of corresponding regions in the reference image, significantly reducing the time required for the coloring task.	https://dl.acm.org/doi/abs/10.1145/3681756.3697958	Daisuke Nanya, Kouki Yonezawa
Auditory AR System to Induce Pseudo-Haptic Force Feedback for Lateral Hand Movements Using Spatially Localized Sound Stimuli	This proposal presents a pseudo-force feedback design based on spatially localized sound, tailored for the visually impaired. Sound location is adjusted to create an auditory conflict between the perceived hand position in virtual space and its actual position in the real world, thus inducing a force sensation. Two water-stream test scenarios were crafted in an Augmented Reality application built with MediaPipe for hand tracking and OpenAL for sound rendering.	https://dl.acm.org/doi/abs/10.1145/3681756.3697955	Daniel Oswaldo Lopez Tassara, Naoto Wakatsuki, Keiichi Zempo
Authentic Self XR: A live dancer interacting with 3D volumetric captures in XR	This live performance piece explores a dancers interaction with her 3D captured virtual self. The arts-led work investigates notions of authenticity by combine multiple pre-captured 3D volumetric videos and live performance. Using an interactive XR rig and movment generate sound the dancer eventually erases all 3D volumetric representations of self.	https://dl.acm.org/doi/abs/10.1145/3681757.3697046	John McGhee, Conan Bourke, Robert Lawther, Oliver Bown, Charlie Wrublewski
Automatic Generation of Multimodal 4D Effects for Immersive Video Watching Experiences	The recent trend of watching content using over-the-top (OTT) services pushes the 4D movie industry to seek a way of transformation. To address the issue, this paper suggests an AI-driven automatic 4D effects generation algorithm applied to a low-cost comfort chair. The system extracts multiple features using psychoacoustic analysis, saliency detection, optical flow, and an LLM-based thermal effect synthesis, and maps them into various sensory displays such as vibration, heat, wind, and poking automatically. To evaluate the system, a user study with 21 participants across seven film genres was conducted. The results showed that 1) there was a general improvement with 4D effects in terms of immersion, concentration, and expressiveness, and 2) multisensory effects were particularly useful in action and fantasy movie scenes. The suggested system could be directly used in current general video-on-demand services.	https://dl.acm.org/doi/abs/10.1145/3681758.3698021	Seoyong Nam, Minho Chung, Haerim Kim, Eunchae Kim, Taehyeon Kim, Yongjae Yoo
Automotive Holographic Head-Up Display	This paper presents an advanced automotive holographic head-up display (HUD) system for providing three-dimensional holograms, extended virtual image distance (>10m), large field of view (>15 degrees), and wide monocular eye-box (>2cm) without distortion and optical aberrations. Our approach ensures high-quality holographic image projection and comfortable viewing, providing a practical solution for next-generation automotive HUDs.	https://dl.acm.org/doi/abs/10.1145/3681756.3697899	Jinsu Lee, Keehoon Hong, Minsik Park
BEAM: Interactive Music Effects Playground	BEAM brings 3D graphics and interactivity to the world of music-making. BEAM is a real-time audio effects plugin made by Lunacy Inc, which runs inside any digital audio workstation, like Ableton, Logic, and Pro Tools. It lets music producers craft complex chains of audio effects by manipulating a rich, audio-reactive scene of 3D objects. Users feed a sound source into BEAM, which is visualized as an audio-reactive beam of light. Audio effects can be dragged onto the beam to alter the sound, and each effect is visualized with an object that procedurally changes its appearance based on the effect parameters. The audio signal can be split into multiple parallel paths to allow flexible routing and control.	https://dl.acm.org/doi/abs/10.1145/3681757.3697049	Brandon Montell, Casey Kolb
Boundary Conditioned Floor Layout Generation with Diffusion Model	Automated floor plan generation that aligns with exterior wall boundaries is crucial in architectural design. Existing methods using GANs lack accuracy and require raster-to-vector conversion. Our study employs Diffusion Models and Transformers, incorporating self-attention mechanisms between exterior wall coordinates and room corners. This approach effectively generates diverse, accurate floor plans in vector format conditioned on exterior boundaries, addressing key challenges unmet by previous methods.	https://dl.acm.org/doi/abs/10.1145/3681756.3697884	Yusuke Takeuchi, Qi An, Atsushi Yamashita
Boundary Conditions of the Third Kind: Generalized Sources and Sinks in Fluid Simulations	Fluid simulations use Dirichlet or Neumann boundary conditions to create free surfaces, colliders, source, and sinks. There is, however, a third condition: the Robin boundary condition. Considered relevant only for heat or electromagnetic problems, we found it provides a consistent framework to replace the binary choice of Dirichlet or Neumann with a continuum. Blending these conditions enables the simulation of real-world fluid behaviours otherwise not achievable.	https://dl.acm.org/doi/abs/10.1145/3681758.3697988	Jeff Lait, Omar Zarifi, Tomáš Skřivan
CAR: Collision-Avoidance Retargeting for Varied Skeletal Architectures	Motion retargeting is essential for digital human and animation applications, typically demands strict skeletal structure adherence, often simplifying Mixamo-based skeletons to focus on action semantics rather than geometric differences. This paper introduces Collision-Avoidance Retargeting(CAR) method that does not rely on data-driven approaches and can be applicable to different skeleton architectures in cold start situations, ensuring the integrity of the drivable skeleton of the target character and reducing the occurrence of mesh interpenetrations due to shape geometric differences. The method has two stages. Stage one aligns bone chains and transforms motions with matrix operations. Stage two uses geometric data to refine joint rotations, preventing collisions and preserving action accuracy. CAR outperforms existing methods, as shown in extensive experiments, in both quantitative metrics and qualitative assessments.	https://dl.acm.org/doi/abs/10.1145/3681758.3698007	Yu Cao, MingHui Yang
Can GPTs Evaluate Graphic Design Based on Design Principles?	Recent advancements in foundation models show promising capability in graphic design generation. Several studies have started employing Large Multimodal Models (LMMs) to evaluate graphic designs, assuming that LMMs can properly assess their quality, but it is unclear if the evaluation is reliable. One way to evaluate the quality of graphic design is to assess whether the design adheres to fundamental graphic design principles, which are the designer's common practice. In this paper, we compare the behavior of GPT-based evaluation and heuristic evaluation based on design principles using human annotations collected from 60 subjects. Our experiments reveal that, while GPTs cannot distinguish small details, they have a reasonably good correlation with human annotation and exhibit a similar tendency to heuristic metrics based on design principles, suggesting that they are indeed capable of assessing the quality of graphic design. Our dataset is available at: https://cyberagentailab.github.io/Graphic-design-evaluation/.	https://dl.acm.org/doi/abs/10.1145/3681758.3698010	Daichi Haraguchi, Naoto Inoue, Wataru Shimoda, Hayato Mitani, Seiichi Uchida, Kota Yamaguchi
Capturing Light with Robots: A Novel Workflow for Reproducing Realistic Lens Flares	Lens flares are a common optical artifact in photography and filmmaking caused by reflections and scattering of light within a camera system. The task of creating lens flares is usually solved with 2D approaches or simulation. This research compares two alternative methods of reproducing lens flares for a production-ready compositing workflow: traditional image processing and machine learning techniques. To create the dataset, a novel approach to capturing lens flares in a grid-like manner is explored. By systematically varying the position of a light source with a motion control system, flare patterns for a diverse set of lenses are captured.	https://dl.acm.org/doi/abs/10.1145/3681758.3697995	Vincent Maurer
ChoreoSurf: Scalable Surface System with 8-DOF SMA Actuators	The ChoreoSurf system is a scalable surface system with a shape-memory alloy actuator that can bend in eight directions. This system can mount actuators on the surface layers of various three-dimensional shapes. Applications include a tabletop system, interactive wall, tentacles tower, kinetic dress, and kinetic wig.	https://dl.acm.org/doi/abs/10.1145/3681756.3697869	Akira Nakayasu
Controlling Cross-Content Motion Style Transfer via Statistical Style Difference	Decomposing human body motion content (such as walking, jumping, punching) and style (such as angry, old, proud) is a challenging task in style transfer, often causing unrealistic content-style combinations. This study demonstrates a straightforward method obtaining statistical style differences ( ) which in turn effectively replace original style from a motion content to another target style. The strength of transferred style is adjusted using a predefined parameter of our model. Experimental results show that proposed significantly improves style transfer quality particularly in cross-content scenarios.	https://dl.acm.org/doi/abs/10.1145/3681756.3697968	Usfita Kiftiyani, Seungkyu Lee
Controlling Diversity in Single-shot Motion Synthesis	We consider the task of controllable and diverse motion synthesis from a single sequence as an alternative to the data-dependent text-to-motion methods, which pose ambiguities in data ownership and privacy. Recent works in hierarchical single-shot synthesis have paved the path for unconditional generation and editing tools, however the methods that focus on 3D animation have failed to control the diversity of the generated motions. In this paper we propose the integration of the variational inference in single-shot GANs, aiming to encode and control the low-frequency generating factors of the single motion sample. Our experiment showcases the ability of our VAE-GAN model to control the diversity of its generations, while preserving their plausibility and quality.	https://dl.acm.org/doi/abs/10.1145/3681756.3697909	Eleni Tselepi, Spyridon Thermos, Georgios Albanis, Anargyros Chatzitofis
Curtain UI: Augmenting Curtains for Tangible Interactions	Curtains are functional textiles that play a crucial yet invisible role in our daily lives. Despite their widespread use for decoration, blocking heat, privacy, etc., they are still passive in our surroundings. This paper presents a design exploration and development of an interactive curtain interface using capacitive sensing. We augment the capabilities of everyday curtains into touch-sensitive surfaces to facilitate embodied interactions through physical manipulation and gestures. By interfacing these curtains with a smart home environment to control lights, fans, and other appliances, we show that interactive curtains are technically feasible, thus paving the way for novel Curtain UIs as a medium of tangible, embodied, and embedded interaction in a ubiquitous computing scenario.	https://dl.acm.org/doi/abs/10.1145/3681756.3697935	Pranshu Anand, Vishal Bharti, Anmol Srivastava
Debate Generation System in Japanese Rap Battle Format	"We propose a ""Debate System in Japanese Rap Battle Format."" Our goal is to elevate discussions into entertainment, encouraging people of all generations to form their own opinions. This system generates two distinct opinions (lyrics) when presented with a discussion topic, and based on these opinions, agents engage in a debate in the form of a rap battle. The system's technical composition incorporates several innovative elements: (1) Lyric (Opinion) Generation: The system creates lyrics that represent opinions on the given topic. A unique feature of this process is its consideration of rhymes specific to the Japanese language. This ensures that the generated content not only conveys meaningful opinions but also adheres to the rhythmic and phonetic patterns characteristic of Japanese rap. (2) Contextual Awareness: The system is designed to understand and maintain the context of the ongoing debate. This contextual awareness enables coherent and relevant exchanges between the agents, simulating the flow of a real debate or conversation. (3) Responsive Utterances: Building on its contextual awareness, the system generates responses that directly address the opponent's previous statements. This feature creates a dynamic, interactive debate environment, where each agent's contribution is influenced by and responds to the other's arguments. (4) Beat-Adaptive Audio Synthesis: To enhance the rap battle experience, the system incorporates audio synthesis that adapts to the underlying beat. This synchronization between the generated lyrics and the musical rhythm results in a more authentic and engaging rap performance. (5) Integration into Audio-Visual Performance: All these elements---generated lyrics, contextual responses, and beatsyn-chronized audio---are combined to create a comprehensive audio-visual performance. This integration transforms the debate from a mere exchange of words into an entertaining and immersive experience. The culmination of these technical components results in a unique performance where complex debates are conducted through the medium of a Japanese rap battle, offering an innovative blend of technology, language, and music."	https://dl.acm.org/doi/abs/10.1145/3681757.3697050	Ryota Mibayashi, Toru Urakawa, Dai Takanashi, Tomoya Morohoshi, Kanata Yamagishi, Ryuho Sekikawa, Yasuhiko Nishimura, Yuta Takeuchi, Mina Shibasaki, Hideaki Tamori, Takehiro Yamamoto, Hiroaki Ohshima
Design of Wall Art Utilizing Dynamic Color Changes through Photoelasticity	This research proposes a dynamic wall art piece that utilizes color changes through photoelasticity. To achieve this effect, we have developed a device that stretches a single sheet of gel material from multiple points. This device allows for gentle, organic color transitions that cannot be replicated by pixel-based displays like LCDs, offering a unique aesthetic experience as wall art.	https://dl.acm.org/doi/abs/10.1145/3681756.3697902	Ryota Nakayama, Soshi Takeda, Gakuto Sekine, Yuichiro Katsumoto
Designing LLM Response Layouts for XR Workspaces in Vehicles	This study investigates the design of response layouts for large language models in XR environments for vehicle settings. Our formative study identified usability challenges with the current linear layout, such as difficulties in extensive scrolling and mid-air interactions. Based on these findings, we designed an improved layout that utilizes multiple windows for efficient access to diverse content, with a cohesive placement to minimize motion sickness. A user study with 24 participants compared the proposed interface against a conventional web browser interface through various information-seeking tasks. The results demonstrated that the proposed interface enhanced overall usability compared to the baseline.	https://dl.acm.org/doi/abs/10.1145/3681756.3697877	Daun Kim, Jin-Woo Jeong
Designing Reconfigurable Joints	We propose a method to create reconfigurable joints, where reconfigurability entails that a set of components can be connected in multiple ways. The advantage of this type of joint is the possibility of efficiently reusing limited components for multiple purposes. In established carpentry practices, a popular reconfigurable joint geometry called has two components that can be reconfigured in different orthogonal angles. However, the general geometric requirements for the design of reconfigurable joints have not been defined previously. We clarify the conditions for reconfigurable joints from the perspective of symmetry-based geometry repetition and provide guidelines for constructing multi-component joints and for ensuring stability. Moreover, we present a system that assists in the design of voxel-based reconfigurable joints and use it to fabricate several stable reconfigurable joints.	https://dl.acm.org/doi/abs/10.1145/3681758.3698006	Atsushi Maruyama, Maria Larsson, I-Chao Shen, Takeo Igarashi
Designing a Usable Framework for Diverse Users in Synthetic Human Action Data Generation	This paper introduces SynthDa2, a synthetic data generation framework aimed at addressing data scarcity for training video-based machine learning models. Grounded in an initial user study (n=84), SynthDa2 includes both an API and a UI to accommodate technical and non-technical users. The framework leverages generative AI techniques and domain randomization to create diverse, user-customized synthetic video datasets. Case study experiments on dataset permutations demonstrate the feasibility of SynthDa2 in assessing composition impacts. While the initial user study confirmed camera angles as a popular key variation factor, experiments reveal they are insufficient alone for desired outcomes, highlighting the need for further research. A subsequent hands-on user study (n=8) further validates SynthDa2's usability across varied users.	https://dl.acm.org/doi/abs/10.1145/3681758.3697986	Megani Rajendran, Chek Tien Tan, Indriyati Atmosukarto, Aik Beng Ng, Joey Lim, Triston Chan Sheen, Simon See
Development of Tiny Wireless Position Tracker Enabling Real-Time Intuitive 3D Modeling	We propose a wirelessly powered and communicable position tracker implemented in a 10 mm cubic volume. Measurement results with a prototype show that the proposed adaptive power receiver (APR) maintains constant wireless power delivery regardless of the tracker's position. Additionally, the system achieves a maximum localization error of 4.75 mm.	https://dl.acm.org/doi/abs/10.1145/3681756.3697874	Yuki Maegawa, Masanori Hashimoto, Ryo Shirai
DiffOBI: Diffusion-based Image Generation of Oracle Bone Inscription Style Characters	Oracle bone inscriptions are the most valuable asset of humankind with irreplaceable archaeological and visual values. However, it is still challenging to analyze and generate oracle bone inscription-style images for visual identification and art design. In this paper, we propose DiffOBI, a novel approach for generating images in the oracle bone inscription style using diffusion models. We first construct a dataset that aligns with oracle bone inscription, text prompts, and object images. This dataset serves as the foundation for fine-tuning ControlNet. By inputting images of various objects along with corresponding text prompts, the model generates the corresponding images in the style of oracle bone inscription. To further enhance the quality of the generated images, we integrate a refinement module to refine the initial results, ensuring the refined results conform more closely to the original structure and norms of oracle bone inscription. This approach ensures that the generated images conform to the given input images and also preserves the unique pictographic features of oracle bone inscription.	https://dl.acm.org/doi/abs/10.1145/3681758.3698005	Xiaoxuan Xie, Xusheng Du, Minhao Li, Xi Yang, Haoran Xie
Digital Salon: An AI and Physics-Driven Tool for 3D Hair Grooming and Simulation	We introduce Digital Salon, a novel approach to 3D hair grooming and simulation by integrating advanced AI and physics-based algorithms. This tool enables users to create detailed hairstyles through natural language descriptions, seamlessly blending text-driven hair generation, interactive editing, and high-fidelity rendering within a cohesive workflow. With its innovative real-time simulation capabilities, Digital Salon supports dynamic hair interactions, accommodating 10,000 to 80,000 strands, thus making sophisticated hair design accessible to a wide range of users. This tool significantly enhances the creative process in digital media by providing an intuitive, versatile, and efficient solution for hair modeling and animation.	https://dl.acm.org/doi/abs/10.1145/3681757.3697054	Chengan He, Jorge Alejandro Amador Herrera, Yi Zhou, Zhixin Shu, Xin Sun, Yao Feng, Sören Pirk, Dominik L. Michels, Meng Zhang, Yangtuanfeng Wang, Holly Rushmeier
DiskPlay: Dynamic Projection Mapping on Rotating Platforms for Extended Holographic Display	This paper presents DiskPlay, a projection-based platform designed for extended holographic displays through projection techniques on rotating multi-layered disks. This system performs dynamic projection mapping on rotating disks according to their shape, projecting a different image for each layer. It provides special visual effects such as stereoscopic images and interactions such as rearranging the disks or manually adjusting the rotation speed to change the image style. This paper details the implementation methodology, and showcases two types of applications, stacking with depth and interaction with rearranging disks. It also discusses the usefulness and limitations of the system.	https://dl.acm.org/doi/abs/10.1145/3681756.3697888	Hidetaka Katsuyama, Shio Miyafuji, Hideki Koike
Dragravity: Wearable, Reconfigurable, Dynamic Weight-Shifting Waterbags to Enhance Full-Body Weight Sensations	Many studies have explored weight feedback in virtual reality(VR), but few can provide sufficient full-body weight sensations. We present Dragravity, a dynamic weight-shifting haptic proxy using wearable, reconfigurable waterbags. Our waterbags can be worn on arms, lower body, or legs using elastic bands to distribute weight across different body parts. This enhances the user's full-body weight sensation, enabling application possibilities with the haptic proxy. The waterbags can simulate weight sensation in VR using water with a maximum additional weight of 10.4 kg. To demonstrate, we designed two applications. The first is planetary exploration, where users can experience gravitational sensations on planets with the dynamic full-body weight sensation. The second is fitness weight training. By leveraging dynamic weight, users can experience various types of weight training on different muscles.	https://dl.acm.org/doi/abs/10.1145/3681759.3688921	Chi-Yu Lin, Hsin-Chia Chang, Meng-Wei Lu, Guan-Yu Zhou, Yu-Hin Chan, Ping-Hsuan Han
Dynamically Reconfigurable Paper	Paper has long been an indispensable part of our lives, and various types of paper are used in both everyday situations and in specialized fields, regardless of the field. However, paper needs to be used for different purposes, and we believe that this limitation is due to the fixed physical parameters of paper. Therefore, we focused on the fact that the traditional manufacturing process of paper has a unified process of dissolving pulp in water and drying it, regardless of the physical properties of the paper. By combining the papermaking process with an extension technique that regulates the moisture content of the paper, we were able to vary the physical parameters of the paper so that our paper is dynamic and possesses multifunctional properties not found in conventional paper. In this paper, we propose an application of our new paper's functionality to improve the interaction between computers and humans.	https://dl.acm.org/doi/abs/10.1145/3681756.3697980	Ryuhei Furuta, Hikari Kawaguchi, Kazuki Miyasaka, Mika Sai, Toshiki Sato
East Beijing Road	"is an asymmetric VR installation that reimagines the stories of a building with a history spanning over 100 years in Shanghai, China, whose residents were compelled to move out due to an ongoing gentrification policy. The project addresses the perceptions of the past and present, the fluidity of archives, and the meanings of ruins. A synthetic space was reconstructed based on 3D photogrammetry models captured in this building. The audience, both inside and outside VR, must use distinct interfaces and experience different visual presentations to collaboratively unfold the story. Old and new, digital and analog, real and fictional, and virtual and physical elements interweave. The asymmetrical design in interactive storytelling blends different times and spaces, allowing the re-enactment of the past through audience collaborative actions, raising questions about the relationship between interactivity and the visibility of the past. Asymmetry VR can be defined as ""co-located users access the same virtual environment using different kinds of technology"" [Ouverson and Gilbert ]. This project deploys the characteristic of asymmetric VR and provides an experience of unstable, unbalanced, and incomplete information among audiences inside and outside VR. The imbalances and incompleteness in media design are a metaphor for the fragmented time and space inherent in the archival practice of unveiling the past in the digital epoch. No complete information is visible without collaboration between the audiences inside and outside VR. It is an embodied experience that the past can only be revealed through collaborative interaction. The story of the building on East Beijing Road becomes a form of repertoire because of the collaborative engagements of the audiences."	https://dl.acm.org/doi/abs/10.1145/3681759.3688908	Haoran Chang
EchoVision: Experiencing Bat Echolocation via Mixed Reality	EchoVision is an interactive mixed reality art experience that simulates bat echolocation using custom-designed, handheld, bat-shaped masks based on the open-source HoloKit headset. As users initiate sounds, they experience echolocation—the remarkable navigation method bats employ in darkness—through visual representations of propagating echoes mapped onto the real-world 3D shape of the surrounding environment, scanned in real-time by the LiDAR sensor of a smartphone mounted on the masks. Unlike traditional indoor mixed reality headsets that often require time-consuming per-person setup and calibration, EchoVision's ergonomic handlebar design allows for easy passing and sharing among numerous participants, enabling quick engagement with the experience. This feature is especially valuable for in-the-wild, large-scale, pop-up exhibitions in bat habitats, such as Austin's Congress Avenue Bridge, enhancing high-traffic scientific education through deeper empathetic engagement. By providing a unique glimpse into how non-human creatures perceive their sensory world, EchoVision promotes an ecocentric design perspective, fostering interspecies understanding and appreciation.	https://dl.acm.org/doi/abs/10.1145/3681759.3688925	Botao Amber Hu, Jiabao Li, Danlin Huang, Jianan Johanna Liu, Xiaobo Aaron Hu, Yilan Elan Tao
Echoes of Antiquity: An Interactive Installation for Guqin Culture Heritage Using Mid-Air interaction and Generative AI	"With the development of mid-air interaction, the digital preservation and interactive learning of intangible cultural heritage (ICH) have become increasingly significant. However, the intrinsic significance of the cultural symbols embedded within numerous ICH remains largely obscure to the general public. This paper introduces ""Echoes of Antiquity"", an interactive installation that utilizes Leap Motion for gesture recognition and generative AI for image processing to vividly illustrate the symbolic elements of Guqin culture, thus bridge the existing chasm in public understanding and appreciation of Guqin's rich cultural heritage. Specially, our system utilizes Leap Motion to capture gestures and deliver AI-generated images as feedback, thereby enhancing the understanding and retention of the Guqin's cultural heritage through the seamless integration of motion and visual cues."	https://dl.acm.org/doi/abs/10.1145/3681756.3697970	Yuyao Heng, Yingman Chen, Zihan Gao
Editing Fluid Flows with Divergence-Free Biharmonic Vector Field Interpolation	Achieving a satisfying fluid animation through numerical simulation can be time-consuming and there are few practical post-processing tools for editing completed simulations. To address this challenge, we present a divergence-free biharmonic vector field interpolation method that can be used to perform smooth spatial blending between input incompressible flows. Given flow data on the boundary of a desired interpolation domain at each time step, we fill in the given domain by constructing an optimally smooth, divergence-free, boundary-satisfying vector field. We ensure smoothness using the Laplacian energy and enforce divergence constraints through Lagrange multipliers. Prior methods for this problem suffer from visible artifacts due to non-zero divergence and discontinuous velocity gradients. By then replacing the Laplacian energy with the Hessian energy we further extend our method to extrapolation in the presence of open boundaries. We demonstrate that our approach produces smooth and incompressible flows, which enables a range of natural simulation editing capabilities: copy-pasting, hole-filling, and domain extension.	https://dl.acm.org/doi/abs/10.1145/3681758.3698004	Tumay Ozdemir, Jiamin Shi, Nathan King, Christopher Batty
Efficient Space Variant Gaussian Blur Approximation	A space variant Gaussian blur is used to render blur brush effects. Regions of an image or video are blurred for stylistic effect or to obscure information. Exact methods of rendering this effect are typically too slow to provide user feedback. We propose a novel approximating technique which is used to produce both real-time and final renders.	https://dl.acm.org/doi/abs/10.1145/3681756.3697903	Oliver Richards, Chris Cook
Efficient visualization of appearance space of translucent objects using differential rendering	Translucent objects exhibit distinct appearances due to subsurface scattering, but rendering them realistically often involves time-consuming parameter adjustments. This paper proposes an efficient visualization method, using Principal Component Analysis (PCA) and Radial Basis Function (RBF), to allow users to explore subsurface scattering parameters interactively, enabling quicker computation and optimal settings.	https://dl.acm.org/doi/abs/10.1145/3681756.3697925	Riel Suzuki, Yoshinori Dobashi
Empathy Engine: Using Game Design and Real-time Technology to Cultivate Social Connection	Our VR game simulates the experiences of takeaway riders, using real-time data to create scenarios that foster empathy between consumers and riders while highlighting the challenges faced by riders. It employs narrative prompts, empathy-based rewards, and assessment scales to measure cognitive and affective empathy improvements. The VR format elicits stronger emotional resonance than 2.5D prototypes, demonstrating the potential of immersive technologies to foster mutual understanding across different social groups.	https://dl.acm.org/doi/abs/10.1145/3681756.3697867	Yuanlinxi Li, Mengyao Guo, Ze Gao
Emperor	Empereur is an evocative and interactive virtual reality narrative that immerses users in the inner world of a father suffering from aphasia, a condition that severely impairs verbal communication. The story is told from the perspective of his daughter, who seeks to reconnect with him by piecing together his fragmented language and memories. Through hand-tracked interactions, users are invited to participate in the father's attempts to communicate, creating a narrative experience that transcends traditional storytelling formats. Virtual reality plays a crucial role in enabling a fully immersive exploration of memory and language, offering a level of engagement that other formats cannot achieve. The experience is heightened by its poetic, black-and-white aesthetic and innovative hand-tracking system, which fosters a deep emotional connection between the user and the characters. This essay explores the interactive elements and design choices that make Empereur a pioneering achievement in immersive storytelling. It also examines how the project leverages VR's unique capabilities to evoke empathy and engage audiences on a deeper emotional level, contributing significantly to the field of interactive media.	https://dl.acm.org/doi/abs/10.1145/3681759.3688934	Wan-Chen Huang
Empowering CG Production:Cost-Effective Techniques for Voluminous Fur Rendering with Unreal Engine	This paper presents a novel approach to optimizing realistic fur rendering for CG animation using Unreal Engine (UE). We introduce a progressive method combining three key techniques to enhance rendering efficiency while maintaining high quality. These strategies significantly optimize GPU memory use, enabling more complex and realistic results. Our approach streamlines production workflows, reducing both time and costs, offering broader potential applications in the film industry.	https://dl.acm.org/doi/abs/10.1145/3681756.3697930	Ning Xia, Xiaofei Yin, Xuecong Feng
Engaging Racing Fans through Offline E-racing Spectator Experience in AR	In this work, we proposed a new spectator experience for engaging racing fans, even when they cannot be at the race track or, on non-racing days. Audiences can watch an e-racer driving on a simulator race against the pre-recorded car data from an actual race at the Suzuka Circuit. Using mobile phones as AR displays, users can watch the two cars race against each other on a virtual 3D race track, replicating the real race track in AR. This experience was deployed at a motor show, allowing visitors to try this experience. Feedback was also gathered from the visitors, with many of them reporting feeling excited with such kind of racing, and feeling a sense of immersion with such AR experience, indicating strong potential of this new spectator experience.	https://dl.acm.org/doi/abs/10.1145/3681756.3697927	Hsueh Han Wu, Kelvin Cheng, Koji Nishina, Jorge Chavez
Enhancing Mesh Deformation Realism for Synthesizing Wrinkles	We propose a solution for generating dynamic heightmap data to simulate deformations for soft objects, with a focus on the human skin. The solution utilizes mesostructure-level wrinkles and procedural textures to add static microstructure details. It offers flexibility beyond human skin during animations to mimic other material deformations, such as leather and rubber. Various methods suffer from self-intersections and increased storage requirements during synthesizing wrinkles. Although manual intervention using wrinkles and tension maps offers control, it lacks information on principal deformation directions. Physics-based simulations can generate detailed wrinkle maps, but may limit artistic control. Our research presents a procedural method to enhance the generation of dynamic deformation patterns, including wrinkles, with better control and without reliance on captured data. Incorporating static procedural patterns improves realism, and the proposed approach can be used in other application areas.	https://dl.acm.org/doi/abs/10.1145/3681758.3698011	Luis Fernandes, Ozan Cetinaslan, António Coelho
ExpressiveWorld: Detachable Expressions for VR Collaboration	VR collaboration enables users to express their emotions through visual cues. Although various techniques for representing emotions have been proposed, the impact of different representation locations on their effectiveness remains unclear. This research investigates how reprojecting a collaborator's emotions to various locations can enhance the reception of affective cues in VR collaboration. We introduce ExpressiveWorld, a customizable collaborative space that allows VR users to configure both the type and location of their partner's emotion representations. Our system provides four representations methods: 3D head models, emojis, visual effects, and vibrotactile feedback, representing five distinct emotions: Neutral, Happy, Angry, Sad, and Surprised. These representations can be reprojected onto the user's or partner's hand and task objects within the VR environment. With the ability to customize their emotional representations and positions on or off independently, users can create up to 84 different configurations. This flexibility helps VR users maintain focus on tasks while achieving emotional understanding and consensus with their partners.	https://dl.acm.org/doi/abs/10.1145/3681759.3688913	Theophilus Teo, Allison Jing, Xuan Tien Pham, Gun A. Lee
Eyelid Fold Consistency in Facial Modeling	Eyelid shape is integral to identity and likeness in human facial modeling. Human eyelids are diverse in appearance with varied skin fold and epicanthal fold morphology between individuals. Existing parametric face models express eyelid shape variation to an extent, but do not preserve sufficient likeness across a diverse range of individuals. We propose a new definition of eyelid fold consistency and implement geometric processing techniques to model diverse eyelid shapes in a unified topology. Using this method we reprocess data used to train a parametric face model and demonstrate significant improvements in face-related machine learning tasks.	https://dl.acm.org/doi/abs/10.1145/3681758.3697987	Lohit Petikam, Charlie Hewitt, Fatemeh Saleh, Tadas Baltrusaitis
FacialX: A Robust Facial Expression Tracking System based on Multifaceted Expression Embedding	Recent advancements in deep learning have significantly transformed the visual effects (VFX) industry by enabling highly realistic animation of human characters through the precise capture of actors' facial expressions. Despite these innovations, many existing methodologies remain limited by specific environmental constraints, such as camera viewpoints, necessitating extensive optimization efforts to achieve optimal performance. In response to these challenges, we propose a novel approach that not only incorporates diverse facial expressions but also accounts for variations in identity and camera viewpoint. We introduce FacialX, a versatile facial tracking tool, and demonstrate its ability to generate production-quality facial animations from monocular video while consistently maintaining robust performance across a wide range of conditions. Comparative evaluations reveal that FacialX surpasses current state-of-the-art solutions, including FACEGOOD and Apple ARKit, delivering production-quality outcomes, thereby establishing itself as a superior tool within the VFX industry.	https://dl.acm.org/doi/abs/10.1145/3681758.3697984	Da Eun Kim, Geon Kim, Joonho Park, Joo-Haeng Lee
Fast Leak-Resistant Segmentation for Anime Line Art	We propose a fast leak-resistant automatic segmentation method for line art with gaps. Using the existing idea, we develop a fair, prioritized flood-fill that avoids artifacts, augment it with a heuristic region merging strategy and obtain robust results on anime line art minimizing over-segmentation, with consistent performance 5–10 times faster than the baseline method.	https://dl.acm.org/doi/abs/10.1145/3681758.3698003	Benjamin Allen, Akinobu Maejima, Ken Anjyo
FilmAgent: Automating Virtual Film Production Through a Multi-Agent Collaborative Framework	Virtual film production requires intricate decision-making processes, including scriptwriting, virtual cinematography, and precise actor positioning and actions. Remarkable progress in automated decision-making have utilized agent societies powered by large language models (LLMs). This paper introduces FilmAgent, a novel LLM-based multi-agent collaborative framework designed to automate and streamline the film production process. FilmAgent simulates key crew roles—directors, screenwriters, actors, and cinematographers—within a sandbox environment, integrating efficient human workflows. The process is divided into three stages: planning, scriptwriting, and cinematography. Each stage engages a team of film crews providing iterative feedback, thus verifying intermediate results and reducing errors. Our evaluation of generated videos reveals that collaborative FilmAgent significantly outperforms individual efforts in line consistency, script coherence, character actions, and camera settings. Further analysis highlights the importance of feedback and verification in reducing hallucinations, enhancing script quality, and improving camera choices. We hope that this project lays the groundwork and shows the potential of integrating LLMs into creative multimedia tasks .	https://dl.acm.org/doi/abs/10.1145/3681758.3698014	Zhenran Xu, Jifang Wang, Longyue Wang, Zhouyi Li, Senbao Shi, Baotian Hu, Min Zhang
Finger Painting in VR: Multi-Dynamic Gestural Input for VR Painting	This study explores the multi-dynamic gestural interaction system using VR headsets and wearable devices, for enhancing VR painting with pressure control, gesture recognition, and haptic feedback. Testing demonstrated novel visual expressions through hand gestures, suggesting the potential for more nuanced and dynamic interactions in VR art and beyond.	https://dl.acm.org/doi/abs/10.1145/3681759.3688918	Rosina Yuan, Antony Tang, Qianyuan Zou, Masoumeh Hesam Mahmoudinezhad, Yuewei Zhang, Iain Anderson
Finger-Pointing Interface for Human Gesture Recognition Based on Real-Time Geometric Comprehension	This study proposes a system to recognize finger-pointing gestures and estimate their 3D coordinates to provide an intuitive and natural interface in the field of human-computer interaction. The study delineates a method commonly used in human conversations to describe locations and adapts it for interface application. It focuses on pose estimation using a stereo camera and provides mathematical and technical explanations, demonstrating the application of this interface to a four-wheeled mobile robot. The interaction between the user and the robot is detailed, alongside demonstrations and elucidations of the errors and their causes during the process. The study proposes methods to minimize these errors and explores additional potential applications of the finger-pointing gesture interface, highlighting its feasibility.	https://dl.acm.org/doi/abs/10.1145/3681756.3697892	Minjae Lee, Jiho Bae, Sang-Min Choi, Suwon Lee
Fitting Spherical Gaussians to Dynamic HDRI Sequences	We present a technique for fitting high dynamic range illumination (HDRI) sequences using anisotropic spherical Gaussians (ASGs) while preserving temporal consistency in the compressed HDRI maps. Our approach begins with an optimization network that iteratively minimizes a composite loss function, which includes both reconstruction and diffuse losses. This allows us to represent all-frequency signals with a small number of ASGs, optimizing their directions, sharpness, and intensity simultaneously for an individual HDRI. To extend this optimization into the temporal domain, we introduce a temporal consistency loss, ensuring a consistent approximation across the entire HDRI sequence.	https://dl.acm.org/doi/abs/10.1145/3681756.3698208	Pascal Clausen, Li Ma, Mingming He, Ahmet Levent Taşel, Oliver Pilarski, Paul Debevec
Flying Your Imagination: Integrating AI in VR for Kite Heritage	"""Flying Your Imagination"" investigates the innovative integration of Virtual Reality (VR), Artificial Intelligence (AI) technology, and embodied interaction design to revitalize and preserve China's significant intangible cultural heritage (ICH) of kite culture. We designed a VR kite simulation environment that allows users to immerse themselves in the joy of kite flying and making within a virtual space. The system incorporates AI to generate visual designs for kites and offers diverse interactive scenarios, opening up new avenues for transmitting cultural heritage."	https://dl.acm.org/doi/abs/10.1145/3681756.3697907	Kexin Nie, Mengyao Guo
Focal Surface Holographic Light Transport using Learned Spatially Adaptive Convolutions	Computer-Generated Holography (CGH) is a set of algorithmic methods for identifying holograms that reconstruct Three-Dimensio-nal (3D) scenes in holographic displays. CGH algorithms decompose 3D scenes into multiplanes at different depth levels and rely on simulations of light that propagated from a source plane to a targeted plane. Thus, for planes, CGH typically optimizes holograms using plane-to-plane light transport simulations, leading to major time and computational demands. Our work replaces multiple planes with a focal surface and introduces a learned light transport model that could propagate a light field from a source plane to the focal surface in a single inference. Our model leverages spatially adaptive convolution to achieve depth-varying propagation demanded by targeted focal surfaces. The proposed model reduces the hologram optimization process up to 1.5x, which contributes to hologram dataset generation and the training of future learned CGH models.	https://dl.acm.org/doi/abs/10.1145/3681758.3697989	Chuanjun Zheng, Yicheng Zhan, Liang Shi, Ozan Cakmakci, Kaan Akşit
Fringe Lights: Colored Penumbra in Glimpse	The recent popularity of stylized rendering calls for new approaches to help artists produce the desired look. Although some effects can be added to the rendered frames in compositing, this requires manual work at the end of the pipeline, leaving preceding stages unclear as to the impact on the final image. In this paper, we present our implementation of in our production path tracer, , for Netflix's Leo. Fringe lights allow lighting artists to easily modify the appearance of the penumbra, leaving both the unoccluded and fully shadowed parts of the scene unaffected. The soft transition between these two regions can be estimated by tracing at most one additional shadow ray towards the light source, allowing separate illumination at a minimal computational overhead. We extended our light sampling and evaluation for fringe lights to account for three different shading regions and modify the light contribution accordingly. Our method offers artists the freedom to stylize the penumbra and match the desired look of the show with direct visual feedback at every stage of the pipeline.	https://dl.acm.org/doi/abs/10.1145/3681758.3697998	Emanuel Schrade, Basile Fraboni, Thibault Vergne
Fukushima – The Home That Once Was	At 2:46 PM the lives of Hidenori, Mao, Kinue and thousands of others changed, irreversibly. The Fukushima Daiichi accident on the 11th of March 2011 is the worst nuclear power plant accident after Chernobyl. Fukushima – The Home That Once Was is a free-movement virtual reality documentary. The viewer can move freely inside the realistically captured 3D-houses and down the town streets inside the Fukushima Daiichi's off-limits Exclusion Zone using their VR-headset. The viewer will meet six former residents, who share their memories about losing their home, about the importance of community and of their special connection to the land. In the film there is around 1,5 hours of content, but the viewer can stay in the experience only up to 20 minutes. Thus each viewing will be different and each viewer will see a different version of the film.	https://dl.acm.org/doi/abs/10.1145/3681759.3688906	Timo Wright
Galerkin Method of Regularized Stokeslets for Procedural Fluid Flow with Control Curves	We present a new procedural incompressible velocity field authoring tool, which lets users design a volumetric flow by directly specifying velocity along control curves. Our method combines the Method of Regularized Stokeslets with Galerkin discretization. Based on the highly viscous Stokes flow assumption, we find the force along a given set of curves that satisfies the velocity constraints along them. We can then evaluate the velocity anywhere inside the surrounding infinite 2D or 3D domain. We also show the extension of our method to control the angular velocity along control curves. Compared to a collocation discretization, our method is not very sensitive to the vertex sampling rate along control curves and only requires a small linear system solve.	https://dl.acm.org/doi/abs/10.1145/3681758.3698019	Ryusuke Sugimoto, Jeff Lait, Christopher Batty, Toshiya Hachisuka
Gaussians in the City: Enhancing 3D Scene Reconstruction under distractors with Text-guided Segmentation and Inpainting	We propose a novel method to reconstruct 3D Gaussian scene from images that contain both static and dynamic distractors, e.g., vehicles and pedestrians, by using text-guided segmentation and inpainting techniques. Our approach generates masks for distractors, detects heavily masked regions and inpaints them to suppress defects and artifacts for scene optimization while ignoring distractors.	https://dl.acm.org/doi/abs/10.1145/3681756.3697897	Naoki Shitanda, Jun Rekimoto
Generalizing Human Motion Style Transfer Method Based on Metadata-independent Learning	This study aims to extend the applicability of motion style transfer methods to be robust for diverse and complex motions akin to those found in real-world data. We introduce a new training method without style labels which are metadata needed by conventional motion style transfer methods and enable a model to learn from almost motion datasets. This contribution mitigates performance degradation for motions absent in style-motion datasets. Compared to conventional methods, the proposed method demonstrates superior transfer performance, particularly under conditions featuring more diverse and complex motions.	https://dl.acm.org/doi/abs/10.1145/3681756.3697890	Yuki Era, Ren Togo, Keiske Maeda, Takahiro Ogawa, Miki Haseyama
Generative Terrain Fast Prototyping in Virtual Reality with Freehand Interface	Terrain generation and authoring in Virtual Reality (VR) offers unique benefits for terrain authoring including stereo display, immersive and intuitive design experience, and natural input modalities. We present this VR-based terrain fast prototyping system to integrate natural input modalities, preserve artistic controls and lower the effort of landscape prototyping. The system utilizes freehand interfaces and a generative model to help users quickly prototype different types of natural landscapes, such as mountains, mesas, canyons, and volcanoes. With the freehand interfaces, users can use their hands to draw mid-air strokes as the 3D contours of the desired landscapes. Then, a Conditional Generative Adversarial Network (CGAN) generates realistic landscapes based on the 3D contour. The freehand interface detects users' gestures to control landscape editing. By incorporating CGAN as the terrain synthesizer, our system allows users to immersively, rapidly, and easily prototype terrains using intuitive interactive hand controls.	https://dl.acm.org/doi/abs/10.1145/3681759.3688935	Yushen Hu, Keru Wang, Zhu Wang, Ken Perlin
GentlePoles : Designing Wooden Pole Actuators for Guiding People	"GentlePoles are wooden pole-like actuators that gently rotate to guide people without relying on text signs or staff. By arranging poles with individually controllable rotation direction and speed, the system gently and subtly directs people. For example, changes in rotation can convey messages such as ""go"" or ""stop"". In environments like airports, these poles can serve as triggers for passengers to access the information they need, while providing visual reassurance to surrounding passengers. The goal is to gently present information in public spaces with low cognitive load, addressing challenges such as staff shortages and information overload."	https://dl.acm.org/doi/abs/10.1145/3681756.3697922	Masaya Shimizu, Berend te Linde, Takatoshi Yoshida, Arata Horie, Nobuhisa Hanamitsu, Kouta Minamizawa
Gradient Traversal: Accelerating Real-Time Rendering of Unstructured Volumetric Data	We present a novel gradient traversal algorithm for real-time volume rendering of large, unstructured, dense datasets. Our key contributions include a two-pass approach consisting of a gradient estimation pass with random offsetting and a divergent gradient traversal refinement pass, achieving significant improvements over traditional methods per traversal step. By leveraging modern GPU capabilities and maintaining uniform control flow, our method enables interactive exploration of complex, dynamic, unstructured volumetric data under real-time constraints, addressing a critical challenge in scientific visualization and medical imaging.	https://dl.acm.org/doi/abs/10.1145/3681756.3697979	Mehmet Oguz Derin, Takahiro Harada
GravField: Live-coding Bodies through Mixed Reality	"GravField (short for ""Gravitational Field"") is a live-coding intercorporeal improvisation system within a collocated Mixed Reality (MR) environment. It explores the dynamic interplay between bodies, mediated through live-coded MR audiovisual affordances. Inspired by contact improvisation techniques, the system offers several MR audiovisual affordances that drive different modes of intercorporeal interactions. For example, ""Spring"" shapes spatial relations through proximity, ""Rope"" fosters bodily synchronization, and ""Magnetic Field"" captures emotional responses of attraction or repulsion. The landscape of these affordances, dynamically adjusted by live coders, actively influences participants' collective movements, which in turn alter the live music generation, creating a feedback loop. Drawing on Merleau-Ponty's phenomenology, GravField illuminates the potential for future somaesthetic interplay systems in holistic interactive MR environments."	https://dl.acm.org/doi/abs/10.1145/3681759.3688926	Botao Amber Hu, Rem RunGu Lin, Yuemin Huang, Mingze Chai, Xiaobo Aaron Hu, Yilan Elan Tao
HidEye: Proposal of HMD Interaction Method by Hiding One Eye	Immersive head-mounted display (HMD) provide a highly immersive experience by blocking the view of the real space, but using them for an extended period in daily life is challenging due to difficulties in switching tasks between virtual and real spaces and communicating with neighbors. We propose HidEye, an interaction method that enables users to easily switch contents by covering one eye. The goal is to seamlessly integrate tasks in virtual and real space through natural movements, without the need for special sensors or other devices on the HMD.	https://dl.acm.org/doi/abs/10.1145/3681756.3697915	Ryunosuke Ise, Koji Tsukada
High Spatial Resolution Projection Mapping for Visually Consistent Reproduction of Physical Surfaces	In texture representation by projection mapping, it is crucial that the appearance of the presented virtual object matches that of the real object to maintain the quality of the user experience. This study investigates the feasibility of reproducing a virtual object whose appearance perceptually matches that of a real object with fine texture, achieved by using high pixel density projection within an optically reduced projection area of the projector.	https://dl.acm.org/doi/abs/10.1145/3681756.3697942	Ikuho Tani, Daisuke Iwai, Kosuke Sato
Hybrid Physical Model and Status Data-Driven Dynamic Control for Digital Light Processing 3D Printing	In digital light processing (DLP) 3D printing, fixed control protocol parameters limit adaptability and lead to conservative settings, reducing printing efficiency. Existing methods that optimize parameters through physical models linked to the printing process do not account for real-time environmental changes, often resulting in potential print failures. This paper proposes a dynamic control scheme for DLP 3D printing that combines physical models with real-time data. Initially, a physical model of the printing process is developed to pre-generate the printing protocol. Then, a multimodal data capture scheme is designed to access the current state of the material and model. Finally, the printing protocol parameters are dynamically updated based on the analysis. Experimental results demonstrate that this method optimizes both printing time and success rate, significantly enhancing overall printing performance.	https://dl.acm.org/doi/abs/10.1145/3681756.3697957	Lidong Zhao, Xueyun Zhang, Lin Lu, Lifang Wu
Hyperstroke: A Novel High-quality Stroke Representation for Assistive Artistic Drawing	Assistive drawing aims to facilitate the creative process by providing intelligent guidance to artists. Existing solutions often fail to effectively model intricate stroke details or adequately address the temporal aspects of drawing. We introduce hyperstroke, a novel stroke representation designed to capture precise fine stroke details, including RGB appearance and alpha-channel opacity. Using a Vector Quantization approach, hyperstroke learns compact tokenized representations of strokes from real-life drawing videos of artistic drawing. With hyperstroke, we propose to model assistive drawing via a transformer-based architecture, to enable intuitive and user-friendly drawing applications, which are experimented in our exploratory evaluation.	https://dl.acm.org/doi/abs/10.1145/3681758.3697985	Haoyun Qin, Jian Lin, Hanyuan Liu, Xueting Liu, Chengze Li
IT3: Immersive Table Tennis Training Based on 3D Reconstruction of Broadcast Video	For professional players, observing their opponents' serves in detail typically involves watching video recordings, usually from broadcast footage. However, broadcast videos often capture players from a side view and lack immersiveness. In this work, we aim to reconstruct 3D table tennis games, incorporating AI-predicted player movements and ball placements, based on any given broadcast table tennis video. Moreover, an editing tool is developed for setting the table position and correcting the wrongly estimated player or ball placement positions. The ball trajectory is then simulated based on the corrected player and ball placement positions. With the proposed simulation system, players can train their reactions and responses to different types of serves in a VR environment from the first-person perspective. They can also observe their opponent's as well as their own movements from any chosen viewing angle, enhancing their training experience.	https://dl.acm.org/doi/abs/10.1145/3681756.3697917	Pei-Hsin Huang, Shang-Ching Liu, Li-Yang Huang, Chuan-Meng Chiu, Jo-Chien Wang, Pu Ching, Hung-Kuo Chu, Min-Chun Hu
Improved Morphological Anti-Aliasing for Japanese Animation	Digitalization of 2D animation deeply modified artists' workflows and brought many challenges in that industry. While vector-based technologies have been adopted in many fields, Japanese animation still heavily relies on raster aliased drawings in their workflows. Thus post-process anti-aliasing solutions tailored towards traditional Japanese animation were developed based on Morphological Anti-Aliasing (MLAA). After a decade, MLAA has been refined and extended, especially in the context of 3D real-time rendering. In this paper, we present a revised solution which incorporates features from existing anti-aliasing techniques, tailored torwards Japanese 2D animation.	https://dl.acm.org/doi/abs/10.1145/3681758.3697990	Tanguy Cesaratto, Alexandre Derouet-Jourdan, Marc Salvati
Incremental Gaussian Splatting: Gradual 3D Reconstruction from a Monocular Camera Following Physical World Changes	Real-time 3D reconstruction is crucial for remote collaboration, but adapting to dynamic environments remains challenging. We introduce Incremental Gaussian Splatting (I-GS), a novel approach for efficient 3D reconstruction in changing scenes. I-GS focuses on human-induced changes, using images from an operator-worn monocular camera. By processing only regions consistent with the current state, I-GS achieves sequential updates. Our evaluation demonstrates that I-GS outperforms conventional Gaussian Splatting, providing accurate spatial representations resilient to moving objects. This advance significantly improves the quality of remote collaboration in dynamic environments.	https://dl.acm.org/doi/abs/10.1145/3681756.3697913	Keigo Minamida, Jun Rekimoto
Individual Diffusion Auralize Display Using an Array of Audio Source Position Tracking Ultrasonic Speakers	"We developed a prototype system called the ""Individual Diffusion Auralize Display,"" which independently generates each instrument's sound using multiple parametric array loudspeakers (PAL) and monitor speakers. The system adjusts the reflection points of the sounds based on the players' positions. In this study, we demonstrated that the system meets the expected requirements, with the monitor particularly offering an optimal acoustic environment for multi-person viewing"	https://dl.acm.org/doi/abs/10.1145/3681756.3697976	Hyuma Auchi, Akito Fukuda, Yuta Yamauchi, Homura Kawamura, Keiichi Zempo
Ink-Edit: Interactive color-constrained textures editing	Procedural textures are able to generate large and detailed textures on-demand, at rendering time, with minimal memory usage. They are defined by parallel algorithms, which are easily integrated into modern graphics hardware. As a drawback, they may be difficult to control, namely in an interactive and user-friendly manner. In this paper, we define an interactive tool to control the parameters of the procedural model introduced by Grenier et al. [Grenier et al. ], which is based on a noise vector field (Figure (a), bottom and middle), and a color map (Figure (a), top). In our interactive tool, the noise is controlled through a small set of parameters in the spectral domain. To control the color map, the user first prescribes the colors (inks) and their proportions (ink volumes in the final result), and then adjusts interactively the adjacency between colors. This is done through a new constrained optimal transport point of view: the colors in the map are regarded as cells of a weighted Voronoi diagram, and the noise distribution is regarded as a probability measure. The ink volumes are automatically enforced as hard constraints of an optimization process during the interactive session, while the user focuses on high-level control over the adjacency of the colors.	https://dl.acm.org/doi/abs/10.1145/3681758.3697991	Charline Grenier, Pooran Memari, Basile Sauvage
Inside Out 2 characters: revisiting the old and making space for the new	(2024) presented a unique set of technical and artistic challenges, requiring careful decisions on retaining elements from the original film while embracing new technologies. As we transitioned from RenderMan's REYES to the newer RIS framework, we navigated the complicated task of preserving the iconic look, particularly the emotions and human elements. We enhanced the visual quality and accessibility for artists through advancements in our character pipeline, including reusing shading libraries and optimizing procedural workflows in Houdini, implementing show emotion specific hair illumination. Innovative rigging and grooming techniques were created to address technical and design challenges in character creation. Lighting techniques were refined to reflect the characters' story arcs, we also enhanced the Hexport [Coleman et al. ] system to be more user-friendly and accessible, streamlining shading and lighting workflows while reducing computation time and storage costs.	https://dl.acm.org/doi/abs/10.1145/3681758.3698012	Ana Lacaze, Masha Ellsworth, Athena Xenakis, Ben Porter, Jacob Kuenzel, Markus Kranzler, Lin Zhang, Jessica Harvill, Grace Gilbert, Patrick Colemand
Into the Womb -I want to be born again-	"""Into the Womb"" is an XR content with a simulated experience of being born again. The author who has a developmental disability expresses her hope that if she could be reborn without her disorder, she would feel universal love. The work raises social issues about women with developmental disabilities, who have lost love, which is the most important human emotion, due to trauma. The protagonist, who suffers from a developmental disability at the beginning, is verbally tricked by people and expresses her difficulty in living, having been traumatized by love and other things. The story begins with a scene of the world from the perspective of a girl with developmental disabilities in a night city called Kabuki-cho in Shinjuku, Tokyo. Participants will see the transition from the dark night city back into the womb of their mothers, experiencing a simulated escape from a society filled with contradictions. They can hear the mother's words and the encouraging words around them, which confirm their love. Then, they realize that they are being born again by moving their hands inside the womb to be born again. In the end, they assimilate with the fetus and are enveloped in light, and they are born again and 'alive' in the world. When they finish the experience and remove the headset, they feel a world full of hope after they have been born again. This work aims to help people feel free from trauma and have heart-warming feelings by going through a simulated experience of being born again."	https://dl.acm.org/doi/abs/10.1145/3681759.3688911	Shoko Kimura, Ayaka Fujii, Kenichi Ito, Rihito Tsuboi, Yoshinori Natsume
Intrinsic Morphological Relationship Guided 3D Craniofacial Reconstruction Using Siamese Cycle Attention GAN	Craniofacial reconstruction is essential in forensic science and has widespread applications. It is challenging due to the detailed facial geometry, complex skull topology, and nonlinear skull-face relationship. We propose a novel approach for 3D craniofacial reconstruction using a Siamese cycle attention mechanism within Generative Adversarial Networks (GAN). Benefiting from the cycle attention mechanism, our method focuses on high-frequency features and morphological connections between the skull and face. Additionally, a Siamese network preserves its identity consistently. Extensive experiments demonstrate superior accuracy and high-quality details of our approach.	https://dl.acm.org/doi/abs/10.1145/3681758.3698016	Junli Zhao, Chengyuan Wang, Yu-Hui Wen, Fuqing Duan, Ran Yi, Yong-Jin Liu, Qingdong Long, Zhenkuan Pan, Xianfeng Gu
Jaku-in: A Cultural Skills Training System for Recording and Reproducing Three-dimensional Body, Eye, and Hand Movements	In skill acquisition, it is crucial not only to mimic an expert's body movements but also to understand their underlying intentions, which can be achieved by observing their hand movements and gaze. However, it was difficult to understand the difference between one's posture and that of the expert in previous systems that assisted in understanding the intent of the expert. To overcome this limitation, we propose Jaku-in, which displays the expert's hand movements and gazes in a three-dimensional reconstructed space using a point cloud. The system's pass-through functionality of head-mounted displays allows novices to observe and emulate a life-size expert from multiple viewpoints: first-person, third-person, and behind-view. This research initially focuses on the Japanese tea ceremony, a practice where the precision and beauty of physical movements are fundamental. This showcases the effectiveness of 'Jaku-in' in this domain and inspires potential applications in other intricate skill domains.	https://dl.acm.org/doi/abs/10.1145/3681756.3697977	Sotaro Yokoi, Kaishi Amitani, Natsuki Hamanishi, Jun Rekimoto
Latent Bias Correction in Outpainting Artworks	This paper describes research on applying latent correction to image outpainting using a diffusion model. The purpose of this study is to eliminate unnecessary tendencies that frequently occur when outpainting an artwork, which lower the completeness of the resulting work. The core of the proposed method is to apply the error correction value calculated in the already known input region to the area to be generated during the denoising process in the latent space. The effectiveness of the proposed method was verified quantitatively and qualitatively through experiments.	https://dl.acm.org/doi/abs/10.1145/3681756.3697914	Jung-Jae Yu, Dae-Young Song
Li Bai the Youth: An LLM-Powered Virtual Agent for Children's Chinese Poetry Education	Large language models (LLMs) are increasingly recognized for their potential, but their application in fostering children's poetry learning remains underexplored. This paper introduces , an interactive installation that leverages a virtual agent powered by an LLM. We present a technical pipeline incorporating text-to-speech, lip synchronization, and other functionalities to enable real-time conversation between users and the virtual agent, Li Bai. Additionally, we implemented strategies to enhance the user experience during interaction. Li Bai the Youth offers a novel approach to poetry learning, promoting cultural heritage engagement.	https://dl.acm.org/doi/abs/10.1145/3681756.3697967	Yurun Chen, Xin Lyu, Tianzhao Li, Zihan Gao
Locally Editing Steady Fluid Flow via Controlling Repulsive Forces from Terrain	This paper presents a novel control method for steady fluid flows, such as rivers and waterfalls, simulated using SPH. Our system allows the user to place target points through which the fluids should pass, and the fluid flows can be controlled with these points. This is achieved through the control of repulsive forces on terrain surfaces. We detect positions on the terrain that affect fluid particles approaching the target points, and repulsive forces at these positions are automatically adjusted through a feedback control mechanism. Our method achieves the local control of steady fluid flows, and we demonstrate its effectiveness through several examples.	https://dl.acm.org/doi/abs/10.1145/3681756.3698210	Yuki Kimura, Yoshinori Dobashi, Syuhei Sato
Location-Based Artifact Installation Interaction	Our project establishes digital 3D models of artifacts through digital scanning technology and develops proportionate interactive devices that can interact with projection images using spatial location technology. The project aims to commemorate the Southward Evacuation of the artifacts led by the Palace Museum in China during World War II. By allowing visitors to physically touch the artifact installations for experiential purposes, it breaks the traditional exhibition limitation of only being able to view artifacts from a distance. This approach enables audiences to gain a more comprehensive understanding of cultural heritage through a multi-sensory experience, thereby encouraging reflection on the value and significance of artifact preservation.	https://dl.acm.org/doi/abs/10.1145/3681759.3688936	Sixue Zhang, Haitao Wang, Zhen Li, Lan Bai
MMM: Mid-air image Moving in and out of the Mirror with backward glance in the mirror	"We propose an optical system displaying mid-air images that move between the inside and outside of a mirror with backward glance in the mirror. Previous research has not been able to achieve all three of these goals: the standing image floats in space, moves across the mirror's surface, and is reflected in the mirror. Proposed system ""MMM"" achieves all three of these goals and presents a worldview of the mirror as an adjacent virtual world. A magic mirror application that brings characters into the real world from a display have been developed. In this application, the mirror space connects the cyberspace inside the display with the real world."	https://dl.acm.org/doi/abs/10.1145/3681756.3697881	Yasunori Akashi, Changyo Han, Takeshi Naemura
MOBILE SUIT GUNDAM: Silver Phantom	"Bandai Namco Filmworks is pleased to announce that it will produce ""Mobile Suit Gundam: Silver Phantom"" the latest pioneering VR film based on the ""Mobile Suit Gundam"" series, with Atlas V, a VR production company that has created numerous immersive experiences, including ""Gloomy Eyes"" and ""Battlescar. ""Mobile Suit Gundam: Silver Phantom"" is a visual work that offers fans the opportunity to immerse themselves in the Gundam world in a new way using VR and invites them into an unprecedented interactive story. This work will be distributed by Astrea, a company that has developed numerous VR titles, and will be available on Meta's VR headset, Meta Quest. Through this new VR experience of the Gundam world, we will deliver the appeal of Gundam to fans around the world."	https://dl.acm.org/doi/abs/10.1145/3681759.3688933	Kiichiro Inoue
Magic You	"""Magic You"" is a virtual reality interactive narrative experience, a coming-of-age personal story about ADHD, with joys, anxieties, bitter memories, and growing pains, told in a hand-drawn, colored-pencil aesthetic as a magical journey with surreal overtones, providing a more in-depth look into the inner world of people with ADHD. The artwork hopes to present the experiences and imagination of ADHD patients to the audience in poetic and romantic way, make audience spiritual healing and empathizing."	https://dl.acm.org/doi/abs/10.1145/3681759.3688919	Tongze Guo, Wen Zhou, Xiangrong Xiao, Ni Ding, Yansong Chen, Shaolong Liu
MambaPainter: Neural Stroke-Based Rendering in a Single Step	Stroke-based rendering aims to reconstruct an input image into an oil painting style by predicting brush stroke sequences. Conventional methods perform this prediction stroke-by-stroke or require multiple inference steps due to the limitations of a predictable number of strokes. This procedure leads to inefficient translation speed, limiting their practicality. In this study, we propose MambaPainter, capable of predicting a sequence of over 100 brush strokes in a single inference step, resulting in rapid translation. We achieve this sequence prediction by incorporating the selective state-space model. Additionally, we introduce a simple extension to patch-based rendering, which we use to translate high-resolution images, improving the visual quality with a minimal increase in computational cost. Experimental results demonstrate that MambaPainter can efficiently translate inputs to oil painting-style images compared to state-of-the-art methods. The codes are available at this URL.	https://dl.acm.org/doi/abs/10.1145/3681756.3697906	Tomoya Sawada, Marie Katsurai
Mapping and Recognition of Body Movements on Another Person's Look-Alike Avatar	Research is needed to understand how users perceive the body movements of the look-alike avatar of a remote collaborator. To investigate, we captured three actors performing seven actions and mapped their body movements onto the look-alike avatar of one of the actors. Subsequently, we asked participants to identify the body movements of the actors rendered on the look-alike avatar. We found that participants were able to identify biological motions irrespective of the resemblance of the avatar to the controlling actor. The results of this study provide valuable insights into the accuracy of identifying body movements when mapped onto an avatar that bears no resemblance to the user. We discuss whether there are certain body movements that enables the user to accurately determine the person behind the avatar. The results have significant implications for trust and realism in collaborative virtual environments.	https://dl.acm.org/doi/abs/10.1145/3681758.3697999	Kwame Baffour, Anthony Williams, John Lee, Oyewole Oyekoya
Material and Colored Illumination Separation from Single Real Image via Self-Supervised Domain Adaptation	Separating material and illumination from images allows for realistic manipulation, which is crucial for image editing and augmented reality. In this work, we propose a training strategy for intrinsic decomposition networks that combines unsupervised domain adaptation with self-supervised constraints and sparse-guided fine-tuning in the target domain. Through two complex optimization steps, even a lightweight CNN can achieve outstanding material and illumination separation in real single images. The final separation results and various realistic image manipulation applications demonstrate the effectiveness and potential of our proposed method.	https://dl.acm.org/doi/abs/10.1145/3681756.3697963	Hao Sha, Tongtai Cao, Yue Liu
Media Bus: XR-Based Immersive Cultural Heritage Tourism	This study presents Media Bus prototype for facilitating digital storytelling experiences through extended reality (XR), head mounted displays (HMDs), and transparent OLEDs within the city of Seoul. The system offers an immersive tourism experience by integrating precise location tracking, which combines Visual Positioning Service (VPS) and Global Positioning System (GPS), along with TOLED displays and wearable augmented reality (AR) content. Two rounds of expert interviews were conducted to guide the development and assess the prototype. The preliminary interview provided foundational concepts and technical requirements, while the subsequent interview focused on evaluating the prototype and suggesting potential improvements. The results indicate that the proposed system has significant potential for enhancing urban tourism experiences in an innovative manner. However, challenges remain in improving location accuracy and refining user interfaces. This research presents a novel application of XR and is anticipated to advance smart city initiatives and cultural tourism efforts.	https://dl.acm.org/doi/abs/10.1145/3681756.3697931	Jieon Du, Heewon Lee, Jeongmin Lee, Gewon Kim
MeiMeiRoRo	"""MeiMeiRoRo"" is an interactive experience in a nested maze, and its concept is to present two consciousnesses, active and passive. In this experience, operations to a miniature avatar, such as tilting, are returned to the user through a nested structure. Operations on the miniature avatar are an active awareness, and when the resulting operations are returned to the user, a passive awareness occurs. These two consciousnesses are the concept, which works because the nested structure implies that the operations on the miniature avatar are an operation on him/herself."	https://dl.acm.org/doi/abs/10.1145/3681759.3688928	Osuke Funabiki, Naoki Morita, Yasuyuki Yanagida
Mixed Reality Solutions for Tremor Disorders: Ergonomic Hand Motion and AR Rehabilitation	This study introduces an innovative mixed reality (MR) system for managing tremor disorders, including essential tremor and Parkinson's disease. The system combines an ergonomic hand motion assistance device that mimics natural hand movements to stabilize tremors with MR-based rehabilitation exercises that dynamically adjust in difficulty. Telehealth capabilities enable remote monitoring and consultations, enhancing accessibility. An iterative design process informed by feedback from medical professionals, patients, and design experts led to significant improvements in motor control, task performance, and user autonomy. This comprehensive MR intervention represents a substantial advancement in tremor disorder treatment, offering a versatile and user-friendly solution.	https://dl.acm.org/doi/abs/10.1145/3681756.3697969	Xinjun Li, Zhenhong Lei
Multidirectional Superimposed Projection for Delay-free Shadow Suppression on 3D Objects	The method of superimposed projection, which involves using a projector array, allows for projection from various directions. This technique helps to minimize the appearance of shadows caused by obstacles. This paper explores the implementation of a multidirectional superimposed projection system and analyzes the projection results through both actual projection and simulation.	https://dl.acm.org/doi/abs/10.1145/3681756.3697948	Takahiro Okamoto, Daisuke Iwai, Kosuke Sato
Multimodal Learning for Autoencoders	In this work, Multimodal Autoencoder is proposed in which images are reconstructed using both image and text inputs, rather than just images. Two new loss terms are introduced: Image-Text-loss ( ) that measures similarity between input image and input text, and Text-Similarity-loss ( ) that measures similarity between generated text from the reconstructed image and input text. Our experiments demonstrate that images reconstructed using both modalities (image and text) are of significantly higher quality than those reconstructed from either modality alone, highlighting how features learned from one modality can enhance another in the reconstruction process.	https://dl.acm.org/doi/abs/10.1145/3681756.3697974	Wajahat Ali Khan, Seungkyu Lee
NatureBlendVR: A Hybrid Space Experience for Enhancing Emotional Regulation and Cognitive Performance	NatureBlendVR is an immersive experience designed to enhance well-being through forest bathing. This system integrates XR technology with interactive, bio-responsive physical elements. Through the experience, participants find themselves in a blended environment where physical components of nature are integrated into their immediate surroundings. The experience gradually transitions from the real world to a designed virtual forest, where digital elements align perfectly with the physical environment. This fosters a deep sense of presence, allowing users to feel fully immersed as their embodied sensations align with the virtual interactions they encounter.	https://dl.acm.org/doi/abs/10.1145/3681756.3697956	Kinga Skiers, Peng Danyang, Giulia Barbareschi, Pai Yun Suen, Kouta Minamizawa
NatureBlendVR: Hybrid Space Interactive Experience For Emotional Regulation And Cognition Improvement	NatureBlendVR is a hybrid interactive experience designed to promote wellbeing by leveraging the benefits of forest bathing. The system combines XR technology with interactive bio-responsive physical elements. Throughout the experience, users are immersed in a hybrid space where elements of a physical garden are placed in the immediate surroundings of the user, including a flower sphere that provides haptic and visual biofeedback reacting to the person's heartbeat. A gradual transition from the view of the real space to a meticulously crafted virtual forest where digital elements match the position of physical ones promotes a sense of continuity, allowing the person to feel present in the natural space as embodied sensations match the expectation created by virtual interactions.	https://dl.acm.org/doi/abs/10.1145/3681759.3688929	Kinga Skiers, Danyang Peng, Giulia Barbareschi, Yun Suen Pai, Kouta Minamizawa
Necomimi illusion: Generating Ownership of Cat Ears through Haptic Feedback via Hair	The sense of ownership over non-human body parts, such as tails and third arms, has been explored using Virtual Reality (VR) technology. These studies are grounded in evolutionary backgrounds and anatomical associations. However, whether the body model can be extended to imaginary body parts without such evolutionary and anatomical associations remains unclear. In this demonstration, we developed a device that creates a sense of ownership over imaginary body parts, specifically cat ears. We achieve this through haptic feedback to the head via hair. Using soft actuators made of shape memory alloys, we move the hair to reproduce various haptic sensations and the comfort associated with stroking cat ears, including the range and direction of the touch. Participants transform into an avatar with cat ears and experience having their imaginary cat ears stroked.	https://dl.acm.org/doi/abs/10.1145/3681759.3688923	Hiroo Yamamura, Ryota Kondo, Maki Sugimoto
Neural Clustering for Prefractured Mesh Generation in Real-time Object Destruction	Prefracture method is a practical implementation for real-time object destruction that is hardly achievable within performance constraints, but can produce unrealistic results due to its heuristic nature. To mitigate it, we approach the clustering of prefractured mesh generation as an unordered segmentation on point cloud data, and propose leveraging the deep neural network trained on a physics-based dataset. Our novel paradigm successfully predicts the structural weakness of object that have been limited, exhibiting ready-to-use results with remarkable quality.	https://dl.acm.org/doi/abs/10.1145/3681756.3697973	Seunghwan Kim, Sunha Park, Seungkyu Lee
New Fashion: Personalized 3D Design with a Single Sketch Input	In this study, we present a method that enables individuals to generate 3D garment designs from basic sketches, thus making a previously specialized creative field more accessible. Our approach takes a single freehand sketch as input and employs generative deep learning techniques to automatically create high-fidelity 3D garment models using a conditional diffusion 3D generation network. Our proposed method comprises two key components: 1) a pre-training phase that uses a 3D prior, drawing on a varied dataset of clothing shapes in 3D to grasp the essential characteristics of these forms, and 2) a sketch-to-prior mapping module that establishes a connection between the sketches and the pre-trained manifold, facilitating the effective generation of 3D shapes. Our method not only overcomes existing limitations but also introduces new possibilities for shape prototyping and exploration in fashion design, thus broadening the scope of creativity for a more diverse audience.	https://dl.acm.org/doi/abs/10.1145/3681756.3697946	Tianrun Chen, Xinyu Chen, Chaotao Ding, Ling Bai, Shangzhan Zhang, Lanyun Zhu, Ying Zang, Wenjun Hu, Zejian Li, Lingyun Sun
No Exit in Hell: A Role-Switching Narrative Experience in VR Theatre	No Exit in Hell is an innovative recreation of Jean-Paul Sartre's classic play No Exit in VR theatre. It immerses viewers in a novel narrative experience by not only bringing realistic theatre acting into virtual reality but also allowing them to take on different roles of the play. In this role-switching experience, gamification designs are integrated to guide viewers through each role transformation and maintain their focus, ensuring that every shift in character unveils a new facet of the story.	https://dl.acm.org/doi/abs/10.1145/3681759.3688937	Guangxing Guo, Ziyuan Hu, Jiayu Hou, Shan Wang
Not Just a Gimmick: A Preliminary Study on Designing Interactive Media Art to Empower Embedded Culture's Practitioner	Interactive Media Art (IMA) offers a promising avenue for preserving and promoting cultural heritage by engaging audiences through immersive experiences. However, its potential to support the creation of cultural content and empower practitioners has been largely underutilized. Taking shadow puppetry, a traditional art form often featured in IMA, as a cut point to examine how current IMA practices can be reimagined to better serve the needs of cultural custodians, this paper adopting a practitioner-centered design approach, aim to develop IMA content that not only showcases traditional art but also supports its sustainable innovation and development. While our research is still in its early stages, short-term experiments suggest that IMA can serve as an effective tool for creative support, assisting artists in producing their work. The long-term impact of these systems on artistic output remains to be explored.	https://dl.acm.org/doi/abs/10.1145/3681756.3697872	Yihao He
ODA-GS: Occlusion- and Distortion-aware Gaussian Splatting for Indoor Scene Reconstruction	In this work, we aim to address the quality degradation issues of indoor scene reconstruction using 3D Gaussian Splatting (3DGS). Existing methods enhance reconstruction quality by exploiting learned geometric priors like Signed Distance Functions (SDF), but these come with significant computational costs. We analyze the traditional 3DGS training process and identify key factors contributing to quality degradation: over-reconstruction and gradient dilution during the densification stage, and the occurrence of distorted/redundant Gaussians during the post-optimization stage. To tackle these issues, we introduce ODA-GS, a novel framework that modifies 3DGS with tailored modules. During densification, we employ occlusion-aware gradient accumulation to prevent gradient dilution and use homo-directional gradients to mitigate over-reconstruction. In the post-optimization stage, we introduce post-pruning to eliminate distorted and redundant Gaussians, thereby enhancing visual quality and reducing computational overhead. Tested on the ScanNet++ and Replica datasets, ODA-GS outperforms several baselines both qualitatively and quantitatively.	https://dl.acm.org/doi/abs/10.1145/3681758.3697997	Chai-Rong Lee, Ting-Yu Yen, Kai-Wen Hsiao, Shih-Hsuan Hung, Sheng-Chi Hsu, Min-Chun Hu, Chih-Yuan Yao, Hung-Kuo Chu
Once a Glacier	tells the story of a relationship between a girl and a glacier. As the girl grows older, the existence of the ice is threatened, and the viewer is taken on a journey through her seemingly futile efforts to protect what was once an entire glacier. The story is inspired by Jiabao Li's own experience from two years that she lived in Alaska, where she was the young girl protecting a piece of ice in the freezer. In Inupiaq tradition, a tribe of indigenous people from northwestern Alaska, glaciers carry memories from the past and communicate them in song. The climate crisis has become a terrifying reality that includes seeing the end of glaciers—the end of these sung histories—happen before our eyes. shows a gesture of nurturing, and whether the girl's efforts are successful or not, the work suggests a poignant level of grace and humility for moving forward into the future.	https://dl.acm.org/doi/abs/10.1145/3681759.3688920	Jiabao Li
Online Chat with Living Neuronal Cultures	We demonstrate a combination of neuroscience experiment and visual interaction over the internet. Activity of cultured neurons is obtained by measurement instrument, transmitted to WebGL visualization in real-time, and broadcasted online as light and sound effects. The system reveals the beauty of the dynamics within a living neural network and enables the audience to interact with the culture by sending stimulation commands via the chat interface.	https://dl.acm.org/doi/abs/10.1145/3681757.3697053	Teruki Mayama, Dai Akita, Wataru Kawakami, Hirokazu Takahashi
OrienText: Surface Oriented Textual Image Generation	Textual content in images is crucial in e-commerce sectors, particularly in marketing campaigns, product imaging, advertising, and the entertainment industry. Current text-to-image (T2I) generation diffusion models, though proficient at producing high-quality images, often struggle to incorporate text accurately onto complex surfaces with varied perspectives, such as angled views of architectural elements like buildings, banners, or walls. In this paper, we introduce the Surface ted ual Image Generation (OrienText) method, which leverages region-specific surface normals as conditional input to T2I generation diffusion model. Our approach ensures accurate rendering and of the text within the image context. We demonstrate the effectiveness of the OrienText method on a self-curated dataset of images and compare it against the existing textual image generation methods.	https://dl.acm.org/doi/abs/10.1145/3681758.3698008	Shubham Singh Paliwal, Arushi Jain, Monika Sharma, Vikram Jamwal, Lovekesh Vig
Out-Of-Core Diffraction for Terascale Holography	Displaying large-scale holograms with a wide field of view (FoV) requires ultra-high-resolution data, often reaching tera-scale sizes. We propose an out-of-core diffraction method that utilizes multiple SSDs simultaneously to manage tera-scale holography within limited memory constraints. To enhance I/O bandwidth, we introduce a block-wise I/O approach for diffraction computation. Additionally, our method employs a compressed data transfer scheme to reduce I/O costs. As a result, our method performs diffraction up to 4.2 faster compared to alternative methods. We also validate our approach by generating a 256 resolution hologram, which would typically require 4TB of memory using conventional diffraction methods, on a GPU with only 24 GB of memory.	https://dl.acm.org/doi/abs/10.1145/3681756.3697885	Jaehong Lee, Duksu Kim
OverallNet: Scale-Arbitrary Lightweight SR Model for handling 360° Panoramic Images	Estimating room layouts from 360° panoramic images is an essential task in computer vision, enhancing 3D scene understanding from 2D images. To achieve and handle high-quality panoramas necessitates a Super-Resolution (SR) technique that is both light and capable of arbitrary-scale SR, optimized for efficient inference. In this study, we propose a simple model that employs a modular arbitrary-scale technique. Additionally, our model incorporates quantization to maximize efficiency during user inference, making it well-suited for processing high-quality panoramic images.	https://dl.acm.org/doi/abs/10.1145/3681756.3697939	DongSik Yoon, Jongeun Kim, Seonggeun Song, Yejin Lee, Gunhee Lee
Perceiving 3D from a 2D Mid-air Image	In this study, we aim to quantify the sense of depth and perceived position in mid-air images. In the experiment, the participants were instructed to indicate the nearest frontal point and zenith of both mid-air images and actual spherical objects. The results suggest that the frontal surface of mid-air images is generally perceived on the image plane or behind it. However, when depth is recognized, it appears slightly less pronounced compared to actual objects.	https://dl.acm.org/doi/abs/10.1145/3681756.3697900	Saki Kominato, Miyu Fukuoka, Naoya Koizumi
Petroller: Altering the Virtual Reality Controller with an Attachable Prop-based Haptic for Embodied Virtual Companion	"Previous studies have explored various forms of virtual companions, including displaying companions on flat screens, headsets, or the embodiment of their physical bodies. Although most studies use additional devices to enrich sensory feedback to embody the virtual companion in a virtual reality (VR) headset, it requires electricity to activate. We present ""Petroller,"" an attachable mechanism that embodies a virtual companion by altering the built-in VR controller with the prop-based haptic, allowing users to hug, pat, and exercise together. Additionally, we designed two usage scenarios: pet companionship and rehabilitation exercises. We aim for users to interact with the Petroller by pressing and stroking, providing relaxation, emotional healing, and even promoting physical exercise."	https://dl.acm.org/doi/abs/10.1145/3681759.3688912	Ta-Wei Liu, Pei-Cih Zeng, Guan-Yi Lu, Kuan-Ning Chang, Jih Hsuan Peng, Ping-Hsuan Han
Phantom Audition: Using the Visualization of Electromyography and Vocal Metrics as Tools in Singing Training	Our approach aims to use electromyography (EMG) and vocal metrics to enhance vocal physiological feedback, comparing a professional singer and students to analyze muscle control and quality.	https://dl.acm.org/doi/abs/10.1145/3681756.3697908	Kanyu Chen, Emiko Kamiyama, Ruiteng Li, Yichen Peng, Daichi Saito, Erwin Wu, Hideki Koike, Akira Kato
PianoKeystroke-EMG: Piano Hand Muscle Electromyography Estimation from Easily Accessible Piano Keystroke	The acquisition of motor skills is intrinsically related to human movement dynamics. Traditional methods for measuring muscle activation via electromyography (EMG) sensors are often prohibitively expensive. Previous approaches developed algorithms to infer muscular information from other modalities, though predominantly concentrating on gross motor activities. In contrast, dexterous skills, such as piano performance, mostly engage small muscles, for which reliable and cost-effective solutions remain underexplored. We introduce , an approach to estimate EMG data from readily accessible data, such as piano keystroke motions. Further evaluation demonstrates that our system outperforms baselines in accuracy and versatility, potentially offering a practical tool for pianists to enhance their performance techniques.	https://dl.acm.org/doi/abs/10.1145/3681756.3697878	Ruofan Liu, Yichen Peng, Takanori Oku, Erwin Wu, Shinichi Furuya, Hideki Koike
PnRInfo : Interactive Tactical Information Visualization for Pick and Roll Event	With pick-and-roll (PnR) being a commonly used tactic in basketball, providing a thorough analysis of it proves to be beneficial to improving a basketball team's overall performance. In this work, we propose PnRInfo, a tool for automatically detecting PnR plays within basketball footage and visualizing respective tactical information in a 3D simulation space to facilitate interactive discussion of PnR tactics.	https://dl.acm.org/doi/abs/10.1145/3681756.3697936	Li-Huan Shen, Joyce Sun, Jan-Yue Lin, Yi-Hsuan Chiu, Ssu-Hsuan Wu, Tai-Chen Tsai, Shun-Han Chang, Hung-Kuo Chu, Min-Chun Hu
Prototyping Game Character Animations with AI in Unity	Most 3D games leverage animations to breathe life into characters. Even at the early stages of game development, prototyping with working animations helps developers quickly understand and adapt the game design. Controllable characters require animations that are constrained in multiple ways in order to blend together and avoid artifacts such as feet sliding. Authoring, modifying and iterating on such animations is a costly process that often requires high level expertise or expensive motion capture. We present a novel AI-powered graph tool that allows users to leverage generative machine learning models, presented as nodes in the graph, and create animations from only a few high-level inputs. This greatly reduces the time and expertise required to author animations from scratch, while offering unseen levels of control with generative motion creation. The combination of the many relevant nodes that the graph supports and the flexibility of our state-of-the-art diffusion models allows for going beyond text-to-motion and in-betweening, common in the literature. We can generate motions that can be synchronized on multiple aspects, such as duration, speed, feet contact timings, while being constrained by signals such as text-prompts and trajectories. Our diffusion models also allow for stylizing existing motions, and generating looping animations. This makes it possible, for the first time to our knowledge, to generate complete working locomotion sets from high level inputs such as text and duration, directly usable with common character controllers. Our system being implemented in Unity, we showcase the power of this novel approach by constructing a prototype animated character with working locomotion and attack motions without preexisting animations, in a few minutes.	https://dl.acm.org/doi/abs/10.1145/3681757.3697051	Florent Bocquelet, Félix Harvey, Pierre-Luc Loyer
Re-Touch: A VR Experience for Enhancing Autobiographical Memory Recall Through Haptic and Affective Feedback	Autobiographical memory recall can be triggered through sensory stimuli, often creating a positive impact on emotional well-being. However, there are few systems that can adapt to users' emotional state and provide personalized stimuli to better support this process. Re-Touch enhances memory recall through the integration of Virtual Reality (VR), haptic feedback, and affective computing. It allows users to revisit their personal memories in a controlled VR space. By monitoring physiological responses (photoplethysmography (PPG) and electrodermal activity (EDA)) the system adjusts the haptic feedback intensity and the VR content to match the user's emotional needs, enhancing sensory and emotional immersion.	https://dl.acm.org/doi/abs/10.1145/3681759.3688916	Tamil Selvan Gunasekaran, Yulan Ju, Giulia Barbareschi, Kouta Minamizawa, Yun Suen Pai, Mark Billinghurst
Real-Time Enveloped Mesh Editing Using Vector Graph Representation	In mesh processing, enveloping establishes a relationship between mesh and control structure deformation. Once enveloped, the mesh is edited via control structure deformation. This editing process aims for realistic and computationally efficient mesh deformation. In this work, we propose a data-driven enveloping approach designed for efficient mesh editing and producing realistic deformations. The proposed method computes geometric model deformations by leveraging the Vector Graph (VG) representation. By establishing a map between skeleton (control structure) and mesh deformations, the proposed approach achieves realistic results. Comparative analysis demonstrates qualitative parity with leading techniques, while computational efficiency remains akin to Linear Blend Skinning. Extensive experiments across diverse mesh datasets validate the proposed method, substantiated by qualitative and quantitative comparisons against state-of-the-art linear and non-linear approaches.	https://dl.acm.org/doi/abs/10.1145/3681758.3698001	Prashant Domadiya, Pratik Shah
Real-Time Transfer Function Editor for Direct Volume Rendering in Mixed Reality	Direct Volume Rendering (DVR) effectively visualizes volumetric data, allowing focus on specific regions of interest (ROIs) while retaining surrounding context. In mixed reality (MR), DVR offers an immersive and intuitive way to interact with volumetric data. However, the ability to adjust transfer functions (TF), which control the appearance of DVR, has been limited in MR settings, often relying on predefined TFs that restrict real-time customization. In this paper, we introduce a novel system designed to enhance DVR within MR environments by providing an interactive TF editor. This system allows users to intuitively adjust the optical properties of volumetric data through a user-friendly interface. Key features include node creation and deletion for defining ROIs, a color palette and opacity control for appearance settings. Immediate visual feedback is achieved by converting the user-defined 1D TF into a 2D texture that is applied in real-time using a DVR Unity shader.	https://dl.acm.org/doi/abs/10.1145/3681756.3697953	Junseo Choi, Hyeonji Kim, Haill An, Younhyun Jung
Real-Time Virtual Try-On Using Generative AI	We introduce a novel real-time virtual try-on system powered by generative AI. Our demonstration highlights key features, including real-time virtual try-on, realistic wrinkle generation, and human-garment interaction. We showcase the system's ability to produce highly plausible results across diverse poses and perspectives, offering a seamless and interactive experience for users.	https://dl.acm.org/doi/abs/10.1145/3681757.3697048	Zaiqiang Wu, I-Chao Shen, Yuki Shibata, Takayuki Hori, Mengjia Jin, Wataru Kubo, Takeo Igarashi
Real-time 3D Human Reconstruction and Rendering System from a Single RGB Camera	Transforming 2D human images into 3D appearance is essential for immersive communication. In this paper, we introduce a low-cost real-time 3D human reconstruction and rendering system with a single RGB camera at 28+ FPS, which guarantees both real-time computing speed and realistic rendering results. We use WebRTC to transmit captured images over the Internet for low-latency remote communication. In addition, we design a lighting-robust rendering approach to enhance the lighting perception and generalization ability of the model. Experimental results show that our system achieves high-quality real-time 3D human reconstruction and rendering for different persons wearing various clothes, even with challenging poses. Our system makes use of only a common USB webcam and a consumer-level GPU with real-time performance and high-fidelity results, which provides a consumer-accessible immersive telepresence solution.	https://dl.acm.org/doi/abs/10.1145/3681758.3697993	Yuanwang Yang, Qiao Feng, Yu-Kun Lai, Kun Li
Real-time Holographic Media System Utilizing HBM-based Holography Processor	This paper introduces a real-time holographic media system that converts 2D or RGBD videos into 3D holograms. The core of this system includes a Linux host that extracts depth information from 2D images and transmits it via packets, and a holography processor leveraging high-bandwidth memory (HBM) to generate volumetric holograms with 8-layer depths at 30 frames per second (fps). Demonstrations highlight the potential of the proposed system for advancing future holographic media technologies.	https://dl.acm.org/doi/abs/10.1145/3681756.3697871	Wonok Kwon, Sanghoon Cheon, Kihong Choi, Keehoon Hong
Reborn of the White Bone Demon: Role-Playing Game Design Using Generative AI in XR	This paper explores the application of Generative Artificial Intelligence (GenAI) techniques to the design of Role Playing Games (RPGs) in Extended Reality (XR) environments. We developed the game , which utilizes AI speech emotion recognition technology to generate story lines and game assets in real-time based on the player's conversations with NPCs, enhancing the player's immersion and personalized experience, demonstrating the potential of GenAI in enhancing the XR gaming experience.	https://dl.acm.org/doi/abs/10.1145/3681756.3697949	Xiaozhan Liang, Yu Wang, Fengyi Yan, Zehong Ouyang, Yong Hu, Siyu Luo
Rethinking motion keyframe extraction: a greedy procedural approach using a neural control rig	"3D animators traditionally use a ""pose to pose"" approach, whereas motion capture (MoCap) tools generate a pose for every frame, making the motion challenging to edit. We argue that current keyframe extraction methods are inadequate for human editing. To address this, we propose a novel approach that bridges the gap between MoCap animations and traditional 3D artist tools. Our contributions include learning a neural control rig as a differentiable proxy for more accurate key pose interpolation and formulating the task as an optimization problem, solved efficiently with a greedy dynamic programming algorithm."	https://dl.acm.org/doi/abs/10.1145/3681756.3697960	Théo Cheynel, Omar El Khalifi, Baptiste Bellot-Gurlet, Damien Rohmer, Marie-Paule Cani
Reyeal: Implicit Gaze-based Interaction for Creating Personal Landscape Painting in Cinematic Virtual Reality	Cinematic virtual reality (CVR) brings viewers an immersive movie-watching experience. Different from storytelling of other media, CVR directors will use different interaction techniques and visual cues to guide the viewers through the immersive experience. In this paper, we present Reyeal, an implicit gaze-based interaction for creating personal landscape painting in cinematic virtual reality, in which the users will have their own experience of immersive landscape painting through their eyes. While most of the visual cues rely on visible objects, with Reyeal (Reveal by Eye), the CVR directors do not need to design interactions to guide the users looking at specific target objects. To demonstrate our technique, different elements of a Chinese landscape painting such as clouds and mountains will be drawn to the virtual environment by the users' gaze accordingly, which will result in a compelling experience for each user.	https://dl.acm.org/doi/abs/10.1145/3681759.3688922	Yang-Sheng Chen, Miguel Then Ying Jie, Chiao-En Hsieh, Jing-Yuan Huang, Ping-Hsuan Han, Yi-Ping Hung
RobotSketch: A Real-Time Live Showcase of Superfast Design of Legged Robots	Soon, many robots equipped with AI capable of providing valuable services will appear in people's lives, much like the Cambrian explosion, but for robots. However, until now, robots have been developed primarily from a technical perspective, such as sensing, locomotion, and manipulation, but to become truly successful products, they will require a proper product design process, similar to that of the automotive industry. With [Lee et al. 2024] (Figure 1), we show that such is possible for the robotics industry and highlight the growing importance of future-oriented robot design tools. These new tools can help robot designers explore and develop a wide range of alternative shapes, structures, and movements of robots in a short period during the early stages of design, and enhance the services and experiences that the robots can offer. RobotSketch has been made possible by the recent development of three key technologies. First, a 3D sketching technology that enables the quick and easy creation of shapes and structures of robots using intuitive pen and multi-touch gestures [Lee et al. 2022]. Second, a VR technology that enables the use of a tablet device as a transparent window for 3D sketching in an immersive workspace [Lee et al. 2023]. Third, an AI technology that enables the fluent locomotion skills of robots through reinforcement learning in a physics simulation [Hwangbo et al. 2019].	https://dl.acm.org/doi/abs/10.1145/3681757.3697055	Joon Hyub Lee, Hyunsik Oh, Junwoo Yoon, Seung-Jun Lee, Taegyu Jin, Jemin Hwangbo, Seok-Hyung Bae
SLAM-Based Illegal Parking Detection System	In this study, we propose a novel illegal parking detection system based on simultaneous localization and mapping (SLAM). The system identifies the presence of illegal parking in real-time based on user-defined parking zones. Furthermore, considering the increasing deployment and pilot testing of unmanned patrol vehicles, we explore the application of this system to enhance the efficiency of automated illegal parking detection and management. The proposed system demonstrates high accuracy and real-time detection capabilities in identifying illegal parking and is expected to significantly contribute to addressing the issue of illegal parking in urban centers in the future.	https://dl.acm.org/doi/abs/10.1145/3681756.3697873	Jiho Bae, Minjae Lee, Ungsik Kim, Suwon Lee
See-Through Face Display: Enabling Gaze Communication for Any Face—Human or AI	We present See-Through Face Display, an eye-contact display system designed to enhance gaze awareness in both human-to-human and human-to-avatar communication. The system addresses the limitations of existing gaze correction methods by combining a transparent display with a strategically positioned camera. The display alternates rapidly between a visible and transparent state, thereby enabling the camera to capture clear images of the user's face from behind the display. This configuration allows for mutual gaze awareness among remote participants without the necessity of a large form factor or computationally resource-intensive image processing. In comparison to conventional methodologies, See-Through Face Display offers a number of practical advantages. The system requires minimal physical space, operates with low computational overhead, and avoids the visual artifacts typically associated with software-based gaze redirection. These features render the system suitable for a variety of applications, including multi-party teleconferencing and remote customer service. Furthermore, the alignment of the camera's field of view with the displayed face position facilitates more natural gaze-based interactions with AI avatars. This paper presents the implementation of See-Through Face Display and examines its potential applications, demonstrating how this compact eye-contact system can enhance gaze communication in both human-to-human and human-AI interactions.	https://dl.acm.org/doi/abs/10.1145/3681758.3698020	Kazuya Izumi, Ryosuke Hyakuta, Ippei Suzuki, Yoichi Ochiai
Segmentation of 3D Gaussians using Masked Gradients	We present a simple yet powerful method for segmenting 3D Gaussian splatting models using 2D segmentation masks from a limited number of viewpoints. Our approach leverages inference-time gradient backpropagation, making it both easy to implement and fast enough for interactive segmentation. The underlying formulation ensures high accuracy, making this method a highly effective tool for 3D segmentation and related downstream tasks such as AR, VR, 3DGS editing, and digital twins.	https://dl.acm.org/doi/abs/10.1145/3681756.3697941	Joji Joseph, Bharadwaj Amrutur, Shalabh Bhatnagar
Self-attention Handwriting Generative Model	Recent advancements in font generation models include GANs, diffusion models, and transformers. This study introduces a GAN-based model, zi2zi self-attention, which enhances the zi2zi model by incorporating Residual Blocks (ResNet Block) and Self-Attention Layers in the encoder and decoder. These enhancements improve the ability to capture complex font details, mimicking the writer's style while preserving the source image's content. The study also introduces Perceptual Loss, using high-level features from the VGG-19 network to improve visual consistency and quality. The Adam optimizer with appropriate learning rates and Beta parameters is employed to enhance convergence speed and stability. For comparison, four other mainstream models are evaluated: MX-Font, CF-Font, SDT, and Font-Diffuser. These models differ from zi2zi in their focus on extracting content characters and writing style features rather than solely using adversarial networks. Experimental results show the potential and effectiveness of zi2zi-Self-Attention in generating high-quality, visually appealing handwritten fonts.	https://dl.acm.org/doi/abs/10.1145/3681756.3697883	Yu-Chiao Wang, Tung-Ju Hsieh, Pei-Ying Chiang
Semantics-guided 3D Indoor Scene Reconstruction from a Single RGB Image with Implicit Representation	Single-view 3D scene reconstruction is challenging due to limited single-image information. Existing methods often overlook the importance of image feature extraction. We propose a novel approach that integrates semantic segmentation with an implicit function, using a semantic-guided image encoder to enhance feature extraction for improved background and object reconstruction. A categorical attention module based on semantic segmentation further aids object reconstruction. Experimental results show our method's strong performance in both background and object reconstruction.	https://dl.acm.org/doi/abs/10.1145/3681756.3697923	Yi-Ju Pan, Pei-Chun Tsai, Kuan-Wen Chen
Sensory Cravings: A Mixed Reality Installation Enhancing Psychological Experiences through Multisensory Interactions	Recent advancements in virtual and mixed reality have created opportunities to explore how sensory experiences influence emotional and psychological states. Our installation, Sensory Cravings, leverages mixed reality to create immersive environments simulating the emotional impact of everyday consumables like coffee, alcohol, and desserts. Using Meta's hand-tracking technology and Arduino-based sensor feedback, this work integrates visual, auditory, gustatory, olfactory, and tactile feedback to mitigate modern stress and promote emotional well-being. By incorporating real food choices that guide the virtual experience, the system enhances interactivity and immersion while offering innovative ways to perceive the real world within VR settings, adding to the existing body of work on multisensory integration in virtual cognitive environments.	https://dl.acm.org/doi/abs/10.1145/3681756.3697918	Shuyi Li, Yifan Ding, Zihan Gao
Shortest Path Speed-up Through Binary Image Downsampling	We propose a novel approach to achieve huge speed-ups for shortest path computations on 2D binary images at the cost of slight inaccuracies. This is done by migrating the arc flag-based shortest path methods, which can deliver large speed-ups for run-time shortest path computations but needed a computationally expensive preprocessing step, to work on downsampled versions of the input images. Through extensive tests, we found that our approach hugely reduces the costs of the preprocessing step, therefore resolved a performance bottleneck of the arc flag-based methods.	https://dl.acm.org/doi/abs/10.1145/3681756.3697911	Chia-Chia Chen, Chi-Han Peng
Shrunken Reality: Augmenting Real-World Contexts in Real-Time on Realistic Miniature Dioramas	This study presents a new form of augmented reality (AR), referred to as shrunken reality (SR), that captures various real-world contexts in real-time using cameras and augments them onto realistic miniature dioramas, denoted as shrunken worlds (SWs), providing a distinctive experience different from existing AR technologies. We explored the mathematical and technical methods to realize SR, focusing on the processes involved in mapping and augmenting real-world contexts onto miniature, scaled-down models. By exploring the integration of physical miniaturization with digital augmentation, we investigated the potential applications of SR across various sectors, highlighting its relevance to both public services and industries. Finally, we discuss future research directions, such as increasing the number of cameras to capture comprehensive real-world contexts, utilizing deep learning models to enhance user's immersive experience, improving the naturalness of the augmented overlays on SWs, and broadening the scope of augmentations to cover a wider range of real-world, real-time contexts.	https://dl.acm.org/doi/abs/10.1145/3681758.3697983	Minjae Lee, Jiho Bae, Ungsik Kim, Sang-Min Choi, Suwon Lee
Signal Journey: Sense of Connection in a Two-Player VR Game Through a Proximity-Based Interactive Experience	This project aims to build a sense of connection in a remote two-player VR game by offering proximity-based interaction with audio and video connectivity. We develop a co-dependent game system where virtual proximity, or the distance between two players are assumed to reflect emotional closeness of the two individuals. The VR metaphorically reflect and promote players' mutual engagement. Positioned at opposite ends of the virtual environment, the two players exchange audio and visual signals to locate each other until they come close. As they get nearer, visual and audio elements, such as color saturation and diverse sounds, are designed to enhance their connectivity, reflecting their emotional closeness and awareness of each other's presence. After gameplay, the players' locations are recorded and displayed on a map.	https://dl.acm.org/doi/abs/10.1145/3681759.3688917	Dayoung Lee, JiYeong Kim, Gwonyeong Lim, Yunbeen Cho, Sihun Lee, Jean Ho Chu
Signal2Hand: Sensor Modality Translation from Body-Worn Sensor Signals to Hand-Depth Images	We present Signal2Hand, a method that reconstructs hand-depth images from body-worn sensor signals. To do this, we trained VQ-VAE using a pair of body-worn sensor signals and a hand-depth image. We conducted a preliminary study of the method and evaluated the reconstruction results using four evaluation metrics.	https://dl.acm.org/doi/abs/10.1145/3681756.3697943	Yuki Kubo, Buntarou Shizuki
Slime Hand XR: Distinct Illusory Skin Deformation in HMD Space	Slime Hand XR is an interactive head-mounted display (HMD) system that induces illusory skin deformation in VR. In the proposed system, participants wearing the HMD place their hands on a tray where a chunk of slime is visible within the HMD's view. Participants can instantly and boldly feel illusory skin stretching by looking at the deformed slime while the experimenter pinches and pulls their hand's skin at the same time. In addition, the tip of the deformed slime can be clipped with a clothespin in VR by the experimenter. Then, this setup can maintain the form of illusory skin deformation. This system adopts the principle of the slime hand illusion, which can induce a strong sense of skin deformation. By using computer-generated slime, we achieved a unique skin deformation illusion that is hard to replicate in reality, such as suspended deformation. In testing the illusion effect of this system at an open laboratory exhibition for children, 56 out of 63 participants reported a strong reaction to the sensation of skin deformation in the questionnaire.	https://dl.acm.org/doi/abs/10.1145/3681759.3688938	Yutaro Sato, An Ito, Kousuke Motohashi, Tsuyoshi Suzuki, Kenri Kodaka
Sound Signatures for Geometrical Shapes	We propose automatic generation of sound signatures — short pseudowords which can be associated with certain features of geometric shapes such as roundness, spikiness, etc. This research is related to sound symbolism, a sub-track of synesthesia where people describe information with different sounds. First, we propose a method which allows us to automatically calculate a measure of roundness of geometric shapes. We verify the obtained results with the numerous user tests conducted over the century by the sound symbolism researchers. Next, we propose a deep learning-based method of new sound signatures generation for different shapes.	https://dl.acm.org/doi/abs/10.1145/3681756.3697882	Hanqin Wang, Alexei Sourin
SpecTrack: Learned Multi-Rotation Tracking via Speckle Imaging	Precision pose detection is increasingly demanded in fields such as personal fabrication, Virtual Reality (VR), and robotics due to its critical role in ensuring accurate positioning information. However, conventional vision-based systems used in these systems often struggle with achieving high precision and accuracy, particularly when dealing with complex environments or fast-moving objects. To address these limitations, we investigate Laser Speckle Imaging (LSI), an emerging optical tracking method that offers promising potential for improving pose estimation accuracy. Specifically, our proposed LSI-Based Tracking (SpecTrack) leverages the captures from a lensless camera and a retro-reflector marker with a coded aperture to achieve multi-axis rotational pose estimation with high precision. Our extensive trials using our in-house built testbed have shown that SpecTrack achieves an accuracy and of 0.31° ( = 0.43°), significantly outperforming state-of-the-art approaches and improving accuracy up to .	https://dl.acm.org/doi/abs/10.1145/3681756.3697875	Ziyang Chen, Mustafa Dogan, Josef Spjut, Kaan Akşit
Splanting: 3D plant capture with gaussian splatting	3D capture and characterization of plant shoot architecture is a grand challenge in plant phenotyping research, made difficult by plants' intricate 3D shape, composed of thin and flat sub-structures (stems, leaves, flowers, pods, etc.). In this paper, we show that 3D gaussian splatting is well-suited for capturing 3D plant representations, which we call . We report a simple and fast capture procedure and 3DGS processing software that is tailored to foreground object capture. Splant generation worked well across plant species and growth stages. Our preliminary results point to a promising future for splant phenotyping, which we expect will lead to a dramatic increase in the use of multi-view imaging and 3D analysis in plant pathology and plant breeding research.	https://dl.acm.org/doi/abs/10.1145/3681758.3698009	Tommy Ojo, Thai La, Andrew Morton, Ian Stavness
Strainer GAN: Filtering out Impurity Samples in GAN Training	In practical applications of GAN for image generation, large size training samples may be collected from random databases or web- pages. For example, if we collect human face images for training set it may include unexpected impure samples such as cartoon or anime human face images that hinder realistic and high quality human face generation. Manually removing such impure samples is extremely time-consuming and impractical due to the large volume of data. In this work, we propose a novel method to au- tomatically remove impure samples in GAN training.	https://dl.acm.org/doi/abs/10.1145/3681756.3697961	Jiho Shin, Seungkyu Lee
Style Transfer with Gesture Style Generator	"Traditionally, style transfer methods have extracted style element from user-provided "" Style motion"" and content element from ""Content motion"", and combining these two elements to achieve transferred style in the content motion. In the process, they attempted to separate movements into style and content elements in a binary way. However, ambiguity exists between the definitions of style and content. An action of crossing your arms when you are angry (style) while walking (content) is not clearly categorized as either style or content. In this work we define ""Gesture Style"" referring to a short-term action revealing style (not content) in a motion sequence. Crossing arms in the example falls in Gesture Style, as it represents anger but is performed for short time. We propose a new style transfer method with Gesture Style Generator. It transfers style to the output motion in the conventional style transfer manner while also incorporating generated Gesture Style. "	https://dl.acm.org/doi/abs/10.1145/3681756.3697972	DaYeon Lee, Seungkyu Lee
StyleGaussian: Instant 3D Style Transfer with Gaussian Splatting	We introduce StyleGaussian, a novel 3D style transfer technique that allows instant transfer of any image's style to a 3D radiance field at 10 frames per second (fps). Leveraging 3D Gaussian Splatting (3DGS), StyleGaussian achieves style transfer without compromising its real-time rendering ability and multi-view consistency. It achieves instant style transfer with three steps: embedding, transfer, and decoding. Initially, 2D VGG scene features are embedded into reconstructed 3D Gaussians. Next, the embedded features are transformed according to a reference style image. Finally, the transformed features are decoded into the stylized RGB. StyleGaussian has two novel designs. The first is an efficient feature rendering strategy that first renders low-dimensional features and then maps them into high-dimensional features while embedding VGG features. It cuts the memory consumption significantly and enables 3DGS to render the high-dimensional memory-intensive features. The second is a K-nearest-neighbor-based 3D CNN. Working as the decoder for the stylized features, it eliminates the 2D CNN operations that compromise strict multi-view consistency. Extensive experiments show that StyleGaussian achieves instant 3D stylization with superior stylization quality while preserving real-time rendering and strict multi-view consistency. Project page: https://kunhao-liu.github.io/StyleGaussian/	https://dl.acm.org/doi/abs/10.1145/3681758.3698002	Kunhao Liu, Fangneng Zhan, Muyu Xu, Christian Theobalt, Ling Shao, Shijian Lu
The Secrets of Penalty Functions on Edge-preserving Image Smoothing	Recently, penalty functions are applied to the optimization-based edge-preserving image smoothing problem. But, to select appropriate parameter(s) for a penalty function to achieve desired smoothing effect is nontrivial. In this paper, we study the influence of penalty function on the performance of the edge-preserving image smoothing from the shrinkage rule perspective. We find some interesting secrets about penalty function on the edge-preserving image smoothing. Firstly, the shrinkage rule of a penalty function can help to determine its appropriate parameter(s). Secondly, it is more important is to select appropriate parameters for a penalty function than to select a specific penalty function, because different penalties may have very similar shrinkage rules by changing their parameter(s). Thirdly, a simple optimization framework with an appropriate parameter(s) setting of a penalty function can achieve comparable smoothing effects to those produced by much complex algorithms. To cope with the difficulties brought by nonconvex penalties, we propose an iterative algorithm by virtue of local quadratic approximation.	https://dl.acm.org/doi/abs/10.1145/3681758.3698017	Xiqun Lu
Theater of Future Puppetry: An Immersive Puppeteering Experience Based on Hands Tracking and Gestures Recognition	There are many studies on hand tracking and interaction with virtual puppets in the immersive experience. This research presents an advanced gesture recognition system called Theater of Future Puppetry. Unlike systems that only use hand tracking and hand skeleton manipulation of puppets, this system can recognize specific gestures used in traditional Budaixi (Taiwanese glove puppetry) and interact with them. The gestures were designed based on discussions with traditional Budaixi masters. Through this system, users can learn and understand the knowledge and cultural background of Budaixi puppet manipulation.	https://dl.acm.org/doi/abs/10.1145/3681759.3688909	Wei-Chen Yen, Jen-Kai Liu, Jia-Jiu Peng, Hsiao-Yu Luo, Ping-Hsuan Han, Chun-Cheng Hsu
Thermiapt: Sensory Perception of Quantitative Thermodynamics Concepts in Education	Traditional text-based methods for learning thermodynamics are often inefficient according to neuroscientific principles. Multi-sensory inputs, particularly visual and haptic, have been shown to enhance memory retention and comprehension by engaging the hippocampus. This paper presents , a haptic device designed to integrate sensory experiences of quantitative thermodynamic concepts, such as heat capacity. The device is not only simple and reproducible but also has the potential to significantly enhance understanding and retention in educational settings by leveraging multi-sensory learning.	https://dl.acm.org/doi/abs/10.1145/3681756.3697966	Anji Fujiwara, Kodai Iwasaki, Tamami Watanabe, Hideaki Uchiyama
Time Light: An Interface for Comparing National Treasure Murals Across Time	Time Light is an innovative interface developed as part of a Mixed Reality (MR) system designed to deepen the understanding of the renowned Takamatsuzuka Kofun's murals. This interface allows users to compare and observe both the severely deteriorated murals, affected by looting and plaster degradation at the time of discovery, and the estimated reconstructed images that illustrate how the murals might have appeared when originally created. Although Time Light was developed to enhance the understanding of the Takamatsuzuka Kofun, it can be applied to any murals with both discovered and reconstructed images. By using Time Light, users can experience a unique perspective on the historical and cultural significance of these national treasures.	https://dl.acm.org/doi/abs/10.1145/3681756.3697952	Wenze Song, Takefumi Hayashi
Tingle Tennis: Menstrual Experience Sensory Simulation Sport Device	Tingle Tennis, a menstrual period sensory simulation game, leverages Virtual Reality (VR) technology, haptic feedback, and IoT techniques to create an immersive experience that highlights the physical, psychological, and social challenges athletes face during their menstrual cycles. Providing users with a situational life experience, the VR application aims to foster empathy and raise awareness about the importance of addressing menstruation-related issues in the psychology of sports and exercise. The overall experience is divided into tutorial, preparation, tennis training, and final match stages, with users assuming the role of a tennis athlete over a span of three days. The project's novelty lies in its comprehensive approach to addressing menstruation-related issues in sports by using hardware devices to mimic and control the pain of menstrual cramps based on the user's condition while experiencing the mental state of an athlete going through periods. The users also have to use various items to help users live with this situation and be fully prepared for the final match.	https://dl.acm.org/doi/abs/10.1145/3681756.3697905	Shun-Han Chang, Chen-Chun Wu, ZI-YUN LAI, TSUNG-YEN LEE, CHENG-EN HO, Min-Chun Hu
Towards Accelerating Physics Informed Graph Neural Network for Fluid Simulation	Fluid simulations in Computational Fluid Dynamics (CFD) often involve solving complex Partial Differential Equations (PDEs) with varying parameters, leading to high computational costs and slow inference times. Graph neural networks (GNNs) offer a promising alternative by efficiently representing mesh spaces and reducing these costs. In this work, we introduce a pioneering Physics-Informed Graph Neural Network (PIGNN) approach, utilizing a multi-GNN processor architecture that assigns each output parameter to a dedicated GNN processor with individual decoders. This innovative method reduces the training epochs for PIGNN by half while preserving accuracy. Additionally, we adopted mixed-precision training and achieved further improvements in reducing the training time to one-quarter of the original network while maintaining VRAM usage.	https://dl.acm.org/doi/abs/10.1145/3681756.3697879	Yidi Wang, Frank Guan, Malcolm Yoke Hean Low, Zhengkui Wang, Aik Beng Ng, Simon See
Towards Wave Function Collapse using Optimization with Quantum Algorithms	Quantum computing has emerged in recent years as a rapidly evolving field, presenting the potential to solve problems that are difficult for classical computers. Our work presents a new implementation of procedural generation using Wave Function Collapse (WFC), solved using Quantum Approximate Optimization Algorithm (QAOA). The problem is formatted as a Constraint Satisfaction Problem (CSP), where the edge rules in classical WFC are encoded as linear constraints. We successfully demonstrate the generation of valid tile configuration in both 2D and 3D, showcasing the potential of quantum computing in hybrid quantum-classical systems. However, our algorithm is constrained by limitations set by current quantum computers, which prevents real-world deployment at this stage.	https://dl.acm.org/doi/abs/10.1145/3681758.3698015	Zirui Zhang, Shannon Cheng, Kevin Xiao, Priyam Gupta, Sean Ruda
Transcendental Chakra: A Multi-Sensory Meditation Spiritual Journey to Enhance Self-Awareness Based on VR	Chakra, originating in Hinduism, is described as luminous wheels or auras representing different elements within the body that reflect a person's self-awareness. Chrakra-based meditation techniques can support individual wellbeing, but the provision of Chakra feedback in a visual and tangible manner to facilitate mindfulness is largely unexplored. Transcendental Chakra is a virtual reality (VR) multi-sensory experience using guided audio, visual effects, and vibrotactile feedback to aid beginners in chakra meditation by visualizing their astral avatar. The goal of this work is to foster both spiritual and physical self-awareness.	https://dl.acm.org/doi/abs/10.1145/3681759.3688927	Danyang Peng, Shengyin Li, Tanner Person, Giulia Barbareschi, Pai Yun Suen, Kouta Minamizawa
Transparent 360-Degree Display for High-Resolution Naked-Eye Stereoscopic Aerial Images	We developed a display that presents high-resolution stereoscopic images floating in mid-air. Conventional methods have not yet achieved the presentation of realistic images floating in mid-air due to issues such as resolution and the prominence of the display medium. Our method realizes a thin directional display that can present directional images at the observer's position and display high-resolution naked-eye stereoscopic images. Additionally, by combining our method with a curved transparent reflective panel, we can present stereoscopic images in mid-air that are observable from all directions.	https://dl.acm.org/doi/abs/10.1145/3681756.3697887	Mari Shiina, Naoki Hashimoto
Tripo Doodle: The Next-Gen AI 3D Creative Tool	Creating 3D digital content has been a tough challenge, especially when dealing with scenes packed with objects or characters performing complex motions. With Tripo Doodle, we can now rapidly prototype entire scenes and fully animatable characters, with nothing more than simple doodles and text prompts. The AI-generated assets are high- quality and ready to be used across a range of applications---from gaming and animation to immersive virtual experiences and beyond. This technology opens the door to new creative possibilities, making 3D content creation faster and more accessible than ever before.	https://dl.acm.org/doi/abs/10.1145/3681757.3697052	Sienna Hwang, Muqing Jia, Yan-Pei Cao, Yuan-Chen Guo, Yangguang Li, Ding Liang
Unsteady Streamline Synthesis	Streamlines tracing out a vector field are important for graphics and visualization, yet the way of controllably arranging the streamlines in unsteady flows, even in 2D, has not been well studied to this day. We thus propose an framework that can create a full set of coherent streamlines following certain inputs under 2D and 3D time-varying scenarios while satisfying coverage, continuity, and controllability purposes. Our key concept is to treat the time-varying streamline arrangement like a dynamic packing of anisotropic elements with deformability such that both quality and efficiency can be fulfilled. Specifically, we devise a synthesis process based on inter- and intra-streamline relationships to dynamically synthesize all the coherent streamlines in parallel and incorporate a regulation mechanism with primitive operations to timely adjust each streamline's continuity and the overall streamline coverage. With specification, our framework can further controllably produce desired streamline arrangements for various application demands.	https://dl.acm.org/doi/abs/10.1145/3681758.3697981	Chen-Yuan Hsu, Li-Yi Wei
V-Wire: A Single-Wire System for Simplified Hardware Prototyping and Enhanced Fault Detection in Education	We introduces V-Wire, an single-wire system designed to simplify hardware prototyping and improve fault detection in educational settings. V-Wire addresses key challenges in hardware development by reducing wiring complexity, eliminating port assignment constraints, and simplifying troubleshooting. The system utilizes a single closed loop wire for two-way communication and power supply, allowing for easy connection of multiple modules and straightforward detection of disconnections. This paper describes the system's architecture, implementation, and its significant advantages in educational applications. This system can support beginner developers in connecting a hardware device easily.	https://dl.acm.org/doi/abs/10.1145/3681756.3697921	Hideaki Nii, Kazutoshi Kashimoto, Shozaburo Shimada
Vibrotactile Invisible Presence: Conveying Remote Presence through Moving Vibrotactile Footstep Cues on a Haptic Floor	Inspired by the human ability to sense the presence of people walking behind them through floor vibrations, we propose a concept to convey presence by transmitting footsteps and vibrotactile cues from one space to another. Based on this concept, we developed a prototype that transmits footsteps captured by multiple microphones installed on the floor surface to another space and presents a moving vibration source by switching between multiple transducers on the floor's underside. Preliminary experiments with the prototype confirmed that the direction and trajectory of the vibration source can be perceived to some extent.	https://dl.acm.org/doi/abs/10.1145/3681756.3697926	Takahiro Kusabuka, Yuichi Maki, Kakagu Komazaki, Masafumi Suzuki, Hiroshi Chigira, Takayoshi Mochizuki
Viewtify: Next-Generation Medical Image Viewer with Stereoscopic Display	Viewtify® fully leverages a game engine and GPU to generate and render high-quality 3DCG from CT and MRI images in real time. By using stereoscopic displays, it presents 3D visuals with depth information. Its high-speed processing also enables the real-time display of 4D CT and 4D MRI images as animated 3DCG.	https://dl.acm.org/doi/abs/10.1145/3681757.3697047	Hirofumi Seo
Visualization Methods for Manual Wheelchair Training: Impact on Communication Between Coaches and Users	This study evaluates the effectiveness of a proposed visualization method for enhancing communication regarding skill improvement between wheelchair users and coaches. Two measurements were conducted to observe changes in communication dynamics and skill development. The study involved recording and analyzing a coach's evaluation of a user's 40-m sprint utilizing video, pose estimation, and sensor data graphs. The interactions between the coach and the user were subsequently analyzed to elucidate how communication evolved and to identify any improvements in the skills of users. The findings suggest that integrating these visualization tools may enhance discussions on skill enhancement and contribute to more effective training outcomes.	https://dl.acm.org/doi/abs/10.1145/3681756.3697893	Xu Han, Mina Shibasaki, Saki Sakaguchi, Asuka Mano, Tsuyoshi Nakayama, Yuji Higashi, Kumiko Kushiyama
What's New in Pixar's Presto: ML Posing, Invertible Rigs, and Interactive Motion Blur	"This presentation features three distinct technologies that together will demonstrate a unique animation experience to the SIGGRAPH Asia audience. Our ML Posing technology is the realization of the SIGGRAPH Asia 2023 paper ""Pose and Skeleton-aware Neural IK for Pose and Motion Editing"" running live in a production animation setting. We'll be demonstrating on Buzz Lightyear, and as we manipulate the ML Posing handles, the character does feel ""alive"" in a way that feels unique compared to traditional workflows. Less flashy, but actually far more involved, is the underlying ""Invertible Rig"" technology that ML Posing utilizes. This technology is many years in the making and represents a fundamentally new approach to rig construction: each rig component can run bi-drectionally, thus making the animation controls and rig joints fully invertible at a fundamental level. Finally, interactive motion blur in Presto's viewport realizes a longtime animation request of visualizing motion blur as they animate."	https://dl.acm.org/doi/abs/10.1145/3681757.3697056	Paul Kanyuk, Arnold Moon, Haldean Brown, Matthias Goerner
Wireless Vibrant Virtual Walker: Wireless Foot Vibration Device for Virtual Walking Experience	This research proposes a wireless foot vibration device designed to enhance virtual walking experiences in virtual environments. The device, constructed from snowboard bindings and 3D-printed parts, features vibrators and pressure sensors to provide tactile feedback and control walking direction. Users can navigate virtual environments, created in Unity, by shifting their weight without moving their legs. This system provides a realistic walking sensation through synchronized foot vibrations corresponding to various ground textures. The compact design offers high immersion and freedom, suitable for use in standing, seated, or lying down postures, overcoming physical constraints of traditional systems.	https://dl.acm.org/doi/abs/10.1145/3681759.3688931	Junya Nakamura, Michiteru Kitazaki
XR Avatar Prototype for Art Performance Supporting the Inclusion of Neurodiverse Artists	Utilizing volumetric video capture technology and augmented reality, we have developed an extended reality prototype to support the development of a hybrid Japanese Noh performance involving neurodiverse sound artists and a professional Noh singer. Through augmented reality, the volumetric video capture of the Noh performer is integrated into the live production to accommodate the needs of the neurodiverse artists. The recorded performer augmented within a physical diorama of a Noh theatre stage is used flexibly as a surrogate virtual avatar by the sound artists in developing, rehearsing, and performing. Through the artists' reflections we offer their preliminary insights in process of conceiving a performance that is mediated through extended reality tools.	https://dl.acm.org/doi/abs/10.1145/3681756.3697932	Shigenori Mochizuki, Jonathan Duckworth, Ross Eldridge, James Hullick
Zenbu Koko - A mixed reality platform for inward contemplation	We present the first showcase of Zenbu Koko, a XR meditation platform, developed by All Here and designed in collaboration with Kengo Kuma and Associates. This platform presents a 5 minute immersive experience that guides participants on a journey focused on self-awareness and inner sensations. It features immersive visuals and audio, meditation guidance, haptic feedback, and a tool for reconstructing and displaying participants' bodies in virtual environments using depth sensor cameras. Originally conceived as a project bridging neuroscience and meditation, this platform has been accepted for a talk presentation at SIGGRAPH Denver in 2024. We aim to provide a first public demonstration here.	https://dl.acm.org/doi/abs/10.1145/3681759.3688915	Loup Vuarnesson, Richard David Nelson, Erkin Bek
[INDRA] Interactive Deep-dreaming Robotic Artist: Perceived artistic agency when collaborating with Embodied AI	AI art generators such as DALL-E and MidJourney create artwork after man-made art styles in seconds, leveraging developments in machine learning. Traditional art, such as painting and sculpture, has long been a cornerstone of cultural expression. Human value-centered design considerations are essential when implementing AI for traditional artists, balancing automation and meaningful human control levels to produce a positive sense of creation. This research explores artistic agency in human-computer collaborative painting through embodied AI. We present INDRA, an Interactive Deep-Dreaming Robotic Artist to enhance fine art capabilities and assist users dynamically. INDRA is designed to be an artist-friendly AI agent inspired to improve the relationship between AI and creatives.	https://dl.acm.org/doi/abs/10.1145/3681756.3697950	Marina Nakagawa, Sohei Wakisaka
k-DOP Clipping: Robust Ghosting Mitigation in Temporal Antialiasing	"Temporal antialiasing is one of the most common methods for removing aliasing artifacts in contemporary real-time rendering, based on utilizing reprojected color data from previous frames. One typical issue with the method is ghosting: moving objects leaving a wake of visual trails. To mitigate this, a common technique is to validate and rectify reused history colors by comparing and clipping them to the color neighborhoods of the current frame's pixels. Previous, bounding box based methods are only situationally effective and cause significant ghosting in less favorable circumstances. We propose using k-Discrete Oriented Polytopes (""k-DOPs"") for more robust neighborhood clipping. For a 0.2 ms performance overhead, our method more reliably mitigates ghosting across scenes where previous methods have inconsistent results."	https://dl.acm.org/doi/abs/10.1145/3681758.3697996	Julius Ikkala, Tuomas Lauttia, Pekka Jääskeläinen, Markku Mäkitalo
"""MONOLITH"": Exploring the Virtual Reality Viewing Experience of Non-Linear and Multi-Threaded Narrative Structures"	"This paper introduces ""MONOLITH"", a non-linear, multi-threaded narrative film based on VR headset technology. Viewers immerse themselves in the VR experience from a first-person perspective, navigating through time and space to witness stories triggered by a monolith amidst the evolution of civilization. The film uses a multi-threaded structure. The overt thread highlights key events and character interactions with the monolith across different periods, while the covert thread reveals the protagonist's background and identity metaphors. In this science fiction story, viewers explore the complex relationships between time, consciousness, and human nature."	https://dl.acm.org/doi/abs/10.1145/3681759.3688930	Yunuo Chen, Xianzhe Long, Weitai Xu, Ling Zou
