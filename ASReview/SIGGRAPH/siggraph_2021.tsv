title	abstract	url	authors
"""Can the subaltern speak?"": critical making in design"	The Bandari women from the southern coast of Iran are famous for their intriguing masks, known as Niqab masks. Legend has it that the practice started during Portuguese colonial rule as a way of protecting the wearer, not only from the harsh sun of the Persian Gulf, but also from slave masters looking for pretty women. Viewed from a contemporary perspective, these masks can be seen as a means of protecting women from patriarchal and colonial oppression.	https://dl.acm.org/doi/abs/10.1145/3450507.3457429	Behnaz Farahi
3D Meister Planner: The simplest floor planner worldwide	3D Meister Planner is the simplest real time floor planner worldwide. It is a Progressive Web App in which users are able to define and customize their room in 2D and 3D. Users can position and select which elements are present and choose from the catalogue of products that the client offers, including wall and floor designs. Objects can be visualized independently using the 3D Product Viewer, and in the room using the 3D Room Viewer. 3D meister Planner is based on WebGL API which allows fast real time hardware accelerated computer graphics on mobile devices and home computers.	https://dl.acm.org/doi/abs/10.1145/3450415.3464405	Ivan Moreno, Delia Otetea
3D weaving with curved ribbons	Basket weaving is a traditional craft for creating curved surfaces as an interwoven array of thin, flexible, and initially straight ribbons. The three-dimensional shape of a woven structure emerges through a complex interplay of the elastic bending behavior of the ribbons and the contact forces at their crossings. Curvature can be injected by carefully placing topological singularities in the otherwise regular weaving pattern. However, shape control through topology is highly non-trivial and inherently discrete, which severely limits the range of attainable woven geometries. Here, we demonstrate how to construct arbitrary smooth free-form surface geometries by weaving carefully optimized ribbons. We present an optimization-based approach to solving the inverse design problem for such woven structures. Our algorithm computes the ribbons' planar geometry such that their interwoven assembly closely approximates a given target design surface in equilibrium. We systematically validate our approach through a series of physical prototypes to show a broad range of new woven geometries that is not achievable by existing methods. We anticipate our computational approach to significantly enhance the capabilities for the design of new woven structures. Facilitated by modern digital fabrication technology, we see potential applications in material science, bio- and mechanical engineering, art, design, and architecture.	https://dl.acm.org/doi/abs/10.1145/3450626.3459788	Yingying Ren, Julian Panetta, Tian Chen, Florin Isvoranu, Samuel Poincloux, Christopher Brandt, Alison Martin, Mark Pauly
@A Tiny Tale	A dog gets abandoned on the side of the road. Attached to a street light, he stays alone until the day he meets a young astronaut wannabe and a professional cyclist who keeps on trying to beat her highest score.	https://dl.acm.org/doi/abs/10.1145/3446562.3448972	Sylvain Cuvillier, Chloé Bourdic, Théophile Coursimault, Noémie Halberstam, Maÿlis Mosny, Zijing Ye
@Blood Song: A Silent Ballad	"""Blood Song: A Silent Ballad"" is based on the graphic novel authored by Eric Drooker. It's about an innocent young girl whose life was drastically affected by a war. Her surreal journey took place from childhood to adulthood and from a small village to an urban life."	https://dl.acm.org/doi/abs/10.1145/3446562.3458514	Phanuthep Sutthithepthamrong, Vadim Marshalkovskiy
@Carried Away	A dark comedy about antagonist twins who have to fulfill their mother's last will: Bury her corpse in the forest.	https://dl.acm.org/doi/abs/10.1145/3446562.3452903	Etienne Fagnère
@DNEG VFX showcase	At DNEG we believe in the positive power of storytelling. We are celebrating over 20 years of Award-winning visual effects. Enjoy our DNEG 2021 VFX showcase!	https://dl.acm.org/doi/abs/10.1145/3446562.3458692	Nicolas Chevallier
@Dead End	Our story takes place in a cyberpunk universe. We follow a character named Esis, who one day come across a robot in an alley. The latter being inert, she decides to conduct an experiment.	https://dl.acm.org/doi/abs/10.1145/3446562.3452015	Maxime Recuyer
@Flora & Ulysses	The film follows 10-year-old Flora and her journey in protecting her superhero CG squirrel named Ulysses.	https://dl.acm.org/doi/abs/10.1145/3446562.3458688	Gregory Diaz
@Gladius	In ancient Rome, Marcus has an anxiety attack and is lying on the ground, he remembers his past.	https://dl.acm.org/doi/abs/10.1145/3446562.3450498	Dylan Brown, Noah Stacey, Guillaume Belanger
@Hardspace: Shipbreaker - Opening Cinematic (Early Access)	300 years from now, humankind has industrialized much of the solar system. Corporations are all powerful. Earth has deteriorated into a place of squalor and decay. In orbit, a new breed of worker has emerged - the Shipbreaker. The labor is extremely dangerous, but for a select few, the hazard pay is worth the risk.	https://dl.acm.org/doi/abs/10.1145/3446562.3458912	Maxime Le Chapelain
@I am a Pebble	Bubble a young otter, lives with three mossy stones and thinks of them as her family. Bulle imagines them as real otters, but as she becomes aware of their true nature, she has to face her loneliness.	https://dl.acm.org/doi/abs/10.1145/3446562.3450280	Ian Spendloff, Johannes Sambs, Tim Jenkinson, Lucy Hare
@Jingle Jangle: A Christmas Journey - animated sequences	Framestore created nearly eight minutes of full CG animation, designed to reflect the magically inventive aesthetic of David E. Talbert's film and establishes a world within a world which is loaded with emotional resonance.	https://dl.acm.org/doi/abs/10.1145/3446562.3458574	Cezary Albiński, Marcelina Salwin
@Julian Tuwim: To Everyman	"""Julian Tuwin: To Everyman"" it's a manifesto that uncovers the techniques of political propaganda. The film reveals the manipulations to paint war as necessary and make it widely accepted by the society. This animated short shows a neverending circle and can be seamlessly looped. It starts with a spark to ignite the conflict and seems to end with the remembrance of the fallen. However, if played continuously, the story moves to another hotbed of tension."	https://dl.acm.org/doi/abs/10.1145/3446562.3458685	Raphael Pfyffer, Elena Heller, Marina Kunz, Kai Müri
@La vida de una Piñata	A piñata experiences the same fateful day over and over again, on which it is bought by a girl and finds death at her garden party. Shocked, the piñata tries to break out of this eternal cycle.	https://dl.acm.org/doi/abs/10.1145/3446562.3457534	Ka yu Leung
@Louis' shoes	Louis, an eight-and-a-half-year-old autistic kid, arrives in his new school and is about to introduce himself.	https://dl.acm.org/doi/abs/10.1145/3446562.3452380	Hugo Caby, Antoine Dupriez, Aubin Kubiak, Lucas Lermytte, Zoé Devise
@Meerkat	"Wetag Digital's ""Meerkat"" is a real-time animated short featuring a winsome tussle between a meerkat and an eagle. The production allowed Weta to push how far they could take movie-quality hair, fur, and feathers created with real-time tools, and rendered entirely in Unreal Engine."	https://dl.acm.org/doi/abs/10.1145/3446562.3458690	Simone Giampaolo
@Migrants	Two polar bears are driven into exile due to global warming. They will encounter brown bears along their journey, with whom they will try to cohabitate.	https://dl.acm.org/doi/abs/10.1145/3446562.3448966	Keith Miller
@Only a Child	"""Only a Child"" is a visual poem created by over 20 animation directors under the artistic supervision of Simone Giampaolo, which gives shape and color to the originalwords spoken by Severn Suzuki at the UN Summit in Rio in 1992, a child's desperate call to action for the future of our planet. An omnibus film celebrating the environmental youth movement 30 years in the making."	https://dl.acm.org/doi/abs/10.1145/3446562.3449273	Harry Chen
@Signal Lingers	"""Signal Lingers"" is about a mysterious man trying to revive an abandoned planet and bring back its vibrant nature."	https://dl.acm.org/doi/abs/10.1145/3446562.3450955	Dawn Fidrick, Bob Niemack
@Signs of Life	"There is plenty of life here on Earth, but where else might it be found? In ""Signs of Life"", we discover what it took to put life in the universe in the one place where we know it exists. We see how the laws of chemistry and physics drive cosmic evolution, and we travel through the solar system, the MilkyWay Galaxy, and beyond in a search for more signs of life."	https://dl.acm.org/doi/abs/10.1145/3446562.3453875	Taz Tron Delix, Pablo Gostanian, Agustin Valcarenghi
@Stranded	Alaska, late 19th century, a strong trapper named Hawk meets an huge and uncredible radiant moose herald of the apocalypse.	https://dl.acm.org/doi/abs/10.1145/3446562.3450501	Di Lu
@Super Generic	"A character model sheet tries to change himself after getting critique from an instructor saying that he was ""super generic."""	https://dl.acm.org/doi/abs/10.1145/3446562.3457584	Chris Lawrence, Max Solomon, Graham Page, Shawn Hillier
@The Midnight Sky	From crisp, frozen snowscapes to the depths of outer space, Framestore's VFX team created the pixel-perfect backdrop to George Clooney's dystopian sci-fi epic.	https://dl.acm.org/doi/abs/10.1145/3446562.3458713	Camille Di Dio
@The Source of the Mountains	The Paccha-Picchus are festive little creatures. They live a carefree daily life in sync with the mountains. When the mountains come, their oasis rises and they are lifted up into a winter climate. The Paccha-Picchus are very fond of the winter climate, which is vital for them. But one day, the mountains stop coming and the restless Kinko decides to go looking for them.	https://dl.acm.org/doi/abs/10.1145/3446562.3449275	Ariel Song
@The Very Hungry Duck	Narrated like a children's book, a hungry duck indulges in the human world's copious amounts of food, unknowing of the evils that follow it.	https://dl.acm.org/doi/abs/10.1145/3446562.3457582	Alberto Mielo
@Tipping Point	In a near and dystopian future in London, we are witnessing the desperate escape of a masked street-artist pursued by security forces. Despite his agility, he owes his salvation to a taxi driver who decides to act against the government controlling the media and technology and threatening citizens.	https://dl.acm.org/doi/abs/10.1145/3446562.3450979	Kel Elkins, Dan Gallagher, Adriana Manrique Gutierrez, Jonathan North, Ernie Wright
@Tour of Asteroid Bennu	Take a narrated tour of asteroid Bennu's remarkable terrain.	https://dl.acm.org/doi/abs/10.1145/3446562.3456718	Alexandre Manzanares, Guillaume Cosenza, Philipp Merten, Silvan Moutte-Roulet
@Trésor	Two explorers in search of a forgotten treasure disturb the romance between an octopus and his beloved.	https://dl.acm.org/doi/abs/10.1145/3446562.3458547	Aphton Corbin, Erik Langley
@Twenty Something	Adulting can be hard. Some days you're nailing it, while other days, you're just a stack of kids hiding in a trench coat hoping no one notices. Gia finds herself in this exact scenario the night of her 21st birthday. This is a story about the insecurities of adulting and how we're all just faking it 'till we make it.	https://dl.acm.org/doi/abs/10.1145/3446562.3456720	Alexandre Amancio
@Unknown 9: Awakening Teaser Trailer	Raised on the streets of Kolkata India and haunted by visions of her own death, Haroona struggles to understand her mysterious innate abilities to manipulate the unseen. A mentor soon helps Haroona hone her gifts, teaches her to access the mysterious hidden dimension known as The Fold and propels her on a journey to unlock the mysteries of this new realm.	https://dl.acm.org/doi/abs/10.1145/3446562.3457375	Peter Mindek, Ivan Viola, Ondrej Strnad, Ciril Bohak, Sai Li, Tobias Klein
@What does a virus actually look like?	This is the first time you can see real (flash-frozen) coronavirus in 3D.	https://dl.acm.org/doi/abs/10.1145/3446562.3458551	Marc Messenger, Kevin Vanderjagt, David Stephens, Fabio Zungrone
A Hybrid 2D-3D Tangible Interface for Virtual Reality	Virtual Reality (VR) controllers are widely used for easy object selection and manipulation as a primary 3D input method in the virtual environment. Mobile devices with touchscreens like smartphones or tablets provide precise 2D tangible inputs. This research combines a VR controller and a touch-based smartphone to create a novel hybrid 2D-3D interface for enhanced VR interaction. We present the interface design and its implementation and also demonstrate four featured scenarios with the hybrid interface.	https://dl.acm.org/doi/abs/10.1145/3450618.3469166	Li Zhang, Weiping He, Huidong Bai, Jun He, Yiyue Qiao, Mark Billinghurst
A New Normal: A story about warmth, hope, and family, A New Normal explores themes of ‘home' and 'belonging' combining elements and processes of traditional narrative filmmaking with augmented reality.	As we learn to keep social and familial connections alive amidst the pandemic and rely heavily on digital media, I realize this has been my own 'normal' for most of the past decade. After immigrating to the US from India, my ability to travel home and be physically present with my family became limited, particularly after the 2016 elections. Thinking about home and belonging today, my thoughts go to my sister in Copenhagen and my parents in New Delhi. Using Augmented Reality as a storytelling tool for this film, allows me to see the evolving definition of 'home' through the eyes of my family. My experiments in early 2020 as an artist in the Adobe Aero AR Residency, helped explore the possibilities and limitations of AR, as experienced through the Adobe Aero application. Following this, I was interested in seeing how AR could fit into the scope of a narrative project and how it would interact with a traditional animation or video workflow when used by a filmmaker. I discovered many efficiencies during the production process, the most powerful being in-camera, real-time compositing. The process of creating 'A New Normal' combines the technical and conceptual workflows of both animation and documentary filmmaking. One scene has been made available to view in AR via the Adobe Aero app on iOS. Shot entirely in my apartment while sheltering in place, A New Normal is a product of remote collaboration between artists based in Copenhagen, Madrid, New Delhi, Mumbai and Los Angeles. In this short, my everyday digital conversations with family are overlaid with AR versions of my parents and sister in my own environment, to co-create a mixed reality experience that for the time being, is the closest thing I have to the feeling of home.	https://dl.acm.org/doi/abs/10.1145/3450615.3464525	Asavari Kumar, Shaivalini Kumar
A Pipeline Retrospective on USD & Conduit	Over the past three years, Blue Sky Studios built a USD-centric layer on top of its next generation pipeline framework, Conduit. This transition involved mapping the legacy Blue Sky workflows into USD constructs. In addition, direct artist feedback during the delivery of six short films provided insights that informed the evolution of the Conduit backend to support these modernized workflows.	https://dl.acm.org/doi/abs/10.1145/3450623.3464633	Rebecca Hallac, Tim Hoff, Chris Rydalch, Ryan Bland, Oliver Staeubli, Karyn Buczek Monschein, Mark McGuire
A fast sparse QR factorization for solving linear least squares problems in graphics	A wide range of problems in computer graphics and vision can be formulated as sparse least squares problems. For example, Laplacian mesh deformation, Least Squares Conformal Maps, Poisson image editing, and as-rigid-as-possible (ARAP) image warping involve solving a linear or non-linear sparse least squares problem. High performance is crucial in many of these applications for interactive user feedback. For these applications, we show that the matrices produced by factorization methods such as QR have a special structure: the off-diagonal blocks are low-rank. We leverage this property to produce a fast sparse approximate QR factorization, spaQR, for these matrices in near-linear time. In our benchmarks, spaQR shows up to 57% improvement over solving the normal equations using Cholesky and 63% improvement over a standard preconditioner with Conjugate Gradient Least Squares (CGLS).	https://dl.acm.org/doi/abs/10.1145/3450623.3464639	Abeynaya Gnanasekaran, Eric Darve
A fitted radiance and attenuation model for realistic atmospheres	We present a fitted model of sky dome radiance and attenuation for realistic terrestrial atmospheres. Using scatterer distribution data from atmospheric measurement data, our model considerably improves on the visual realism of existing analytical clear sky models, as well as of interactive methods that are based on approximating atmospheric light transport. We also provide features not found in fitted models so far: radiance patterns for post-sunset conditions, in-scattered radiance and attenuation values for finite viewing distances, an observer altitude resolved model that includes downward-looking viewing directions, as well as polarisation information. We introduce a fully spherical model for in-scattered radiance that replaces the family of hemispherical functions originally introduced by Perez et al., and which was extended for several subsequent analytical models: our model relies on reference image compression via tensor decomposition instead.	https://dl.acm.org/doi/abs/10.1145/3450626.3459758	Alexander Wilkie, Petr Vevoda, Thomas Bashford-Rogers, Lukáš Hošek, Tomáš Iser, Monika Kolářová, Tobias Rittig, Jaroslav Křivánek
A generic framework for physical light transport	Physically accurate rendering often calls for taking the wave nature of light into consideration. In computer graphics, this is done almost exclusively locally, i.e. on a micrometre scale where the diffractive phenomena arise. However, the statistical properties of light, that dictate its coherence characteristics and its capacity to give rise to wave interference effects, evolve globally: these properties change on, e.g., interaction with a surface, diffusion by participating media and simply by propagation. In this paper, we derive the first global light transport framework that is able to account for these properties of light and, therefore, is fully consistent with Maxwell's electromagnetic theory. We show that our framework is a generalization of the classical, radiometry-based light transport---prominent in computer graphics---and retains some of its attractive properties. Finally, as a proof of concept, we apply the presented framework to a few practical problems in rendering and validate against well-studied methods in optics.	https://dl.acm.org/doi/abs/10.1145/3450626.3459791	Shlomi Steinberg, Ling-Qi Yan
A gradient-based framework for 3D print appearance optimization	In full-color inkjet 3D printing, a key problem is determining the material configuration for the millions of voxels that a printed object is made of. The goal is a configuration that minimises the difference between desired target appearance and the result of the printing process. So far, the techniques used to find such a configuration have relied on domain-specific methods or heuristic optimization, which allowed only a limited level of control over the resulting appearance. We propose to use differentiable volume rendering in a continuous material-mixture space, which leads to a framework that can be used as a general tool for optimising inkjet 3D printouts. We demonstrate the technical feasibility of this approach, and use it to attain fine control over the fabricated appearance, and high levels of faithfulness to the specified target.	https://dl.acm.org/doi/abs/10.1145/3450626.3459844	Thomas Klaus Nindel, Tomáš Iser, Tobias Rittig, Alexander Wilkie, Jaroslav Křivánek
A mathematical foundation for foundation paper pieceable quilts	Foundation paper piecing is a popular technique for constructing fabric patchwork quilts using printed paper patterns. But, the construction process imposes constraints on the geometry of the pattern and the order in which the fabric pieces are attached to the quilt. Manually designing foundation paper pieceable patterns that meet all of these constraints is challenging. In this work we mathematically formalize the foundation paper piecing process and use this formalization to develop an algorithm that can automatically check if an input pattern geometry is foundation paper pieceable. Our key insight is that we can represent the geometric pattern design using a certain type of where nodes represent faces and hyperedges represent connecting two or more nodes. We show that determining whether the pattern is paper pieceable is equivalent to checking whether this hypergraph is acyclic, and if it is acyclic, we can apply a algorithm to the hypergraph to generate viable sewing orders for the pattern geometry. We implement this algorithm in a design tool that allows quilt designers to focus on producing the geometric design of their pattern and let the tool handle the tedious task of determining whether the pattern is foundation paper pieceable.	https://dl.acm.org/doi/abs/10.1145/3450626.3459853	Mackenzie Leake, Gilbert Bernstein, Abe Davis, Maneesh Agrawala
A momentum-conserving implicit material point method for surface tension with contact angles and spatial gradients	We present a novel Material Point Method (MPM) discretization of surface tension forces that arise from spatially varying surface energies. These variations typically arise from surface energy dependence on temperature and/or concentration. Furthermore, since the surface energy is an interfacial property depending on the types of materials on either side of an interface, spatial variation is required for modeling the contact angle at the triple junction between a liquid, solid and surrounding air. Our discretization is based on the surface energy itself, rather than on the associated traction condition most commonly used for discretization with particle methods. Our energy based approach automatically captures surface gradients without the explicit need to resolve them as in traction condition based approaches. We include an implicit discretization of thermomechanical material coupling with a novel particle-based enforcement of Robin boundary conditions associated with convective heating. Lastly, we design a particle resampling approach needed to achieve perfect conservation of linear and angular momentum with Affine-Particle-In-Cell (APIC) [Jiang et al. 2015]. We show that our approach enables implicit time stepping for complex behaviors like the Marangoni effect and hydrophobicity/hydrophilicity. We demonstrate the robustness and utility of our method by simulating materials that exhibit highly diverse degrees of surface tension and thermomechanical effects, such as water, wine and wax.	https://dl.acm.org/doi/abs/10.1145/3450626.3459874	Jingyu Chen, Victoria Kala, Alan Marquez-Razon, Elias Gueidon, David A. B. Hyde, Joseph Teran
A non-exponential transmittance model for volumetric scene representations	We introduce a novel transmittance model to improve the volumetric representation of 3D scenes. The model can represent opaque surfaces in the volumetric light transport framework. Volumetric representations are useful for complex scenes, and become increasingly popular for level of detail and scene reconstruction. The traditional exponential transmittance model found in volumetric light transport cannot capture correlations in visibility across volume elements. When representing opaque surfaces as volumetric density, this leads to both bloating of silhouettes and light leaking artifacts. By introducing a parametric non-exponential transmittance model, we are able to approximate these correlation effects and significantly improve the accuracy of volumetric appearance representation of opaque scenes. Our parametric transmittance model can represent a continuum between the linear transmittance that opaque surfaces exhibit and the traditional exponential transmittance encountered in participating media and unstructured geometries. This covers a large part of the spectrum of geometric structures encountered in complex scenes. In order to handle the spatially varying transmittance correlation effects, we further extend the theory of non-exponential participating media to a heterogeneous transmittance model. Our model is compact in storage and computationally efficient both for evaluation and for reverse-mode gradient computation. Applying our model to optimization algorithms yields significant improvements in volumetric scene appearance quality. We further show improvements for relevant applications, such as scene appearance prefiltering, image-based scene reconstruction using differentiable rendering, neural representations, and compare it to a conventional exponential model.	https://dl.acm.org/doi/abs/10.1145/3450626.3459815	Delio Vicini, Wenzel Jakob, Anton Kaplanyan
A perceptual model for eccentricity-dependent spatio-temporal flicker fusion and its applications to foveated graphics	Virtual and augmented reality (VR/AR) displays strive to provide a resolution, framerate and field of view that matches the perceptual capabilities of the human visual system, all while constrained by limited compute budgets and transmission bandwidths of wearable computing systems. Foveated graphics techniques have emerged that could achieve these goals by exploiting the falloff of spatial acuity in the periphery of the visual field. However, considerably less attention has been given to temporal aspects of human vision, which also vary across the retina. This is in part due to limitations of current eccentricity-dependent models of the visual system. We introduce a new model, experimentally measuring and computationally fitting eccentricity-dependent critical flicker fusion thresholds jointly for both space and time. In this way, our model is unique in enabling the prediction of temporal information that is imperceptible for a certain spatial frequency, eccentricity, and range of luminance levels. We validate our model with an image quality user study, and use it to predict potential bandwidth savings 7X higher than those afforded by current spatial-only foveated models. As such, this work forms the enabling foundation for new temporally foveated graphics techniques.	https://dl.acm.org/doi/abs/10.1145/3450626.3459784	Brooke Krajancich, Petr Kellnhofer, Gordon Wetzstein
A time-independent deformer for elastic contacts	We present a purely geometric, time-independent deformer resolving local contacts between elastic objects, including self-collisions between adjacent parts of the same object that often occur in character skinning animation. Starting from multiple meshes in intersection, our deformer first computes the parts of the surfaces remaining in contact, and then applies a procedural displacement with volume preservation. Although our deformer processes each frame independently, it achieves temporally continuous deformations with artistic control of the bulge through few pseudo-stiffness parameters. The plausibility of the deformation is further enhanced by anisotropically spreading the volume-preserving bulge. The result is a robust, real-time deformer that can handle complex geometric configurations such as a ball squashed by a hand, colliding lips, bending fingers, etc.	https://dl.acm.org/doi/abs/10.1145/3450626.3459879	Camille Brunel, Pierre Bénard, Gaël Guennebaud
A unified second-order accurate in time MPM formulation for simulating viscoelastic liquids with phase change	We assume that the viscous forces in any liquid are simultaneously and , and introduce the [McLeish and Larson 1998; Oishi et al. 2012; Verbeeten et al. 2001] to computer graphics to design a unified constitutive model for viscosity that generalizes prior models, such as Oldroyd-B, the Upper-convected Maxwell (UCM) model [Sadeghy et al. 2005], and classical Newtonian viscosity under one umbrella, recovering each of them with different parameter values. Implicit discretization of our model via backward Euler recovers the variational Stokes solver of [Larionov et al. 2017] for Newtonian viscosity. For greater accuracy, however, we introduce the second-order accurate Generalized Single Step Single Solve (GS4) scheme [Tamma et al. 2000; Zhou and Tamma 2004] to computer graphics, which recovers all prior second-order accurate time integration schemes to date. Using GS4 and our generalized constitutive model, we present a Material Point Method (MPM) for simulating various viscoelastic liquid behaviors, such as classical liquid rope coiling, buckling, folding, and shear thinning/thickening. In addition, we show how to couple our viscoelastic liquid simulator with the recently introduced non-Fourier heat diffusion solver [Xue et al. 2020] for simulating problems with phase change, such as melting chocolate and digital fabrication with 3D printing. While the discretization of heat diffusion is slightly different within GS4, we show that it can still be efficiently solved using an assembly-free Multigrid-preconditioned Conjugate Gradients solver. We present end-to-end 3D simulations to demonstrate the versatility of our framework.	https://dl.acm.org/doi/abs/10.1145/3450626.3459820	Haozhe Su, Tao Xue, Chengguizi Han, Chenfanfu Jiang, Mridul Aanjaneya
AMP: adversarial motion priors for stylized physics-based character control	Synthesizing graceful and life-like behaviors for physically simulated characters has been a fundamental challenge in computer animation. Data-driven methods that leverage motion tracking are a prominent class of techniques for producing high fidelity motions for a wide range of behaviors. However, the effectiveness of these tracking-based methods often hinges on carefully designed objective functions, and when applied to large and diverse motion datasets, these methods require significant additional machinery to select the appropriate motion for the character to track in a given scenario. In this work, we propose to obviate the need to manually design imitation objectives and mechanisms for motion selection by utilizing a fully automated approach based on adversarial imitation learning. High-level task objectives that the character should perform can be specified by relatively simple reward functions, while the low-level style of the character's behaviors can be specified by a dataset of unstructured motion clips, without any explicit clip selection or sequencing. For example, a character traversing an obstacle course might utilize a task-reward that only considers forward progress, while the dataset contains clips of relevant behaviors such as running, jumping, and rolling. These motion clips are used to train an adversarial motion prior, which specifies style-rewards for training the character through reinforcement learning (RL). The adversarial RL procedure automatically selects which motion to perform, dynamically interpolating and generalizing from the dataset. Our system produces high-quality motions that are comparable to those achieved by state-of-the-art tracking-based techniques, while also being able to easily accommodate large datasets of unstructured motion clips. Composition of disparate skills emerges automatically from the motion prior, without requiring a high-level motion planner or other task-specific annotations of the motion clips. We demonstrate the effectiveness of our framework on a diverse cast of complex simulated characters and a challenging suite of motor control tasks.	https://dl.acm.org/doi/abs/10.1145/3450626.3459670	Xue Bin Peng, Ze Ma, Pieter Abbeel, Sergey Levine, Angjoo Kanazawa
Acorn: adaptive coordinate networks for neural scene representation	Neural representations have emerged as a new paradigm for applications in rendering, imaging, geometric modeling, and simulation. Compared to traditional representations such as meshes, point clouds, or volumes they can be flexibly incorporated into differentiable learning-based pipelines. While recent improvements to neural representations now make it possible to represent signals with fine details at moderate resolutions (e.g., for images and 3D shapes), adequately representing large-scale or complex scenes has proven a challenge. Current neural representations fail to accurately represent images at resolutions greater than a megapixel or 3D scenes with more than a few hundred thousand polygons. Here, we introduce a new hybrid implicit-explicit network architecture and training strategy that adaptively allocates resources during training and inference based on the local complexity of a signal of interest. Our approach uses a multiscale block-coordinate decomposition, similar to a quadtree or octree, that is optimized during training. The network architecture operates in two stages: using the bulk of the network parameters, a coordinate encoder generates a feature grid in a single forward pass. Then, hundreds or thousands of samples within each block can be efficiently evaluated using a lightweight feature decoder. With this hybrid implicit-explicit network architecture, we demonstrate the first experiments that fit gigapixel images to nearly 40 dB peak signal-to-noise ratio. Notably this represents an increase in scale of over 1000X compared to the resolution of previously demonstrated image-fitting experiments. Moreover, our approach is able to represent 3D shapes significantly faster and better than previous techniques; it reduces training times from days to hours or minutes and memory requirements by over an order of magnitude.	https://dl.acm.org/doi/abs/10.1145/3450626.3459785	Julien N. P. Martel, David B. Lindell, Connor Z. Lin, Eric R. Chan, Marco Monteiro, Gordon Wetzstein
Action Reproducer: Virtual Reality Rehabilitation System to Reduce Fear of Walking	Walking is a daily activity for most people. Lack of opportunities or inability to walk may cause both mental and physical health problems. However, in some circumstances, such as during a global pandemic, fear of heights, or withdrawal from society (hikikomori), people tend to walk less. To overcome such issues, we developed a walking rehabilitation system, Action Reproducer, to encourage people to walk in a virtual environment, e.g., around sightseeing spots, or to train walking on a high building. The proposed system comprised a motion seat to present vestibular sensation to the waist, slider-pedal devices to provide motion sensation to the lower limbs, wearable pseudo force devices to pull sensation to the fingers, and an avatar in the virtual environment to hold the user's hand during walking. This system can reduce user burden because the user simply sits on the motion seat and perceives multiple sensations that allow them to enjoy walking activities for long periods of time. During the virtual conference, we will conduct a live demonstration and present the details of our system with some interactive content, such as virtual traveling and walk rehabilitation between high buildings.	https://dl.acm.org/doi/abs/10.1145/3450616.3464522	Minori Unno, Yusuke Kikuchi, Kentaro Yamaoka, Gaku Sueta, Vibol Yem, Yasushi Ikei
Adaptive Radiometric Compensation on Deforming Surfaces	In this research, we propose an adaptive radiometric compensation method, which uses only a projector and a camera, on continuously deforming projection surfaces. Radiometric compensation has been widely studied as a technique for making various objects usable as screens, by canceling out the influence of the color and pattern of the projection target. However, since it is necessary to continuously maintain the inter-pixel correspondence between a projector and a camera, to date, the projection target has been limited to stationary objects. Therefore, we propose a method to estimate the inter-pixel correspondence in real-time, using only a normal projector and camera. The method expands the scope of application of projection mapping greatly, by applying radiometric compensation to deforming clothes, and making them available as screens.	https://dl.acm.org/doi/abs/10.1145/3450618.3469150	Kazuma Yoshimura, Naoki Hashimoto
Adding Style, Folds, and Energy to the Costumes of Soul	The Human World of Soul takes place in a vibrant New York City, full of life, energy, and everyday people. Our character designers captured this in their expressive drawings, depicting clothing in a complex and artfully messy way. When creating costumes in CG, however, cloth TDs were accustomed to simplifying the designs to make cleaner, more graphic looks. These techniques have been established and refined on our previous films, such as Incredibles 2 and Up. On Soul, we sought to develop a different look for costumes that would support the story, style, and energy of the film.	https://dl.acm.org/doi/abs/10.1145/3450623.3464673	Aimei Kutt, Donald Fong, Tiffany Klohn
Advances in neural rendering	Loss functions for Neural Rendering Jun-Yan Zhu	https://dl.acm.org/doi/abs/10.1145/3450508.3464573	A. Tewari, O. Fried, J. Thies, V. Sitzmann, S. Lombardi, Z. Xu, T. Simon, M. Nießner, E. Tretschk, L. Liu, B. Mildenhall, P. Srinivasan, R. Pandey, S. Orts-Escolano, S. Fanello, M. Guo, G. Wetzstein, J.-Y. Zhu, C. Theobalt, M. Agrawala, D. B Goldman, M. Zollhöfer
African Space Makers	The only way to understand Urban Storytelling is by experiencing it! Choose which film director you want to be and experience urban Africa with your crew. This is your assignment and how you are going to understand what it means to be an African Space Maker, a real urban hero!	https://dl.acm.org/doi/abs/10.1145/3446367.3452359	Sönke Kirchhof, Vincenzo Cavallo Faras, Brian Afande
Agence, A Dynamic Film about (and with) Artificial Intelligence	"Agence is a short ""dynamic film"" that uses AI to power a real-time story. It was co-produced by Transitional Forms and the National Film Board of Canada (NFB). It is available on VR, PC and mobile, but for the purposes of this paper, we will be talking about the VR version, since it most closely matches the director's vision. The film is directed by Pietro Gagliano whose work on interactive stories has spanned many years and technologies. A few years ago he started Transitional Forms to combine real-time storytelling with artificial intelligence. The intention behind that process is twofold: First, we believe that entertainment will soon be driven by AI. And secondly, artificial intelligence is poised to be humanity's greatest tool, and stories might be the best way to make sense of it. To this end, we believe that Agence is an innovative production with bold strides in immersion, interactivity and technology. The approaches taken in this film are novel and unique in their propositions, and may open the door to many new projects that may build upon them."	https://dl.acm.org/doi/abs/10.1145/3450615.3464538	Pietro Gagliano, Casey Blustein, David Oppenheim
AgileGAN: stylizing portraits by inversion-consistent transfer learning	Portraiture as an art form has evolved from realistic depiction into a plethora of creative styles. While substantial progress has been made in automated stylization, generating high quality stylistic portraits is still a challenge, and even the recent popular Toonify suffers from several artifacts when used on real input images. Such StyleGAN-based methods have focused on finding the best latent inversion mapping for reconstructing input images; however, our key insight is that this does not lead to good generalization to different portrait styles. Hence we propose AgileGAN, a framework that can generate high quality stylistic portraits via inversion-consistent transfer learning. We introduce a novel hierarchical variational autoencoder to ensure the inverse mapped distribution conforms to the original latent Gaussian distribution, while augmenting the original space to a multi-resolution latent space so as to better encode different levels of detail. To better capture attribute-dependent stylization of facial features, we also present an attribute-aware generator and adopt an early stopping strategy to avoid overfitting small training datasets. Our approach provides greater agility in creating high quality and high resolution (1024×1024) portrait stylization models, requiring only a limited number of style exemplars (~100) and short training time (~1 hour). We collected several style datasets for evaluation including 3D cartoons, comics, oil paintings and celebrities. We show that we can achieve superior portrait stylization quality to previous state-of-the-art methods, with comparisons done qualitatively, quantitatively and through a perceptual user study. We also demonstrate two applications of our method, image editing and motion retargeting.	https://dl.acm.org/doi/abs/10.1145/3450626.3459771	Guoxian Song, Linjie Luo, Jing Liu, Wan-Chun Ma, Chunpong Lai, Chuanxia Zheng, Tat-Jen Cham
An Examination of View-Settings for Long Texts in VR Reading	To reduce the burden from VR reading of long texts, this study finds the view-settings for better readability and less fatigue. As the view-settings, we focus on the font type, the font color, the font size, and the view-distance from the text. Our results show the relation among the view-settings, the readability, and the fatigue for long texts in VR reading.	https://dl.acm.org/doi/abs/10.1145/3450618.3469164	Seina Kobayashi, Kei Kanari, Mie Sato
An interview with ALEX	"An is a 12-minute interactive experience that engages the participant in a job interview with ALEX, a powerful artificial intelligence HR employed by a speculative tech giant called ""Open Mind Corporation."" Through a science-fiction lens, the experience reveals how artificial intelligence (AI) and the gamification of work can be used as subtle tools of control in the interest of those in power."	https://dl.acm.org/doi/abs/10.1145/3450507.3457428	Carrie Wang
An inverse method for the exploration of layered material appearance	Layered materials exhibit a wide range of appearance, due to the combined effects of absorption and scattering at and between interfaces. Yet most existing approaches let users set the physical parameters of all layers by hand, a process of trial and error. We introduce an inverse method that provides control over BRDF lobe properties of layered materials, while automatically retrieving compatible physical parameters. Our method permits to explore the space of layered material appearance: it lets users find configurations with nearly indistinguishable appearance, isolate grazing angle effects, and give control over properties such as the color, blur or haze of reflections.	https://dl.acm.org/doi/abs/10.1145/3450626.3459857	Mégane Bati, Pascal Barla, Romain Pacanowski
An unbiased ray-marching transmittance estimator	We present an in-depth analysis of the sources of variance in state-of-the-art unbiased volumetric transmittance estimators, and propose several new methods for improving their efficiency. These combine to produce a single estimator that is universally optimal relative to prior work, with up to several orders of magnitude lower variance at the same cost, and has zero variance for any ray with non-varying extinction. We first reduce the variance of truncated power-series estimators using a novel efficient application of U-statistics. We then greatly reduce the average expansion order of the power series and redistribute density evaluations to filter the optical depth estimates with an equidistant sampling comb. Combined with the use of an online control variate built from a sampled mean density estimate, the resulting estimator effectively performs ray marching most of the time while using rarely-sampled higher-order terms to correct the bias.	https://dl.acm.org/doi/abs/10.1145/3450626.3459937	Markus Kettunen, Eugene D'Eon, Jacopo Pantaleoni, Jan Novák
Animated Futurist Sculpting as Dynamic Implicit Shapes	In this work, we present an approach to obtain futurist sculptures. Our approach is inspired by the works of Italian Futurist artists such as Umberto Boccioni. Futurism, as an art movement, aims to achieve to define forms that are a product of time but is permanent in space. In this work, we have developed a methodology to produce a set of futurist sculptures from any given animation of any object that is defined as a triangular mesh. Each produced futurist sculpture is a still frame of what can be rendered as a sculpture animation. Our method is based on the conversion of a given polygonal mesh and its motion into an implicit shape in 4D space which consists of 3-spatial and one temporal dimension. To create each specific futurist sculpture, we compute a subset of this 4D implicit shape in a given time interval. The resulting immersion of 4D structure into the 3D spatial domain provides us desired futurist sculpture for the given time interval. The most important aspect of our methodology is the conversion of animated polygonal mesh into a 4D implicit shape. We first convert a polygonal mesh into a set of particles. Each particle can have its own color. All the points that are closer to the trajectory of the particle form an implicitly defined swept volume [Kim et al. 2004]. These swept volumes appear to be similar to the extrusion of a circle along a curve, but they are guaranteed to be free of artifacts caused by intersections.	https://dl.acm.org/doi/abs/10.1145/3450618.3469148	Pablo Vielman, Ergun Akleman
Antithetic sampling for Monte Carlo differentiable rendering	Stochastic sampling of light transport paths is key to Monte Carlo forward rendering, and previous studies have led to mature techniques capable of drawing high-contribution light paths in complex scenes. These sampling techniques have also been applied to differentiable rendering. In this paper, we demonstrate that path sampling techniques developed for forward rendering can become inefficient for differentiable rendering of glossy materials---especially when estimating derivatives with respect to global scene geometries. To address this problem, we introduce of BSDFs and light-transport paths, allowing significantly faster convergence and can be easily integrated into existing differentiable rendering pipelines. We validate our method by comparing our derivative estimates to those generated with existing unbiased techniques. Further, we demonstrate the effectiveness of our technique by providing equal-quality and equal-time comparisons with existing sampling methods.	https://dl.acm.org/doi/abs/10.1145/3450626.3459783	Cheng Zhang, Zhao Dong, Michael Doggett, Shuang Zhao
Applying Virtual Reality for Systematic Gaze Pattern Evaluation in Simulated Retinitis Pigmentosa Patients	"We apply virtual reality headsets with eye tracking capabilities to evaluate new training methods for patients living with loss of peripheral vision (""tunnel vision""). It can be shown that systematic gaze patterns, taught in a virtual reality environment, are able to significantly increase the effectively perceived visual area of the participants as well as reduce the number of obstacle collisions in navigation tasks."	https://dl.acm.org/doi/abs/10.1145/3450618.3469178	Alexander Neugebauer, Katarina Stingl, Iliya Ivanov, Siegfried Wahl
Area Light Sources in Cyberpunk 2077	This talk discusses in detail the area lights technique used in Cyberpunk 2077. We outline the limitations and challenges we had, and then present our solution. Particularly, we describe our 100% analytical capsule lights, our spot-capsule solution, and our capsule light shadow technique. We then discuss our artistic pipeline, our performance results, and limitations.	https://dl.acm.org/doi/abs/10.1145/3450623.3464630	Peter Sikachev, Giovanni De De Francesco, Kamil Nowakowski, Karol Kowalczyk
Artist-Centered Design for Feature Animation	Product designers from Disney, Pixar, Blue Sky, and DreamWorks Animation discuss the challenges of designing proprietary software for feature animation production, why UX design is necessary for studios that build their own tools, and how it has impacted their studios.	https://dl.acm.org/doi/abs/10.1145/3450617.3464506	Jason Kim, Jordan Wild, Fatima Anes, Seehyun Kim, Sally Kong*
Augmented reality representation of virtual user avatars moving in a virtual representation of the real world at their respective real world locations	In this work we present an augmented reality (AR) application that allows a user with an AR display to watch another user, flying an airplane in the Microsoft Flight Simulator 2020 (MSFS), at their respective location in the real world. To do that, we take the location data of a virtual 3D airplane model in a virtual representation of the world of a user playing MSFS, and stream it via a server to a mobile device. The mobile device user can then see the same 3D airplane model at exactly that real world location, that corresponds to the location of the virtual 3D airplane model in the virtual representation of the world. The mobile device user can also see the avatar movement updated according to the 3D airplane movement in the virtual world. We implemented the application on both a cellphone and a see-through headset.	https://dl.acm.org/doi/abs/10.1145/3450550.3465337	Christoph Leuze, Matthias Leuze
Authoring consistent landscapes with flora and fauna	We present a novel method for authoring landscapes with flora and fauna while considering their mutual interactions. Our algorithm outputs a steady-state ecosystem in the form of density maps for each species, their daily circuits, and a modified terrain with eroded trails from a terrain, climatic conditions, and species with related biological information. We introduce the Resource Access Graph, a new data structure that encodes both interactions between food chain levels and animals traveling between resources over the terrain. A novel competition algorithm operating on this data progressively computes a steady-state solution up the food chain, from plants to carnivores. The user can explore the resulting landscape, where plants and animals are instantiated on the fly, and interactively edit it by over-painting the maps. Our results show that our system enables the authoring of consistent landscapes where the impact of wildlife is visible through animated animals, clearings in the vegetation, and eroded trails. We provide quantitative validation with existing ecosystems and a user-study with expert paleontologist end-users, showing that our system enables them to author and compare different ecosystems illustrating climate changes over the same terrain while enabling relevant visual immersion into consistent landscapes.	https://dl.acm.org/doi/abs/10.1145/3450626.3459952	Pierre Ecormier-Nocca, Guillaume Cordonnier, Philippe Carrez, Anne-Marie Moigne, Pooran Memari, Bedrich Benes, Marie-Paule Cani
BRDF importance sampling for polygonal lights	With the advent of real-time ray tracing, there is an increasing interest in GPU-friendly importance sampling techniques. We present such methods to sample convex polygonal lights approximately proportional to diffuse and specular BRDFs times the cosine term. For diffuse surfaces, we sample the polygons proportional to projected solid angle. Our algorithm partitions the polygon suitably and employs inverse function sampling for each part. Inversion of the distribution function is challenging. Using algebraic geometry, we develop a special iterative procedure and an initialization scheme. Together, they achieve high accuracy in all possible situations with only two iterations. Our implementation is numerically stable and fast. For specular BRDFs, this method enables us to sample the polygon proportional to a linearly transformed cosine. We combine these diffuse and specular sampling strategies through novel variants of optimal multiple importance sampling. Our techniques render direct lighting from Lambertian polygonal lights with almost no variance outside of penumbrae and support shadows and textured emission. Additionally, we propose an algorithm for solid angle sampling of polygons. It is faster and more stable than existing methods.	https://dl.acm.org/doi/abs/10.1145/3450626.3459672	Christoph Peters
Baba Yaga	Baobab Studios' Baba Yaga, combines animation and immersive cinematography, placing you inside a fairytale. Baba Yaga (Kate Winslet) uses powers to stop the villagers encroaching on the Forest (Jennifer Hudson). When the Chief (Glen Close) falls ill, her daughter Magda (Daisy Ridley) must do the unthinkable and retrieve the cure.	https://dl.acm.org/doi/abs/10.1145/3446367.3452127	Eric Darnell, Larry Cutler, Nathaniel Dirksen, Scott Mease
Balanced Glass Design: A flavor perception changing system by controlling the center-of-gravity	We propose Balanced Glass Design, a flavor perception changing system. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted demonstrations as a user study. In this paper, we describe the system design and comments obtained through a user study.	https://dl.acm.org/doi/abs/10.1145/3450618.3469145	Masaharu Hirose, Masahiko Inami
Balanced Glass Design: A flavor perception changing system by controlling the center-of-gravity	We propose Balanced Glass Design, a flavor perception changing system. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted demonstrations as a user study. In this paper, we describe the system design and comments obtained through a user study.	https://dl.acm.org/doi/abs/10.1145/3450618.3469145	Masaharu Hirose, Masahiko Inami
Balanced Glass Design: A flavor perception changing system by controlling the center-of-gravity	We propose Balanced Glass Design, a flavor perception changing system. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted demonstrations as a user study. In this paper, we describe the system design and comments obtained through a user study.	https://dl.acm.org/doi/abs/10.1145/3450550.3465344	Masaharu Hirose, Masahiko Inami
Balanced Glass Design: A flavor perception changing system by controlling the center-of-gravity	We propose Balanced Glass Design, a flavor perception changing system. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted demonstrations as a user study. In this paper, we describe the system design and comments obtained through a user study.	https://dl.acm.org/doi/abs/10.1145/3450550.3465344	Masaharu Hirose, Masahiko Inami
Balanced Glass Design: A flavor perception changing system by controlling the center-of-gravity	In this paper, we propose Balanced Glass Design, a system to change flavor perception. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted experiments on weight perception and demonstrations as a user study. This paper describes the system design, the result of experiments, and comments obtained through a user study.	https://dl.acm.org/doi/abs/10.1145/3450618.3469145	Masaharu Hirose, Masahiko Inami
Balanced Glass Design: A flavor perception changing system by controlling the center-of-gravity	In this paper, we propose Balanced Glass Design, a system to change flavor perception. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted experiments on weight perception and demonstrations as a user study. This paper describes the system design, the result of experiments, and comments obtained through a user study.	https://dl.acm.org/doi/abs/10.1145/3450618.3469145	Masaharu Hirose, Masahiko Inami
Balanced Glass Design: A flavor perception changing system by controlling the center-of-gravity	In this paper, we propose Balanced Glass Design, a system to change flavor perception. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted experiments on weight perception and demonstrations as a user study. This paper describes the system design, the result of experiments, and comments obtained through a user study.	https://dl.acm.org/doi/abs/10.1145/3450550.3465344	Masaharu Hirose, Masahiko Inami
Balanced Glass Design: A flavor perception changing system by controlling the center-of-gravity	In this paper, we propose Balanced Glass Design, a system to change flavor perception. The system consists of glass-type device shifting its center of gravity in response to the user's motion which allows drinking a beverage with a virtual perception of weight through drinking motion. We thought It's possible to intervene in the user's perception of flavor by displaying virtual weight perception, and so conducted experiments on weight perception and demonstrations as a user study. This paper describes the system design, the result of experiments, and comments obtained through a user study.	https://dl.acm.org/doi/abs/10.1145/3450550.3465344	Masaharu Hirose, Masahiko Inami
Beat	"""Beat"" is a story elaborated from your ""Heart."" Viewers experience the work with their hearts in their hands. Viewers encounter a rusted robot without a ""heart"" to move. Viewers can grant him a new heart by putting theirs on the robot. ""Heart"" becomes the key to move the story forward."	https://dl.acm.org/doi/abs/10.1145/3446367.3451996	Keisuke Itoh, Hiroko Fujioka, Katsutoshi Machiba, Tetsuya Ohashi
Beeing - A nature inspired immersive VR journey designed to enhance public transportation	Climate change, environmental protection and sustainability dominate media and political affairs. The demand for increased use of public transport instead of cars is obvious. Beeing – the nature inspired VR journey is intended to raise awareness of these topics and at the same time create an example for added value for public transportation. Additionally, a prototype for a new content platform is being elaborated, which will also enable future-oriented developments by providing a variety of entertaining content between the train stations. The prototype presented is designed for short distance trains in the metropolitan area of Stuttgart, Germany with an approximate duration of three minutes. The physical conditions of the train ride are reflected in VR. With this special form of customer experience, the user is to be picked-up in the real world, i.e. in the real train, in order to experience a fantastic ride that far exceeds the experience of a normal train ride.	https://dl.acm.org/doi/abs/10.1145/3450623.3464643	Felix Bucella, Volker Helzle, Simon Spielmann
Behind The Game: Implicit Spatio-Temporal Intervention in Inter-personal Remote Physical Interactions on Playing Air Hockey	When playing inter-personal sports games remotely, the time lag between user actions and feedback decreases the user's performance and sense of agency. While computational assistance can improve performance, naive intervention independent of the context also compromises the user's sense of agency. We propose a context-aware assistance method that retrieves both user performance and sense of agency, and we demonstrate the method using air hockey (a two-dimensional physical game) as a testbed. Our system includes a 2D plotter-like machine that controls the striker on half of the table surface, and a web application interface that enables manipulation of the striker from a remote location. Using our system, a remote player can play against a physical opponent from anywhere through a web browser. We designed the striker control assistance based on the context by computationally predicting the puck's trajectory using a real-time captured video image. With this assistance, the remote player exhibits an improved performance without compromising their sense of agency, and both players can experience the excitement of the game.	https://dl.acm.org/doi/abs/10.1145/3450550.3465348	Azumi Maekawa, Hiroto Saito, Narin Okazaki, Shunichi Kasahara, Masahiko Inami
Beyond blur: real-time ventral metamers for foveated rendering	To peripheral vision, a pair of physically different images can look the same. Such pairs are relative to each other, just as physically-different spectra of light are perceived as the same color. We propose a real-time method to compute such ventral metamers for foveated rendering where, in particular for near-eye displays, the largest part of the framebuffer maps to the periphery. This improves in quality over state-of-the-art foveation methods which blur the periphery. Work in Vision Science has established how peripheral stimuli are ventral metamers if their statistics are similar. Existing methods, however, require a costly optimization process to find such metamers. To this end, we propose a novel type of statistics particularly well-suited for practical real-time rendering: smooth moments of steerable filter responses. These can be extracted from images in time constant in the number of pixels and in parallel over all pixels using a GPU. Further, we show that they can be compressed effectively and transmitted at low bandwidth. Finally, computing realizations of those statistics can again be performed in constant time and in parallel. This enables a new level of quality for foveated applications such as such as remote rendering, level-of-detail and Monte-Carlo denoising. In a user study, we finally show how human task performance increases and foveation artifacts are less suspicious, when using our method compared to common blurring.	https://dl.acm.org/doi/abs/10.1145/3450626.3459943	David R. Walton, Rafael Kuffner Dos Anjos, Sebastian Friston, David Swapp, Kaan Akşit, Anthony Steed, Tobias Ritschel
Bijective and coarse high-order tetrahedral meshes	We introduce a robust and automatic algorithm to convert linear triangle meshes with feature annotated into coarse tetrahedral meshes with curved elements. Our construction guarantees that the high-order meshes are free of element inversion or self-intersection. A user-specified maximal geometrical error from the input mesh controls the faithfulness of the curved approximation. The boundary of the output mesh is in bijective correspondence to the input, enabling attribute transfer between them, such as boundary conditions for simulations, making our curved mesh an ideal replacement or complement for the original input geometry. The availability of a bijective shell around the input surface is employed to ensure robust curving, prevent self-intersections, and compute a bijective map between the linear input and curved output surface. As necessary building blocks of our algorithm, we extend the bijective shell formulation to support features and propose a robust approach for boundary-preserving linear tetrahedral meshing. We demonstrate the robustness and effectiveness of our algorithm by generating high-order meshes for a large collection of complex 3D models.	https://dl.acm.org/doi/abs/10.1145/3450626.3459840	Zhongshi Jiang, Ziyi Zhang, Yixin Hu, Teseo Schneider, Denis Zorin, Daniele Panozzo
Bistable auxetic surface structures	We present , a novel deployable material system based on optimized bistable auxetic cells. Such a structure can be flat-fabricated from elastic sheet material, then deployed towards a desired double-curved target shape by activating the bistable mechanism of its component cells. A unique feature is that the deployed model is by design in a stable state. This facilitates deployment without the need of complex external supports or boundary constraints. We introduce a computational solution for the inverse design of our Bistable Auxetic Surface Structures. Our algorithm first precomputes a library of bistable auxetic cells to cover a range of in-plane expansion / contraction ratios, while maximizing the bistability and stiffness of the cell to ensure robust deployment. We then use metric distortion analysis of the target surface to compute the planar fabrication state as a composition of cells that best matches the desired deployment deformation. As each cell expands or contracts during deployment, metric frustration forces the surface towards its target equilibrium state. We validate our method with several physical prototypes.	https://dl.acm.org/doi/abs/10.1145/3450626.3459940	Tian Chen, Julian Panetta, Max Schnaubelt, Mark Pauly
BodyMap: Medical Virtual Reality Education and Simulation	BodyMap is a medically accurate representation of the human body that can be manipulated in 3D virtual reality. Usersmay interact with the virtual body in numerous ways, including walking into the virtual body for a detailed inspection ofinternal organs, grabbing out anatomy structures for a closer look, and simulating instrument insertion techniques withinstant haptic feedback. This immersive learning approach enables users to transfer their knowledge gained fromanatomy textbooks and cadaver dissection lessons into an immersive environment and enhance it by continuousrepetition. This way of learning increases confidence in students' own abilities and knowledge.	https://dl.acm.org/doi/abs/10.1145/3450615.3464527	Sam Jang, Li-Ying Huang, Tomas Bartipan
Bodyless	"""Bodyless"" is an interactive surreal VR experience based on the history local to Taiwan. The story is from the director's childhood memories which depict the reduction of humanity by the military government during martial law, the colonial culture, and the digital era into a story beyond reality."	https://dl.acm.org/doi/abs/10.1145/3446367.3451510	Hsin-Chien Huang
Boundary-sampled halfspaces: a new representation for constructive solid modeling	We present a novel representation of solid models for shape design. Like Constructive Solid Geometry (CSG), the solid shape is constructed from a set of halfspaces without the need for an explicit boundary structure. Instead of using Boolean expressions as in CSG, the shape is defined by sparsely placed samples on the boundary of each halfspace. This representation, called Boundary-Sampled Halfspaces (BSH), affords greater agility and expressiveness than CSG while simplifying the reverse engineering process. We discuss theoretical properties of the representation and present practical algorithms for boundary extraction and conversion from other representations. Our algorithms are demonstrated on both 2D and 3D examples.	https://dl.acm.org/doi/abs/10.1145/3450626.3459870	Xingyi Du, Qingnan Zhou, Nathan Carr, Tao Ju
Bowing-Net: Motion Generation for String Instruments Based on Bowing Information	This paper presents a deep learning based method that generates body motion for string instrument performance from raw audio. In contrast to prior methods which aim to predict joint position from audio, we first estimate information that dictates the bowing dynamics, such as the bow direction and the played string. The final body motion is then determined from this information following a conversion rule. By adopting the bowing information as the target domain, not only is learning the mapping more feasible, but also the produced results have bowing dynamics that are consistent with the given audio. We confirmed that our results are superior to existing methods through extensive experiments.	https://dl.acm.org/doi/abs/10.1145/3450618.3469170	Asuka Hirata, Keitaro Tanaka, Ryo Shimamura, Shigeo Morishima
Bystanding: The Feingold Syndrome: Step outside your shoes: exploring the Bystander Effect through Virtual Reality	'Bystanding: The Feingold Syndrome' is an immersive interactive VR docufiction exploring the drowning and rescue of Israeli rowing champion Jasmine Feingold. In 2009, Feingold lost consciousness and capsized while rowing in Tel Aviv's Ha'Yarkon River. She stayed submerged for nearly five minutes. During that time, none of the dozens of bystanders on the riverbank took any action to help her, until finally one person did. Using novel techniques of volumetric capture, photogrammetry, animations, and 360º videos, 'Bystanding' recreates the incident and allows participants to embody bystanders' points of view. Each point of view is represented as a wholly different memory, providing a glimpse into the individual's stream of consciousness.	https://dl.acm.org/doi/abs/10.1145/3450615.3464539	Roi Lev, Nimrod Shapira, Yaara Yacoby
Cangjie's poetry	is an interactive art installation that provides a conceptual response to the semantic human-machine reality. In the art installation, an intelligent system constantly observes the surroundings through the lens of a camera, writes poetry using a symbolic system based on its interpretation of the surroundings, and explains the evolving poem in natural language to audiences in real-time. This work prioritizes the ambiguity and tension between machinic vision and human perception, the actual and the virtual, past and present.	https://dl.acm.org/doi/abs/10.1145/3450507.3457426	Weidi Zhang, Donghao Ren
Capturing detailed deformations of moving human bodies	We present a new method to capture detailed human motion, sampling more than 1000 unique points on the body. Our method outputs highly accurate 4D (spatio-temporal) point coordinates and, crucially, automatically assigns a unique to each of the points. The locations and unique labels of the points are inferred from individual 2D input images only, without relying on temporal tracking or any human body shape or skeletal kinematics models. Therefore, our captured point trajectories contain all of the details from the input images, including motion due to breathing, muscle contractions and flesh deformation, and are well suited to be used as training data to fit advanced models of the human body and its motion. The key idea behind our system is a new type of motion capture suit which contains a special pattern with checkerboard-like corners and two-letter codes. The images from our multi-camera system are processed by a sequence of neural networks which are trained to localize the corners and recognize the codes, while being robust to suit stretching and self-occlusions of the body. Our system relies only on standard RGB or monochrome sensors and fully passive lighting and the passive suit, making our method easy to replicate, deploy and use. Our experiments demonstrate highly accurate captures of a wide variety of human poses, including challenging motions such as yoga, gymnastics, or rolling on the ground.	https://dl.acm.org/doi/abs/10.1145/3450626.3459792	He Chen, Hyojoon Park, Kutay Macit, Ladislav Kavan
Caricature Creation with Conformal Mapping in Complex Domain	Caricature is an art form of exaggeration of features [Akleman 1997; Akleman et al. 2000; Akleman and Reisch 2004; Brennan 1985; Klare et al. 2012; Liang et al. 2002]. An important property of feature exaggeration is that it is not deformation. By deforming features we can obtain funny looking portraits, however the resulting features will not look exaggerated. In this work, we present an approach for extreme exaggeration of facial features to obtain caricature effect. Our approach is based on the well-known conformal property of maps in complex domains. Namely, any map in a complex domain is angle preserving, which is crucial for caricature generation. Without angle preservation, the maps can result in deformations that look funny or grotesque, but not caricature. We have developed a particular mapping in a complex domain and show that we can obtain a wide variety of faces starting from any illustration (or photograph) of a human face.	https://dl.acm.org/doi/abs/10.1145/3450618.3469149	Ergun Akleman, Tevfik Akgun
Cartoons in the Cloud	The SparkShorts program at Pixar Animation Studios allows for directors to try new and different looks. Our short, Twenty Something is a 2d, hand-drawn animated film. When the pandemic forced all of our artist to work from home, we scrambled to create a workflow for managing, sharing, and reviewing 2d assets. While we have a long history of collaborating on 3d films, we did not have a solution for 2d imagery. We created a cloud-based pipeline based around on-premises bucket storage, microservices, and event-driven workflows. The result was Toontown, a suite of technologies that allowed our artists to complete Twenty Something working from home.	https://dl.acm.org/doi/abs/10.1145/3450623.3464680	Yun Lien, Michael K. O'Brien, Laura Savidge
ChoreoMaster: choreography-oriented music-driven dance synthesis	Despite strong demand in the game and film industry, automatically synthesizing high-quality dance motions remains a challenging task. In this paper, we present ChoreoMaster, a production-ready music-driven dance motion synthesis system. Given a piece of music, ChoreoMaster can automatically generate a high-quality dance motion sequence to accompany the input music in terms of style, rhythm and structure. To achieve this goal, we introduce a novel choreography-oriented choreomusical embedding framework, which successfully constructs a unified choreomusical embedding space for both style and rhythm relationships between music and dance phrases. The learned choreomusical embedding is then incorporated into a novel choreography-oriented graph-based motion synthesis framework, which can robustly and efficiently generate high-quality dance motions following various choreographic rules. Moreover, as a production-ready system, ChoreoMaster is sufficiently controllable and comprehensive for users to produce desired results. Experimental results demonstrate that dance motions generated by ChoreoMaster are accepted by professional artists.	https://dl.acm.org/doi/abs/10.1145/3450626.3459932	Kang Chen, Zhipeng Tan, Jin Lei, Song-Hai Zhang, Yuan-Chen Guo, Weidong Zhang, Shi-Min Hu
Clebsch gauge fluid	We propose a novel gauge fluid solver based on Clebsch wave functions to solve incompressible fluid equations. Our method combines the expressive power of Clebsch wave functions to represent coherent vortical structures and the generality of gauge methods to accommodate a broad array of fluid phenomena. By evolving a transformed wave function as the system's gauge variable enhanced by an additional projection step to enforce pressure jumps on the free boundaries, our method can significantly improve the vorticity generation and preservation ability for a broad range of gaseous and liquid phenomena. Our approach can be easily implemented by modifying a standard grid-based fluid simulator. It can be used to solve various fluid dynamics, including complex vortex filament dynamics, fluids with different obstacles, and surface-tension flow.	https://dl.acm.org/doi/abs/10.1145/3450626.3459866	Shuqi Yang, Shiying Xiong, Yaorui Zhang, Fan Feng, Jinyuan Liu, Bo Zhu
Coarse-to-fine: facial structure editing of portrait images via latent space classifications	Facial structure editing of portrait images is challenging given the facial variety, the lack of ground-truth, the necessity of jointly adjusting color and shape, and the requirement of no visual artifacts. In this paper, we investigate how to perform chin editing as a case study of editing facial structures. We present a novel method that can automatically remove the double chin effect in portrait images. Our core idea is to train a fine classification boundary in the latent space of the portrait images. This can be used to edit the chin appearance by manipulating the latent code of the input portrait image while preserving the original portrait features. To achieve such a fine separation boundary, we employ a carefully designed training stage based on latent codes of paired synthetic images with and without a double chin. In the testing stage, our method can automatically handle portrait images with only a refinement to subtle misalignment before and after double chin editing. Our model enables alteration to the neck region of the input portrait image while keeping other regions unchanged, and guarantees the rationality of neck structure and the consistency of facial characteristics. To the best of our knowledge, this presents the first effort towards an effective application for editing double chins. We validate the efficacy and efficiency of our approach through extensive experiments and user studies.	https://dl.acm.org/doi/abs/10.1145/3450626.3459814	Yiqian Wu, Yong-Liang Yang, Qinjie Xiao, Xiaogang Jin
Codimensional incremental potential contact	We extend the incremental potential contact (IPC) model [Li et al. 2020a] for contacting elastodynamics to resolve systems composed of codimensional degrees-of-freedoms in arbitrary combination. This enables a unified, interpenetration-free, robust, and stable simulation framework that couples codimension-0,1,2, and 3 geometries seamlessly with frictional contact. Extending the IPC model to thin structures poses new challenges in computing strain, modeling thickness and determining collisions. To address these challenges we propose three corresponding contributions. First, we introduce a constitutive barrier model that directly enforces strain limiting as an energy potential while preserving rest state. This provides energetically-consistent strain limiting models (both isotropic and anisotropic) for cloth that enable strict satisfaction of strain-limit inequalities with direct coupling to both elastodynamics and contact via minimization of the incremental potential. Second, to capture the geometric thickness of codimensional domains we extend the IPC model to directly enforce distance offsets. Our treatment imposes a strict guarantee that mid-surfaces (respectively mid-lines) of shells (respectively rods) will not move closer than applied thickness values, even as these thicknesses become characteristically small. This enables us to account for thickness in the contact behavior of codimensional structures and so robustly capture challenging contacting geometries; a number of which, to our knowledge, have not been simulated before. Third, codimensional models, especially with modeled thickness, mandate strict accuracy requirements that pose a severe challenge to all existing continuous collision detection (CCD) methods. To address these limitations we develop a new, efficient, simple-to-implement (ACCD) method that applies conservative advancement [Mirtich 1996; Zhang et al. 2006] to iteratively refine a lower bound for deforming primitives, converging to time of impact. In combination these contributions enable IPC (C-IPC). We perform extensive benchmark experiments to validate the efficacy of our method in capturing intricate behaviors of thin-structure contact and resulting bulk effects. In our experiments C-IPC obtains feasible, convergent, and so artifact-free solutions for all time steps, across all tested examples - producing robust simulations. We test C-IPC across extreme deformations, large time steps, and exceedingly close contact over all possible pairings of codimensional domains. Finally, with our strain-limit model, we confirm C-IPC guarantees non-intersection and strain-limit satisfaction for all reasonable (and well below - verified down to 0.1%) strain limits throughout all time steps.	https://dl.acm.org/doi/abs/10.1145/3450626.3459767	Minchen Li, Danny M. Kaufman, Chenfanfu Jiang
Color matters for digital media & visualization	Comparison of the RGB and CMYK colors models. This image depicts the differences between how colors appear on a color display (RGB) compared to how the colors reproduce in the CMYK print process.	https://dl.acm.org/doi/abs/10.1145/3450508.3464547	Dmitry Sokolov, Nicolas Ray, Étienne Corman
Colors - One: Perceptually Based Color Photo Editing	We introduce 'Colors - One', a perceptually based color photo editing app built for the Apple ecosystem. The app's core algorithm augments standard Poisson image editing methods to allow the prediction and editing of perceived image color, rather than pixel color. Users can isolate 16 unique hues and edit the contrast color of each hue individually. The resulting photo edits are striking and provide new insights into the nature of perceptual color representations.	https://dl.acm.org/doi/abs/10.1145/3450415.3464399	Tony Vladusich
Colour-Managed LED Walls for Virtual Production	We present DNEG's approach to colour-managing LED walls for in-camera VFX in virtual production. By characterising the entire imaging pipeline end-to-end with a closed loop, we enable filmmakers and visual effects artists to prepare virtual environments in advance of shooting, confident that their colour intent will be preserved in the final footage. Our system flexibly adapts to the Cinematographer's choice of exposure and white-balance, allowing them to focus more on story-telling and less on technical constraints of the wall. Our contribution takes place in two stages; first we measure and characterise the response of the camera to the LED wall; and secondly we apply the results of this characterisation in real time to images as they are displayed.	https://dl.acm.org/doi/abs/10.1145/3450623.3464682	Oliver James, Rémi Achard, James Bird, Sean Cooper
Common datum	The air we exhale is 100% saturated with water. The air in the lungs is essentially saturated with water at 37 C, which is about 44 mg/liter. The average lung capacity of an adult is about 6 liters. Once exhaled, the air cools to the ambient temperature, leaving the air supersaturated. If it is cool enough it will form a visible cloud. When our breath comes in contact with a cold surface, it will leave visible condensation.	https://dl.acm.org/doi/abs/10.1145/3450507.3457433	Tobias Klein, Jane Prophet
Computational design of weingarten surfaces	In this paper we study Weingarten surfaces and explore their potential for fabrication-aware design in freeform architecture. Weingarten surfaces are characterized by a functional relation between their principal curvatures that implicitly defines approximate local congruences on the surface. These symmetries can be exploited to simplify surface paneling of double-curved architectural skins through mold re-use. We present an optimization approach to find a Weingarten surface that is close to a given input design. Leveraging insights from differential geometry, our method aligns curvature isolines of the surface in order to contract the curvature diagram from a 2D region into a 1D curve. The unknown functional curvature relation then emerges as the result of the optimization. We show how a robust and efficient numerical shape approximation method can be implemented using a guided projection approach on a high-order B-spline representation. This algorithm is applied in several design studies to illustrate how Weingarten surfaces define a versatile shape space for fabrication-aware exploration in freeform architecture. Our optimization algorithm provides the first practical tool to compute general Weingarten surfaces with arbitrary curvature relation, thus enabling new investigations into a rich, but as of yet largely unexplored class of surfaces.	https://dl.acm.org/doi/abs/10.1145/3450626.3459939	Davide Pellis, Martin Kilian, Helmut Pottmann, Mark Pauly
Computational inverse design of surface-based inflatables	We present a computational inverse design method for a new class of surface-based inflatable structure. Our deployable structures are fabricated by fusing together two layers of inextensible sheet material along carefully selected curves. The fusing curves form a network of tubular channels that can be inflated with air or other fluids. When fully inflated, the initially flat surface assumes a programmed double-curved shape and becomes stiff and load-bearing. We present a method that solves for the layout of air channels that, when inflated, best approximate a given input design. For this purpose, we integrate a forward simulation method for inflation with a gradient-based optimization algorithm that continuously adapts the geometry of the air channels to improve the design objectives. To initialize this non-linear optimization, we propose a novel surface flattening algorithm. When a channel is inflated, it approximately maintains its length, but contracts transversally to its main direction. Our algorithm approximates this deformation behavior by computing a mapping from the 3D design surface to the plane that allows for anisotropic metric scaling within the bounds realizable by the physical system. We show a wide variety of inflatable designs and fabricate several prototypes to validate our approach and highlight potential applications.	https://dl.acm.org/doi/abs/10.1145/3450626.3459789	Julian Panetta, Florin Isvoranu, Tian Chen, Emmanuel Siéfert, Benoît Roman, Mark Pauly
Computing minimal surfaces with differential forms	We describe a new algorithm that solves a classical geometric problem: Find a surface of minimal area bordered by an arbitrarily prescribed boundary curve. Existing numerical methods face challenges due to the non-convexity of the problem. Using a representation of curves and surfaces via differential forms on the ambient space, we reformulate this problem as a convex optimization. This change of variables overcomes many difficulties in previous numerical attempts and allows us to find the global minimum across all possible surface topologies. The new algorithm is based on differential forms on the ambient space and does not require handling meshes. We adopt the Alternating Direction Method of Multiplier (ADMM) to find global minimal surfaces. The resulting algorithm is simple and efficient: it boils down to an alternation between a Fast Fourier Transform (FFT) and a pointwise shrinkage operation. We also show other applications of our solver in geometry processing such as surface reconstruction.	https://dl.acm.org/doi/abs/10.1145/3450626.3459781	Stephanie Wang, Albert Chern
Consistent depth of moving objects in video	We present a method to estimate depth of a dynamic scene, containing arbitrary moving objects, from an ordinary video captured with a moving camera. We seek a solution to this under-constrained problem: the depth predictions of corresponding points across frames should induce plausible, smooth motion in 3D. We formulate this objective in a new test-time training framework where a depth-prediction CNN is trained in tandem with an auxiliary scene-flow prediction MLP over the entire input video. By recursively unrolling the scene-flow prediction MLP over varying time steps, we compute both short-range scene flow to impose local smooth motion priors directly in 3D, and long-range scene flow to impose multi-view consistency constraints with wide baselines. We demonstrate accurate and temporally coherent results on a variety of challenging videos containing diverse moving objects (pets, people, cars), as well as camera motion. Our depth maps give rise to a number of depth-and-motion aware video editing effects such as object and lighting insertion.	https://dl.acm.org/doi/abs/10.1145/3450626.3459871	Zhoutong Zhang, Forrester Cole, Richard Tucker, William T. Freeman, Tali Dekel
Constrained projective dynamics: real-time simulation of deformable objects with energy-momentum conservation	This paper proposes a novel energy-momentum conserving integration method. Adopting Projective Dynamics, the proposed method extends its unconstrained minimization for time integration into the constrained form with the position-based energy-momentum constraints. This resolves the well-known problem of unwanted dissipation of energy and momenta without compromising the real-time performance and simulation stability. The proposed method also enables users to directly control the energy and momenta so as to easily create the vivid deformable and global motions they want, which is a fascinating feature for many real-time applications such as virtual/augmented reality and games.	https://dl.acm.org/doi/abs/10.1145/3450626.3459878	Min Hyung Kee, Kiwon Um, Wooseok Jeong, Junghyun Han
Constrained willmore surfaces	Smooth curves and surfaces can be characterized as minimizers of squared curvature bending energies subject to constraints. In the univariate case with an isometry (length) constraint this leads to classic non-linear splines. For surfaces, isometry is too rigid a constraint and instead one asks for minimizers of the Willmore (squared mean curvature) energy subject to a conformality constraint. We present an efficient algorithm for (conformally) constrained Willmore surfaces using triangle meshes of arbitrary topology with or without boundary. Our conformal class constraint is based on the discrete notion of conformal equivalence of triangle meshes. The resulting non-linear constrained optimization problem can be solved efficiently using the competitive gradient descent method together with appropriate Sobolev metrics. The surfaces can be represented either through point positions or differential coordinates. The latter enable the realization of abstract metric surfaces without an initial immersion. A versatile toolkit for extrinsic conformal geometry processing, suitable for the construction and manipulation of smooth surfaces, results through the inclusion of additional point, area, and volume constraints.	https://dl.acm.org/doi/abs/10.1145/3450626.3459759	Yousuf Soliman, Albert Chern, Olga Diamanti, Felix Knöppel, Ulrich Pinkall, Peter Schröder
Contact and friction simulation for computer graphics	Efficient simulation of contact is of interest for numerous physics-based animation applications. For instance, virtual reality training, video games, rapid digital prototyping, and robotics simulation are all examples of applications that involve contact modeling and simulation. However, despite its extensive use in modern computer graphics, contact simulation remains one of the most challenging problems in physics-based animation. This course covers fundamental topics on the nature of contact modeling and simulation for computer graphics. Specifically, we provide mathematical details about formulating contact as a complementarity problem in rigid body and soft body animations. We briefly cover several approaches for contact generation using discrete collision detection. Then, we present a range of numerical techniques for solving the associated LCPs and NCPs. The advantages and disadvantages of each technique are further discussed in a practical manner, and best practices for implementation are discussed. Finally, we conclude the course with several advanced topics, such as anisotropic friction modeling and proximal operators. Programming examples are provided on the course website to accompany the course notes.	https://dl.acm.org/doi/abs/10.1145/3450508.3464571	Sheldon Andrews, Kenny Erleben
Control strategies for physically simulated characters performing two-player competitive sports	In two-player competitive sports, such as and , athletes often demonstrate efficient and tactical movements during a competition. In this paper, we develop a learning framework that generates control policies for physically simulated athletes who have many degrees-of-freedom. Our framework uses a two step-approach, learning basic skills and learning bout-level strategies, with deep reinforcement learning, which is inspired by the way that people how to learn competitive sports. We develop a policy model based on an encoder-decoder structure that incorporates an autoregressive latent variable, and a mixture-of-experts decoder. To show the effectiveness of our framework, we implemented two competitive sports, and , and demonstrate control policies learned by our framework that can generate both tactical and natural-looking behaviors. We also evaluate the control policies with comparisons to other learning configurations and with ablation studies.	https://dl.acm.org/doi/abs/10.1145/3450626.3459761	Jungdam Won, Deepak Gopinath, Jessica Hodgins
Cooking Southeast Asia-inspired Soup in Animated film	"Walt Disney Animation Studios' ""Raya and the Last Dragon"" is an animated film inspired by the people and culture of Southeast Asia. In ""Raya and the Last Dragon"", we created a soup inspired by Thailand's Tom Yum soup to help represent the food cultural richness of that region. Our goal was a more believable and authentic representation of food than we have previously achieved, which required a novel approach, especially on how to simulate the motion of the chili oil on top of the soup and multiple representative ingredients. This talk will describe the collaborative process of designing, simulating and creating materials to achieve the final look of the soup. Figure 1 shows three renders under different camera angles."	https://dl.acm.org/doi/abs/10.1145/3450623.3464651	Cong Wang, Dale Mayeda, Jacob Rice, Thom Whicks, Benjamin Huang
Covid-19 - VR Strikes Back: innovative medical VR training	"In this work, we present ""Covid-19 VR Strikes Back"" (CVRSB), a novel Virtual Reality (VR) medical training application focusing on a faster and more efficient teaching experience for medical personnel regarding the nasopharyngeal swab and the proper Personal Protective Equipment (PPE) donning and doffing. Our platform incorporates a diversity of innovations: a) techniques to avoid the uncanny valley observed in human representation and interactivity in VR simulations, b) exploitation of Geometric Algebra interpolation engine capabilities and c) supervised machine learning analytics module for real-time recommendations. Our application is publicly available at no cost for most Head Mount Displays (HMDs) and Desktop VR. The impact and effectiveness of our application is proved by recent clinical trials."	https://dl.acm.org/doi/abs/10.1145/3450615.3464546	Paul Zikas, Manos Kamarianakis, Ioanna Kartsonaki, Nick Lydatakis, Steve Kateros, Mike Kentros, Efstratios Geronikolakis, Giannis Evangelou, Achilles Apostolou, Paolo Alejandro Alejandro Catilo, George Papagiannakis
Creating Diversity and Variety in the People of Kumandra for Disney’s Raya And The Last Dragon	"In Walt Disney Animation Studios' ""Raya and the Last Dragon"", the fantasy world of Kumandra is composed of five lands, representing five parts of a dragon. All aspects of the character designs were inspired by the many cultures of Southeast Asia. Each land is inhabited by a unique clan and the crowds assets need to reflect this diversity and variety both within and between the clans. This was achieved by introducing a novel approach that is modular in both design and construction of the assets. Key aspects include strategic reuse and refit, and new look techniques for creating additional variation between clans. We also employed a tracking and management system for visually validating the assets which played an important role in the efficient use of the data downstream. In addition, an extremely collaborative workflow between all departments involved was critical, including the Visual Design, Character Asset, and Crowds Simulation departments. The overall enhancements to the workflow made it possible to creatively generate the thousands of crowd assets with the desired art direction for the film."	https://dl.acm.org/doi/abs/10.1145/3450623.3464660	AVNEET KAUR, ERIK EULEN, JOHANN FRANCOIS COETZEE
Creating a diverse workplace with authentic multicultural voices; how can we create real long-term equality?	Computer graphics media industries see themselves as forward thinking and inclusive. However, BIPOC (black, Indigenous and people of color) are often not at the table when issues regarding inclusion are discussed. Inclusion requires a plan that reaches not only the candidate, but the educational and home communities a candidate is from. This panel will discuss the experience of BIPOC artists entering a predominantly white male workforce and what change must occur to make the journey a little better for everyone. Filmmakers, artists, and educators comprise this panel and will represent the barriers experienced by persons of color that occur not just at the interview, but in the educational system and BIPOC community. They will share experiences on production and give honest feedback on how to create positive change.	https://dl.acm.org/doi/abs/10.1145/3450617.3464489	Pat Beckmann Wells, Sonya Carey, Magdiela H. Duhamel, Dr. Linc Johnson, Dr. Margaret Martin
Cross Sample Similarity for Stable Training of GAN	Recently attention network finding similarity in non-local area within a 2D image has shown outstanding improvement in multi-class generation task in GAN. However it frequently shows unstable training state sometimes falling in mode collapse. We propose cross sample similarity loss to penalize similar features of fake samples that are rarely observed in reals. Proposed method shows improved FID score compared to baseline methods on CelebA, LSUN, and decreased mode collapse on Cifar10[Krizhevsky 2009].	https://dl.acm.org/doi/abs/10.1145/3450618.3469169	JUNG EUN Lee, Seungkyu Lee
DAG amendment for inverse control of parametric shapes	Parametric shapes model objects as programs producing a geometry based on a few semantic degrees of freedom, called hyper-parameters. These shapes are the typical output of non-destructive modeling, CAD modeling or rigging. However they suffer from the core issue of being manipulated only indirectly, through a series of values rather than the geometry itself. In this paper, we introduce an amendment process of the underlying direct acyclic graph (DAG) of a parametric shape. This amendment enables a local differentiation of the shape w.r.t. its hyper-parameters that we leverage to provide interactive direct manipulation of the output. By acting on the shape synthesis process itself, our method is agnostic to the variations of the connectivity and topology that may occur in its output while changing the input hyper-parameters. Furthermore, our method is oblivious to the internal logic of the DAG nodes. We illustrate our approach on a collection of examples combining the typical nodes found in modern parametric modeling packages - such as deformation, booleans and surfacing operators - for which our method provides the user with inverse control over the hyper-parameters through a brush stroke metaphor.	https://dl.acm.org/doi/abs/10.1145/3450626.3459823	Élie Michel, Tamy Boubekeur
Deep relightable appearance models for animatable faces	We present a method for building high-fidelity animatable 3D face models that can be posed and rendered with novel lighting environments in real-time. Our main insight is that relightable models trained to produce an image lit from a single light direction can generalize to natural illumination conditions but are computationally expensive to render. On the other hand, efficient, high-fidelity face models trained with point-light data do not generalize to novel lighting conditions. We leverage the strengths of each of these two approaches. We first train an expensive but on point-light illuminations, and use it to generate a training set of high-quality synthetic face images under natural illumination conditions. We then train an on this augmented dataset, reducing the generalization ability requirements. As the efficacy of this approach hinges on the quality of the synthetic data we can generate, we present a study of lighting pattern combinations for dynamic captures and evaluate their suitability for learning generalizable relightable models. Towards achieving the best possible quality, we present a novel approach for generating dynamic relightable faces that exceeds state-of-the-art performance. Our method is capable of capturing subtle lighting effects and can even generate compelling near-field relighting despite being trained exclusively with far-field lighting data. Finally, we motivate the utility of our model by animating it with images captured from VR-headset mounted cameras, demonstrating the first system for face-driven interactions in VR that uses a photorealistic relightable face model.	https://dl.acm.org/doi/abs/10.1145/3450626.3459829	Sai Bi, Stephen Lombardi, Shunsuke Saito, Tomas Simon, Shih-En Wei, Kevyn Mcphail, Ravi Ramamoorthi, Yaser Sheikh, Jason Saragih
DeepFaceEditing: deep face generation and editing with disentangled geometry and appearance control	Recent facial image synthesis methods have been mainly based on conditional generative models. Sketch-based conditions can effectively describe the geometry of faces, including the contours of facial components, hair structures, as well as salient edges (e.g., wrinkles) on face surfaces but lack effective control of appearance, which is influenced by color, material, lighting condition, etc. To have more control of generated results, one possible approach is to apply existing disentangling works to disentangle face images into geometry and appearance representations. However, existing disentangling methods are not optimized for human face editing, and cannot achieve fine control of facial details such as wrinkles. To address this issue, we propose DeepFaceEditing, a structured disentanglement framework specifically designed for face images to support face generation and editing with disentangled control of geometry and appearance. We adopt a local-to-global approach to incorporate the face domain knowledge: local component images are decomposed into geometry and appearance representations, which are fused consistently using a global fusion module to improve generation quality. We exploit sketches to assist in extracting a better geometry representation, which also supports intuitive geometry editing via sketching. The resulting method can either extract the geometry and appearance representations from face images, or directly extract the geometry representation from face sketches. Such representations allow users to easily edit and synthesize face images, with decoupled control of their geometry and appearance. Both qualitative and quantitative evaluations show the superior detail and appearance control abilities of our method compared to state-of-the-art methods.	https://dl.acm.org/doi/abs/10.1145/3450626.3459760	Shu-Yu Chen, Feng-Lin Liu, Yu-Kun Lai, Paul L. Rosin, Chunpeng Li, Hongbo Fu, Lin Gao
DeepFormableTag: end-to-end generation and recognition of deformable fiducial markers	Fiducial markers have been broadly used to identify objects or embed messages that can be detected by a camera. Primarily, existing detection methods assume that markers are printed on ideally planar surfaces. The size of a message or identification code is limited by the spatial resolution of binary patterns in a marker. Markers often fail to be recognized due to various imaging artifacts of optical/perspective distortion and motion blur. To overcome these limitations, we propose a novel deformable fiducial marker system that consists of three main parts: First, a fiducial marker generator creates a set of free-form color patterns to encode significantly large-scale information in unique visual codes. Second, a differentiable image simulator creates a training dataset of photorealistic scene images with the deformed markers, being rendered during optimization in a differentiable manner. The rendered images include realistic shading with specular reflection, optical distortion, defocus and motion blur, color alteration, imaging noise, and shape deformation of markers. Lastly, a trained marker detector seeks the regions of interest and recognizes multiple marker patterns simultaneously via inverse deformation transformation. The deformable marker creator and detector networks are jointly optimized via the differentiable photorealistic renderer in an end-to-end manner, allowing us to robustly recognize a wide range of deformable markers with high accuracy. Our deformable marker system is capable of decoding 36-bit messages successfully at ~29 fps with severe shape deformation. Results validate that our system significantly outperforms the traditional and data-driven marker methods. Our learning-based marker system opens up new interesting applications of fiducial markers, including cost-effective motion capture of the human body, active 3D scanning using our fiducial markers' array as structured light patterns, and robust augmented reality rendering of virtual objects on dynamic surfaces.	https://dl.acm.org/doi/abs/10.1145/3450626.3459762	Mustafa B. Yaldiz, Andreas Meuleman, Hyeonjoong Jang, Hyunho Ha, Min H. Kim
Demonstrating MagnetIO: Passive yet Interactive Soft Haptic Patches Anywhere	We demonstrate a new type of haptic actuator, which we call MagnetIO, that is comprised of two parts: one battery-powered voice-coil worn on the user's fingernail and any number of interactive soft patches that can be attached onto any surface (everyday objects, user's body, appliances, etc.). When the user's finger wearing our voice-coil contacts any of the interactive patches it detects its magnetic signature via magnetometer and vibrates the patch, adding haptic feedback to otherwise input-only interactions. To allow these passive patches to vibrate, we make them from silicone with regions doped with polarized neodymium powder, resulting in soft and stretchable magnets. This stretchable form-factor allows them to be wrapped to the user's body or everyday objects of various shapes. We demonstrate how these add haptic output to many situations, such as adding haptic buttons to the walls of one's home.	https://dl.acm.org/doi/abs/10.1145/3450550.3465342	Alex Mazursky, Shan-Yuan Teng, Romain Nith, Pedro Lopes
Demonstrating Touch&Fold: A Foldable Haptic Actuator for Rendering Touch in Mixed Reality	We propose a nail-mounted foldable haptic device that provides tactile feedback to mixed reality (MR) environments by pressing against the user's fingerpad when a user touches a virtual object. What is novel in our device is that it quickly tucks away when the user interacts with real-world objects. Its design allows it to fold back on top of the user's nail when not in use, keeping the user's fingerpad free to, for instance, manipulate handheld tools and other objects while in MR. To achieve this, we engineered a wireless and self-contained haptic device, which measures 24×24×41 mm and weighs 9.5 g. Furthermore, our foldable end-effector also features a linear resonant actuator, allowing it to render not only touch contacts (i.e., pressure) but also textures (i.e., vibrations). We demonstrate how our device renders contacts with MR surfaces, buttons, low- and high-frequency textures.	https://dl.acm.org/doi/abs/10.1145/3450550.3465340	Shan-Yuan Teng, Pengyu Li, Romain Nith, Joshua Fonseca, Pedro Lopes
Designing actuation systems for animatronic figures via globally optimal discrete search	We present an algorithmic approach to designing animatronic figures - expressive robotic characters whose movements are driven by a large number of actuators. The input to our design system provides a high-level specification of the space of motions the character should be able to perform. The output consists of a fully functional mechatronic blueprint. We cast the design task as a search problem in a vast combinatorial space of possible solutions. To find an optimal design in this space, we propose an efficient best-first search algorithm that is guided by an admissible heuristic. The objectives guiding the search process demand that the design remains free of singularities and self-collisions at any point in the high-dimensional space of motions the character is expected to be able to execute. To identify worst-case self-collision scenarios for multi degree-of-freedom closed-loop mechanisms, we additionally develop an elegant technique inspired by the concept of adversarial attacks. We demonstrate the efficacy of our approach by creating designs for several animatronic figures of varying complexity.	https://dl.acm.org/doi/abs/10.1145/3450626.3459867	Simon Huber, Roi Poranne, Stelian Coros
Designing an encoder for StyleGAN image manipulation	Recently, there has been a surge of diverse methods for performing image editing by employing pre-trained unconditional generators. Applying these methods on real images, however, remains a challenge, as it necessarily requires the inversion of the images into their latent space. To successfully invert a real image, one needs to find a latent code that reconstructs the input image accurately, and more importantly, allows for its meaningful manipulation. In this paper, we carefully study the latent space of StyleGAN, the state-of-the-art unconditional generator. We identify and analyze the existence of a distortion-editability tradeoff and a distortion-perception tradeoff within the StyleGAN latent space. We then suggest two principles for designing encoders in a manner that allows one to control the proximity of the inversions to regions that StyleGAN was originally trained on. We present an encoder based on our two principles that is specifically designed for facilitating editing on real images by balancing these tradeoffs. By evaluating its performance qualitatively and quantitatively on numerous challenging domains, including cars and horses, we show that our inversion method, followed by common editing techniques, achieves superior real-image editing quality, with only a small reconstruction accuracy drop.	https://dl.acm.org/doi/abs/10.1145/3450626.3459838	Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or
Designing for Storyliving Experiences:: Tinker, A Case Study	Tinker defines a new genre of storytelling called storyliving. Through interactive and embodied immersive experiences, participants can connect with narrative in a more meaningful way. In this live, bespoke virtual reality theatre experience, the participant becomes the main character of the story. Based upon the true story of Director Lou Ward and his relationship with his grandfather who developed Alzheimer's disease, Tinker places the participant in the role of the grandchild so that Ward's story, in turn, becomes their own. Over time, the participant creates new memories alongside their grandfather in his workshop, and their connection to the grandfather and the story grows stronger with time. Tinker is a cornerstone in compelling storyliving experiences; moreover, it is because of how it is designed that participants feel connected to the story.	https://dl.acm.org/doi/abs/10.1145/3450615.3464534	Lou Ward, Cristopher David, Lara Bucarey
Developable Surface Segmentation For CAD Models	We present a novel method to segment CAD models into developable patches by detecting curve-like features on Gauss images of the corresponding patches. A region-growing approach is employed to detect planar and curved developable patches. The Gauss image of each segmented patch is constrained to be curve-like via principal component analysis and Pearson correlation analysis. Experimental results demonstrate that our approach generates nice results on CAD models with all kinds of developable surfaces.	https://dl.acm.org/doi/abs/10.1145/3450618.3469167	Zheng Zeng, Xiaohong Jia, Liyong Shen, Pengbo Bo
DiffAqua: a differentiable computational design pipeline for soft underwater swimmers with shape interpolation	The computational design of soft underwater swimmers is challenging because of the high degrees of freedom in soft-body modeling. In this paper, we present a differentiable pipeline for co-designing a soft swimmer's geometry and controller. Our pipeline unlocks gradient-based algorithms for discovering novel swimmer designs more efficiently than traditional gradient-free solutions. We propose Wasserstein barycenters as a basis for the geometric design of soft underwater swimmers since it is differentiable and can naturally interpolate between bio-inspired base shapes optimal transport. By combining this design space with differentiable simulation and control, we can efficiently optimize a soft underwater swimmer's performance with fewer simulations than baseline methods. We demonstrate the efficacy of our method on various design problems such as fast, stable, and energy-efficient swimming and demonstrate applicability to multi-objective design.	https://dl.acm.org/doi/abs/10.1145/3450626.3459832	Pingchuan Ma, Tao Du, John Z. Zhang, Kui Wu, Andrew Spielberg, Robert K. Katzschmann, Wojciech Matusik
Direct delta mush skinning compression with continuous examples	Direct Delta Mush (DDM) is a high-quality, direct skinning method with a low setup cost. However, its storage and run-time computing cost are relatively high for two reasons: its skinning weights are 4 X 4 matrices instead of scalars like other direct skinning methods, and its computation requires one 3 X 3 Singular Value Decomposition per vertex. In this paper, we introduce a compression method that takes a DDM model and splits it into two layers: the first layer is a smaller DDM model that computes a set of virtual bone transformations and the second layer is a Linear Blend Skinning model that computes per-vertex transformations from the output of the first layer. The two-layer model can approximate the deformation of the original DDM model with significantly lower costs. Our main contribution is a novel problem formulation for the DDM compression based on a continuous example-based technique, in which we minimize the compression error on an uncountable set of example poses. This formulation provides an elegant metric for the compression error and simplifies the problem to the common linear matrix factorization. Our formulation also takes into account the skeleton hierarchy of the model, the bind pose, and the range of motions. In addition, we propose a new update rule to optimize DDM weights of the first layer and a modification to resolve the floating-point cancellation issue of DDM.	https://dl.acm.org/doi/abs/10.1145/3450626.3459779	Binh Huy Le, Keven Villeneuve, Carlos Gonzalez-Ochoa
Discovering diverse athletic jumping strategies	We present a framework that enables the discovery of diverse and natural-looking motion strategies for athletic skills such as the high jump. The strategies are realized as control policies for physics-based characters. Given a task objective and an initial character configuration, the combination of physics simulation and deep reinforcement learning (DRL) provides a suitable starting point for automatic control policy training. To facilitate the learning of realistic human motions, we propose a Pose Variational Autoencoder (P-VAE) to constrain the actions to a subspace of natural poses. In contrast to motion imitation methods, a rich variety of novel strategies can naturally emerge by exploring initial character states through a sample-efficient Bayesian diversity search (BDS) algorithm. A second stage of optimization that encourages novel policies can further enrich the unique strategies discovered. Our method allows for the discovery of diverse and novel strategies for athletic jumping motions such as high jumps and obstacle jumps with no motion examples and less reward engineering than prior work.	https://dl.acm.org/doi/abs/10.1145/3450626.3459817	Zhiqi Yin, Zeshi Yang, Michiel Van De Panne, Kangkang Yin
Discrete conformal equivalence of polyhedral surfaces	This paper describes a numerical method for surface parameterization, yielding maps that are locally injective and discretely conformal in an exact sense. Unlike previous methods for discrete conformal parameterization, the method is guaranteed to work for any manifold triangle mesh, with no restrictions on triangulatiothat each task can be formulated as a convex problem where the triangulation is allowed to change---we complete the picture by introducing the machinery needed to actually construct a discrete conformal map. In particular, we introduce a new scheme for tracking correspondence between triangulations based on , and a new interpolation procedure based on layout in the Stress tests involving difficult cone configurations and near-degenerate triangulations indicate that the method is extremely robust in practice, and provides high-quality interpolation even on meshes with poor elements.	https://dl.acm.org/doi/abs/10.1145/3450626.3459763	Mark Gillespie, Boris Springborn, Keenan Crane
Displaced signed distance fields for additive manufacturing	We propose displaced signed distance fields, an implicit shape representation to accurately, efficiently and robustly 3D-print finely detailed and smoothly curved surfaces at native device resolution. As the resolution and accuracy of 3D printers increase, accurate reproduction of such surfaces becomes increasingly realizable from a hardware perspective. However, representing such surfaces with polygonal meshes requires high polygon counts, resulting in excessive storage, transmission and processing costs. These costs increase with print size, and can become exorbitant for large prints. Our implicit formulation simultaneously allows the augmentation of low-polygon meshes with compact meso-scale topographic information, such as displacement maps, and the realization of curved polygons, while leveraging efficient, streaming-compatible, discrete voxel-wise algorithms. Critical for this is careful treatment of the input primitives, their voxel approximation and the displacement to the true surface. We further propose a robust sign estimation to allow for incomplete, non-manifold input, whether human-made for onscreen rendering or directly out of a scanning pipeline. Our framework is efficient both in terms of time and space. The running time is independent of the number of input polygons, the amount of displacement, and is constant per voxel. The storage costs grow sub-linearly with the number of voxels, making our approach suitable for large prints. We evaluate our approach for efficiency and robustness, and show its advantages over standard techniques.	https://dl.acm.org/doi/abs/10.1145/3450626.3459827	Alan Brunton, Lubna Abu Rmaileh
DreamWorks Art-Driven Shot Sculpting Toolset	This talk presents DreamWorks' art-driven shot sculpting toolset used by the Character Effects (CFX) Department to efficiently and logically sculpt shapes of character skin, clothing, hair/fur, and props in shots. The ability to visualize an Animator's drawovers during CFX shot work introduced an improved visual communication language between Animators and CFX artists. The toolset's wide range of shot sculpting abilities helps achieve the different artistic styles of various films and enhances the visual impact of animation. This efficient toolset makes the shot sculpting an intuitive process for an artist rather than one littered with cleanup work.	https://dl.acm.org/doi/abs/10.1145/3450623.3464649	Arunachalam Somasundaram, Felege Gebru, William Sokoloski, Nate Yellig
Driving-signal aware full-body avatars	We present a learning-based method for building driving-signal aware full-body avatars. Our model is a conditional variational autoencoder that can be animated with incomplete driving signals, such as human pose and facial keypoints, and produces a high-quality representation of human geometry and view-dependent appearance. The core intuition behind our method is that better drivability and generalization can be achieved by disentangling the driving signals and remaining generative factors, which are not available during animation. To this end, we explicitly account for information deficiency in the driving signal by introducing a latent space that exclusively captures the remaining information, thus enabling the imputation of the missing factors required during full-body animation, while remaining faithful to the driving signal. We also propose a learnable localized compression for the driving signal which promotes better generalization, and helps minimize the influence of global chance-correlations often found in real datasets. For a given driving signal, the resulting variational model produces a compact space of uncertainty for missing factors that allows for an imputation strategy best suited to a particular application. We demonstrate the efficacy of our approach on the challenging problem of full-body animation for virtual telepresence with driving signals acquired from minimal sensors placed in the environment and mounted on a VR-headset.	https://dl.acm.org/doi/abs/10.1145/3450626.3459850	Timur Bagautdinov, Chenglei Wu, Tomas Simon, Fabián Prada, Takaaki Shiratori, Shih-En Wei, Weipeng Xu, Yaser Sheikh, Jason Saragih
DronePaint: Swarm Light Painting with DNN-based Gesture Recognition	We propose a novel human-swarm interaction system, allowing the user to directly control a swarm of drones in a complex environment through trajectory drawing with a hand gesture interface based on the DNN-based gesture recognition. The developed CV-based system allows the user to control the swarm behavior without additional devices through human gestures and motions in real-time, providing convenient tools to change the swarm's shape and formation. The two types of interaction were proposed and implemented to adjust the swarm hierarchy: trajectory drawing and free-form trajectory generation control. The experimental results revealed a high accuracy of the gesture recognition system (99.75%), allowing the user to achieve relatively high precision of the trajectory drawing (mean error of 5.6 cm in comparison to 3.1 cm by mouse drawing) over the three evaluated trajectory patterns. The proposed system can be potentially applied in complex environment exploration, spray painting using drones, and interactive drone shows, allowing users to create their own art objects by drone swarms.	https://dl.acm.org/doi/abs/10.1145/3450550.3465349	Valerii Serpiva, Ekaterina Karmanova, Aleksey Fedoseev, Stepan Perminov, Dzmitry Tsetserukou
Dynamic Diffuse Global Illumination Resampling	Ray traced global illumination can be partitioned into direct contributions of the light sources that reflect to the camera after one bounce and indirect contributions that scatter for multiple bounces. We propose a new real-time solution called dynamic diffuse global illumination resampling that computes direct and indirect illumination accurately and with low noise. The key idea is to derive a new, unified algorithm from the principles of the state of the art ReSTIR many-lights direct shadowing [Bitterli et al. 2020] and the DDGI indirect light probes [Majercik et al. 2019] real-time algorithms. By this unification, global illumination resampling achieves higher quality than the combination of its two components at real-time framerates. At the cost of little bias, our technique also outperforms hardware accelerated path tracing in both runtime and noise.	https://dl.acm.org/doi/abs/10.1145/3450623.3464635	Zander Majercik, Thomas Mueller, Alexander Keller, Derek Nowrouzezahrai, Morgan McGuire
Dynamic closest color warping to sort and compare palettes	A color palette is one of the simplest and most intuitive descriptors that can be extracted from images or videos. This paper proposes a method to assess the similarity between color palettes by sorting colors. While previous palette similarity measures compare only colors without considering the overall palette combination, we sort palettes to minimize the geometric distance between colors and align them to share a common color tendency. We propose dynamic closest color warping (DCCW) to calculate the minimum distance sum between colors and the graph connecting the colors in the other palette. We evaluate the proposed palette sorting and DCCW with several datasets and demonstrate that DCCW outperforms previous methods in terms of accuracy and computing time. We validate the effectiveness of the proposed sorting technique by conducting a perceptual study, which indicates a clear preference for the results of our approach. We also demonstrate useful applications enabled by DCCW, including palette interpolation, palette navigation, and image recoloring.	https://dl.acm.org/doi/abs/10.1145/3450626.3459776	Suzi kim, Sunghee Choi
Editable free-viewpoint video using a layered neural representation	Generating free-viewpoint videos is critical for immersive VR/AR experience, but recent neural advances still lack the editing ability to manipulate the visual perception for large dynamic scenes. To fill this gap, in this paper, we propose the first approach for editable free-viewpoint video generation for large-scale view-dependent dynamic scenes using only 16 cameras. The core of our approach is a new layered neural representation, where each dynamic entity, including the environment itself, is formulated into a spatio-temporal coherent neural layered radiance representation called ST-NeRF. Such a layered representation supports manipulations of the dynamic scene while still supporting a wide free viewing experience. In our ST-NeRF, we represent the dynamic entity/layer as a continuous function, which achieves the disentanglement of location, deformation as well as the appearance of the dynamic entity in a continuous and self-supervised manner. We propose a scene parsing 4D label map tracking to disentangle the spatial information explicitly and a continuous deform module to disentangle the temporal motion implicitly. An object-aware volume rendering scheme is further introduced for the re-assembling of all the neural layers. We adopt a novel layered loss and motion-aware ray sampling strategy to enable efficient training for a large dynamic scene with multiple performers, Our framework further enables a variety of editing functions, i.e., manipulating the scale and location, duplicating or retiming individual neural layers to create numerous visual effects while preserving high realism. Extensive experiments demonstrate the effectiveness of our approach to achieve high-quality, photo-realistic, and editable free-viewpoint video generation for dynamic scenes.	https://dl.acm.org/doi/abs/10.1145/3450626.3459756	Jiakai Zhang, Xinhang Liu, Xinyi Ye, Fuqiang Zhao, Yanshun Zhang, Minye Wu, Yingliang Zhang, Lan Xu, Jingyi Yu
Electriflow: Augmenting Books With Tangible Animation Using Soft Electrohydraulic Actuators	We present Electriflow: a method of augmenting books with tangible animation employing soft electrohydraulic actuators. These actuators are compact, silent and fast in operation, and can be fabricated with commodity materials. They generate an immediate hydraulic force upon electrostatic activation without an external fluid supply source, enabling a simple and self-contained design. Electriflow actuators produce an immediate shape transition from flat to folded state which enabled their seamless integration into books. For the Emerging Technologies exhibit, we will demonstrate the prototype of a book augmented with the capability of tangible animation.	https://dl.acm.org/doi/abs/10.1145/3450616.3464523	Purnendu, Sasha Novack, Eric Acome, Mirela Alistar, Christoph Keplinger, Mark D. Gross, Carson Bruns, Daniel Leithinger
Eliminating topological errors in neural network rotation estimation using self-selecting ensembles	Many problems in computer graphics and computer vision applications involves inferring a rotation from a variety of different forms of inputs. With the increasing use of deep learning, neural networks have been employed to solve such problems. However, the traditional representations for 3D rotations, the quaternions and Euler angles, are found to be problematic for neural networks in practice, producing seemingly unavoidable large estimation errors. Previous researches has identified the discontinuity of the mapping from SO(3) to the quaternions or Euler angles as the source of such errors, and to solve it, embeddings of SO(3) have been proposed as the output representation of rotation estimation networks instead. In this paper, we argue that the argument against quaternions and Euler angles from local discontinuities of the mappings from SO(3) is flawed, and instead provide a different argument from the global topological properties of SO(3) that also establishes the lower bound of maximum error when using quaternions and Euler angles for rotation estimation networks. Extending from this view, we discover that rotation symmetries in the input object causes additional topological problems that even using embeddings of SO(3) as the output representation would not correctly handle. We propose the self-selecting ensemble, a topologically motivated approach, where the network makes multiple predictions and assigns weights to them. We show theoretically and with experiments that our methods can be combined with a wide range of different rotation representations and can handle all kinds of finite symmetries in 3D rotation estimation problems.	https://dl.acm.org/doi/abs/10.1145/3450626.3459882	Sitao Xiang
End-to-end complex lens design with differentiate ray tracing	Imaging systems have long been designed in separated steps: experience-driven optical design followed by sophisticated image processing. Although recent advances in computational imaging aim to bridge the gap in an end-to-end fashion, the image formation models used in these approaches have been quite simplistic, built either on simple wave optics models such as Fourier transform, or on similar paraxial models. Such models only support the optimization of a single lens surface, which limits the achievable image quality. To overcome these challenges, we propose a general end-to-end complex lens design framework enabled by a differentiable ray tracing image formation model. Specifically, our model relies on the differentiable ray tracing rendering engine to render optical images in the full field by taking into account all on/off-axis aberrations governed by the theory of geometric optics. Our design pipeline can jointly optimize the lens module and the image reconstruction network for a specific imaging task. We demonstrate the effectiveness of the proposed method on two typical applications, including large field-of-view imaging and extended depth-of-field imaging. Both simulation and experimental results show superior image quality compared with conventional lens designs. Our framework offers a competitive alternative for the design of modern imaging systems.	https://dl.acm.org/doi/abs/10.1145/3450626.3459674	Qilin Sun, Congli Wang, Qiang Fu, Xiong Dun, Wolfgang Heidrich
Endless loops: detecting and animating periodic patterns in still images	We present an algorithm for producing a seamless animated loop from a single image. The algorithm detects periodic structures, such as the windows of a building or the steps of a staircase, and generates a non-trivial displacement vector field that maps each segment of the structure onto a neighboring segment along a user- or auto-selected main direction of motion. This displacement field is used, together with suitable temporal and spatial smoothing, to warp the image and produce the frames of a continuous animation loop. Our cinemagraphs are created in under a second on a mobile device. Over 140,000 users downloaded our app and exported over 350,000 cinemagraphs. Moreover, we conducted two user studies that show that users prefer our method for creating surreal and structured cinemagraphs compared to more manual approaches and compared to previous methods.	https://dl.acm.org/doi/abs/10.1145/3450626.3459935	Tavi Halperin, Hanit Hakim, Orestis Vantzos, Gershon Hochman, Netai Benaim, Lior Sassy, Michael Kupchik, Ofir Bibi, Ohad Fried
Esports as a Driving Problem in Computer Graphics	Esports is a growing worldwide phenomenon now rivaling traditional sports, with a deep dependence on real-time graphics technology. Despite this, the SIGGRAPH research community has largely ignored it. This panel brings together esports experts in engineering, medicine as well as cognitive and data science to argue that this must change. Like film, esports is an important problem for computer graphics, and could give rise to technologies and techniques benefitting not only esports, but society more broadly. With a series of moderated and audience questions, this panel will sketch the research challenges and potential benefits of esports, while also considering its risks.	https://dl.acm.org/doi/abs/10.1145/3450617.3464499	Benjamin A. Watson, Josef Spjut, Caitlin McGee, Amine Issa, Wayne Mackey
Experiment Assisting System with Local Augmented Body (EASY-LAB) for Subject Experiments under the COVID-19 Pandemic	Since it is challenging to perceive space and objects with a video conferencing system, which communicates using only video and audio, there are difficulties in testing subjects in the COVID-19 pandemic. We propose the EASY-LAB system that allows an experimenter to perform observation and physical interaction with the subject even from a remote location actively. The proposed system displays the camera image on a HMD worn by the experimenter, which camera is mounted on a small 6 DOF robot arm end, allowing observation from an easy-to-see perspective. The experimenter can also instruct the subject using another robot arm with a laser pointer. The robot's joint angles are calculated by Inverse Kinematics from the experimenter's head movements, then reflected in the actual robot. Photon Unity Networking component was used for the synchronization process with remote locations. These devices are affordable, effortless to set up, and can be delivered to the subject's home. Finally, the proposed system was evaluated by four subjects, As a preliminary result, the mean pointing error was 1.1 cm, and the operation time was reduced by 60% compared with the conventional video conferencing system. This result indicated the EASY-LAB's capability, at least in tasks that require pointing and observation from various angles. The statistical study with more subjects will be conducted in the follow-up study.	https://dl.acm.org/doi/abs/10.1145/3450550.3465345	Yukiko Iwasaki, Joi Oh, Takumi Handa, Ahmed A. Sereidi, Vitvasin Vimolmongkolporn, Fumihiro Kato, Hiroyasu Iwata
Exposition of Music: VR Exhibition	"Nam June Paik's first solo exhibition in 1963 titled ""Exposition of Music - Electronic Television"" marked the beginning of his career, and he is often referred to as the father of video art. In this project, we attempted to virtually recreate some of his exhibits and exhibition spaces that are currently unavailable to elucidate their meaning. Among the exhibits, the three most interactive and meaningful works, namely Prepared Pianos (4 units), Electronic Television (13 units), and Random Access, were recreated in virtual reality (VR) space. To compensate for the limitations imposed by simple interactions between existing VR exhibitions of art works, this project was developed with the utmost focus on preserving the artistic value of the original work while maximizing the exhibition space reproduced in VR as well as audience immersion in the work."	https://dl.acm.org/doi/abs/10.1145/3450615.3464535	Jiyoung Kang, Byung-kyu Jeon, Seon-hwi Kim, Su-yong Park
FLIP Fluids as a Bi-directional Fuel Source in a Volumetric Fluid Simulation	We present a fast and flexible technique for creating Pyro simulations directly from and coupled with FLIP simulations for fuel. A typical Pyro simulation involves numerous ways to generate fuel but mostly as an input exclusively into the Pyro simulation not as a coupled partner into the simulation. None of the characteristics of the fuel and specifically the reaction of the fuel consumption is considered in a traditional Pyro simulation. We strived to create this relationship in a coupled simulation. This introduced shared fuel, divergence, and velocity data. All this sharing creates a more realistic simulation with little artificial initial velocity.	https://dl.acm.org/doi/abs/10.1145/3450623.3464683	Nema Safvati, Ashraf Ghoniem
Fast Facial Animation from Video	Real time facial animation for virtual 3D characters has important applications such as AR/VR, interactive 3D entertainment, pre-visualization and video conferencing. Yet despite important research breakthroughs in facial tracking and performance capture, there are very few commercial examples of real-time facial animation applications in the consumer market. Mass adoption requires realtime performance on commodity hardware and visually pleasing animation that is robust to real world conditions, without requiring manual calibration. We present an end-to-end deep learning framework for regressing facial animation weights from video that addresses most of these challenges. Our formulation is fast (3.2 ms), utilizes images of real human faces along with millions of synthetic rendered frames to train the network on real-world scenarios, and produces jitter-free visually pleasing animations.	https://dl.acm.org/doi/abs/10.1145/3450623.3464681	Inaki Navarro, Dario Kneubuehler, Tijmen Verhulsdonck, Eloi Du Du Bois, Will Welch, Vivek Verma, Ian Sachs, Kiran Bhat
Fast diffraction pathfinding for dynamic sound propagation	In the context of geometric acoustic simulation, one of the more perceptually important yet difficult to simulate acoustic effects is diffraction, a phenomenon that allows sound to propagate around obstructions and corners. A significant bottleneck in real-time simulation of diffraction is the enumeration of high-order diffraction propagation paths in scenes with complex geometry (e.g. highly tessellated surfaces). To this end, we present a dynamic geometric diffraction approach that consists of an extensive mesh preprocessing pipeline and complementary runtime algorithm. The preprocessing module identifies a small subset of edges that are important for diffraction using a novel silhouette edge detection heuristic. It also extends these edges with planar diffraction geometry and precomputes a graph data structure encoding the visibility between the edges. The runtime module uses bidirectional path tracing against the diffraction geometry to probabilistically explore potential paths between sources and listeners, then evaluates the intensities for these paths using the Uniform Theory of Diffraction. It uses the edge visibility graph and the A* pathfinding algorithm to robustly and efficiently find additional high-order diffraction paths. We demonstrate how this technique can simulate 10th-order diffraction up to 568 times faster than the previous state of the art, and can efficiently handle large scenes with both high geometric complexity and high numbers of sources.	https://dl.acm.org/doi/abs/10.1145/3450626.3459751	Carl Schissler, Gregor Mückl, Paul Calamia
Fast linking numbers for topology verification of loopy structures	It is increasingly common to model, simulate, and process complex materials based on loopy structures, such as in yarn-level cloth garments, which possess topological constraints between inter-looping curves. While the input model may satisfy specific topological linkages between pairs of closed loops, subsequent processing may violate those topological conditions. In this paper, we explore a family of methods for efficiently computing and verifying linking numbers between closed curves, and apply these to applications in geometry processing, animation, and simulation, so as to verify that topological invariants are preserved during and after processing of the input models. Our method has three stages: (1) we identify potentially interacting loop-loop pairs, then (2) carefully discretize each loop's spline curves into line segments so as to enable (3) efficient linking number evaluation using accelerated kernels based on either counting projected segment-segment crossings, or by evaluating the Gauss linking integral using direct or fast summation methods (Barnes-Hut or fast multipole methods). We evaluate CPU and GPU implementations of these methods on a suite of test problems, including yarn-level cloth and chainmail, that involve significant processing: physics-based relaxation and animation, user-modeled deformations, curve compression and reparameterization. We show that topology errors can be efficiently identified to enable more robust processing of loopy structures.	https://dl.acm.org/doi/abs/10.1145/3450626.3459778	Ante Qu, Doug L. James
Fast median filters using separable sorting networks	Median filters are a widely-used tool in graphics, imaging, machine learning, visual effects, and even audio processing. Currently, very-small-support median filters are performed using sorting networks, and large-support median filters are handled by (1) histogram-based methods. However, the constant factor on these (1) algorithms is large, and they scale poorly to data types above 8-bit integers. On the other hand, good sorting networks have not been described above the 7 X 7 case, leaving us with no fast way to compute integer median filters of modest size, and no fast way to compute floating point median filters for any size above 7 X 7. This paper describes new sorting networks that efficiently compute median filters of arbitrary size. The key idea is that these networks can be factored to exploit the separability of the sorting problem - they share common work across scanlines, and within small tiles of output. We also describe new ways to run sorting networks efficiently, using a sorting-specific instruction set, compiler, and interpreter. The speed-up over prior work is more than an order of magnitude for a wide range of data types and filter sizes. For 8-bit integers, we describe the fastest median filters for all sizes up to 25 X 25 on CPU, and up to 33 X 33 on GPU. For higher-precision types, we describe the fastest median filters at all sizes tested on both CPU and GPU.	https://dl.acm.org/doi/abs/10.1145/3450626.3459773	Andrew Adams
Fast quasi-harmonic weights for geometric data interpolation	We propose for interpolating geometric data, which are orders of magnitude faster to compute than state-of-the-art. Currently, interpolation (or, skinning) weights are obtained by solving large-scale constrained optimization problems with explicit constraints to suppress oscillative patterns, yielding smooth weights only after a substantial amount of computation time. As an alternative, our weights are obtained as minima of an unconstrained problem that can be optimized quickly using straightforward numerical techniques. We consider weights that can be obtained as solutions to a parameterized family of second-order elliptic partial differential equations. By leveraging the maximum principle and careful parameterization, we pose weight computation as an inverse problem of recovering optimal anisotropic diffusivity tensors. In addition, we provide a customized ADAM solver that significantly reduces the number of gradient steps; our solver only requires inverting tens of linear systems that share the same sparsity pattern. Overall, our approach achieves orders of magnitude acceleration compared to previous methods, allowing weight computation in near real-time.	https://dl.acm.org/doi/abs/10.1145/3450626.3459801	Yu Wang, Justin Solomon
Feedback of Rotational Sensation Experienced by Body for Immersive Telepresence	In our previous study, we proposed a telepresence system that can transfer the riding sensation of a vehicle (Segway) for assisting collaborative task. The system could provide a local expert who remotely attend the task not only the view of a remote environment that is captured by a camera but also the vestibular perception during the movement of the camera. In this study, we examined the rotation feedback by the rotary seat when the camera is rotated. The measured intensity adjustment showed that the angular acceleration of the rotary seat was about half that of the camera rotation. Further, the result of the simulator sickness questionnaire scores showed that the inphase rotation of the seat with the camera is appropriate for suppressing virtual reality sickness, indicating that the requirement of vestibular intensity is quite low compared with the visual cue showed on the head mounted display, which allows a designer to develop a sensation feedback device that has an actuator of low strength.	https://dl.acm.org/doi/abs/10.1145/3450618.3469154	Vibol Yem, Tsubasa Morita, Tomohiro Amemiya, Michiteru Kitazaki, Yasushi Ikei
Figmin XR: AR content creation platform	Figmin XR is a spatial computing application that allows non-technical users to easily create, collect & play with digital content. Featuring: Figmin XR is a multi-purpose app for the consumer AR market. It runs on Magic Leap 1, Hololens 2 and Nreal light. See it in action: https://youtu.be/0z3P21WLNiU	https://dl.acm.org/doi/abs/10.1145/3450615.3464532	Javier Davalos
Figure 1	"is a visual essay on the proliferation and mediation of the ""digital body"" in the contemporary politics of images. It is an attempt at locating the virtual body in the processes of production, circulation, and consumption of images concerning continuing computational advancements."	https://dl.acm.org/doi/abs/10.1145/3450507.3457435	Hirad Sab
Fire in paradise: mesoscale simulation of wildfires	Resulting from changing climatic conditions, wildfires have become an existential threat across various countries around the world. The complex dynamics paired with their often rapid progression renders wildfires an often disastrous natural phenomenon that is difficult to predict and to counteract. In this paper we present a novel method for simulating wildfires with the goal to realistically capture the combustion process of individual trees and the resulting propagation of fires at the scale of forests. We rely on a state-of-the-art modeling approach for large-scale ecosystems that enables us to represent each plant as a detailed 3D geometric model. We introduce a novel mathematical formulation for the combustion process of plants - also considering effects such as heat transfer, char insulation, and mass loss - as well as for the propagation of fire through the entire ecosystem. Compared to other wildfire simulations which employ geometric representations of plants such as cones or cylinders, our detailed 3D tree models enable us to simulate the interplay of geometric variations of branching structures and the dynamics of fire and wood combustion. Our simulation runs at interactive rates and thereby provides a convenient way to explore different conditions that affect wildfires, ranging from terrain elevation profiles and ecosystem compositions to various measures against wildfires, such as cutting down trees as firebreaks, the application of fire retardant, or the simulation of rain.	https://dl.acm.org/doi/abs/10.1145/3450626.3459954	Torsten Hädrich, Daniel T. Banuti, Wojtek Pałubicki, Sören Pirk, Dominik L. Michels
Fluid Fabrics in Trolls World Tour	We outline the development of natural effects like waterfalls, rivers and lava to the small scale world represented in Trolls World Tour. Creating natural effects in a world made of various fabrics brought new challenges in representing movement and scale. We examine our problem solving methods and how we blended fluid motion with cloth/fabric motion to achieve the desired effect.	https://dl.acm.org/doi/abs/10.1145/3450623.3464641	Steve Avoujageli, Landon Gray
Foldover-free maps in 50 lines of code	Mapping a triangulated surface to 2D space (or a tetrahedral mesh to 3D space) is an important problem in geometry processing. In computational physics, untangling plays an important role in mesh generation: it takes a mesh as an input, and moves the vertices to get rid of foldovers. In fact, mesh untangling can be considered as a special case of mapping where the geometry of the object is to be defined in the map space and the geometric domain is not explicit, supposing that each element is regular. In this paper, we propose a mapping method inspired by the untangling problem and compare its performance to the state of the art. The main advantage of our method is that the untangling aims at producing locally injective maps, which is the major challenge of mapping. In practice, our method produces locally injective maps in very difficult settings, both in 2D and 3D. We demonstrate it on a large reference database as well as on more difficult stress tests. For a better reproducibility, we publish the code in Python for a basic evaluation, and in C++ for more advanced applications.	https://dl.acm.org/doi/abs/10.1145/3450626.3459847	Vladimir Garanzha, Igor Kaporin, Liudmila Kudryavtseva, François Protais, Nicolas Ray, Dmitry Sokolov
Forward Selfies	Taking selfies is a common practice for smartphone users. Simultaneously capturing oneself and the desired background is not a trivial task, because it is often not possible to get a good view of both. Moreover, users often loose attention of their surroundings, thus taking a selfie also showed to lead to serious injuries. To ease the process of capturing selfies and to make it more safe, this work proposes forward selfies as a simple yet effective concept to account for both, risk and challenges. Forward selfies seamlessly combine images of the front-facing and the rear-facing smartphone camera. We propose a mobile app that builds on this concept and implements the selfie synthesis in a post-processing image composition stage. Thereby, we can take advantage of the commonly more advanced back-camera hardware, i.e., providing higher image resolutions, larger field of views, and different perspectives. Finally, we leverage built-in camera optimizations for independently (de-)focusing objects at different distances, such as for persons and backgrounds. We conclude that the concept of forward selfies can effectively address and solve certain challenges of capturing selfies, which we demonstrate by a simple app user interface.	https://dl.acm.org/doi/abs/10.1145/3450415.3464403	Philipp Trenz, Sebastian Pasewaldt, Mandy Klingbeil, Jürgen Döllner, Matthias Trapp
FovVideoVDP: a visible difference predictor for wide field-of-view video	FovVideoVDP is a video difference metric that models the spatial, temporal, and peripheral aspects of perception. While many other metrics are available, our work provides the first practical treatment of these three central aspects of vision simultaneously. The complex interplay between spatial and temporal sensitivity across retinal locations is especially important for displays that cover a large field-of-view, such as Virtual and Augmented Reality displays, and associated methods, such as foveated rendering. Our metric is derived from psychophysical studies of the early visual system, which model spatio-temporal contrast sensitivity, cortical magnification and contrast masking. It accounts for physical specification of the display (luminance, size, resolution) and viewing distance. To validate the metric, we collected a novel foveated rendering dataset which captures quality degradation due to sampling and reconstruction. To demonstrate our algorithm's generality, we test it on 3 independent foveated video datasets, and on a large image quality dataset, achieving the best performance across all datasets when compared to the state-of-the-art.	https://dl.acm.org/doi/abs/10.1145/3450626.3459831	Rafał K. Mantiuk, Gyorgy Denes, Alexandre Chapiro, Anton Kaplanyan, Gizem Rufo, Romain Bachy, Trisha Lian, Anjul Patney
Foveated Monte-Carlo Denoising	In this work, we propose a temporally-stable denoising system that is capable of reconstructing MC renderings in a foveated manner. We develop a multi-scale convolutional neural network that starts at a base (downsampled) resolution and denoises progressively higher resolutions. Our network learns to use the lower resolutions and the previous frames to denoise each foveal layer. We demonstrate how this architecture produces accurate denoised results at a much lower computational cost.	https://dl.acm.org/doi/abs/10.1145/3450618.3469140	Nicholas Milef, Nima Kalantari
Free-form scanning of non-planar appearance with neural trace photography	We propose neural trace photography, a novel framework to automatically learn high-quality scanning of non-planar, complex anisotropic appearance. Our key insight is that free-form appearance scanning can be cast as a geometry learning problem on unstructured point clouds, each of which represents an image measurement and the corresponding acquisition condition. Based on this connection, we carefully design a neural network, to jointly optimize the lighting conditions to be used in acquisition, as well as the spatially independent reconstruction of reflectance from corresponding measurements. Our framework is not tied to a specific setup, and can adapt to various factors in a data-driven manner. We demonstrate the effectiveness of our framework on a number of physical objects with a wide variation in appearance. The objects are captured with a light-weight mobile device, consisting of a single camera and an RGB LED array. We also generalize the framework to other common types of light sources, including a point, a linear and an area light.	https://dl.acm.org/doi/abs/10.1145/3450626.3459679	Xiaohe Ma, Kaizhang Kang, Ruisheng Zhu, Hongzhi Wu, Kun Zhou
Freezing Fire – Automated Light-Passes for Stop-Motion VFX	This work proposes and evaluates a method of image-based rendering for integrating light-emitting CG assets with digital photography. The framework consists of a capture stage, in which footage of the scene under varied lighting is acquired, and a reconstruction stage, which outputs the calculated light contribution of the CG element upon the scene. This form of relighting is novel as it embraces scenarios where the light source is intended to be in the frame. The freedom to introduce emissive objects in post opens creative room for light animation and was assessed here as employed in the production of a stop-motion short-film.	https://dl.acm.org/doi/abs/10.1145/3450623.3464640	Paulo Scatena
From A-Pose to AR-Pose: Animating Characters in Mobile AR	We present AR-Pose, a mobile AR app to generate keyframe-based animations of rigged humanoid characters. The smartphone's positional and rotational degrees of freedom are used for two purposes: (i) as a 3D cursor to interact with inverse kinematic (IK) controllers placed on or near the character's joints; and (ii) as a virtual camera that enables users to freely move around the character. Through the touch screen, users can activate/deactivate actions such as selecting an IK controller or pressing animation control buttons placed in a hovering 3D panel. By systematically re-positioning and saving the positions of the IK controllers, different poses can be achieved and, therefore, used to generate a 3D animation.	https://dl.acm.org/doi/abs/10.1145/3450415.3464401	Andreia Valente, Augusto Esteves, Daniel Lopes
From Creative Coding to Digital Humans:: Proceduralism as a Catalyst for Storytelling	Visual effects is a multi-disciplinary medium—how can we support the next generation of artists to engage deeply with animation, compositing, effects, and lighting in order to produce emotionally and visually compelling narrative work? How do we bridge the gulf between specialties that require an entire career to master? These are the key challenges we face in teaching the Master of Design Technology (MDT), a one-year graduate level program.	https://dl.acm.org/doi/abs/10.1145/3450549.3464410	Raqi Syed, Areito Echevarria, Lucy Jagers, Ripley Shi, Brock Trewavas, Phil Matich, Junqi Zhang, Jared Lee
From quest to quill: pushing the boundaries of VR storytelling in baobab's Baba Yaga and Namoo	"In this session, the team behind the Immersive Best-in-Show winner (Bonfire) at Siggraph 2019 reveals creative and technical insights from their two recent award winning VR projects: Baba Yaga and Namoo. Baba Yaga: Inspired by one of the most distinctive and well-known characters from Eastern European folklore, Baobab Studio's interactive VR story Baba Yaga re-imagines this ancient fairytale with themes of environmental conservation and female empowerment (the project features an all-female, diverse cast with Kate Winslet, Daisy Ridley, Jennifer Hudson, and Glenn Close). Baba Yaga is Baobab's most ambitious interactive experience to date, the culmination of all of its previous narrative experiments with AI intelligent characters, real-time responsive environments, emergent branching storytelling, all while pushing the boundaries of what it means to tell stories in immersive animation. The creative team will explore the following areas of innovation (and more) on this project: How do they make you, the audience, a main character where your choices really matter and have meaningful consequences. How did they create a fairytale universe that is fully interactive with real-time AI-driven characters and environments. How did they employ a theatrical art style for VR that combines theatrical lighting, stage-craft design elements, and a hand-crafted feel all running in real-time on a mobile headset. How did they layer spatialized sound and music into our process to recreate the mythical world of Baba Yaga? The Baba Yaga speakers are Eric Darnell, writer/director and co-founder of Baobab Studios, Nathaniel Dirksen, visual effects supervisor, Amy Tucker, lighting supervisor, Larry Cutler, executive producer, and Scot Stafford, Sound Supervisor. Namoo: Namoo (meaning ""tree"" in Korean), is a narrative poem come to life as an animated VR experience entirely created with Oculus's VR animation tool ""Quill."" The project is led by esteemed Korean director Erick Oh (who won Annecy's Cristal Award for TV for The Dam Keeper Poems with Tonko House) in partnership with Baobab Studios. The entire piece takes place on a grassy knoll next to a seed that grows into a sapling and eventually a fully mature tree. This namoo might be interpreted as a kind of metaphor for the man's life, as it collects his meaningful memories in its branches - from pacifiers and stuffed animals to books, typewriters, and favorite scarves - to broken glasses and objects from times he'd rather soon forget. Namoo is a deeply personal yet surprisingly universal piece that will undoubtedly resonate with each viewer differently. The Namoo team will dive into all aspects of VR filmmaking to bring this visually rich film to life using Quill, from storyboarding to visual development to camera and staging to animation to optimizations for rendering on the Oculus Quest mobile headset. The Namoo speakers are Erick Oh, writer/director, Anika Nagpal, production manager, Eusong Lee, art director, and Nick Ladd, lead quill artist."	https://dl.acm.org/doi/abs/10.1145/3446368.3452126	Larry Cutler, Eric Darnell, Nathaniel Dirksen, Amy Tucker, Scot Stafford, Erick Oh, Anika Nagpal, Eusong Lee, Nick Ladd
Fusion 360 gallery: a dataset and environment for programmatic CAD construction from human design sequences	Parametric computer-aided design (CAD) is a standard paradigm used to design manufactured objects, where a 3D shape is represented as a program supported by the CAD software. Despite the pervasiveness of parametric CAD and a growing interest from the research community, currently there does not exist a dataset of realistic CAD models in a concise programmatic form. In this paper we present the , consisting of a simple language with just the and modeling operations, and a dataset of 8,625 human design sequences expressed in this language. We also present an interactive environment called the , which exposes the sequential construction of a CAD program as a Markov decision process, making it amendable to machine learning approaches. As a use case for our dataset and environment, we define the CAD reconstruction task of recovering a CAD program from a target geometry. We report results of applying state-of-the-art methods of program synthesis with neurally guided search on this task.	https://dl.acm.org/doi/abs/10.1145/3450626.3459818	Karl D. D. Willis, Yewen Pu, Jieliang Luo, Hang Chu, Tao Du, Joseph G. Lambourne, Armando Solar-Lezama, Wojciech Matusik
GPU-based simulation of cloth wrinkles at submillimeter levels	In this paper, we study physics-based cloth simulation in a very high resolution setting, presumably at submillimeter levels with millions of vertices, to meet perceptual precision of our human eyes. State-of-the-art simulation techniques, mostly developed for unstructured triangular meshes, can hardly meet this demand due to their large computational costs and memory footprints. We argue that in a very high resolution, it is more plausible to use regular meshes with an underlying grid structure, which can be highly compatible with GPU acceleration like high-resolution images. Based on this idea, we formulate and solve the nonlinear optimization problem for simulating high-resolution wrinkles, by a fast block-based descent method with reduced memory accesses. We also investigate the development of the collision handling component in our system, whose performance benefits greatly from the grid structure. Finally, we explore various issues related to the applications of our system, including initialization for fast convergence and temporal coherence, gathering effects, inflation and stuffing models, and mesh simplification. We can treat our system as a quasistatic wrinkle synthesis tool, run it as a standalone dynamic simulator, or integrate it into a multi-resolution solver as an additional component. The experiment demonstrates the capability, efficiency and flexibility of our system in producing a variety of high-resolution wrinkles effects.	https://dl.acm.org/doi/abs/10.1145/3450626.3459787	Huamin Wang
Gaming at Warp Speed: Improving Aiming with Late Warp	Latency can make all the difference in competitive online games. Late warp is a class of techniques used in VR that can reduce latency in FPS games as well. Prior work has demonstrated these techniques can recover most of the player performance lost to computer or network latency. Inspired by work demonstrating the usefulness of late warp as a potential solution to FPS latency, we provide an interactive demonstration, playable in a web browser, that shows how much latency limits aiming performance, and how late warp can help.	https://dl.acm.org/doi/abs/10.1145/3450550.3465347	Ben Boudaoud, Pyarelal Knowles, Joohwan Kim, Josef Spjut
Garage: GPU particle-based AR content for futuristic experiences	"In futuristic AR, we believe that both real and virtual objects surrounding the player should be interactive and controllable. With this in mind, we introduce ""Garage"", which is an AR project based on our particle-based system capable of outputting a variety of interactive content. In our system, everything in the player's surrounding environment is presented as particles and adequately simulated in real-time on a desktop PC equipped with a discrete GPU and rendered to in-house HMD, while their color and depth information is captured and sent by RGB camera and LiDAR sensor. LiDAR data is converted to particles using an algorithm that calculates world coordinated positions from depth values. Our system content and provided experiences have time flexibility and spatial control features that cannot be achieved in conventional polygon mesh-based systems. Additionally, the AR information output is presented in an appealing visual style that conserves GPU resources. Because of these features, Garage has a profound impact on AR immersion, and can augments our perception of the world in a limitless and creative manner. To demonstrate the abilities of our system and build new interactive AR experiences, in this project, we designed a game and created several demos that can give players interesting glimpses into the future world of augmented reality."	https://dl.acm.org/doi/abs/10.1145/3450615.3464529	Daiki Taniguchi
Gaze-aware displays and interaction	Being able to detect and to employ gaze enhances digital displays. Research on gaze-contingent or gaze-aware display devices dates back two decades. This is the time, though, that it could truly be employed for fast, low-latency gaze-based interaction and for optimization of computer graphics rendering such as in foveated rendering. Moreover, Virtual Reality (VR) is becoming ubiquitous. The widespread availability of consumer grade VR Head Mounted Displays (HMDs) transformed VR to a commodity available for everyday use. VR applications are now abundantly designed for recreation, work and communication. However, interacting with VR setups requires new paradigms of User Interfaces (UIs), since traditional 2D UIs are designed to be viewed from a static vantage point only, e.g. the computer screen. Adding to this, traditional input methods such as the keyboard and mouse are hard to manipulate when the user wears a HMD. Recently, companies such as HTC announced embedded eye-tracking in their headsets and therefore, novel, immersive 3D UI paradigms embedded in a VR setup can now be controlled via eye gaze. Gaze-based interaction is intuitive and natural the users. Tasks can be performed directly into the 3D spatial context without having to search for an out-of-view keyboard/mouse. Furthermore, people with physical disabilities, already depending on technology for recreation and basic communication, can now benefit even more from VR. This course presents timely, relevant information on how gaze-contingent displays, in general, including the recent advances of Virtual Reality (VR) eye tracking capabilities can leverage eye-tracking data to optimize the user experience and to alleviate usability issues surrounding intuitive interaction challenges. Research topics to be covered include saliency models, gaze prediction, gaze tracking, gaze direction, foveated rendering, stereo grading and 3D User Interfaces (UIs) based on gaze on any gaze-aware display technology.	https://dl.acm.org/doi/abs/10.1145/3450508.3464606	Carl S. Marshall
General virtual sketching framework for vector line art	Vector line art plays an important role in graphic design, however, it is tedious to manually create. We introduce a general framework to produce line drawings from a wide variety of images, by learning a mapping from raster image space to vector image space. Our approach is based on a recurrent neural network that draws the lines one by one. A differentiable rasterization module allows for training with only supervised raster data. We use a dynamic window around a virtual pen while drawing lines, implemented with a proposed aligned cropping and differentiable pasting modules. Furthermore, we develop a stroke regularization loss that encourages the model to use fewer and longer strokes to simplify the resulting vector image. Ablation studies and comparisons with existing methods corroborate the efficiency of our approach which is able to generate visually better results in less computation time, while generalizing better to a diversity of images and applications.	https://dl.acm.org/doi/abs/10.1145/3450626.3459833	Haoran Mo, Edgar Simo-Serra, Chengying Gao, Changqing Zou, Ruomei Wang
Geometry and tool motion planning for curvature adapted CNC machining	"CNC machining is the leading subtractive manufacturing technology. Although it is in use since decades, it is far from fully solved and still a rich source for challenging problems in geometric computing. We demonstrate this at hand of 5-axis machining of freeform surfaces, where the degrees of freedom in selecting and moving the cutting tool allow one to adapt the tool motion optimally to the surface to be produced. We aim at a high-quality surface finish, thereby reducing the need for hard-to-control post-machining processes such as grinding and polishing. Our work is based on a careful geometric analysis of curvature-adapted machining via so-called second order line contact between tool and target surface. On the geometric side, this leads to a new continuous transition between ""dual"" classical results in surface theory concerning osculating circles of surface curves and osculating cones of tangentially circumscribed developable surfaces. Practically, it serves as an effective basis for tool motion planning. Unlike previous approaches to curvature-adapted machining, we solve locally optimal tool positioning and motion planning within a single optimization framework and achieve curvature adaptation even for convex surfaces. This is possible with a toroidal cutter that contains a negatively curved cutting area. The effectiveness of our approach is verified at hand of digital models, simulations and machined parts, including a comparison to results generated with commercial software."	https://dl.acm.org/doi/abs/10.1145/3450626.3459837	Michael Bartoň, Michal Bizzarri, Florian Rist, Oleksii Sliusarenko, Helmut Pottmann
Global Illumination-Aware Color Remapping with Fidelity for Texture Values	Our aim is to convert an object's appearance to an arbitrary color considering the light scattering in the entire scene, which is often called the global illumination. Existing stylization methods convert the color of an object with a 1-dimensional texture for 3-dimensional computer graphics to reproduce a typical style used in illustrations and cel animations. However, they cannot express global illumination effects such as color bleedings and soft shadows. We propose a method to compute the global illumination and convert the shading to an arbitrary color. It consists of subpath tracing from the eye to the object, and radiance estimation on the object. The radiance is stored and used later to convert its color. The method reproduces reflections in other objects with the converted color. As a result, we can convert the color of illumination effects such as soft shadows and refractions.	https://dl.acm.org/doi/abs/10.1145/3450618.3469165	Kohei Doi, Yuki Morimoto, Reiji Tsuruno
Goodbye Mister Octopus	Goodbye Mister Octopus is an illuminating coming of age tale entirely hand-animated on Quill about the questioning of identity, of what our loved ones represent, and the perception of those around us. Follow Stella, as she learns about herself, her family, and what it means to grow up.	https://dl.acm.org/doi/abs/10.1145/3446367.3452140	Amaury Campion, Lily Lambert
Greyhound: a dive into the depths of colossal photorealism	"Derived from a novel called ""The Good Shepherd"" by C.S. Forester, Greyhound was adapted for the screen by Tom Hanks. The story follows the experience of U.S. Naval Commander Ernest Krause (played by Hanks) as he escorts a convoy across the Mid-Atlantic Gap in 1942. Visualizing this story brought complex but exciting challenges to the DNEG team. We had to deliver elaborate shots of WWII ships and submarines, produce ocean sims, enhance limited live-action set photography and craft the North Atlantic around it - all while coming onto the film after principal photography had finished. Once awarded to DNEG, Greyhound's VFX work had an immediately tight time-frame. An early objective was to produce shot content that genuinely assisted the film-makers in making confident narrative and editorial decisions. From our side at DNEG, this meant implementing efficient workflows that allowed a shot in layout to be passed quickly through the pipeline, all the way to producing a client deliverable with minimal repetitive human input. Although we were working with a short post-production period, we were able to allow the filmmakers a surprising amount of latitude by letting them view the impact of their decisions, not only as cheap low-fi renders but as lit, rendered and composited sequences. Authenticity is key for a show like this. A minute-by-minute account via radar plans was issued by production under the remit of a naval professional. This determined the weather conditions, ocean Beaufort, time of day, ship orientation and course per shot. We mocked out all of these plans into one master scene in layout, and this gave us a shot-by-shot lighting timeline for the entire show. The story required the portrayal of different hours (and subsequent weather changes) over a 24-hour period. To achieve this visualization we used a specially built multi-camera rig which enabled us to shoot 360-degree time-lapses from dawn until dusk in high dynamic range. For night-time battle sequences, we achieved photorealistic looks by using subtle moonlight, fire, flares, and gun-muzzle-flashes as light sources. The story of Greyhound follows Allied convoys as they cross an oceanic zone known as the 'Black Pit', called so because it is an area out of range of protective air cover. Because of this, the digital recreation of the North Atlantic gap was critical to visualizing the story. The ocean itself is also critical in affecting how ships would move and react to changes in the weather. Using the Beaufort scale, DNEG was able to match the sea conditions to the film's story beats. This in turn drove the animation of the ships, the water simulations and the look of the shots. In Greyhound, every shot that featured the North Atlantic as a background was a digital replacement."	https://dl.acm.org/doi/abs/10.1145/3446368.3453723	Haja Raparison, Sebastian von Overheidt
Guaranteed globally injective 3D deformation processing	We extend recent advances in the numerical time-integration of contacting elastodynamics [Li et al. 2020] to build a new framework, called Injective Deformation Processing (IDP), for the robust solution of a wide range of mesh deformation problems requiring injectivity. IDP solves challenging 3D (and 2D) geometry processing and animation tasks on meshes, via artificial time integration, with guarantees of both non-inversion and non-overlap. To our knowledge IDP is the first framework for 3D deformation processing that can efficiently guarantee globally injective deformation without geometric locking. We demonstrate its application on a diverse set of problems and show its significant improvement over state-of-the-art for globally injective 3D deformation.	https://dl.acm.org/doi/abs/10.1145/3450626.3459757	Yu Fang, Minchen Li, Chenfanfu Jiang, Danny M. Kaufman
Guaranteed-quality higher-order triangular meshing of 2D domains	We present a guaranteed quality mesh generation algorithm for the curvilinear triangulation of planar domains with piecewise polynomial boundary. The resulting mesh consists of higher-order triangular elements which are not only regular (i.e., with injective geometric map) but respect strict bounds on quality measures like scaled Jacobian and MIPS distortion. This also implies that the curved triangles' inner angles are bounded from above and below. These are key quality criteria, for instance, in the field of finite element analysis. The domain boundary is reproduced exactly, without geometric approximation error. The central idea is to transform the curvilinear meshing problem into a linear meshing problem via a carefully constructed transformation of bounded distortion, enabling us to leverage key results on guaranteed-quality straight-edge triangulation. The transformation is based on a simple yet general construction and observations about convergence properties of curves under subdivision. Our algorithm can handle arbitrary polynomial order, arbitrarily sharp corners, feature and interface curves, and can be executed using rational arithmetic for strict reliability.	https://dl.acm.org/doi/abs/10.1145/3450626.3459673	Manish Mandad, Marcel Campen
H2ope	A student, one day, asks around the class for water; however none is left. Questions hence arise among his classmates about what would happen if the water runs out? (This story is purely experimental and illustrated according to children's point of view about the thirst and water shortage.)	https://dl.acm.org/doi/abs/10.1145/3446367.3451991	Ashkan Rahgozar, Negin Khojaie, Tala Porbaha
Hair Grooming with Imageworks’ Fyber	Fyber is our new proprietary standalone grooming software solution for hair and fur on all current and upcoming film projects. It was developed at Sony Picture Imageworks (SPI) to address the need for a faster, more interactive and more artist-friendly tool to generate any kind of hair, ranging from a characters head hair to fully furred animals, with the goal to significantly lower grooming times and an easier learning experience for new artists. As a node based software, Fyber offers great flexibility to achieve any look an artist might desire while also providing fast visual feedback thanks to its highly multi-threaded computation graph and integrated OpenGL and Arnold viewports. Fyber's underlying engine is fully separated from its user interface which allows for a seamless and easy integration into 3rd party applications like Maya and Katana where it can be used to compute hair on the fly or to render it to their respective viewports. It was first used for SPI's work on Disney's Mulan and has replaced our previous grooming solution on all shows ever since.	https://dl.acm.org/doi/abs/10.1145/3450623.3464668	Daniela Hasenbring, Henrik Karlsson
Health Greeter Kiosk: Tech-Enabled Signage to Encourage Face Mask Use and Social Distancing	COVID-19 has been the cause of a global health crisis over the last year. High transmission rates of the virus threaten to cause a wave of infections which have the potential to overwhelm hospitals, leaving infected individuals without treatment. The World Health Organization (WHO) endorses two primary preventative measures for reducing transmission rates: the usage of face masks and adherence to social distancing [World Health Organization 2021]. In order to increase population adherence to these measures, we designed the Health Greeter Kiosk: a form of digital signage. Traditional physical signage has been used throughout the pandemic to enforce COVID-19 mandates, but lack population engagement and can easily go unnoticed. We designed this kiosk with the intent to reinforce these COVID-19 prevention mandates while also considering the necessity of population engagement. Our kiosk encourages engagement by providing visual feedback which is based on analysis from our kiosk's computer vision software. This software integrates real-time face mask and social distance detection on a low-budget computer, without the need of a GPU. Our kiosk also collects statistics, relevant to the WHO mandates, which can be used to develop well-informed reopening strategies.	https://dl.acm.org/doi/abs/10.1145/3450550.3465339	Max Hudnell, Steven King
Hexells: self-organizing textures	is a self-organizing system of cells that was designed to synthesize and maintain various textures through local communication between the cells. It is inspired by natural pattern formations found on plants and animal skins. The cellular automata (CA) update rule is modeled using a small neural network inspired by Mordvintsev et al. [2020]. We created a WebGL demo that allows users to explore and interact with more than one hundred learned CA texture-generating behaviors. The chosen projection shows the system behavior at local and global scales at the same time.	https://dl.acm.org/doi/abs/10.1145/3450507.3457438	Alexander Mordvintsev
Hierarchical neural reconstruction for path guiding using hybrid path and photon samples	Path guiding is a promising technique to reduce the variance of path tracing. Although existing online path guiding algorithms can eventually learn good sampling distributions given a large amount of time and samples, the speed of learning becomes a major bottleneck. In this paper, we accelerate the learning of sampling distributions by training a light-weight neural network offline to reconstruct from sparse samples. Uniquely, we design our neural network to directly operate convolutions on a sparse quadtree, which regresses a high-quality hierarchical sampling distribution. Our approach can reconstruct reasonably accurate sampling distributions faster, allowing for efficient path guiding and rendering. In contrast to the recent offline neural path guiding techniques that reconstruct low-resolution 2D images for sampling, our novel hierarchical framework enables more fine-grained directional sampling with less memory usage, effectively advancing the practicality and efficiency of neural path guiding. In addition, we take advantage of hybrid bidirectional samples including both path samples and photons, as we have found this more robust to different light transport scenarios compared to using only one type of sample as in previous work. Experiments on diverse testing scenes demonstrate that our approach often improves rendering results with better visual quality and lower errors. Our framework can also provide the proper balance of speed, memory cost, and robustness.	https://dl.acm.org/doi/abs/10.1145/3450626.3459810	Shilin Zhu, Zexiang Xu, Tiancheng Sun, Alexandr Kuznetsov, Mark Meyer, Henrik Wann Jensen, Hao Su, Ravi Ramamoorthi
High-order differentiable autoencoder for nonlinear model reduction	This paper provides a new avenue for exploiting deep neural networks to improve physics-based simulation. Specifically, we integrate the classic Lagrangian mechanics with a deep autoencoder to accelerate elastic simulation of deformable solids. Due to the inertia effect, the dynamic equilibrium cannot be established without evaluating the second-order derivatives of the deep autoencoder network. This is beyond the capability of off-the-shelf automatic differentiation packages and algorithms, which mainly focus on the gradient evaluation. Solving the nonlinear force equilibrium is even more challenging if the standard Newton's method is to be used. This is because we need to compute a third-order derivative of the network to obtain the variational Hessian. We attack those difficulties by exploiting complex-step finite difference, coupled with reverse automatic differentiation. This strategy allows us to enjoy the convenience and accuracy of complex-step finite difference and in the meantime, to deploy complex-value perturbations as collectively as possible to save excessive network passes. With a GPU-based implementation, we are able to wield deep autoencoders (e.g., 10+ layers) with a relatively high-dimension latent space in real-time. Along this pipeline, we also design a sampling network and a weighting network to enable Cubature integration in order to incorporate nonlinearity in the model reduction. We believe this work will inspire and benefit future research efforts in nonlinearly reduced physical simulation problems.	https://dl.acm.org/doi/abs/10.1145/3450626.3459754	Siyuan Shen, Yin Yang, Tianjia Shao, He Wang, Chenfanfu Jiang, Lei Lan, Kun Zhou
Highlight-aware two-stream network for single-image SVBRDF acquisition	This paper addresses the task of estimating spatially-varying reflectance (i.e., SVBRDF) from a single, casually captured image. Central to our method is a highlight-aware (HA) convolution operation and a two-stream neural network equipped with proper training losses. Our HA convolution, as a novel variant of standard (ST) convolution, directly modulates convolution kernels under the guidance of automatically learned masks representing potentially overexposed highlight regions. It helps to reduce the impact of strong specular highlights on diffuse components and at the same time, hallucinates plausible contents in saturated regions. Considering that variation of saturated pixels also contains important cues for inferring surface bumpiness and specular components, we design a two-stream network to extract features from two different branches stacked by HA convolutions and ST convolutions, respectively. These two groups of features are further fused in an attention-based manner to facilitate feature selection of each SVBRDF map. The whole network is trained end to end with a new perceptual adversarial loss which is particularly useful for enhancing the texture details. Such a design also allows the recovered material maps to be disentangled. We demonstrate through quantitative analysis and qualitative visualization that the proposed method is effective to recover clear SVBRDFs from a single casually captured image, and performs favorably against state-of-the-arts. Since we impose very few constraints on the capture process, even a non-expert user can create high-quality SVBRDFs that cater to many graphical applications.	https://dl.acm.org/doi/abs/10.1145/3450626.3459854	Jie Guo, Shuichang Lai, Chengzhi Tao, Yuelong Cai, Lei Wang, Yanwen Guo, Ling-Qi Yan
HodgeNet: learning spectral geometry on triangle meshes	Constrained by the limitations of learning toolkits engineered for other applications, such as those in image processing, many mesh-based learning algorithms employ data flows that would be atypical from the perspective of conventional geometry processing. As an alternative, we present a technique for learning from meshes built from standard geometry processing modules and operations. We show that low-order eigenvalue/eigenvector computation from operators parameterized using discrete exterior calculus is amenable to efficient approximate backpropagation, yielding spectral per-element or per-mesh features with similar formulas to classical descriptors like the heat/wave kernel signatures. Our model uses few parameters, generalizes to high-resolution meshes, and exhibits performance and time complexity on par with past work.	https://dl.acm.org/doi/abs/10.1145/3450626.3459797	Dmitriy Smirnov, Justin Solomon
Hollow earth and revisiting kong	Godzilla vs. Kong is a classic hero's journey that follows Kong on his quest to reconcile his past and defend his future. In this talk, VFX Supervisor Kevin Smith teams up with Animation Supervisor Dave Clayton to discuss Kong and the evolution of his personality and creating some of the amazing worlds he explores. Weta Digital worked hand-in-hand with filmmakers to imagine and visualise shots of Kong's story moments well in advance, including Kong's hilarious 'morning routine' Animation beats, editing style, and pacing were heavily explored from the early stages. Weta was responsible for Hollow Earth and the spectacular effects created by the ships that travel there in pursuit of Kong. Weta assumed responsibility for building thirteen hero environments, some of which sprawled hundreds of kilometres. One features a physical impossibility, with the horizon meeting an entirely new landscape rather than the sky. Another is in Antarctica, where wild weather whips through the scenes, coating sets and characters in layers of snow. Kevin and Dave will explain how they worked out a system of blocking out action beats and layouts as a single big choreographed movement independent of shot cuts. This approach gave filmmakers flexibility and freedom to get their action locked down in unison with FX and layout and edit the film as if it were a live-action sporting event, capturing a moment in time and presenting it to an audience with maximum drama.	https://dl.acm.org/doi/abs/10.1145/3446368.3452131	Kevin Smith, Dave Clayton
Holo-Box: Level-of-Detail Glanceable Interfaces for Augmented Reality	"Glanceable interfaces are Augmented Reality (AR) User Interfaces (UIs) for information retrieval ""at a glance"" relying on eye gaze for implicit input. While they provide rapid information retrieval, they often occlude a large part of the real-world. This is compounded as the amount of virtual information increases. Interacting with complex glanceable interfaces often results in unintentional eye gaze interaction and selections due to the Midas Touch problem. In this work, we present Holo-box, an innovative AR UI design that combines 2D compact glanceable interfaces with 3D virtual ""Holo-boxes"". We can utilize the glanceable 2D interface to provide compact information at a glance while using Holo-box for explicit input such as hand tracking activated when necessary, surpassing the Midas Touch problem and resulting in Level-of-Detail(LOD) for AR glanceable UIs. We test our proposed system inside a real-world machine shop to provide on-demand virtual information while minimizing unintentional real-world occlusion."	https://dl.acm.org/doi/abs/10.1145/3450618.3469175	Grigoris Daskalogrigorakis, Ann McNamara, Katerina Mania
HoloFight: An Augmented Reality Fighting Game	Augmented Reality (AR) provides opportunities to create exciting new kinds of digital entertainment, such as watching movies on a large virtual screen or playing games that interact with a real physical room. While a number of AR games have been built, many do not build on the control innovations found in modern console, PC, and mobile gaming [Von Itzstein et al. 2019]. To explore the space of immersive multiplayer experiences with support for control innovations found in common non-immersive video games, we present HoloFight, a multiplayer fighting game using two or more Microsoft HoloLens 2s, two or more Xbox controllers, and the various natural user interfaces supported by the Microsoft HoloLens 2.	https://dl.acm.org/doi/abs/10.1145/3450615.3464531	Shalva Kohen, Carmine Elvezio, Steven Feiner
HoloVista: Designing for Immersion: Using a mobile app to simulate an alternate reality	HoloVista is a mixed reality social media simulator game reminiscent of a near-future Instagram. Players experience a week in our protagonist Carmen's life through the places she goes, the objects she photographs, the thoughts she shares on social media, and her chats with friends. Every time Carmen travels to a new location in the story, players access a virtual camera, which allows them to view the game's environments in full 360°, finding and photographing significant objects. By taking photos and solving puzzles, players learn a secret that Carmen has been running since childhood. Our goal was to create an immersive mobile XR experience with no peripherals. To achieve this, we relied on interaction design and narrative. Leveraging the phone's gyroscope and accelerometer, we gave players a sense of presence within a fictional space by letting them use the same motions/gestures to explore it as they would when examining a real-life scene through the game's camera. In this way, HoloVista engages the proprioception area of the brain, making people feel as though they are physically present in the world we have built. In this document, we explore several of our techniques for player immersion.	https://dl.acm.org/doi/abs/10.1145/3450415.3466172	Nadya Lev, Star St.Germain
Home Studio: DIY Interior Design in Mixed Reality	Virtual staging of real estate listings increases the appeal of a property by letting prospective buyers envision a living space remotely. However, existing tools employed to stage homes limit the scale of the visualization to a set of fixed images provided by customers or require 3D artist expertise to reconstruct the space. The adoption of 3D Matterport scans has accelerated due to the Covid-19 pandemic as a means to enable virtual tours and adhere to social distancing guidelines. We present Home Studio, a virtual staging tool that empowers non-experts, letting them furnish any Matterport scene and create photo-realistic renders in a matter of minutes. Our tool lets customers dive into their designs using a virtual reality headset to assess the final product in an immersive experience.	https://dl.acm.org/doi/abs/10.1145/3450615.3464528	Christian Vazquez, Nicole Tan, Shrenik Sadalgi
How a Basement Inventor Builds Volumetric Displays	This interactive session introduces participants to a systematic approach to building solutions for difficult problems. By looking at the challenges the author faced when building a volumetric display, the session participants are invited to engage in a discussion of problem-solving techniques that could potentially be applied to this domain area. Participants will come out of this session with an alternative set of tools and an appreciation for what is possible to accomplish by those with a limited budget and resources (aka the basement inventor).	https://dl.acm.org/doi/abs/10.1145/3450616.3470531	Dan Foisy
Hush	Hush is an immersive Virtual Reality experience rooted in the Northern myths of the merpeople, who lured sailors and longing souls to the sea. Like the lost ones of the past, you begin by the seaside. The world around you dissolves as you hear the calling from the sea, and you are submerged in a suggestive underwater world, where the distinction between reality and imagination, man and nature, disappears. Hush is a stand-alone VR piece, but it is also a companion piece to the hybrid documentary film Elsewhere, also directed by Vibeke Bryld and supported by New Danish Screen at the Danish Film Institute, which is based in the same universe as Hush. Elsewhere premiered at CPH:DOX 2021.	https://dl.acm.org/doi/abs/10.1145/3446367.3448635	Vibeke Bryld, Maria Christensen, Lars Hemmingsen Nørgaard
ILM presents: the visual effects of the mandalorian: from virtual production to seamless VFX	"ILM and its partner visual effects companies take you behind the scenes of the second season of Lucasfilm's hit Disney+ series ""The Mandalorian."" The team will discuss an array of the 5,000 visual effects shots created by the global team from sand dragons to ice spiders and miniatures as well. advancements made in the virtual production arena. The panelists will discuss ILM StageCraft 2.0 as well as Helios, ILM's groundbreaking new real-time render engine implemented for the first time this season."	https://dl.acm.org/doi/abs/10.1145/3446368.3452368	Richard Bluff, Rachel Rose, Joseph Kasparian, Patrick Gehlen, Hal Hickel, Charmaine Chan, Safari Sosebee
Imagining the Great Before	During the making of Pixar's 2020 animated movie Soul, we were tasked with having to create a brand-new world, the Soul World, which posed as a challenge to design and express within traditional art forms. As with most animated features, we had to execute within in a limited amount of time, while responding to an ever-evolving storyline. In order to achieve this goal, we had to approach it unconventionally. One method that helped greatly, was expanding an in-house texture development tool into a real-time look development environment. This new tool enabled us to iterate much more quickly and frequently, which in turn, helped us receive more timely feedback from the Director and Production Designer in order to hit the look they were after. We also used more established tools to explore new looks. Maya, for example, allowed us to effectively and quickly mock up entire environments with enough color and lighting information to make broad decisions. Since one of the new worlds we were building had to emulate a child's playground while incorporating symmetry, we were able to establish the language quite effectively thank's to Maya's familiar interface. For the parts of the set that were unfamiliar to us, like 'etherial Pavilions', we turned to Houdini to try capture something fresh and new. We achieved the look of these by freezing motion blur into still kinetic forms. All three techniques, whether using new tools or existing, ended up contributing to the 'not-of-this-Earth' look, desired by the Director and Production Designer on Soul.	https://dl.acm.org/doi/abs/10.1145/3450623.3464661	Hosuk Chang, Peter Roe, Frank Tai, Francisco De La Torre, David Munier, Jun Han Cho
Incompressible flow simulation on vortex segment clouds	We propose a novel Lagrangian geometric representation using segment clouds to simulate incompressible fluid exhibiting strong anisotropic vortical features. The central component of our approach is a cloud of discrete segments enhanced by a set of local segment reseeding operations to facilitate both the geometrical evolution and the topological updates of vortical flow. We build a vortex dynamics solver with the support for dynamic solid boundaries based on discrete segment primitives. We demonstrate the efficacy of our approach by simulating a broad range of challenging flow phenomena, such as reconnection of non-closed vortex tubes and vortex shedding behind a rotating object.	https://dl.acm.org/doi/abs/10.1145/3450626.3459865	Shiying Xiong, Rui Tao, Yaorui Zhang, Fan Feng, Bo Zhu
Inside COVID19	"""Inside COVID19"" uses the power of stereoscopic 360° video to immerse viewers into a personal journey of contracting the novel coronavirus. Molecular 3D animation takes us into the story in a new way, both microscopic and macrocosmically, connecting us to the deeper challenges that are revealed through the pandemic crisis."	https://dl.acm.org/doi/abs/10.1145/3446367.3451162	Gary Yost, Adam Loften, Andy Murdock
Interacting with Humanoid Robots: Affective Robot Motion Design with 3D Squash and Stretch Using Japanese Jo-ha-kyu Principles in Bunraku	"The Bunraku puppets' affective motions are often praised as ""one of the most beautiful motions in the world"" by UNESCO. We characterize 3D ""squash and stretch"" motion in Bunraku puppet plays and realize them in a real life-size robot with unique mechanical structures. Our results reveal that the music tempos and the puppet movements of ""squash and stretch"" follow the principle so-called ""Jo-Ha-Kyū,"" which is artistic modulations in traditional Japanese performances. Our research reveals that the affective robot motion design with the 3D ""squash and stretch"" and Jo-Ha-Kyū principle is one of the keys in affective human-robot interactions."	https://dl.acm.org/doi/abs/10.1145/3450623.3464669	Ran Dong, Yuying He, Dongsheng Cai, Jinichi Yamaguchi, Hayato Kondo, Shinobu Nakagawa, Soichiro Ikuno, Shingo Hayano
Interactive Illustrations on HTML5 Canvas: A Creative Introduction to Computer Programming	"In the first assignment of a class entitled ""Creative Coding"", students are asked to convert a pre-existing 2D illustration into an interactive digital interpretation, as an introduction to the general elements of coding and computer graphics in 2D environments. The majority of students taking this class have never coded in their lives, turning this assignment into an ideal introduction to principles of computer programming. Javascript, a very accessible and forgiving scripting language, is used to study the visual properties of real time graphic development on the HTML5 Canvas Object on any capable browser. Using a basic coding shell and any text editor, students learn about variables, coordinates, elemental shapes, quadratic and Bézier curves, RGB color definitions, linear and radial gradients, random elements, etc., in a new approach to drawing through code, that questions and challenges traditional analog illustration paradigms."	https://dl.acm.org/doi/abs/10.1145/3450549.3464414	Santiago Echeverry
Interactive Monte Carlo denoising using affinity of neural features	High-quality denoising of Monte Carlo low-sample renderings remains a critical challenge for practical interactive ray tracing. We present a new learning-based denoiser that achieves state-of-the-art quality and runs at interactive rates. Our model processes individual path-traced with a lightweight neural network to extract per-pixel feature vectors. The rest of our pipeline operates in pixel space. We define a novel pairwise affinity over the features in a pixel neighborhood, from which we assemble dilated spatial kernels to filter the noisy radiance. Our denoiser is temporally stable thanks to two mechanisms. First, we keep a running average of the noisy radiance and intermediate features, using a per-pixel recursive filter with learned weights. Second, we use a small temporal kernel based on the pairwise affinity between features of consecutive frames. Our experiments show our new affinities lead to higher quality outputs than techniques with comparable computational costs, and better high-frequency details than kernel-predicting approaches. Our model matches or outperfoms state-of-the-art offline denoisers in the low-sample count regime (2--8 samples per pixel), and runs at interactive frame rates at 1080p resolution.	https://dl.acm.org/doi/abs/10.1145/3450626.3459793	Mustafa Işik, Krishna Mullia, Matthew Fisher, Jonathan Eisenmann, Michaël Gharbi
Interactive modelling of volumetric musculoskeletal anatomy	We present a new approach for modelling musculoskeletal anatomy. Unlike previous methods, we do not model individual muscle shapes as geometric primitives (polygonal meshes, NURBS etc.). Instead, we adopt a volumetric segmentation approach where every point in our volume is assigned to a muscle, fat, or bone tissue. We provide an interactive modelling tool where the user controls the segmentation via muscle curves and we visualize the muscle shapes using volumetric rendering. Muscle curves enable intuitive yet powerful control over the muscle shapes. This representation allows us to automatically handle intersections between different tissues (muscle-muscle, muscle-bone, and muscle-skin) during the modelling and automates computation of muscle fiber fields. We further introduce a novel algorithm for converting the volumetric muscle representation into tetrahedral or surface geometry for use in downstream tasks. Additionally, we introduce an interactive skeleton authoring tool that allows the users to create skeletal anatomy starting from only a skin mesh using a library of bone parts.	https://dl.acm.org/doi/abs/10.1145/3450626.3459769	Rinat Abdrashitov, Seungbae Bang, David Levin, Karan Singh, Alec Jacobson
Intersection-free rigid body dynamics	We introduce the first implicit time-stepping algorithm for rigid body dynamics, with contact and friction, that guarantees intersection-free configurations at every time step. Our algorithm explicitly models the curved trajectories traced by rigid bodies in both collision detection and response. For collision detection, we propose a conservative narrow phase collision detection algorithm for curved trajectories, which reduces the problem to a sequence of linear CCD queries with minimal separation. For time integration and contact response, we extend the recently proposed incremental potential contact framework to reduced coordinates and rigid body dynamics. We introduce a benchmark for rigid body simulation and show that our approach, while less efficient than alternatives, can robustly handle a wide array of complex scenes, which cannot be simulated with competing methods, without requiring per-scene parameter tuning.	https://dl.acm.org/doi/abs/10.1145/3450626.3459802	Zachary Ferguson, Minchen Li, Teseo Schneider, Francisca Gil-Ureta, Timothy Langlois, Chenfanfu Jiang, Denis Zorin, Danny M. Kaufman, Daniele Panozzo
Introduction to WebXR: SIGGRAPH 2021 course	WebXR seamlessly combines XR technologies (VR, AR and MR) with the flexibility and accessibility of your browser to help you easily and quickly develop versatile and creative XR solutions. In this course, you'll learn definitions, terminologies and implementation details. The course goes through the basic concepts using uncomplicated working examples. As we believe, a strong understanding of the underlying principles is important if you're to leverage the full potential of WebXR. The purpose of this course is to introduce you to WebXR from the ground-up. As you'll learn in this course, WebXR is a powerful interface that pulls together elements from extensible technologies (VR, AR and MR), enabling you to rapidly connect hardware and software seamlessly. WebXR's versatility and improvisation will allow you to rapidly and freely develop expressive prototypes. While WebXR offers unprecedented means to immerse and interact with your audiences, it also enables you to balance and manage the ever-changing and diverse XR landscape (evolving hardware and standards). This is partly due to the fact that WebXR blend the strength and control of your browser. WebXR is a fusion of Javascript, WebGL and other libraries that allow you to connect movement and visuals in unique ways (e.g., interpret expressive emotions or tell stories through action and movement). Through WebXR, you'll be able to nurture your creativity and encourage yourself to explore designs that work in interesting and novel ways. Once you've mastered the basics of WebXR you'll have opportunities to invent new interactive interfaces for your applications, instead of following traditional designs which may not fit the style or approach of your system. Another characteristic of WebXR is the deliberate use of Javascript (which is simple, light and flexible). This lets you easily write and prototype ideas, such as stories with emotional content that embrace the user's surrounding or training simulations that immersive users in realistic situations. Overall, WebXR will allow you to support special hardware effortlessly (let your browser manage compatibility issues), while helping you develop applications that possess coordinated, powerful visual and emotional experiences.	https://dl.acm.org/doi/abs/10.1145/3450508.3464557	Ken Museth
Isle of reflections	"is an interactive lighting installation that can only be remotely explored via videotelephony. Viewers visit the island filled with iridescent lights and colorful reflections through Zoom, a popular web-based video communication tool. When the viewers see the lights and shadows that respond immediately to their voice through the screen, they recognize that they are interacting with a distant physical space in real-time. The viewers move between ""breakout rooms"" in Zoom to explore this virtual island filled with an immersive spectrum of light and color. Each room provides live scenes of the island from different viewing angles."	https://dl.acm.org/doi/abs/10.1145/3450507.3457434	Chaeeun Lee, Myeongseong Kim, Hyunjung Kim
JetController: High-speed Ungrounded 3-DoF Force Feedback Controllers using Air Propulsion Jets	JetController is a novel high-speed, persistent 3-DoF ungrounded force feedback controller. It uses high-speed pneumatic solenoid valves to modulate compressed air to achieve full impulses of 50Hz at 1.0N (20Hz at 4.0N), and combines multiple air propulsion jets to generate 3-DoF ungrounded force feedback. Compared to propeller-based approaches, JetController supports 10-30 times faster impulse frequency, and its handheld device is significantly lighter and more compact. JetController enables a wide range of haptic events in games and VR experiences, from firing automatic weapons in games like Halo (15Hz) to slicing fruits in Fruit Ninja in 3-DoF (up to 45Hz). To demonstrate JetController, we integrated our prototype with two best-selling VR games, Half-life: Alyx and Fruit Ninja VR, to highlight a variety of 3-DoF interactions that were not possible before.	https://dl.acm.org/doi/abs/10.1145/3450616.3464520	Yu-Wei Wang, Yu-Hsin Lin, Yoko Miyatake, Ching-Yi Tsai, Pin-Sung Ku, Mike Y. Chen
Joji - 777 : Animated Multi-Character Paintings with a Single Performer: A novel approach to realtime motion capture and choreography	"Tableau paintings, described as ""living pictures"" often take the form of a painting or photograph in which characters are arranged for picturesque or dramatic effect. These paintings and photographs are inherently defined by the motion of a character, but have traditionally been presented as static two dimensional images. What would it feel like to create a tableau painting that is not static, and is inherently three dimensional? This talk will center around an analysis of the creative and technical work-flows used during the production of Joji - 777, in which a small crew created an animated video where each scene was composed with intention of depicting a moving, 3D tableau painting. The technical complexities of achieving the desired result were amplified due to COVID lockdown restrictions, which at the time of production ruled out the ability to motion capture multiple per-formers at once. Using real time game engine technology in conjunction with skeletal retargeting in post production, a novel approach was developed to allow a single performer to play multiple characters simultaneously."	https://dl.acm.org/doi/abs/10.1145/3450623.3469663	Saad Moosajee, Maya Man, James Bartolozzi
Kelvin transformations for simulations on infinite domains	Solving partial differential equations (PDEs) on infinite domains has been a challenging task in physical simulations and geometry processing. We introduce a general technique to transform a PDE problem on an unbounded domain to a PDE problem on a bounded domain. Our method uses the Kelvin Transform, which essentially inverts the distance from the origin. However, naive application of this coordinate mapping can still result in a singularity at the origin in the transformed domain. We show that by factoring the desired solution into the product of an analytically known (asymptotic) component and another function to solve for, the problem can be made continuous and compact, with solutions significantly more efficient and well-conditioned than traditional finite element and Monte Carlo numerical PDE methods on stretched coordinates. Specifically, we show that every Poisson or Laplace equation on an infinite domain is transformed to another Poisson (Laplace) equation on a compact region. In other words, any existing Poisson solver on a bounded domain is readily an infinite domain Poisson solver after being wrapped by our transformation. We demonstrate the integration of our method with finite difference and Monte Carlo PDE solvers, with applications in the fluid pressure solve and simulating electromagnetism, including visualizations of the solar magnetic field. Our transformation technique also applies to the Helmholtz equation whose solutions oscillate out to infinity. After the transformation, the Helmholtz equation becomes a tractable equation on a bounded domain without infinite oscillation. To our knowledge, this is the first time that the Helmholtz equation on an infinite domain is solved on a bounded grid without requiring an artificial absorbing boundary condition.	https://dl.acm.org/doi/abs/10.1145/3450626.3459809	Mohammad Sina Nabizadeh, Ravi Ramamoorthi, Albert Chern
Knit sketching: from cut & sew patterns to machine-knit garments	We present a novel workflow to design and program knitted garments for industrial whole-garment knitting machines. Inspired by traditional garment making based on cutting and sewing, we propose a sketch representation with additional annotations necessary to model the knitting process. Our system bypasses complex editing operations in 3D space, which allows us to achieve interactive editing of both the garment shape and its underlying time process. We provide control of the local knitting direction, the location of important course interfaces, as well as the placement of stitch irregularities that form seams in the final garment. After solving for the constrained knitting time process, the garment sketches are automatically segmented into a minimal set of simple regions that can be knitted using simple knitting procedures. Finally, our system optimizes a stitch graph hierarchically while providing control over the tradeoff between accuracy and simplicity. We showcase different garments created with our web interface.	https://dl.acm.org/doi/abs/10.1145/3450626.3459752	Alexandre Kaspar, Kui Wu, Yiyue Luo, Liane Makatura, Wojciech Matusik
KnitKit: a flexible system for machine knitting of customizable textiles	In this work, we introduce , a flexible and customizable system for the computational design and production of functional, multi-material, and three-dimensional knitted textiles. Our system greatly simplifies the knitting of 3D objects with complex, varying patterns that use multiple yarns and stitch patterns by separating the high-level design specification in terms of geometry, stitch patterns, materials or colors from the low-level, machine-specific knitting instruction generation. Starting from a triangular 3D mesh and a 2D texture that specifies knitting patterns on top of the geometry, our system generates the required machine instructions in three major steps. First, the input is processed and the data structure is generated. This graph structure serves as an abstract interface between the high-level geometric and knitting configuration and the low-level, machine-specific knitting instructions. Second, a graph rewriting procedure is applied on the that produces a sequence of abstract machine actions. Finally, the low-level machine instructions are generated by adapting those abstract actions to a specific machine context. We showcase the potential of this computational approach by designing and fabricating a variety of objects with complex geometries, multiple yarns, and multiple stitch patterns.	https://dl.acm.org/doi/abs/10.1145/3450626.3459790	Georges Nader, Yu Han Quek, Pei Zhi Chia, Oliver Weeger, Sai-Kit Yeung
Knitting 4D garments with elasticity controlled for body motion	In this paper, we present a new computational pipeline for designing and fabricating 4D garments as knitwear that considers comfort during body movement. This is achieved by careful control of elasticity distribution to reduce uncomfortable pressure and unwanted sliding caused by body motion. We exploit the ability to knit patterns in different elastic levels by (SJJ) with two yarns. We design the distribution of elasticity for a garment by physics-based computation, the optimized elasticity on the garment is then converted into instructions for a digital knitting machine by two algorithms proposed in this paper. Specifically, a graph-based algorithm is proposed to generate knittable stitch meshes that can accurately capture the 3D shape of a garment, and a tiling algorithm is employed to assign SJJ patterns on the stitch mesh to realize the designed distribution of elasticity. The effectiveness of our approach is verified on simulation results and on specimens physically fabricated by knitting machines.	https://dl.acm.org/doi/abs/10.1145/3450626.3459868	Zishun Liu, Xingjian Han, Yuchen Zhang, Xiangjia Chen, Yu-Kun Lai, Eugeni L. Doubrovski, Emily Whiting, Charlie C. L. Wang
LED Paper: Physical Computing with Handmade Paper	Physical computing involves using embedded computing to interact with the physical world. It's a core technology for interactive computing. This assignment introduces physical computing through the incorporation of LEDs into handmade paper to make an interactive, visual, and physical artifact.	https://dl.acm.org/doi/abs/10.1145/3450549.3464418	Erik Brunvand
Learning a family of motor skills from a single motion clip	We present a new algorithm that learns a parameterized family of motor skills from a single motion clip. The motor skills are represented by a deep policy network, which produces a stream of motions in physics simulation in response to user input and environment interaction by navigating continuous action space. Three novel technical components play an important role in the success of our algorithm. First, it explicitly constructs motion parameterization that maps action parameters to their corresponding motions. Simultaneous learning of motion parameterization and motor skills significantly improves the performance and visual quality of learned motor skills. Second, continuous-time reinforcement learning is adopted to explore temporal variations as well as spatial variations in motion parameterization. Lastly, we present a new automatic curriculum generation method that explores continuous action space more efficiently. We demonstrate the flexibility and versatility of our algorithm with highly dynamic motor skills that can be parameterized by task goals, body proportions, physical measurements, and environmental conditions.	https://dl.acm.org/doi/abs/10.1145/3450626.3459774	Seyoung Lee, Sunmin Lee, Yongwoo Lee, Jehee Lee
Learning active quasistatic physics-based models from data	Humans and animals can control their bodies to generate a wide range of motions via low-dimensional action signals representing high-level goals. As such, human bodies and faces are prime examples of objects, which can affect their shape via an internal actuation mechanism. This paper explores the following proposition: given a training set of example poses of an active deformable object, can we learn a low-dimensional control space that could reproduce the training set and generalize to new poses? In contrast to popular machine learning methods for dimensionality reduction such as auto-encoders, we model our active objects in a physics-based way. We utilize a differentiable, quasistatic, physics-based simulation layer and combine it with a decoder-type neural network. Our differentiable physics layer naturally fits into deep learning frameworks and allows the decoder network to learn actuations that reach the desired poses after physics-based simulation. In contrast to modeling approaches where users build anatomical models from first principles, medical literature or medical imaging, we do not presume knowledge of the underlying musculature, but learn the structure and control of the actuation mechanism directly from the input data. We present a training paradigm and several scalability-oriented enhancements that allow us to train effectively while accommodating high-resolution volumetric models, with as many as a quarter million simulation elements. The prime demonstration of the efficacy of our example-driven modeling framework targets facial animation, where we train on a collection of input expressions while generalizing to unseen poses, drive detailed facial animation from sparse motion capture input, and facilitate expression sculpting via direct manipulation.	https://dl.acm.org/doi/abs/10.1145/3450626.3459883	Sangeetha Grama Srinivasan, Qisi Wang, Junior Rojas, Gergely Klár, Ladislav Kavan, Eftychios Sifakis
Learning an animatable detailed 3D face model from in-the-wild images	While current monocular 3D face reconstruction methods can recover fine geometric details, they suffer several limitations. Some methods produce faces that cannot be realistically animated because they do not model how wrinkles vary with expression. Other methods are trained on high-quality face scans and do not generalize well to in-the-wild images. We present the first approach that regresses 3D face shape and animatable details that are specific to an individual but change with expression. Our model, DECA (Detailed Expression Capture and Animation), is trained to robustly produce a UV displacement map from a low-dimensional latent representation that consists of person-specific detail parameters and generic expression parameters, while a regressor is trained to predict detail, shape, albedo, expression, pose and illumination parameters from a single image. To enable this, we introduce a novel detail-consistency loss that disentangles person-specific details from expression-dependent wrinkles. This disentanglement allows us to synthesize realistic person-specific wrinkles by controlling expression parameters while keeping person-specific details unchanged. DECA is learned from in-the-wild images with no paired 3D supervision and achieves state-of-the-art shape reconstruction accuracy on two benchmarks. Qualitative results on in-the-wild data demonstrate DECA's robustness and its ability to disentangle identity- and expression-dependent details enabling animation of reconstructed faces. The model and code are publicly available at https://deca.is.tue.mpg.de.	https://dl.acm.org/doi/abs/10.1145/3450626.3459936	Yao Feng, Haiwen Feng, Michael J. Black, Timo Bolkart
Learning contact corrections for handle-based subspace dynamics	This paper introduces a novel subspace method for the simulation of dynamic deformations. The method augments existing linear handle-based subspace formulations with nonlinear learning-based corrections parameterized by the same subspace. Together, they produce a compact nonlinear model that combines the fast dynamics and overall contact-based interaction of subspace methods, with the highly detailed deformations of learning-based methods. We propose a formulation of the model with nonlinear corrections applied on the local undeformed setting, and decoupling internal and external contact-driven corrections. We define a simple mapping of these corrections to the global setting, an efficient implementation for dynamic simulation, and a training pipeline to generate examples that efficiently cover the interaction space. Altogether, the method achieves unprecedented combination of speed and contact-driven deformation detail.	https://dl.acm.org/doi/abs/10.1145/3450626.3459875	Cristian Romero, Dan Casas, Jesús Pérez, Miguel Otaduy
Learning meaningful controls for fluids	While modern fluid simulation methods achieve high-quality simulation results, it is still a big challenge to interpret and control motion from visual quantities, such as the advected marker density. These visual quantities play an important role in user interactions: Being familiar and meaningful to humans, these quantities have a strong correlation with the underlying motion. We propose a novel data-driven conditional adversarial model that solves the challenging and theoretically ill-posed problem of deriving plausible velocity fields from a single frame of a density field. Besides density modifications, our generative model is the first to enable the control of the results using all of the following control modalities: obstacles, physical parameters, kinetic energy, and vorticity. Our method is based on a new conditional generative adversarial neural network that explicitly embeds physical quantities into the learned latent space, and a new cyclic adversarial network design for control disentanglement. We show the high quality and versatile controllability of our results for density-based inference, realistic obstacle interaction, and sensitive responses to modifications of physical parameters, kinetic energy, and vorticity. Code, models, and results can be found at https://github.com/RachelCmy/den2vel.	https://dl.acm.org/doi/abs/10.1145/3450626.3459845	Mengyu Chu, Nils Thuerey, Hans-Peter Seidel, Christian Theobalt, Rhaleb Zayer
Learning skeletal articulations with neural blend shapes	Animating a newly designed character using motion capture (mocap) data is a long standing problem in computer animation. A key consideration is the skeletal structure that should correspond to the available mocap data, and the shape deformation in the joint regions, which often requires a tailored, pose-specific refinement. In this work, we develop a neural technique for articulating 3D characters using enveloping with a pre-defined skeletal structure which produces high quality pose dependent deformations. Our framework learns to rig and skin characters with the same articulation structure ( , bipeds or quadrupeds), and builds the desired skeleton hierarchy into the network architecture. , we propose - a set of corrective pose-dependent shapes which improve the deformation quality in the joint regions in order to address the notorious artifacts resulting from standard rigging and skinning. Our system estimates neural blend shapes for input meshes with arbitrary connectivity, as well as weighting coefficients which are conditioned on the input joint rotations. Unlike recent deep learning techniques which supervise the network with ground-truth rigging and skinning parameters, our approach does not assume that the training data has a specific underlying deformation model. Instead, during training, the network observes deformed shapes and learns to infer the corresponding rig, skin and blend shapes using During inference, we demonstrate that our network generalizes to unseen characters with arbitrary mesh connectivity, including unrigged characters built by 3D artists. Conforming to standard skeletal animation models enables direct plug-and-play in standard animation software, as well as game engines.	https://dl.acm.org/doi/abs/10.1145/3450626.3459852	Peizhuo Li, Kfir Aberman, Rana Hanocka, Libin Liu, Olga Sorkine-Hornung, Baoquan Chen
Learning time-critical responses for interactive character control	Creating agile and responsive characters from a collection of unorganized human motion has been an important problem of constructing interactive virtual environments. Recently, learning-based approaches have successfully been exploited to learn deep network policies for the control of interactive characters. The agility and responsiveness of deep network policies are influenced by many factors, such as the composition of training datasets, the architecture of network models, and learning algorithms that involve many threshold values, weights, and hyper-parameters. In this paper, we present a novel teacher-student framework to learn time-critically responsive policies, which guarantee the time-to-completion between user inputs and their associated responses regardless of the size and composition of the motion databases. We demonstrate the effectiveness of our approach with interactive characters that can respond to the user's control quickly while performing agile, highly dynamic movements.	https://dl.acm.org/doi/abs/10.1145/3450626.3459826	Kyungho Lee, Sehee Min, Sunmin Lee, Jehee Lee
"Learning to trust: the making of ""Raya and the Last Dragon"""	"What are the mysterious Druun? How can enemies from different parts of a vast world learn to trust each other again? In Walt Disney Animation Studios' ""Raya and the Last Dragon,"" our protagonist first breaks the world and then leads us on a journey in search of a magical solution to heal it. In this session, our filmmakers show how they collaboratively crafted the extensive lands of Kumandra and filled them with distinctive characters and detail that represent a compelling mix of fantasy and Southeast Asian influences. We'll reveal the challenge of creating a brood of magical water dragons that rippled through multiple departments. Creating a nemesis for the dragons unlike anything seen before was another task for our effects and lighting departments. All shot through the lens of a story-enhancing cinematography plan that considered every detail right down to the dramatic film grain, all while working from home. Please unite with us as we detail our collaborative filmmaking process."	https://dl.acm.org/doi/abs/10.1145/3446368.3451987	Kyle Odermatt, Larry Wu, Carlos Cabral, Rob Dressel, Michael Kaschalk, Adolf Lusinsky
Least squares for programmers: with color plates	This course explains least squares optimization, nowadays a simple and well-mastered technology. We show how this simple method can solve a large number of problems that would be difficult to approach in any other way. This course provides a simple, understandable yet powerful tool that most coders can use, in the contrast with other algorithms sharing this paradigm (numerical simulation and deep learning) which are more complex to master.	https://dl.acm.org/doi/abs/10.1145/3450508.3464554	Andrea Weidlich, Alex Forsythe, Scott Dyer, Thomas Mansencal, Johannes Hanika, Alexander Wilkie, Luke Emrose, Anders Langlands
Lessons Learned and Improvements when Building Screen-Space Samplers with Blue-Noise Error Distribution	Recent work has shown that the error of Monte-Carlo rendering is visually more acceptable when distributed as blue-noise in screen-space. Despite recent efforts, building a screen-space sampler is still an open problem. In this talk, we present the lessons we learned while improving our previous screen-space sampler. Specifically: we advocate for a new criterion to assess the quality of such samplers; we introduce a new screen-space sampler based on rank-1 lattices; we provide a parallel optimization method that is compatible with a GPU implementation and that achieves better quality; we detail the pitfalls of using such samplers in renderers and how to cope with many dimensions; and we provide empirical proofs of the versatility of the optimization process.	https://dl.acm.org/doi/abs/10.1145/3450623.3464645	Laurent Belcour, Eric Heitz
Light-field Projection for Tangible Projection Mapping	In the present study, we propose a novel projection mapping using a 3D light-field image as a light source. In recent years, spatial augmented reality has evolved into dynamic projection mapping that extends the target to moving objects. However, spatial augmented reality causes multiplexing of projection and measurement equipment, which causes various problems, such as increased psychological pressure on users and a reduced production effect. Therefore, based on the concept of stealth projection, which hides the projection device using aerial imaging technology, we propose a dynamic projection mapping method using a 3D light-field image generated in real time according to the position and orientation of the target object. As a result, a simple light-field projector consisting of an LCD panel and a lenticular lens provides projection mapping for moving objects while visually hiding the projection devices.	https://dl.acm.org/doi/abs/10.1145/3450618.3469142	Taichi Watanabe, Naoki Hashimoto
Live Performance in VR: Live performance in virtual reality by creators from different metaverses discuss the challenges and advantages of performance in this new storytelling platform.	Virtual reality is a growing platform for live entertainment, offering the feeling of embodiment and immersion that is central to storytelling for both audience and performers. Find out how several different artists are bringing the magic of theater to digital playhouses around the world.	https://dl.acm.org/doi/abs/10.1145/3450617.3464495	Deirdre Lyons, Stephen G. Butchko, Jason Moore, Brendan Bradley, Tanya Leal Soto
Live from the metaverse: virtual XR performances for audiences on-stage, online, in-game, and in-VR	"In the Fall of 2019, Lifelike & Believable Animation Design, in partnership with Animatrik Film Design, began a multi-year collaboration with world-renowned circus arts collective, Les 7 Doigts (The 7 Fingers) to explore the combination of realtime motion-capture, rendering and projection with traditional circus disciplines to create unique theatrical performances simultaneously presented before live theatre audiences and remotely-connected VR participants. This collaboration came to be known as ""The LiViCi Series"" (for Live Virtual Circus). Shocap Entertainment was born in April 2020 out of this partnership, and in 2021, Shocap and Les 7 Doigts announced plans to present ""The LiViCi Series"", a hybrid livestream / immersive performance series combining live music with deathdefying acrobatics in cinematic virtual environments. In this session, presented from Animatrik's performance capture studio in Burnaby, British Columbia, just outside of Vancouver, Shocap Executive and Creative Director, Athomas Goldberg, along with Les 7 Doigts Artistic Director, Samuel Tetreault, will discuss the unique technical challenges and creative opportunities that come with capturing the breathtakingly dynamic motion of trained circus performers in real-time and translating that into a poetic and life-affirming digital expression. In a series of discussions and live demonstrations, we will take you through the live virtual performance production process, including a discussions of the tools, techniques and best practices used to bring this to project to life, and give you a glimpse into what we have in store for the future of live physical performance that bridges the real and virtual worlds."	https://dl.acm.org/doi/abs/10.1145/3446368.3452125	Athomas Goldberg, Samuel Tetreault
LocalAnesthesiaVR	LocalAnesthesiaVRis a virtual reality training system for dental anesthesia, a clinical procedure every dentist must be competent with, and one that is particularly challenging to master throughout the demanding dental curriculum. This unique VR-based system provides learners with visual, auditory and haptic feedback enabling experiential learning in pre-clinical education.	https://dl.acm.org/doi/abs/10.1145/3450549.3464411	Uttam Grandhi, Cristián Opazo
Low-cost SPAD sensing for non-line-of-sight tracking, material classification and depth imaging	Time-correlated imaging is an emerging sensing modality that has been shown to enable promising application scenarios, including lidar ranging, fluorescence lifetime imaging, and even non-line-of-sight sensing. A leading technology for obtaining time-correlated light measurements are single-photon avalanche diodes (SPADs), which are extremely sensitive and capable of temporal resolution on the order of tens of picoseconds. However, the rare and expensive optical setups used by researchers have so far prohibited these novel sensing techniques from entering the mass market. Fortunately, SPADs also exist in a radically cheaper and more power-efficient version that has been widely deployed as proximity sensors in mobile devices for almost a decade. These commodity SPAD sensors can be obtained at a mere few cents per detector pixel. However, their inferior data quality and severe technical drawbacks compared to their high-end counterparts necessitate the use of additional optics and suitable processing algorithms. In this paper, we adopt an existing evaluation platform for commodity SPAD sensors, and modify it to unlock time-of-flight (ToF) histogramming and hence computational imaging. Based on this platform, we develop and demonstrate a family of hardware/software systems that, for the first time, implement applications that had so far been limited to significantly more advanced, higher-priced setups: direct ToF depth imaging, non-line-of-sight object tracking, and material classification.	https://dl.acm.org/doi/abs/10.1145/3450626.3459824	Clara Callenberg, Zheng Shi, Felix Heide, Matthias B. Hullin
MIDI usage for modeling and animation in Houdini	The hands-on workshop for computer graphics professionals introduces the technique and practical implementation of the usage of MIDI devices in Side FX Houdini software as a relatively easy way to supercharge creative workflows. This technique can significantly improve speed and quality of modeling, animation, and creative iteration for Houdini professionals, especially technical artists, and game artists. It can also present the alternative to the random procedural asset generation or work in conjunction with it and improve results from procedural generators. The workshop covers the brief history of MIDI, practical advice on how to choose the appropriate controller for the specific design needs, and overview of built-in Houdini MIDI workflows and presents a customized approach for creating Houdini digital assets for MIDI mapping in Python.	https://dl.acm.org/doi/abs/10.1145/3450616.3464980	Gordey Chernyy, Mariya Mishurenko
MOCCA: modeling and optimizing cone-joints for complex assemblies	We present a computational framework for modeling and optimizing complex assemblies using cone joints. Cone joints are integral joints that generalize traditional single-direction joints such as mortise and tenon joints to support a general cone of directions for assembly. This additional motion flexibility not just reduces the risk of deadlocking for complex joint arrangements, but also simplifies the assembly process, in particular for automatic assembly by robots. On the other hand, compared to planar contacts, cone joints restrict relative part movement for improved structural stability. Cone joints can be realized in the form of curved contacts between associated parts, which have demonstrated good mechanical properties such as reduced stress concentration. To find the best trade-off between assemblability and stability, we propose an optimization approach that first determines the optimal motion cone for each part contact and subsequently derives a geometric realization of each joint to match this motion cone. We demonstrate that our approach can optimize cone joints for assemblies with a variety of geometric forms, and highlight several application examples.	https://dl.acm.org/doi/abs/10.1145/3450626.3459680	Ziqi Wang, Peng Song, Mark Pauly
MORPH: Taggenbrunn Edition	MORPH TE (Taggenbrunn Edition) is an exploration of the relationship between humanity and robotics. In an age of endless automation and cold, technological prevalence, the piece sheds light on a new kind of artificial life. It is both a modern artwork and a deep-dive into technological anthropomorphism. The piece demonstrates the emergence of complex behavior through well-orchestrated simplicity, while its tessellated, geodesic surface provides a sense of organic intricacy. The work is timely in its reflection of humanity's symbiosis with machines, yet timeless in its pioneering embodiment of symmetry and naturally inspired movement.	https://dl.acm.org/doi/abs/10.1145/3450616.3470886	Nicholas Perillo, Mitchell Nordine, Joshua Batty
ManipNet: neural manipulation synthesis with a hand-object spatial representation	Natural hand manipulations exhibit complex finger maneuvers adaptive to object shapes and the tasks at hand. Learning dexterous manipulation from data in a brute force way would require a prohibitive amount of examples to effectively cover the combinatorial space of 3D shapes and activities. In this paper, we propose a hand-object spatial representation that can achieve generalization from limited data. Our representation combines the global object shape as voxel occupancies with local geometric details as samples of closest distances. This representation is used by a neural network to regress finger motions from input trajectories of wrists and objects. Specifically, we provide the network with the current finger pose, past and future trajectories, and the spatial representations extracted from these trajectories. The network then predicts a new finger pose for the next frame as an autoregressive model. With a carefully chosen hand-centric coordinate system, we can handle single-handed and two-handed motions in a unified framework. Learning from a small number of primitive shapes and kitchenware objects, the network is able to synthesize a variety of finger gaits for grasping, in-hand manipulation, and bimanual object handling on a rich set of novel shapes and functional tasks. We also demonstrate a live demo of manipulating virtual objects in real-time using a simple physical prop. Our system is useful for offline animation or real-time applications forgiving to a small delay.	https://dl.acm.org/doi/abs/10.1145/3450626.3459830	He Zhang, Yuting Ye, Takaaki Shiratori, Taku Komura
Mathematical Tricks for scalable and appealing crowds in Walt Disney Animation Studios’ ”Raya and the Last Dragon”	"The crowds department had to tackle a variety of challenging shots for Walt Disney Animation Studios' ""Raya and the Last Dragon"" such as beetles crawling on top of each other, immense fish simulation or dragon choreography. In order to handle this level of complexity while keeping a good amount of artistic control, we implemented some effective technical solutions such as the use of anisotropic distances in Position based Dynamics (PBD) and boids simulations, procedural animation layers for fish and dragons or distance integral invariant to detect dragon foot contacts."	https://dl.acm.org/doi/abs/10.1145/3450623.3464650	Nicolas Nghiem
Mechanics-aware deformation of yarn pattern geometry	Triangle mesh-based simulations are able to produce satisfying animations of knitted and woven cloth; however, they lack the rich geometric detail of yarn-level simulations. Naive texturing approaches do not consider yarn-level physics, while full yarn-level simulations may become prohibitively expensive for large garments. We propose a method to animate yarn-level cloth geometry on top of an underlying deforming mesh in a mechanics-aware fashion. Using triangle strains to interpolate precomputed yarn geometry, we are able to reproduce effects such as knit loops tightening under stretching. In combination with precomputed mesh animation or real-time mesh simulation, our method is able to animate yarn-level cloth in real-time at large scales.	https://dl.acm.org/doi/abs/10.1145/3450626.3459816	Georg Sperl, Rahul Narain, Chris Wojtan
Medial IPC: accelerated incremental potential contact with medial elastics	We propose a framework of efficient nonlinear deformable simulation with both fast continuous collision detection and robust collision resolution. We name this new framework as it integrates the merits from medial elastics, for an efficient and versatile reduced simulation, as well as incremental potential contact, for a robust collision and contact resolution. We leverage medial axis transform to construct a kinematic subspace. Instead of resorting to projective dynamics, we use classic hyperelastics to embrace real-world nonlinear materials. A novel reduced continuous collision detection algorithm is presented based on the medial mesh. Thanks to unique geometric properties of medial axis and medial primitives, we derive closed-form formulations for identifying between-primitive collision within the reduced medial space. In the meantime, the implicit barrier energy that generates necessary repulsion forces for collision resolution is also formulated with the medial coordinate. In other words, Medial IPC exploits a universal reduced coordinate for simulation, continuous self-/collision detection, and IPC-based collision resolution. Continuous collision detection also allows more aggressive time stepping. In addition, we carefully implement our system with a heterogeneous CPU-GPU deployment such that massively parallelizable computations are carried out on the GPU while few sequential computations are on the CPU. Such implementation also frees us from generating training poses for selecting Cubature points and pre-computing their weights. We have tested our method on complicated deformable models and collision-rich simulation scenarios. Due to the reduced nature of our system, the computation is faster than fullspace IPC or other fullspace methods using continuous collision detection by at least one order. The simulation remains high-quality as the medial subspace captures intriguing and local deformations with sufficient realism.	https://dl.acm.org/doi/abs/10.1145/3450626.3459753	Lei Lan, Yin Yang, Danny Kaufman, Junfeng Yao, Minchen Li, Chenfanfu Jiang
Mementorium: Designing for playful and interactive learning about gender and sexuality-based marginalization	Mementorium is a heartfelt story about identity and belonging told through a virtual reality (VR) branching narrative. Mementorium's design builds upon our previous designs and research on queer reorientations to computing and queer approaches to embodied learning in VR. The design is accomplished through the branching narrative, which supports listening to marginalized experiences and emotional co-construction of the story, and through the interaction design, which encourages play and embodied learning and centers authentic practices of belonging and becoming. This paper introduces Mementorium's narrative and interaction design and research that informed the design. Mementorium is an approximately 30-minute single-player, room-scale interactive VR experience intended for a general audience to learn about gender and sexuality-based marginalization in science and technology.	https://dl.acm.org/doi/abs/10.1145/3450615.3464544	Dylan Paré, Scout Windsor, John Craig
MetamorHockey: A Projection-based Virtual Air Hockey Platform Featuring Transformable Mallet Shapes	"We propose a novel projection-based virtual air hockey system in which not only the puck but also the mallet is displayed as an image. Being a projected image, the mallet can freely ""metamorphose"" into different shapes, which expands the game design beyond the original air hockey. We discuss possible scenarios with a resizable mallet, with mallet shapes defined by drawing, and with a mallet whose collision conditions can be modified. A key challenge in implementation is to minimize the latency because the direct manipulation nature of the mallet positioning imposes a higher demand on latency than the puck positioning. By using a high-speed camera and a high-speed projector running at 420 fps, a satisfactorily quick tracking became possible such that we feel a projected mallet head to be an integral part of a mallet held by hand."	https://dl.acm.org/doi/abs/10.1145/3450550.3465341	Shun Ueda, Shingo Kagami, Koichi Hashimoto
Mixture of volumetric primitives for efficient neural rendering	Real-time rendering and animation of humans is a core function in games, movies, and telepresence applications. Existing methods have a number of drawbacks we aim to address with our work. Triangle meshes have difficulty modeling thin structures like hair, volumetric representations like Neural Volumes are too low-resolution given a reasonable memory budget, and high-resolution implicit representations like Neural Radiance Fields are too slow for use in real-time applications. We present Mixture of Volumetric Primitives (MVP), a representation for rendering dynamic 3D content that combines the completeness of volumetric representations with the efficiency of primitive-based rendering, e.g., point-based or mesh-based methods. Our approach achieves this by leveraging spatially shared computation with a convolutional architecture and by minimizing computation in empty regions of space with volumetric primitives that can move to cover only occupied regions. Our parameterization supports the integration of correspondence and tracking constraints, while being robust to areas where classical tracking fails, such as around thin or translucent structures and areas with large topological variability. MVP is a hybrid that generalizes both volumetric and primitive-based representations. Through a series of extensive experiments we demonstrate that it inherits the strengths of each, while avoiding many of their limitations. We also compare our approach to several state-of-the-art methods and demonstrate that MVP produces superior results in terms of quality and runtime performance.	https://dl.acm.org/doi/abs/10.1145/3450626.3459863	Stephen Lombardi, Tomas Simon, Gabriel Schwartz, Michael Zollhoefer, Yaser Sheikh, Jason Saragih
MoCap-solver: a neural solver for optical motion capture data	In a conventional optical motion capture (MoCap) workflow, two processes are needed to turn captured raw marker sequences into correct skeletal animation sequences. Firstly, various tracking errors present in the markers must be fixed ( or ). Secondly, an agent skeletal mesh must be prepared for the actor/actress, and used to determine skeleton information from the markers ( or ). The whole process, normally referred to as MoCap data, is extremely time-consuming, labor-intensive, and usually the most costly part of animation production. Hence, there is a great demand for automated tools in industry. In this work, we present MoCap-Solver, a production-ready neural solver for optical MoCap data. It can directly produce skeleton sequences and clean marker sequences from raw MoCap markers, without any tedious manual operations. To achieve this goal, our key idea is to make use of neural encoders concerning three key intrinsic components: the template skeleton, marker configuration and motion, and to learn to predict these latent vectors from imperfect marker sequences containing noise and errors. By decoding these components from latent vectors, sequences of clean markers and skeletons can be directly recovered. Moreover, we also provide a novel normalization strategy based on learning a pose-dependent marker reliability function, which greatly improves system robustness. Experimental results demonstrate that our algorithm consistently outperforms the state-of-the-art on both synthetic and real-world datasets.	https://dl.acm.org/doi/abs/10.1145/3450626.3459681	Kang Chen, Yupan Wang, Song-Hai Zhang, Sen-Zhe Xu, Weidong Zhang, Shi-Min Hu
Modeling Asteroid (101955) Bennu as a Real-time Terrain	Using a commercial terrain engine [Englert 2012], we show how to model the complex surface of asteroid (101955) Bennu [Science 1999] with a hybrid approach that combines digital elevation models with static and dynamic displacement. Then we show how to adapt tri-planar material mapping (TRIMAP) to the curvature of planetary bodies, in order to effectively avoid all inherent texturing artefacts.	https://dl.acm.org/doi/abs/10.1145/3450623.3464628	Matthias Englert
Modeling and fabrication with specified discrete equivalence classes	We propose a novel method to model and fabricate shapes using a small set of specified discrete equivalence classes of triangles. The core of our modeling technique is a fabrication-error-driven remeshing algorithm. Given a triangle and a template triangle, which are coplanar and have one-to-one corresponding vertices, we define their similarity error from a manufacturing point of view as follows: the minimizer of the maximum of the three distances between the corresponding pair of vertices concerning a rigid transformation. To compute the similarity error, we convert it into an easy-to-compute form. Then, a greedy remeshing method is developed to optimize the topology and geometry of the input mesh to minimize the fabrication error defined as the maximum similarity error of all triangles. Besides, constraints are enforced to ensure the similarity between input and output shapes and the smoothness of the resulting shapes. Since the fabrication error has been considered during the modeling process, the fabrication process is easy to proceed. To assist users in performing fabrication using common materials and tools manually, we present a straightforward manufacturing solution. The feasibility and practicability of our method are demonstrated over various examples, including seven physical manufacturing models with only nine template triangles.	https://dl.acm.org/doi/abs/10.1145/3450626.3459843	Zhong-Yuan Liu, Zhan Zhang, Di Zhang, Chunyang Ye, Ligang Liu, Xiao-Ming Fu
Models for environmental literacy	"is a series of experimental digital animations combining drone photogrammetry with A.I. generated narratives. These videos creatively and critically explore the challenges of describing a landscape, an ecosystem, or the specter of environmental collapse through human language. The project further explores how language and vision are impacted by the mediating agency of new technologies. How do we see, feel, imagine, and talk about the environment in this post-digital era, when there are indeed non-human/machine agents similarly trained to perceive ""natural"" spaces? This project explores these questions, as well as emerging relationships with environmental surveillance, drone/computer vision, and A.I."	https://dl.acm.org/doi/abs/10.1145/3450507.3457439	Tivon Rice
Monte Carlo estimators for differential light transport	Physically based differentiable rendering algorithms propagate derivatives through realistic light transport simulations and have applications in diverse areas including inverse reconstruction and machine learning. Recent progress has led to unbiased methods that can simultaneously compute derivatives with respect to millions of parameters. At the same time, elementary properties of these methods remain poorly understood. Current algorithms for differentiable rendering are constructed by mechanically differentiating a given primal algorithm. While convenient, such an approach is simplistic because it leaves no room for improvement. Differentiation produces major changes in the integrals that occur throughout the rendering process, which indicates that the primal and differential algorithms should be decoupled so that the latter can suitably adapt. This leads to a large space of possibilities: consider that even the most basic Monte Carlo path tracer already involves several design choices concerning the techniques for sampling materials and emitters, and their combination, e.g. via multiple importance sampling (MIS). Differentiation causes a veritable explosion of this decision tree: should we differentiate only the estimator, or also the sampling technique? Should MIS be applied before or after differentiation? Are specialized derivative sampling strategies of any use? How should visibility-related discontinuities be handled when millions of parameters are differentiated simultaneously? In this paper, we provide a taxonomy and analysis of different estimators for differential light transport to provide intuition about these and related questions.	https://dl.acm.org/doi/abs/10.1145/3450626.3459807	Tizian Zeltner, Sébastien Speierer, Iliyan Georgiev, Wenzel Jakob
MotionViz: Artistic Visualization of Human Motion on Mobile Devices	We present MotionViz, an interactive iOS mobile app that enables users to amplify motion and dynamics in videos. MotionViz implements novel augmented reality and expressive rendering techniques in an end-to-end processing pipeline: multi-dimensional video data is captured, analyzed, and processed to render animated graphical elements that help express figures and actions. Through an easy-to-use graphical user interface, users can choose from a curated list of artistic motion visualization effects, including the overlay of animated silhouettes, halos, and contour lines. MotionViz is based on Apple's LiDAR technology, accelerated image processing APIs, and dedicated Neural Engine for real-time on-device processing.	https://dl.acm.org/doi/abs/10.1145/3450415.3464398	Maximilian Mayer, Philipp Trenz, Sebastian Pasewaldt, Mandy Klingbeil, Jürgen Döllner, Matthias Trapp, Amir Semmo
Movement in capture	is an environmental visual story presented as an installation of 4 videos that explores the impact of pollution on ocean life. Dancers' movements were recorded with motion capture technology as they identified with marine creatures forced to live in a polluted environment.	https://dl.acm.org/doi/abs/10.1145/3450507.3457430	Shira Shvadron
Multiscale cholesky preconditioning for ill-conditioned problems	Many computer graphics applications boil down to solving sparse systems of linear equations. While the current arsenal of numerical solvers available in various specialized libraries and for different computer architectures often allow efficient and scalable solutions to image processing, modeling and simulation applications, an increasing number of graphics problems face large-scale and ill-conditioned sparse linear systems --- a numerical challenge which typically chokes both direct factorizations (due to high memory requirements) and iterative solvers (because of slow convergence). We propose a novel approach to the efficient preconditioning of such problems which often emerge from the discretization over unstructured meshes of partial differential equations with heterogeneous and anisotropic coefficients. Our numerical approach consists in simply performing a fine-to-coarse ordering and a multiscale sparsity pattern of the degrees of freedom, using which we apply an incomplete Cholesky factorization. By further leveraging supernodes for cache coherence, graph coloring to improve parallelism and partial diagonal shifting to remedy negative pivots, we obtain a preconditioner which, combined with a conjugate gradient solver, far exceeds the performance of existing carefully-engineered libraries for graphics problems involving bad mesh elements and/or high contrast of coefficients. We also back the core concepts behind our simple solver with theoretical foundations linking the recent method of operator-adapted wavelets used in numerical homogenization to the traditional Cholesky factorization of a matrix, providing us with a clear bridge between incomplete Cholesky factorization and multiscale analysis that we leverage numerically.	https://dl.acm.org/doi/abs/10.1145/3450626.3459851	Jiong Chen, Florian Schäfer, Jin Huang, Mathieu Desbrun
Namoo	Namoo is a narrative poem come to life as an animated VR experience that follows the journey of a man from his birth until death. Namoo was created entirely in VR with Oculus Quill and pushes the boundaries of what is possible in this new artform and platform for animation.	https://dl.acm.org/doi/abs/10.1145/3446367.3452129	Erick Oh, Larry Cutler, Nick Ladd, Dan Franke, Nathaniel Dirksen
NanoVDB: A GPU-Friendly and Portable VDB Data Structure For Real-Time Rendering And Simulation	We introduce a sparse volumetric data structure, dubbed NanoVDB, which is portable to both C++11 and C99 as well as most graphics APIs, e.g. CUDA, OpenCL, OpenGL, WebGL, DirectX 12, OptiX, HLSL, and GLSL. As indicated by its name, NanoVDB is a mini-version of the much bigger OpenVDB library, both in terms of functionality and scope. However, NanoVDB offers one major advantage over OpenVDB, namely support for GPUs. As such it is applicable to both CPU and GPU accelerated simulation and rendering of high-resolution sparse volumes. In fact, it has already been adopted for real-time applications by several commercial renders and digital content creation tools, e.g. Autodesk's Arnold, Blender, SideFX's Houdini, and NVIDIA's Omniverse just to mention a few.	https://dl.acm.org/doi/abs/10.1145/3450623.3464653	Ken Museth
NeuMIP: multi-resolution neural materials	We propose NeuMIP, a neural method for representing and rendering a variety of material appearances at different scales. Classical prefiltering (mipmapping) methods work well on simple material properties such as diffuse color, but fail to generalize to normals, self-shadowing, fibers or more complex microstructures and reflectances. In this work, we generalize traditional mipmap pyramids to pyramids of neural textures, combined with a fully connected network. We also introduce neural offsets, a novel method which enables rendering materials with intricate parallax effects without any tessellation. This generalizes classical parallax mapping, but is trained without supervision by any explicit heightfield. Neural materials within our system support a 7-dimensional query, including position, incoming and outgoing direction, and the desired filter kernel size. The materials have small storage (on the order of standard mipmapping except with more texture channels), and can be integrated within common Monte-Carlo path tracing systems. We demonstrate our method on a variety of materials, resulting in complex appearance across levels of detail, with accurate parallax, self-shadowing, and other effects.	https://dl.acm.org/doi/abs/10.1145/3450626.3459795	Alexandr Kuznetsov, Krishna Mullia, Zexiang Xu, Miloš Hašan, Ravi Ramamoorthi
Neural animation layering for synthesizing martial arts movements	Interactively synthesizing novel combinations and variations of character movements from different motion skills is a key problem in computer animation. In this paper, we propose a deep learning framework to produce a large variety of martial arts movements in a controllable manner from raw motion capture data. Our method imitates animation layering using neural networks with the aim to overcome typical challenges when mixing, blending and editing movements from unaligned motion sources. The framework can synthesize novel movements from given reference motions and simple user controls, and generate unseen sequences of locomotion, punching, kicking, avoiding and combinations thereof, but also reconstruct signature motions of different fighters, as well as close-character interactions such as clinching and carrying by learning the spatial joint relationships. To achieve this goal, we adopt a modular framework which is composed of the motion generator and a set of different control modules. The motion generator functions as a motion manifold that projects novel mixed/edited trajectories to natural full-body motions, and synthesizes realistic transitions between different motions. The control modules are task dependent and can be developed and trained separately by engineers to include novel motion tasks, which greatly reduces network iteration time when working with large-scale datasets. Our modular framework provides a transparent control interface for animators that allows modifying or combining movements after network training, and enables iterative adding of control modules for different motion tasks and behaviors. Our system can be used for offline and online motion generation alike, and is relevant for real-time applications such as computer games.	https://dl.acm.org/doi/abs/10.1145/3450626.3459881	Sebastian Starke, Yiwei Zhao, Fabio Zinno, Taku Komura
Neural complex luminaires: representation and rendering	Complex luminaires, such as grand chandeliers, can be extremely costly to render because the light-emitting sources are typically encased in complex refractive geometry, creating difficult light paths that require many samples to evaluate with Monte Carlo approaches. Previous work has attempted to speed up this process, but the methods are either inaccurate, require the storage of very large lightfields, and/or do not fit well into modern path-tracing frameworks. Inspired by the success of deep networks, which can model complex relationships robustly and be evaluated efficiently, we propose to use a machine learning framework to compress a complex luminaire's lightfield into an implicit neural representation. Our approach can easily plug into conventional renderers, as it works with the standard techniques of path tracing and multiple importance sampling (MIS). Our solution is to train three networks to perform the essential operations for the complex luminaire at a specific point and view direction, a point on the luminaire given a shading location, and to determine the transparency of luminaire queries to properly composite them with other scene elements. We perform favorably relative to state-of-the-art approaches and render final images that are close to the high-sample-count reference with only a fraction of the computation and storage costs, with no need to store the original luminaire geometry and materials.	https://dl.acm.org/doi/abs/10.1145/3450626.3459798	Junqiu Zhu, Yaoyi Bai, Zilin Xu, Steve Bako, Edgar Velázquez-Armendáriz, Lu Wang, Pradeep Sen, Miloš Hašan, Ling-Qi Yan
Neural monocular 3D human motion capture with physical awareness	"We present a new trainable system for physically plausible markerless 3D human motion capture, which achieves state-of-the-art results in a broad range of challenging scenarios. Unlike most neural methods for human motion capture, our approach, which we dub ""physionical"", is aware of physical and environmental constraints. It combines in a fully-differentiable way several key innovations, , 1) a proportional-derivative controller, with gains predicted by a neural network, that reduces delays even in the presence of fast motions, 2) an explicit rigid body dynamics model and 3) a novel optimisation layer that prevents physically implausible foot-floor penetration as a hard constraint. The inputs to our system are 2D joint keypoints, which are canonicalised in a novel way so as to reduce the dependency on intrinsic camera parameters---both at train and test time. This enables more accurate global translation estimation without generalisability loss. Our model can be finetuned only with 2D annotations when the 3D annotations are not available. It produces smooth and physically-principled 3D motions in an interactive frame rate in a wide variety of challenging scenes, including newly recorded ones. Its advantages are especially noticeable on in-the-wild sequences that significantly differ from common 3D pose estimation benchmarks such as Human 3.6M and MPI-INF-3DHP. Qualitative results are provided in the supplementary video."	https://dl.acm.org/doi/abs/10.1145/3450626.3459825	Soshi Shimada, Vladislav Golyanik, Weipeng Xu, Patrick Pérez, Christian Theobalt
Neural scene graph rendering	We present a neural scene graph---a modular and controllable representation of scenes with elements that are learned from data. We focus on the forward rendering problem, where the scene graph is provided by the user and references learned elements. The elements correspond to geometry and material definitions of scene objects and constitute the leaves of the graph; we store them as high-dimensional vectors. The position and appearance of scene objects can be adjusted in an artist-friendly manner via familiar transformations, e.g. translation, bending, or color hue shift, which are stored in the inner nodes of the graph. In order to apply a (non-linear) transformation to a learned vector, we adopt the concept of linearizing a problem by lifting it into higher dimensions: we first encode the transformation into a high-dimensional matrix and then apply it by standard matrix-vector multiplication. The transformations are encoded using neural networks. We render the scene graph using a streaming neural renderer, which can handle graphs with a varying number of objects, and thereby facilitates scalability. Our results demonstrate a precise control over the learned object representations in a number of animated 2D and 3D scenes. Despite the limited visual complexity, our work presents a step towards marrying traditional editing mechanisms with learned representations, and towards high-quality, controllable neural rendering.	https://dl.acm.org/doi/abs/10.1145/3450626.3459848	Jonathan Granskog, Till N. Schnabel, Fabrice Rousselle, Jan Novák
New techniques in interactive character animation	The application of deep learning for physics-based character animation and for cinematic controllers for interactive animation is changing how we should think about interactive character animation in video games and virtual reality. We will review the benefits and drawbacks of the techniques used and the implementations available to get started.	https://dl.acm.org/doi/abs/10.1145/3450508.3464604	Cengiz Öztireli, Christian Häne, Christian Häne, Forrester Cole, Konstantinos Rematas, Sofien Bouaziz
NoR-VDPNet++: Efficient Training and Architecture for Deep No-Reference Image Quality Metrics	Efficiency and efficacy are two desirable properties of the utmost importance for any evaluation metric having to do with Standard Dynamic Range (SDR) imaging or High Dynamic Range (HDR) imaging. However, these properties are hard to achieve simultaneously. On the one side, metrics like HDR-VDP2.2 are known to mimic the human visual system (HVS) very accurately, but its high computational cost prevents its widespread use in large evaluation campaigns. On the other side, computationally cheaper alternatives like PSNR or MSE fail to capture many of the crucial aspects of the HVS. In this work, we try to get the best of the two worlds: we present NoR-VDPNet++, an improved variant of a previous deep learning-based metric for distilling HDR-VDP2.2 into a convolutional neural network (CNN). In this work, we try to get the best of the two worlds: we present NoR-VDPNet++, an improved version of a deep learning-based metric for distilling HDR-VDP2.2 into a convolutional neural network (CNN).	https://dl.acm.org/doi/abs/10.1145/3450623.3464636	Francesco Banterle, Alessandro Artusi, Alejandro Moreo, Fabio Carrara
Non-photorealistic ray tracing with paint and toon shading	We present a modification to traditional ray tracing that stylistically renders a scene with cartoon and painterly styles. Previous methods rely on post-processing, materials, or textures to achieve a non-photorealistic look. Our method uses a ray tracer to combine cel animation art styles with complex lighting effects, such as reflections, refractions, and global illumination. The ray tracer collects information about objects and their properties to dynamically switch between cartoon and painterly rendering styles. The renderer generates the styles by shooting additional rays for each pixel and collecting information such as normals, distance, slope, object identifiers, and light gradients from neighboring areas of the image. The resulting algorithm produces images with visual and artistic characteristics that allow artists to take advantage of rendering techniques that are not commonly supported in production ray tracers.	https://dl.acm.org/doi/abs/10.1145/3450618.3469173	Nicholas Moon, Megan Reddy, Luther Tychonievich
Once Upon a Sea: A poetic, interactive XR documentary	ONCE UPON A SEA is an immersive virtual reality experience that transports participants to the Dead Sea, and provides access to one of the wonders of the world that has become inaccessible in the past 35 years. The Dead Sea carries a rich history, an undeniable healing powers, and an indescribable magnetism that can now be experienced in a virtual format. The experience takes place in photoreal volumetric captures of some of the most significant and beautiful sites in the Dead Sea, highlighting its beauty, diverse inhabitants, and its recent demise. In the past 30 years, the Dead Sea has receded dramatically due to human intervention and political neglect. The sweet water that fed the Sea was used for irrigation and potash evaporation pools left behind a ravaged land, ridden with sinkholes. Today, all beaches but one are inaccessible to the public due to these dangerous sinkholes, representing Israel's worst ecological crises. The destruction is progressing quickly, causing many socio-political battles as well as financial & personal distress to local residents and individuals who have dedicated their lives to the Sea. Israelis, Jordanians, and Palestinians, all whose countries border this body of water, have been affected by the demise of the Dead Sea. If nothing will be done, the Dead Sea as we know it will be gone for good. ONCE UPON A SEA is our call to action.	https://dl.acm.org/doi/abs/10.1145/3450615.3464536	Nimrod Shanit, Adi Lavy, Ina Fichman
Once upon a time in Ekuar	Welcome to EKUAR, home of the energy creatures known as SUNSHINES. For centuries, these fantastic creatures have shared their energy with the space explorers from the empire, collaborating and creating a delicate balance between them... until everything changed. Join us and witness the rise and fall of these two species.	https://dl.acm.org/doi/abs/10.1145/3446367.3452133	Andres Aguilar, Joseph Game
Only a matter of style: age transformation using a style-based regression model	The task of age transformation illustrates the change of an individual's appearance over time. Accurately modeling this complex transformation over an input facial image is extremely challenging as it requires making convincing, possibly large changes to facial features and head shape, while still preserving the input identity. In this work, we present an image-to-image translation method that learns to directly encode real facial images into the latent space of a pre-trained unconditional GAN (e.g., StyleGAN) subject to a given aging shift. We employ a pre-trained age regression network to explicitly guide the encoder in generating the latent codes corresponding to the desired age. In this formulation, our method approaches the continuous aging process as a regression task between the input age and desired target age, providing fine-grained control over the generated image. Moreover, unlike approaches that operate solely in the latent space using a prior on the path controlling age, our method learns a more disentangled, non-linear path. Finally, we demonstrate that the end-to-end nature of our approach, coupled with the rich semantic latent space of StyleGAN, allows for further editing of the generated images. Qualitative and quantitative evaluations show the advantages of our method compared to state-of-the-art approaches. Code is available at our project page: https://yuval-alaluf.github.io/SAM.	https://dl.acm.org/doi/abs/10.1145/3450626.3459805	Yuval Alaluf, Or Patashnik, Daniel Cohen-Or
Opera	is a massive 8K size animation installation project that portrays our society and history, which is filled with beauty and absurdity. This ambitious piece can be simply defined as a contemporary animated edition of the Renaissance fresco mural paintings. Driven by the spirits of Bosch, Michelangelo, Botticelli, and others, the animation enables viewers to experience a range of in-depth emotions through this epic reflection of human life: it is hopeful, funny, thoughtful, yet scary and sad. This piece is not only a living piece of art, but an invitation to question the mechanisms of your society and behavior.	https://dl.acm.org/doi/abs/10.1145/3450507.3457432	Erick Oh
Optimizing UI layouts for deformable face-rig manipulation	Complex deformable face-rigs have many independent parameters that control the shape of the object. A human face has upwards of 50 parameters (FACS Action Units), making conventional UI controls hard to find and operate. Animators address this problem by tediously hand-crafting in-situ layouts of UI controls that serve as visual deformation proxies, and facilitate rapid shape exploration. We propose the automatic creation of such in-situ UI control layouts. We distill the design choices made by animators into mathematical objectives that we optimize as the solution to an integer quadratic programming problem. Our evaluation is three-fold: we show the impact of our design principles on the resulting layouts; we show automated UI layouts for complex and diverse face rigs, comparable to animator handcrafted layouts; and we conduct a user study showing our UI layout to be an effective approach to face-rig manipulation, preferable to a baseline slider interface.	https://dl.acm.org/doi/abs/10.1145/3450626.3459842	Joonho Kim, Karan Singh
Optimizing dyadic nets	We explore the space of (0, , 2)-nets in base 2 commonly used for sampling. We present a novel constructive algorithm that can exhaustively generate all nets --- up to -bit resolution --- and thereby compute the exact number of distinct nets. We observe that the construction algorithm holds the key to defining a transformation operation that lets us transform one valid net into another one. This enables the optimization of digital nets using arbitrary objective functions. For example, we define an analytic energy function for blue noise, and use it to generate nets with high-quality blue-noise frequency power spectra. We also show that the space of (0, 2)-sequences is significantly smaller than nets with the same number of points, which drastically limits the optimizability of sequences.	https://dl.acm.org/doi/abs/10.1145/3450626.3459880	Abdalla G. M. Ahmed, Peter Wonka
Orders of Magnitude: An immersive educational virtual reality application about the Universe	Orders of Magnitude is an immersive educational virtual reality application. Each player can explore all the known scales in our universe by zooming in or out. This scientifically accurate experience contains elements such as galaxies, stars, the solar system, Earth, the human brain, neurons, DNA, atoms and subatomic particles. The majority of the content is taken from various scientific databases and is represented, wherever possible, as it exists in nature. An artistic impression is used to depict elements for which little or no information is available about their visual presence.	https://dl.acm.org/doi/abs/10.1145/3450615.3464540	Filip Vesely
Orienting point clouds with dipole propagation	Establishing a consistent normal orientation for point clouds is a notoriously difficult problem in geometry processing, requiring attention to both and shape characteristics. The normal direction of a point is a function of the surface neighborhood; yet, point clouds do not disclose the full underlying surface structure. Even assuming known geodesic proximity, calculating a consistent normal orientation requires the global context. In this work, we introduce a novel approach for establishing a globally consistent normal orientation for point clouds. Our solution separates the and components into two different sub-problems. In the local phase, we train a neural network to learn a normal direction per patch ( , consistently oriented normals within a single patch). In the global phase, we propagate the orientation across all coherent patches using a dipole propagation. Our dipole propagation decides to orient each patch using the electric field defined by all previously orientated patches. This gives rise to a global propagation that is stable, as well as being robust to nearby surfaces, holes, sharp features and noise.	https://dl.acm.org/doi/abs/10.1145/3450626.3459835	Gal Metzer, Rana Hanocka, Denis Zorin, Raja Giryes, Daniele Panozzo, Daniel Cohen-Or
PH-CPF: planar hexagonal meshing using coordinate power fields	We present a new approach for computing planar hexagonal meshes that approximate a given surface, represented as a triangle mesh. Our method is based on two novel technical contributions. First, we introduce , which are a pair of tangent vector fields on the surface that fulfill a certain constraint. We prove that the fulfillment of this constraint guarantees the existence of a seamless parameterization with quantized rotational jumps, which we then use to regularly remesh the surface. We additionally propose an optimization framework for finding Coordinate Power Fields, which also fulfill additional constraints, such as alignment, sizing and bijectivity. Second, we build upon this framework to address a challenging meshing problem: planar hexagonal meshing. To this end, we suggest a combination of conjugacy, scaling and alignment constraints, which together lead to planarizable hexagons. We demonstrate our approach on a variety of surfaces, automatically generating planar hexagonal meshes on complicated meshes, which were not achievable with existing methods.	https://dl.acm.org/doi/abs/10.1145/3450626.3459770	Kacper Pluta, Michal Edelstein, Amir Vaxman, Mirela Ben-Chen
Panjam - Reimagining Music Learning to Support Healthy Aging and Wellbeing	In this paper, we present Panjam - a prototype VR application that reimagines music learning for seniors to support healthy aging and wellbeing. Panjam uses the intuitive interface of the steelpan paired with immersion, presence, multi-sensory feedback, and gamification of the VR system to induce active engagement, self-driven practice and learning.	https://dl.acm.org/doi/abs/10.1145/3450615.3464530	Shawn De Freitas
PanoSynthVR: View Synthesis From A Single Input Panorama with Multi-Cylinder Images	We introduce a method to automatically convert a single panoramic input into a multi-cylinder image representation that supports real-time, free-viewpoint view synthesis for virtual reality. We apply an existing convolutional neural network trained on pinhole images to a cylindrical panorama with wrap padding to ensure agreement between the left and right edges. The network outputs a stack of semi-transparent panoramas at varying depths which can be easily rendered and composited with over blending. Initial experiments show that the method produces convincing parallax and cleaner object boundaries than a textured mesh representation.	https://dl.acm.org/doi/abs/10.1145/3450618.3469144	Richa Gadgil, Reesa John, Stefanie Zollmann, Jonathan Ventura
Pareto gamuts: exploring optimal designs across varying contexts	"Manufactured parts are meticulously engineered to perform well with respect to several conflicting metrics, like weight, stress, and cost. The best achievable trade-offs reside on the , which can be discovered via performance-driven optimization. The objectives that define this Pareto front often incorporate assumptions about the in which a part will be used, including loading conditions, environmental influences, material properties, or regions that must be preserved to interface with a surrounding assembly. Existing multi-objective optimization tools are only equipped to study one context at a time, so engineers must run independent optimizations for each context of interest. However, engineered parts frequently appear in many contexts: wind turbines must perform well in many wind speeds, and a bracket might be optimized several times with its bolt-holes fixed in different locations on each run. In this paper, we formulate a framework for variable-context multi-objective optimization. We introduce the , which captures Pareto fronts over a range of contexts. We develop a global/local optimization algorithm to discover the Pareto gamut directly, rather than discovering a single fixed-context ""slice"" at a time. To validate our method, we adapt existing multi-objective optimization benchmarks to contextual scenarios. We also demonstrate the practical utility of Pareto gamut exploration for several engineering design problems."	https://dl.acm.org/doi/abs/10.1145/3450626.3459750	Liane Makatura, Minghao Guo, Adriana Schulz, Justin Solomon, Wojciech Matusik
Passing Multi-Channel Material Textures to a 3-Channel Loss	Our objective is to compute a textural loss that can be used to train texture generators with multiple material channels typically used for physically based rendering such as albedo, normal, roughness, metalness, ambient occlusion, etc. Neural textural losses often build on top of the feature spaces of pretrained convolutional neural networks. Unfortunately, these pretrained models are only available for 3-channel RGB data and hence limit neural textural losses to this format. To overcome this limitation, we show that passing random triplets to a 3-channel loss provides a multi-channel loss that can be used to generate high-quality material textures.	https://dl.acm.org/doi/abs/10.1145/3450623.3464685	Thomas Chambon, Eric Heitz, Laurent Belcour
Path replay backpropagation: differentiating light paths using constant memory and linear time	Differentiable physically-based rendering has become an indispensable tool for solving inverse problems involving light. Most applications in this area jointly optimize a large set of scene parameters to minimize an objective function, in which case reverse-mode differentiation is the method of choice for obtaining parameter gradients. However, existing techniques that perform the necessary differentiation step suffer from either statistical bias or a prohibitive cost in terms of memory and computation time. For example, standard techniques for automatic differentiation based on program transformation or Wengert tapes lead to impracticably large memory usage when applied to physically-based rendering algorithms. A recently proposed adjoint method by Nimier-David et al. [2020] reduces this to a constant memory footprint, but the computation time for unbiased gradient estimates then becomes quadratic in the number of scattering events along a light path. This is problematic when the scene contains highly scattering materials like participating media. In this paper, we propose a new unbiased backpropagation algorithm for rendering that only requires constant memory, and whose computation time is linear in the number of scattering events (i.e., just like path tracing). Our approach builds on the invertibility of the local Jacobian at scattering interactions to recover the various quantities needed for reverse-mode differentiation. Our method also extends to specular materials such as smooth dielectrics and conductors that cannot be handled by prior work.	https://dl.acm.org/doi/abs/10.1145/3450626.3459804	Delio Vicini, Sébastien Speierer, Wenzel Jakob
Path-space differentiable rendering of participating media	Physics-based differentiable rendering---which focuses on estimating derivatives of radiometric detector responses with respect to arbitrary scene parameters---has a diverse array of applications from solving analysis-by-synthesis problems to training machine-learning pipelines incorporating forward-rendering processes. Unfortunately, existing general-purpose differentiable rendering techniques lack either the generality to handle volumetric light transport or the flexibility to devise Monte Carlo estimators capable of handling complex geometries and light transport effects. In this paper, we bridge this gap by showing how generalized path integrals can be differentiated with respect to arbitrary scene parameters. Specifically, we establish the mathematical formulation of generalized differential path integrals that capture both interfacial and volumetric light transport. Our formulation allows the development of advanced differentiable rendering algorithms capable of efficiently handling challenging geometric discontinuities and light transport phenomena such as volumetric caustics. We validate our method by comparing our derivative estimates to those generated using the finite differences. Further, to demonstrate the effectiveness of our technique, we compare both differentiable rendering and inverse rendering performance with state-of-the-art methods.	https://dl.acm.org/doi/abs/10.1145/3450626.3459782	Cheng Zhang, Zihan Yu, Shuang Zhao
Persona: Real-Time Neural 3D Face Reconstruction for Visual Effects on Mobile Devices	We present Persona, a real-time human face-oriented visual effect solution on mobile devices. Persona consists of a 3D face tracker with multi-scale reconstruction models for different-level of mobile devices and a visual effect authoring tool. Our face tracker is able to reliably predict a sequence of facial and illumination parameters from a monocular video in real-time. Those parameters can then be used to develop many interesting applications. We demonstrate that our method outperforms existing state-of-the-art work about 3D face reconstruction on mobile devices and showcase results generated by our tool.	https://dl.acm.org/doi/abs/10.1145/3450623.3464634	Gengdai Liu, Xiaowei Zhang, Feiqian Zhang, Yu Wei
PhotoApp: photorealistic appearance editing of head portraits	Photorealistic editing of head portraits is a challenging task as humans are very sensitive to inconsistencies in faces. We present an approach for high-quality intuitive editing of the camera viewpoint and scene illumination (parameterised with an environment map) in a portrait image. This requires our method to capture and control the full reflectance field of the person in the image. Most editing approaches rely on supervised learning using training data captured with setups such as light and camera stages. Such datasets are expensive to acquire, not readily available and do not capture all the rich variations of in-the-wild portrait images. In addition, most supervised approaches only focus on relighting, and do not allow camera viewpoint editing. Thus, they only capture and control a subset of the reflectance field. Recently, portrait editing has been demonstrated by operating in the generative model space of StyleGAN. While such approaches do not require direct supervision, there is a significant loss of quality when compared to the supervised approaches. In this paper, we present a method which learns from limited supervised training data. The training images only include people in a fixed neutral expression with eyes closed, without much hair or background variations. Each person is captured under 150 one-light-at-a-time conditions and under 8 camera poses. Instead of training directly in the image space, we design a supervised problem which learns transformations in the latent space of StyleGAN. This combines the best of supervised learning and generative adversarial modeling. We show that the StyleGAN prior allows for generalisation to different expressions, hairstyles and backgrounds. This produces high-quality photorealistic results for in-the-wild images and significantly outperforms existing methods. Our approach can edit the illumination and pose simultaneously, and runs at interactive rates.	https://dl.acm.org/doi/abs/10.1145/3450626.3459765	Mallikarjun B R, Ayush Tewari, Abdallah Dib, Tim Weyrich, Bernd Bickel, Hans-Peter Seidel, Hanspeter Pfister, Wojciech Matusik, Louis Chevallier, Mohamed Elgharib, Christian Theobalt
Photogrammetry for a Virtual Reality Nature Scene	This groovy graphics assignment introduces students to the practice of capturing physical objects in nature using photogrammetry and professional software to prepare them as digital assets for building a virtual reality environment in a real-time game engine. Students are tasked with exploring outside, preferably in a natural setting such as a park, nature trail, or backyard, to find ephemeral objects or areas of interest to capture and use to build a virtual reality nature scene. This assignment inspires students to consider the natural environment as a resource for creating virtual environments while simultaneously challenging them to work with an emerging technique for asset creation. It also exposes students to different software packages while preparing the captured data as 3D models which leads to a deep understanding of the 3D pipeline. Once the assets are prepared and the scene is built, viewing the completed environment in VR may strengthen an appreciation for natural environments by viewing a digital representation with an increased sense of presence.	https://dl.acm.org/doi/abs/10.1145/3450549.3464416	Justin Johnson, Amber Johnson
Photonic Rendering for Hair Cuticles using High Accuracy NS-FDTD method	The internal structure of hair consists of three layers: the cuticle, the cortex, and the medulla, and there are multiple membrane structures inside the cuticle. Light incident on these subwavelength structures is subject to scattering and interference phenomena, and the reflected highlights vary depending on the viewing angle. This phenomenon of light coloration due to the microstructure is called structural coloring or photonic coloration. It shows a unique specular highlight and determines the magnitude of the specular highlight, which is not observable in the linear optics of CG. In the case of hairs, this structural coloring or photonic coloration occurs in addition to the simple surface reflections and the backscattering lights, which penetrate the hair and are absorbed by the melanin pigment. In the present report, we mainly discuss the effects of the structural coloring first caused by the multi-layered structure in the cuticle region on the hair surface, simulating the electromagnetic field using the NS-FDTD (Non-Standard Finite Difference in Time Domain) method. In addition, we also discuss the backscattering phenomena inside the hair fibers.	https://dl.acm.org/doi/abs/10.1145/3450623.3464678	Zhuo Hou, Dongsheng Cai, Ran Dong
Physical validation of simulators in computer graphics: a new framework dedicated to slender elastic structures and frictional contact	We introduce a selected set of protocols inspired from the Soft Matter Physics community in order to validate Computer Graphics simulators of slender elastic structures possibly subject to dry frictional contact. Although these simulators were primarily intended for feature film animation and visual effects, they are more and more used as virtual design tools for predicting the shape and deformation of real objects; hence the need for a careful, quantitative validation. Our tests, experimentally verified, are designed to evaluate carefully the predictability of these simulators on various aspects, such as bending elasticity, bend-twist coupling, and frictional contact. We have passed a number of popular codes of Computer Graphics through our benchmarks by defining a rigorous, consistent, and as fair as possible methodology. Our results show that while some popular simulators for plates/shells and frictional contact fail even on the simplest scenarios, more recent ones, as well as well-known codes for rods, generally perform well and sometimes even better than some reference commercial tools of Mechanical Engineering. To make our validation protocols easily applicable to any simulator, we provide an extensive description of our methodology, and we shall distribute all the necessary model data to be compared against.	https://dl.acm.org/doi/abs/10.1145/3450626.3459931	Victor Romero, Mickaël Ly, Abdullah Haroon Rasheed, Raphaël Charrondière, Arnaud Lazarus, Sébastien Neukirch, Florence Bertails-Descoubes
Pixar's soul and the search for authenticity	"The production of Soul faced many immense challenges, not to mention building a dialogue across all elements of the pipeline to help ensure an authentic approach to portraying a culturally specific story onscreen. In this production session, hear from a cross section of people who worked as artists on the film, along with those who participated in the ""cultural trust"" which helped guide many of the artistic choices along the way."	https://dl.acm.org/doi/abs/10.1145/3446368.3451988	Chris Wiggum, Michael Fong, Britta Wilson, Mara MacMahon, Jaclyn Simon, Sean Muriithi, Bryn Imagire, Ian Megibben, Junyi Ling
Pixar’s OUT: Experimental Look Development in the SparkShorts program	"Pixar's OUT, released summer 2020 on Disney+, is a short film with a highly stylized look, produced under the in-house SparkShorts program. The program champions new creative voices and storytelling via tight-knit production teams that work with limited budgets to push the boundaries of animation production at Pixar. In this talk we present the conception, design and implementation of the film's unique visual style. Armed with some early inspirational artwork and some pre-production technical exploration, much of the look for the short was found during the course of production. Ultimately we landed on a style that was somewhere on the bridge between 2D and 3D animation. When we had it right, shots felt like a ""living painting"" with characters and sets that felt like a medium come alive, instead of a series of paintings per-frame. Our goal was not to emulate a particular traditional medium but to evoke a feeling of something crafted that stood on its own as a novel style, which we achieved with a small but enthusiastic crew."	https://dl.acm.org/doi/abs/10.1145/3450623.3464656	Colin Thompson, Gordon Cameron, Matthew Silas, Andrew Pienaar, Kureha Yokoo
Pockets: User-Assigned Menus Based on Physical Buttons for Virtual Environments	We present Pockets, a simple means of organizing and carrying 3D tools and other objects in virtual environments. Previous examples exist of using 3D tools with visually obvious affordances in virtual immersive environments instead of more traditional menus, however, in these applications a 2D menu is still necessary to select 3D tools from. Pockets make use of a belt with physical buttons, that objects can be assigned to. The Pockets design not only enables users to use their muscle memory to store and retrieve objects, thereby making tool use more efficient, but also solves the occlusion problem associated with state of the art approaches such as 2D menus tied to the body or to world space.	https://dl.acm.org/doi/abs/10.1145/3450618.3469174	Aubrey Simonson
Populating the World of Kumandra: Animation at Scale for Disney’s “Raya and the Last Dragon”	"Walt Disney Animation Studios' 59th film ""Raya and the Last Dragon"" takes place in the fantasy world of Kumandra. We look at the challenges of casting and choreographing diverse people, creatures, and props to bring a varied spectrum of cultures and scenes to life: tense gatherings, intimate palace interiors, bustling floating markets with integrated boat traffic, panicked crowds, everyday life, and magical movements of dragons. The sheer diversity of characters presented a new set of obstacles that inspired us to extend our crowd system to efficiently address our increasingly diverse needs. Using production examples and results, we look at how our existing workflows and pipeline were leveraged and augmented to support these efforts. We discuss solutions for art-directed, simulated, and procedural approaches using our in-house Houdini-based system called Skeleton Library [El-Ali et al. 2016]."	https://dl.acm.org/doi/abs/10.1145/3450623.3464648	Alberto Luceno Ros, Kristin Chow, Jack Geckler, Norman Moses Joseph, Nicolas Nghiem
Pose-weight Interpolation: a Lateral Approach to Pose-based Deformations	Sculpting character deformations that stay on-model for an arbitrary pose is a non-trivial task. Example based methods are desirable, depending on how few sculpted examples they require. After experimenting with various methods, we find the results are lacking from an artistic point of view. The core problem comes down to a matter of Pose-weight Interpolation, for which we present a novel, artist-friendly solution, Constrained Weight Smoothing. CWS computes Pose-weights on an n-dimensional mesh in pose-space such that weights for an arbitrary pose can be evaluated in O(1) time.	https://dl.acm.org/doi/abs/10.1145/3450623.3464632	Arthur Gregory
Practical machine learning for rendering: from research to deployment	• Give insights into closing the gap between taking a research neural model to deployment • Understand the challenges in development, training, deployment, and iteration of neural networks for rendering • Show practical use cases, tools, and networks to start your path toward neural rendering in production software	https://dl.acm.org/doi/abs/10.1145/3450508.3464564	Yonghao Yue, Yuki Koyama, Issei Sato, Takeo Igarashi
Procedural Block-Based USD Workflows in Conduit	We present a procedural block-based approach for USD pipelines that minimizes up-front USD knowledge requirements while ensuring users can still leverage the power of native USD. Building on USD and Conduit, we define fundamental workflow principles and philosophies on artist-interaction that guide our modular Houdini-based toolsets. Finally, we discuss the successes and challenges in scaling these workflows into production.	https://dl.acm.org/doi/abs/10.1145/3450623.3464663	Chris Rydalch, Colvin Kenji Endo, Wayne Wu
Procedural Shading for Rendering the Appearance of Feathers	The appearance of a real-world feather is the result of light interactions with complex, patterned structures of varying scale; however, these have not yet been modeled for accurate rendering of feathers in computer graphics. Previously published works have presented simplified curve models for feather appearance. Using imaging from real feathers, we suggest why these approaches are not sufficient and provide motivation for building an appearance model specific to feathers. In that vein we demonstrate a new technique that takes into account the substructures of feathers during shading calculations to produce a more accurate far-field appearance.	https://dl.acm.org/doi/abs/10.1145/3450618.3469161	Jessica Baron, Daljit Singh Dhillon, Eric Patterson
Procedural real time live drawing animation	This work presents a real-time method to create a procedural drawing animation given a simple image and a set of parameters. The resulting animation, based on a GPU particle simulation, respects the input image structure and dynamic to draw and move brushes. Our work could be helpful for both creating live drawing animation and, more generally, to create a stylized image reproduction. The set of parameters allows the user to achieve a wide range of artistic styles.	https://dl.acm.org/doi/abs/10.1145/3450618.3469141	Alain Lioret, Sofiane Ben Embareck, Julien Boutet, Félix Cantet
PushToSki - An Indoor Ski Training System Using Haptic Feedback	Haptic feedback is an intuitive way of improving required postures in sports without having the trainee change their head-pose towards visual cues and therefore possibly worsening their overall body-pose. However, this feedback is not possible in a dynamic sport like alpine skiing which is why we propose a virtual reality ski training system that uses vibration as a haptic feedback method. Our system uses a commercially available indoor ski simulator and several trackers to capture the user's motion together with a set of vibration motors which will provide direct, haptic feedback to the user. Our system therefore allows giving haptic feedback even while the trainee is moving on the simulator.	https://dl.acm.org/doi/abs/10.1145/3450618.3469158	Jana Hoffard, Takuto Nakamura, Erwin Wu, Hideki Koike
QuanTaichi: a compiler for quantized simulations	"High-resolution simulations can deliver great visual quality, but they are often limited by available memory, especially on GPUs. We present a compiler for physical simulation that can achieve both high performance and significantly reduced memory costs, by enabling flexible and aggressive Low-precision (""quantized"") numerical data types are used and packed to represent simulation states, leading to reduced memory space and bandwidth consumption. Quantized simulation allows higher resolution simulation with less memory, which is especially attractive on GPUs. Implementing a quantized simulator that has high performance and packs the data tightly for aggressive storage reduction would be extremely labor-intensive and error-prone using a traditional programming language. To make the creation of quantized simulation practical, we have developed a new set of language abstractions and a compilation system. A suite of tailored domain-specific optimizations ensure quantized simulators often run as fast as the full-precision simulators, despite the overhead of encoding-decoding the packed quantized data types. Our programming language and compiler, based on , allow developers to effortlessly switch between different full-precision and quantized simulators, to explore the full design space of quantization schemes, and ultimately to achieve a good balance between space and precision. The creation of quantized simulation with our system has large benefits in terms of memory consumption and performance, on a variety of hardware, from mobile devices to workstations with high-end GPUs. We can simulate with levels of resolution that were previously only achievable on systems with much more memory, such as multiple GPUs. For example, on a GPU, we can simulate a Game of Life with 20 billion cells (8× compression per pixel), an Eulerian fluid system with 421 million active voxels (1.6× compression per voxel), and a hybrid Eulerian-Lagrangian elastic object simulation with 235 million particles (1.7× compression per particle). At the same time, quantized simulations create physically plausible results. Our quantization techniques are to existing acceleration approaches of physical simulation: they can be used in combination with these existing approaches, such as sparse data structures, for even higher scalability and performance."	https://dl.acm.org/doi/abs/10.1145/3450626.3459671	Yuanming Hu, Jiafeng Liu, Xuanda Yang, Mingkuan Xu, Ye Kuang, Weiwei Xu, Qiang Dai, William T. Freeman, Frédo Durand
Quantum Nodes: Quantum Computing Applied to 3D Modeling	Quantum Nodes is a Blender add-on that introduces the integration of quantum algorithms into the 3D creation process. Our work focuses on allowing users to experiment both new forms of creation and approaching the concepts of quantum computing through 3D creation.	https://dl.acm.org/doi/abs/10.1145/3450618.3469155	Félix Olart, Eloïse Tassin, Laurine Capdeville, Luc Pinguet, Théo Gautier, Alain Lioret
ROSEFusion: random optimization for online dense reconstruction under fast camera motion	Online reconstruction based on RGB-D sequences has thus far been restrained to relatively slow camera motions (<1m/s). Under very fast camera motion (e.g., 3m/s), the reconstruction can easily crumble even for the state-of-the-art methods. Fast motion brings two challenges to depth fusion: 1) the high nonlinearity of camera pose optimization due to large inter-frame rotations and 2) the lack of reliably trackable features due to motion blur. We propose to tackle the difficulties of fast-motion camera tracking in the absence of inertial measurements using random optimization, in particular, the Particle Filter Optimization (PFO). To surmount the computation-intensive particle sampling and update in standard PFO, we propose to accelerate the randomized search via updating a particle swarm template (PST). PST is a set of particles pre-sampled uniformly within the unit sphere in the 6D space of camera pose. Through moving and rescaling the pre-sampled PST guided by swarm intelligence, our method is able to drive tens of thousands of particles to locate and cover a good local optimum extremely fast and robustly. The particles, representing candidate poses, are evaluated with a fitness function defined based on depth-model conformance. Therefore, our method, being depth-only and correspondence-free, mitigates the motion blur impediment as (ToF-based) depths are often resilient to motion blur. Thanks to the efficient template-based particle set evolution and the effective fitness function, our method attains good quality pose tracking under fast camera motion (up to 4m/s) in a realtime framerate without including loop closure or global pose optimization. Through extensive evaluations on public datasets of RGB-D sequences, especially on a newly proposed benchmark of fast camera motion, we demonstrate the significant advantage of our method over the state of the arts.	https://dl.acm.org/doi/abs/10.1145/3450626.3459676	Jiazhao Zhang, Chenyang Zhu, Lintao Zheng, Kai Xu
RXMesh: a GPU mesh data structure	"We propose a new static high-performance mesh data structure for triangle surface meshes on the GPU. Our data structure is carefully designed for parallel execution while capturing mesh locality and confining data access, as much as possible, within the GPU's fast ""shared memory."" We achieve this by subdividing the mesh into and representing these patches compactly using a matrix-based representation. Our patching technique is decorated with , thin mesh strips around patches that eliminate the need to communicate between different computation thread blocks, resulting in consistent high throughput. We call our data structure : Ribbon-matriX Mesh. We hide the complexity of our data structure behind a flexible but powerful programming model that helps deliver high performance by inducing load balance even in highly irregular input meshes. We show the efficacy of our programming model on common geometry processing applications---mesh smoothing and filtering, geodesic distance, and vertex normal computation. For evaluation, we benchmark our data structure against well-optimized GPU and (single and multi-core) CPU data structures and show significant speedups."	https://dl.acm.org/doi/abs/10.1145/3450626.3459748	Ahmed H. Mahmoud, Serban D. Porumbescu, John D. Owens
Rapid prototyping approach for audio augmented reality user experiences	Audio consumer devices, such as headphones, are increasingly supporting spatial audio. This opens opportunities for UX designers to explore the design domain of audio-only Augmented Reality (AAR) experiences. The paper documents a hands-on approach to prototyping audio AR with a combination of game engine software, headphones, and a smartphone. The approach was delivered at SIGGRAPH2021 in the Labs session format.	https://dl.acm.org/doi/abs/10.1145/3450616.3464981	Aki Järvinen
Real Time Interactive Deformer Rig Evaluations in Maya using GPUs	Maya has supported evaluating deformer nodes on GPU since 2016. However, such GPU support in Maya is limited to evaluating simple linear chains of deformer nodes. In feature productions, character rigs have a complex network of deformation chains resulting in most deformers being evaluated on CPU. Here we will detail such architectural limitations within Maya. Then we present our approach that overcomes these limitations to fully evaluate deformation networks on GPU, which has enabled our rigs to perform over 50fps on GPU, compared to 5fps on CPU.	https://dl.acm.org/doi/abs/10.1145/3450623.3464666	FunShing Sin, Parag Havaldar, Vinod Melapudi
Real-time 3D neural facial animation from binocular video	"We present a method for performing real-time facial animation of a 3D avatar from binocular video. Existing facial animation methods fail to automatically capture precise and subtle facial motions for driving a photo-realistic 3D avatar ""in-the-wild"" (i.e., variability in illumination, camera noise). The novelty of our approach lies in a light-weight process for specializing a personalized face model to new environments that enables extremely accurate real-time face tracking anywhere. Our method uses a pre-trained high-fidelity personalized model of the face that we complement with a novel illumination model to account for variations due to lighting and other factors often encountered in-the-wild (e.g., facial hair growth, makeup, skin blemishes). Our approach comprises two steps. First, we solve for our illumination model's parameters by applying analysis-by-synthesis on a short video recording. Using the pairs of model parameters (rigid, non-rigid) and the original images, we learn a regression for real-time inference from the image space to the 3D shape and texture of the avatar. Second, given a new video, we fine-tune the real-time regression model with a few-shot learning strategy to adapt the regression model to the new environment. We demonstrate our system's ability to precisely capture subtle facial motions in unconstrained scenarios, in comparison to competing methods, on a diverse collection of identities, expressions, and real-world environments."	https://dl.acm.org/doi/abs/10.1145/3450626.3459806	Chen Cao, Vasu Agrawal, Fernando De La Torre, Lele Chen, Jason Saragih, Tomas Simon, Yaser Sheikh
Real-time Projection of Lip Animation onto Face Masks using OmniProcam	This paper describes an OmniProcam system, which enables 360 degree horizontal projection by a fisheye lens with a coaxial procam in which the optical axes of the camera and projector are exactly matched. Combined with 2D marker recognition, the OmniProcam can display images onto screens at arbitrary positions in 3D space. As an example application, we developed a system which projects lip animation onto the user's face masks for better communication at the physical meeting in current COVID-19 situation. The system recognizes the user's speech, generates the lip animation using Lipsync, and projects the animation onto the user's face masks.	https://dl.acm.org/doi/abs/10.1145/3450618.3469171	Luna Takagi, Toshiki Sato, Shio Miyafuji, Hideki Koike
Real-time deep dynamic characters	We propose a deep videorealistic 3D human character model displaying highly realistic shape, motion, and dynamic appearance learned in a new weakly supervised way from multi-view imagery. In contrast to previous work, our controllable 3D character displays dynamics, e.g., the swing of the skirt, dependent on skeletal body motion in an efficient data-driven way, without requiring complex physics simulation. Our character model also features a learned dynamic texture model that accounts for photo-realistic motion-dependent appearance details, as well as view-dependent lighting effects. During training, we do not need to resort to difficult dynamic 3D capture of the human; instead we can train our model entirely from multi-view video in a weakly supervised manner. To this end, we propose a parametric and differentiable character representation which allows us to model coarse and fine dynamic deformations, e.g., garment wrinkles, as explicit spacetime coherent mesh geometry that is augmented with high-quality dynamic textures dependent on motion and view point. As input to the model, only an arbitrary 3D skeleton motion is required, making it directly compatible with the established 3D animation pipeline. We use a novel graph convolutional network architecture to enable motion-dependent deformation learning of body and clothing, including dynamics, and a neural generative dynamic texture model creates corresponding dynamic texture maps. We show that by merely providing new skeletal motions, our model creates motion-dependent surface deformations, physically plausible dynamic clothing deformations, as well as video-realistic surface textures at a much higher level of detail than previous state of the art approaches, and even in real-time.	https://dl.acm.org/doi/abs/10.1145/3450626.3459749	Marc Habermann, Lingjie Liu, Weipeng Xu, Michael Zollhoefer, Gerard Pons-Moll, Christian Theobalt
Real-time locally injective volumetric deformation	We present a highly efficient method for interactive volumetric meshless shape deformation. Our method operates within a low dimensional sub-space of shape-aware harmonic maps, and is the first method that is guaranteed to produce a locally injective deformation in 3D. Unlike mesh-based methods in which local injectivity is enforced on tetrahedral elements, our method enforces injectivity on a sparse set of domain samples. The main difficulty is then to certify the map as locally injective throughout the domain. This is done by utilizing the Lipschitz continuity property of the harmonic basis functions. We show a surprising relation between the Lipschitz constant of the smallest singular value of the map Jacobian and the norm of the Hessian. We further carefully derive a Lipschitz constant for the Hessian, and develop a sufficient condition for the injectivity certification. This is done by utilizing the special structure of the harmonic basis functions combined with a novel regularization term that pushes the Lipschitz constants further down. As a result, the injectivity analysis can be performed on a relatively sparse set of samples. Combined with a parallel GPU-based implementation, our method can produce superior deformations with unique quality guarantees at real-time rates which were possible only in 2D so far.	https://dl.acm.org/doi/abs/10.1145/3450626.3459794	Wentao Liao, Renjie Chen, Yuchen Hua, Ligang Liu, Ofir Weber
Real-time neural radiance caching for path tracing	We present a real-time neural radiance caching method for path-traced global illumination. Our system is designed to handle fully dynamic scenes, and makes no assumptions about the lighting, geometry, and materials. The data-driven nature of our approach sidesteps many difficulties of caching algorithms, such as locating, interpolating, and updating cache points. Since pretraining neural networks to handle novel, dynamic scenes is a formidable generalization challenge, we do away with pretraining and instead achieve , i.e. we opt for training the radiance cache while rendering. We employ self-training to provide low-noise training targets and simulate infinite-bounce transport by merely iterating few-bounce training updates. The updates and cache queries incur a mild overhead---about 2.6ms on full HD resolution---thanks to a streaming implementation of the neural network that fully exploits modern hardware. We demonstrate significant noise reduction at the cost of little induced bias, and report state-of-the-art, real-time performance on a number of challenging scenarios.	https://dl.acm.org/doi/abs/10.1145/3450626.3459812	Thomas Müller, Fabrice Rousselle, Jan Novák, Alexander Keller
Reflectance Estimation for Free-viewpoint Video	We present a method to infer physically-based material properties for free-viewpoint video. Given a multi-camera image feed and reconstructed geometry, our method infers material properties, such as albedo, surface normal, metallic and roughness maps. We use a physically based, differentiable renderer to generate candidate images which are compared against the image feed. Our method searches for material textures which minimise an image-space loss metric between candidate renders and the ground truth image feed. Our method produces results that approximate state of the art reflectance capture, and produces texture maps that are compatible with common real-time and offline shading models.	https://dl.acm.org/doi/abs/10.1145/3450618.3469146	George Ash, Juraj Tomori, Mike Pelton, Charles Dupont
Reinventing a Character Creation Pipeline Using Landmarking, Simulation, and Shared Character Data	Reinventing the humanoid character build pipeline at Blue Sky Studios presented several opportunities to create synergy between different processes, all centering around the concept of creating and maintaining a standardized Universal Mesh. The automation of rig argument placement, the building of rigging tools that use aspects of character geometry as inputs, the separation of character data from assets, and the creation of a stylized simulation-based approach to deform animated characters were all influenced by this base Universal Mesh. Ultimately, this approach offered new ways to get the most out of our character pipeline.	https://dl.acm.org/doi/abs/10.1145/3450623.3464658	Ferris Webby, Todd Hill, Brian Anderson, Chris Pagoria, Christian Haniszewski, Daniel Lima
Reliable feature-line driven quad-remeshing	We present a new algorithm for the semi-regular quadrangulation of an input surface, driven by its line features, such as sharp creases. We define a perfectly feature-aligned cross-field and a coarse layout of polygonal-shaped patches where we strictly ensure that all the feature-lines are represented as patch boundaries. To be able to consistently do so, we allow non-quadrilateral patches and T-junctions in the layout; the key is the ability to constrain the layout so that it still admits a globally consistent, T-junction-free, and pure-quad internal tessellation of its patches. This requires the insertion of additional irregular-vertices inside patches, but the regularity of the final-mesh is safeguarded by optimizing for both their number and for their reciprocal alignment. In total, our method guarantees the reproduction of feature-lines by construction, while still producing good quality, isometric, pure-quad, conforming meshes, making it an ideal candidate for CAD models. Moreover, the method is fully automatic, requiring no user intervention, and remarkably reliable, requiring little assumptions on the input mesh, as we demonstrate by batch processing the entire Thingi10K repository, with less than 0.5% of the attempted cases failing to produce a usable mesh.	https://dl.acm.org/doi/abs/10.1145/3450626.3459941	Nico Pietroni, Stefano Nuvoli, Thomas Alderighi, Paolo Cignoni, Marco Tarini
Replacements (penggantian)	"""Replacements"" depicts a Javanese family routinely observing their neighborhood day after day, generation after generation, replacement after replacement. it is a VR story about roots, time and change."	https://dl.acm.org/doi/abs/10.1145/3446367.3449278	Agata Di Tommaso, Jonathan Hagard
Reverse Pass-Through VR	We introduce reverse pass-through VR, wherein a three-dimensional view of the wearer's eyes is presented to multiple outside viewers in a perspective-correct manner, with a prototype headset containing a world-facing light field display. This approach, in conjunction with existing video (forward) pass-through technology, enables more seamless interactions between people with and without headsets in social or professional contexts. Reverse pass-through VR ties together research in social telepresence and copresence, autostereoscopic displays, and facial capture to enable natural eye contact and other important non-verbal cues in a wider range of interaction scenarios.	https://dl.acm.org/doi/abs/10.1145/3450550.3465338	Nathan Matsuda, Brian Wheelwright, Joel Hegland, Douglas Lanman
Revisiting integration in the material point method: a scheme for easier separation and less dissipation	The material point method (MPM) recently demonstrated its efficacy at simulating many materials and the coupling between them on a massive scale. However, in scenarios containing debris, MPM manifests more dissipation and numerical viscosity than traditional Lagrangian methods. We have two observations from carefully revisiting existing integration methods used in MPM. First, nearby particles would end up with smoothed velocities without recovering momentum for each particle during the particle-grid-particle transfers. Second, most existing integrators assume continuity in the entire domain and advect particles by directly interpolating the positions from deformed nodal positions, which would trap the particles and make them harder to separate. We propose an integration scheme that corrects particle positions at each time step. We demonstrate our method's effectiveness with several large-scale simulations involving brittle materials. Our approach effectively reduces diffusion and unphysical viscosity compared to traditional integrators.	https://dl.acm.org/doi/abs/10.1145/3450626.3459678	Yun (Raymond) Fei, Qi Guo, Rundong Wu, Li Huang, Ming Gao
SANM: a symbolic asymptotic numerical solver with applications in mesh deformation	Solving nonlinear systems is an important problem. Numerical continuation methods efficiently solve certain nonlinear systems. The Asymptotic Numerical Method (ANM) is a powerful continuation method that usually converges faster than Newtonian methods. ANM explores the landscape of the function by following a parameterized solution curve approximated with a high-order power series. Although ANM has successfully solved a few graphics and engineering problems, prior to our work, applying ANM to new problems required significant effort because the standard ANM assumes quadratic functions, while manually deriving the power series expansion for nonquadratic systems is a tedious and challenging task. This paper presents a novel solver, SANM, that applies ANM to solve symbolically represented nonlinear systems. SANM solves such systems in a fully automated manner. SANM also extends ANM to support many nonquadratic operators, including intricate ones such as singular value decomposition. Furthermore, SANM generalizes ANM to support the implicit homotopy form. Moreover, SANM achieves high computing performance via optimized system design and implementation. We deploy SANM to solve forward and inverse elastic force equilibrium problems and controlled mesh deformation problems with a few constitutive models. Our results show that SANM converges faster than Newtonian solvers, requires little programming effort for new problems, and delivers comparable or better performance than a hand-coded, specialized ANM solver. While we demonstrate on mesh deformation problems, SANM is generic and potentially applicable to many tasks.	https://dl.acm.org/doi/abs/10.1145/3450626.3459755	Kai Jia
SP-GAN: sphere-guided 3D shape generation and manipulation	We present SP-GAN, a new unsupervised sphere-guided generative model for direct synthesis of 3D shapes in the form of point clouds. Compared with existing models, SP-GAN is able to synthesize diverse and high-quality shapes with fine details and promote controllability for part-aware shape generation and manipulation, yet trainable without any parts annotations. In SP-GAN, we incorporate a global prior (uniform points on a sphere) to spatially guide the generative process and attach a local prior (a random latent code) to each sphere point to provide local details. The key insight in our design is to disentangle the complex 3D shape generation task into a global shape modeling and a local structure adjustment, to ease the learning process and enhance the shape generation quality. Also, our model forms an implicit dense correspondence between the sphere points and points in every generated shape, enabling various forms of structure-aware shape manipulations such as part editing, part-wise shape interpolation, and multi-shape part composition, etc., beyond the existing generative models. Experimental results, which include both visual and quantitative evaluations, demonstrate that our model is able to synthesize diverse point clouds with fine details and less noise, as compared with the state-of-the-art models.	https://dl.acm.org/doi/abs/10.1145/3450626.3459766	Ruihui Li, Xianzhi Li, Ka-Hei Hui, Chi-Wing Fu
SWAGAN: a style-based wavelet-driven generative model	In recent years, considerable progress has been made in the visual quality of Generative Adversarial Networks (GANs). Even so, these networks still suffer from degradation in quality for high-frequency content, stemming from a spectrally biased architecture, and similarly unfavorable loss functions. To address this issue, we present a novel general-purpose Style and WAvelet based GAN (SWAGAN) that implements progressive generation in the frequency domain. SWAGAN incorporates wavelets throughout its generator and discriminator architectures, enforcing a frequency-aware latent representation at every step of the way. This approach, designed to directly tackle the spectral bias of neural networks, yields an improvement in the ability to generate medium and high frequency content, including structures which other networks fail to learn. We demonstrate the advantage of our method by integrating it into the SyleGAN2 framework, and verifying that content generation in the wavelet domain leads to more realistic high-frequency content, even when trained for fewer iterations. Furthermore, we verify that our model's latent space retains the qualities that allow StyleGAN to serve as a basis for a multitude of editing tasks, and show that our frequency-aware approach also induces improved high-frequency performance in downstream tasks.	https://dl.acm.org/doi/abs/10.1145/3450626.3459836	Rinon Gal, Dana Cohen Hochberg, Amit Bermano, Daniel Cohen-Or
Scalable Visual Simulation of Ductile and Brittle Fracture	Fracture of solid objects produces debris. Modelling the physics that produces the broken fragments from the original solid requires an increase in the number of degrees of freedom. This causes a huge increase in computational cost for FEM based methods used to model such phenomena. We present a graph-based FEM method that tackles this issue by relabeling the edges of the graph induced in a volumetric mesh, using a damage variable. We reformulate the system dynamics for this relabelled graph in order to simulate the fracture mechanics using FEM without an explosion in the computation cost. Our method therefore requires no remeshing of the volumetric mesh used for computation and this makes it very scalable to high-resolution meshes. We demonstrate that the method can simulate both brittle and ductile fracture.	https://dl.acm.org/doi/abs/10.1145/3450618.3469152	Avirup Mandal, Parag Chaudhuri, Subhasis Chaudhuri
Scalable image-based indoor scene rendering with reflections	This paper proposes a novel scalable image-based rendering (IBR) pipeline for indoor scenes with reflections. We make substantial progress towards three sub-problems in IBR, namely, depth and reflection reconstruction, view selection for temporally coherent view-warping, and smooth rendering refinements. First, we introduce a global-mesh-guided alternating optimization algorithm that robustly extracts a two-layer geometric representation. The front and back layers encode the RGB-D reconstruction and the reflection reconstruction, respectively. This representation minimizes the image composition error under novel views, enabling accurate renderings of reflections. Second, we introduce a novel approach to select adjacent views and compute blending weights for smooth and temporal coherent renderings. The third contribution is a supersampling network with a motion vector rectification module that refines the rendering results to improve the final output's temporal coherence. These three contributions together lead to a novel system that produces highly realistic rendering results with various reflections. The rendering quality outperforms state-of-the-art IBR or neural rendering algorithms considerably.	https://dl.acm.org/doi/abs/10.1145/3450626.3459849	Jiamin Xu, Xiuchao Wu, Zihan Zhu, Qixing Huang, Yin Yang, Hujun Bao, Weiwei Xu
Screenshots from Screen Photography	Screenshot is a frequently used tool in our daily life, while the screenshot capturing techniques are not much discussed in computer graphics and image processing researches. Capturing a screenshot is not always as easy as it seems. Firstly, the target devices for screenshot capturing must have screenshot software installed or featured in their operating systems. Secondly, the users must have input access to control the screenshot software within the target devices. Thirdly, the target devices must have Internet access or other hardware interfaces (such as USB ports) so that the users can take their screenshots out. When these requirements are not met, people often need to use their smartphones to take photographs in front of the screens as a substitute of screenshots. This allows direct sharing of the screen content, but the fidelity of the obtained content is apparently not as good as software screenshots. Might we be able to achieve a computer graphic solution to directly convert a screen photography to a screenshot, which looks like as if it was taken using software?	https://dl.acm.org/doi/abs/10.1145/3450618.3469136	Lvmin Zhang, Chengze Li
Sculpture Experience: VR discovery tour of 6 sculpture masterpieces, from prehistoric to modern times	This immersive and interactive experience for OCULUS QUEST 2 allows the visitor to observe in real size six masterpieces of sculpture iconic from five periods of history, following an imaginary and poetic journey enriched by numerous media.	https://dl.acm.org/doi/abs/10.1145/3450615.3464541	Frédéric Purgal
Seamless manga inpainting with semantics awareness	"Manga inpainting fills up the disoccluded pixels due to the removal of dialogue balloons or ""sound effect"" text. This process is long needed by the industry for the language localization and the conversion to animated manga. It is mostly done manually, as existing methods (mostly for natural image inpainting) cannot produce satisfying results. Manga inpainting is more tricky than natural image inpainting because its highly abstract illustration using structural lines and screentone patterns, which confuses the semantic interpretation and visual content synthesis. In this paper, we present the first manga inpainting method, a deep learning model, that generates high-quality results. Instead of direct inpainting, we propose to separate the complicated inpainting into two major phases, semantic inpainting and appearance synthesis. This separation eases both the feature understanding and hence the training of the learning model. A key idea is to disentangle the structural line and screentone, that helps the network to better distinguish the structural line and the screentone features for semantic interpretation. Both the visual comparison and the quantitative experiments evidence the effectiveness of our method and justify its superiority over existing state-of-the-art methods in the application of manga inpainting."	https://dl.acm.org/doi/abs/10.1145/3450626.3459822	Minshan Xie, Menghan Xia, Xueting Liu, Chengze Li, Tien-Tsin Wong
SecondSight: Demonstrating Cross-Device Augmented Reality	SecondSight is a framework for rapid prototyping of cross-device interfaces that combine an optical see-through Augmented Reality (AR) head-mounted display (HMD) with a smartphone. SecondSight contains code for simulating AR HMDs with different Fields of View (FOV), providing gesture and head pointing input, and allowing virtual content to be placed in different coordinate frames. Overall, this gives AR researchers flexibility to explore different types of cross-device interfaces and interaction techniques with different types of display, input, and content placement.	https://dl.acm.org/doi/abs/10.1145/3450615.3464545	Carolin Reichherzer, Jack Fraser, Mark Billinghurst
Shadows Optimizations in Cyberpunk 2077	This talk presents significant rendering-related CPU and GPU optimizations concerning shadows in Cyberpunk 2077. Given the scale of the game and the variety of platforms that it has to support, different solutions had to be implemented and coupled in order to fulfil the time and memory requirements. We also introduce our take on runtime and offline techniques for object culling and shadow maps caching in order to minimize potential overhead. The article concerns three different shadow types that can be spotted around Night City: cascaded, distant, and local shadows.	https://dl.acm.org/doi/abs/10.1145/3450623.3464679	Bartłomiej Dybisz, Michał Witanowski
ShapeMOD: macro operation discovery for 3D shape programs	A popular way to create detailed yet easily controllable 3D shapes is via procedural modeling, i.e. generating geometry using programs. Such programs consist of a series of instructions along with their associated parameter values. To fully realize the benefits of this representation, a shape program should be compact and only expose degrees of freedom that allow for meaningful manipulation of output geometry. One way to achieve this goal is to design higher-level operators that, when executed, expand into a series of commands from the base shape modeling language. However, manually authoring such macros, much like shape programs themselves, is difficult and largely restricted to domain experts. In this paper, we present ShapeMOD, an algorithm for automatically discovering macros that are useful across large datasets of 3D shape programs. ShapeMOD operates on shape programs expressed in an imperative, statement-based language. It is designed to discover macros that make programs more compact by minimizing the number of function calls and free parameters required to represent an input shape collection. We run ShapeMOD on multiple collections of programs expressed in a domain-specific language for 3D shape structures. We show that it automatically discovers a concise set of macros that abstract out common structural and parametric patterns that generalize over large shape collections. We also demonstrate that the macros found by ShapeMOD improve performance on downstream tasks including shape generative modeling and inferring programs from point clouds. Finally, we conduct a user study that indicates that ShapeMOD's discovered macros make interactive shape editing more efficient.	https://dl.acm.org/doi/abs/10.1145/3450626.3459821	R. Kenny Jones, David Charatan, Paul Guerrero, Niloy J. Mitra, Daniel Ritchie
She	"""She"" is an interactive film about a boy pursuing his gender identity. The boy got a magic lipstick that helps him to discover feminine tendencies. As the boy goes through the family's confinement and social isolation, viewers stand with the boy's inner self and support him to regain his self-acceptance."	https://dl.acm.org/doi/abs/10.1145/3446367.3452139	Yu-Hao Lee, Neng-Hao Yu, Wei-Zhe Zeng
Silent Speech and Emotion Recognition from Vocal Tract Shape Dynamics in Real-Time MRI	We propose a novel deep neural network-based learning framework that understands acoustic information in the variable-length sequence of vocal tract shaping during speech production, captured by real-time magnetic resonance imaging (rtMRI), and translate it into text. In an experiment, it achieved a 40.6% PER at sentence-level, much better compared to the existing models. We also performed an analysis of variations in the geometry of articulation in each sub-regions of the vocal tract with respect to different emotions and genders. Results suggest that each sub-regions distortion is affected by both emotion and gender.	https://dl.acm.org/doi/abs/10.1145/3450618.3469176	Laxmi Pandey, Ahmed Sabbir Arif
Simplified facial capture with head mounted cameras	We present a unified pipeline for high-resolution facial capture that replaces the initial traditional seated capture with a head-mounted camera setup. At its core, our approach relies on improving roughly personalized blendshapes by fitting handle vertices, in a Laplacian framework, to depth and image data. Thus, refining the geometry. This pipeline has been used in production to generate high quality animation to train our proprietary marker-based solution, leading to large time and cost savings.	https://dl.acm.org/doi/abs/10.1145/3450623.3464637	Jose Serra, Lucio Moser, David A. McLean, Doug Roble
Simulating Cloth Using Bilinear Elements	The most widely used cloth simulation algorithms within the computer graphics community are defined exclusively for triangle meshes. However, assets used in production are often made up of non-planar quadrilaterals. Dividing these elements into triangles and then mapping the displacements back to the original mesh results in faceting and tent-like artifacts when quadrilaterals are rendered as bilinear patches. We propose a method to simulate cloth dynamics on quadrilateral meshes directly, drawing on the well studied Koiter thin sheet model [Koiter 1960] to define consistent elastic energies for linear and bilinear elements. The algorithm elides the need for artifact-prone geometric mapping, and has computation times similar to its fully triangular counterpart.	https://dl.acm.org/doi/abs/10.1145/3450623.3464675	Eston Schweickart, Xiao Zhai
Simulation and Visualization of Virus Transmission for Architectural Design Analysis	The COVID-19 pandemic has made virus transmission a significant factor in designing buildings to ensure a safe and resilient environment. Simulation has been applied to analyze the potential risk of virus transmission within built spaces. Still, most existing simulations focused on a small region of the building, over a short period of time. Here we cover how we leveraged an occupancy simulation to inform and visualize the longitudinal impacts of virus transmission, in relation to a given building design and associated dynamic occupant behaviours. The flexibility of our system makes our simulation scalable and adaptable so that it can be applied to any building or context, with various types of occupants.	https://dl.acm.org/doi/abs/10.1145/3450623.3464638	Bokyung Lee, Michael Lee, Jacobo Bibliowicz, Rhys Goldstein, Jeremy Mogk, Alexander Tessier
Solid-fluid interaction with surface-tension-dominant contact	We propose a novel three-way coupling method to model the contact interaction between solid and fluid driven by strong surface tension. At the heart of our physical model is a thin liquid membrane that simultaneously couples to both the liquid volume and the rigid objects, facilitating accurate momentum transfer, collision processing, and surface tension calculation. This model is implemented numerically under a hybrid Eulerian-Lagrangian framework where the membrane is modelled as a simplicial mesh and the liquid volume is simulated on a background Cartesian grid. We devise a monolithic solver to solve the interactions among the three systems of liquid, solid, and membrane. We demonstrate the efficacy of our method through an array of rigid-fluid contact simulations dominated by strong surface tension, which enables the faithful modeling of a host of new surface-tension-dominant phenomena including: objects with higher density than water that remains afloat; 'Cheerios effect' where floating objects attract one another; and surface tension weakening effect caused by surface-active constituents.	https://dl.acm.org/doi/abs/10.1145/3450626.3459862	Liangwang Ruan, Jinyuan Liu, Bo Zhu, Shinjiro Sueda, Bin Wang, Baoquan Chen
Sony pictures imageworks & sony pictures animation presents: the mitchells vs. the machines	"Join artists from Sony Pictures Imageworks and Sony Pictures Animation for an exclusive behind-the-scenes presentation of ""The Mitchells vs. The Machines."" This production session will focus on the artistic and technological challenges of creating a visual style that has never been seen before, through the lens of the story of an everyday family's struggle to relate while technology rises up around the world! When Katie Mitchell, a creative outsider, is accepted into the film school of her dreams, her plans to meet ""her people"" at college are upended when her nature-loving dad Rick determines the whole family should drive Katie to school together and bond as a family one last time. Katie and Rick are joined by the rest of the family, including Katie's wildly positive mom Linda, her quirky little brother Aaron, and the family's delightfully chubby pug Monchi for the ultimate family road trip. Suddenly, the Mitchells' plans are interrupted by a tech uprising: all around the world, the electronic devices people love -- from phones, to appliances, to an innovative new line of personal robots - decide it's time to take over. With the help of two friendly malfunctioning robots, the Mitchells will have to get past their problems and work together to save each other and the world. From director Mike Rianda (Gravity Falls) and producers Phil Lord and Christopher Miller (Spider-Man: Into the Spider- Verse), ""The Mitchells vs. The Machines"" is coming to Netflix in 2021."	https://dl.acm.org/doi/abs/10.1145/3446368.3450755	Steven Argula, Michael Lasker, Alan Hawkins, Nicola Lavender, Dylan Reid, Lindsey Olivares
Spatially Adaptive Volume Tools in Bifrost	The level set method offers many advantages over e.g. meshes for modelling and visual effects, but a naïve implementation is both computationally expensive and memory intensive. Narrow band level sets alleviate both issues but are still limited by the finest detail resolved due to uniform resolution along the surface. Voxel structures that are adaptive along the surface improve this [Frisken et al. 2000], but have not seen wide adoption. This is presumably due to difficulties matching the performance of optimized narrow band implementations like industry standard OpenVDB [Museth 2013]. We present the adaptive level set implementation in Bifrost which is competitive with OpenVDB in speed while offering lower memory usage thanks to spatial adaptivity. Our contributions include novel algorithms for adaptive sharpened B-spline interpolation of volumes in general, voxelizing meshes and points into adaptive level set volumes, and meshing adaptive level sets.	https://dl.acm.org/doi/abs/10.1145/3450623.3464642	Morten Bojsen-Hansen, Michael Bang Nielsen, Konstantinos Stamatelos, Robert Bridson
Speak to Awaken EP.1 Diving into Siraya: An Endangered Language Speech Interactive VR Documentary	Speak to Awaken: Ep.1 Diving into Siraya is an experimental interactive VR documentary that aims to arouse interest in this issue. Experiencers can speak the endangered Siraya language to engage their reconstructed abstract world. They can also absorb facts on the revitalization process through the perspectives of related key persons and graphics. High-resolution VR360 videos, volumetric captures, and together with the voice donation website are adopted, as a new approach for the preservation of endangered language and its culture.	https://dl.acm.org/doi/abs/10.1145/3450615.3464537	Kuan Yuan Yuan LAI, Tsai-Jung Carol Han
Spectral imaging in production: course notes Siggraph 2021	Unlike path tracing, spectral rendering is still not widely used in production although it has been around for more than thirty years. Traditionally connected to spectral effects such as dispersion and interference, spectral rendering - and, more importantly, the use of spectral data in general - is predominantly a way to guarantee colour fidelity. Additionally, with the rise of path tracing and the growing use of LED lights on-set as well as the recent shift to LED walls in virtual production, it becomes increasingly evident that the traditional way of seeing colour and light as RGB triplets is insufficient if colour accuracy is required. The purpose of the course is two-fold. First and foremost, we want to share what we learned on our way towards a spectral image pipeline. We will talk about the unique opportunities and challenges the use of spectral data brings in a modern production pipeline and our motivation to build a spectral renderer. Since spectral data influences every step of the pipeline, the course will go beyond rendering aspects. We will discuss data acquisition and will shed some light on how to tackle the special problem of LED lights in production as well as its practical usage. The second aim of the course is to build a community. We want to see the topic evolve over the next few years and connect people to shape the future together until spectral imaging is as ubiquitous as path tracing is in production.	https://dl.acm.org/doi/abs/10.1145/3450508.3464582	Tomasz Bednarz, Alex Mathews, Daniel Filonik, Rowan T. Hughes, Dawei Chen, Liming Zhu
Stormzy - Superheroes	We are all superheroes. Stormzy helps us discover that everyone has their own unique super powers, no matter how mundane or boring they may seem. The world can be a truly amazing place when we realise our full potential - dreams really can come true - sometimes we need a little encouragement.	https://dl.acm.org/doi/abs/10.1145/3446562.3458443	Florent Sanglard
Straightened trees	"This series features silver gelatin prints of trees shot on large-format film and then straightened with custom code, giving strip malls, telephone poles, and restaurant signs the curves that once belonged to the elms, palms, and oaks they stand beside. It uses media less associated with technology, in part to emphasize algorithmic and human processes rather than technological tools. Using custom code, the natural curvature of each tree is ""corrected."" Manufactured objects, i.e., buildings and power lines, twist and contort around the artificially plumbed tree. Each photo is shot on large-format film, the only medium that captures enough detail to straighten the tree without pixelly artifacts. Because the trees need to include human-made objects (such as buildings) straight-on, they are often shot from a car's point of view. That aspect, plus the fact that all were shot in North America, emphasizes the classic photographic road trip (e.g., Lee Friedlander's )."	https://dl.acm.org/doi/abs/10.1145/3450507.3457431	Daniel Temkin
Stream-guided smoke simulations	High-resolution fluid simulations are computationally expensive, so many post-processing methods have been proposed to add turbulent details to low-resolution flows. Guiding methods are one promising approach for adding naturalistic, detailed motions as a post-process, but can be inefficient. Thus, we propose a novel, efficient method that formulates fluid guidance as a minimization problem in Input flows are first converted into stream functions, and a high resolution flow is then computed via optimization. The resulting problem sizes are much smaller than previous approaches, resulting in faster computation times. Additionally, our method does not require an expensive pressure projection, but still preserves mass. The method is both easy to implement and easy to control, as the user can control the degree of guiding with a single, intuitive parameter. We demonstrate the effectiveness of our method across various examples.	https://dl.acm.org/doi/abs/10.1145/3450626.3459846	Syuhei Sato, Yoshinori Dobashi, Theodore Kim
StrokeStrip: joint parameterization and fitting of stroke clusters	When creating freeform drawings, artists routinely employ clusters of overdrawn strokes to convey intended, aggregate curves. The ability to algorithmically fit these intended curves to their corresponding clusters is central to many applications that use artist drawings as inputs. However, while human observers effortlessly envision the intended curves given stroke clusters as input, existing fitting algorithms lack robustness and frequently fail when presented with input stroke clusters with non-trivial geometry or topology. We present , a new and robust method for fitting intended curves to vector-format stroke clusters. Our method generates fitting outputs consistent with viewer expectations across a vast range of input stroke cluster configurations. We observe that viewers perceive stroke clusters as continuous, varying-width whose paths are described by the intended curves. An arc length parameterization of these strips defines a natural mapping from a strip to its path. We recast the curve fitting problem as one of parameterizing the cluster strokes using a 1D parameterization that is the restriction of the natural arc length parameterization of this strip to the strokes in the cluster. We simultaneously compute the joint cluster parameterization and implicitly reconstruct the unknown strip geometry by solving a variational problem using a discrete-continuous optimization framework. We use this parameterization to compute parametric aggregate curves whose shape reflects the geometric properties of the cluster strokes at the corresponding isovalues. We demonstrate StrokeStrip outputs to be significantly better aligned with observer preferences compared to those of prior art; in a perceptual study, viewers preferred our fitting outputs by a factor of 12:1 compared to alternatives. We further validate our algorithmic choices via a range of ablation studies; extend our framework to raster data; and illustrate applications that benefit from the parameterizations produced.	https://dl.acm.org/doi/abs/10.1145/3450626.3459777	Dave Pagurek Van Mossel, Chenxi Liu, Nicholas Vining, Mikhail Bessmeltsev, Alla Sheffer
StyleCariGAN: caricature generation via StyleGAN feature map modulation	We present a caricature generation framework based on shape and style manipulation using StyleGAN. Our framework, dubbed , automatically creates a realistic and detailed caricature from an input photo with optional controls on shape exaggeration degree and color stylization type. The key component of our method is shape exaggeration blocks that are used for modulating coarse layer feature maps of StyleGAN to produce desirable caricature shape exaggerations. We first build a layer-mixed StyleGAN for photo-to-caricature style conversion by swapping fine layers of the StyleGAN for photos to the corresponding layers of the StyleGAN trained to generate caricatures. Given an input photo, the layer-mixed model produces detailed color stylization for a caricature but without shape exaggerations. We then append shape exaggeration blocks to the coarse layers of the layer-mixed model and train the blocks to create shape exaggerations while preserving the characteristic appearances of the input. Experimental results show that our StyleCariGAN generates realistic and detailed caricatures compared to the current state-of-the-art methods. We demonstrate StyleCariGAN also supports other StyleGAN-based image manipulations, such as facial expression control.	https://dl.acm.org/doi/abs/10.1145/3450626.3459860	Wonjong Jang, Gwangjin Ju, Yucheol Jung, Jiaolong Yang, Xin Tong, Seungyong Lee
StyleTune: Interactive Style Transfer Enhancement on Mobile Devices	We present StyleTune, a mobile app for interactive style transfer enhancement that enables global and spatial control over stroke elements and can generate high fidelity outputs. The app uses adjustable neural style transfer (NST) networks to enable art-direction of stroke size and orientation in the output image. The implemented approach enables continuous and seamless edits through a unified stroke-size representation in the feature space of the style transfer network. StyleTune introduces a three-stage user interface, that enables users to first explore global stroke parametrizations for a chosen NST. They can then interactively locally retouch the stroke size and orientation using brush metaphors. Finally, high resolution outputs of 20 Megapixels and more can be obtained using a patch-based upsampling and local detail transfer approach, that transfers small-scale details such as paint-bristles and canvas structure. The app uses Apple's CoreML and Metal APIs for efficient on-device processing.	https://dl.acm.org/doi/abs/10.1145/3450415.3464400	Benito Buchheim, Max Reimann, Sebastian Pasewaldt, Jürgen Döllner, Matthias Trapp
Stylizing Metals and More with the Glint Filter	We present a novel and artist-controllable system for stylizing metallic surfaces. This technique filters a beauty render with a Cryptomatte-encoded identifiers pass to generate a new stylized image. The ids pass drives an image-space color flood fill algorithm that uniformly colors regions to create a faceted metal appearance. The ids are generated using a variety of methods that target different aspects of the reflective surfaces. Tools that further modulate the facet ids give artists control over the effect in both render and compositing. The result is a smooth and temporally coherent effect that complements other non-photorealistic imagery. We can expand and generalize this technique to apply to non-faceted metallic surfaces.	https://dl.acm.org/doi/abs/10.1145/3450623.3464674	Eszter Offertaler, Angel Camacho-Torres, Nathan Zeichner
Stylizing Volumes with Neural Networks	"In ""Raya and The Last Dragon"", a blast of energy rings across the desiccated lands of the ancient world of Kumandra. This climactic story point represents a powerful force of magic and transformation, and as such, is art directed to be composed of stylized wave patterns and harmonic textures, as if created by sound vibrations. To achieve this, we artistically stylize a simulated volume using Neural Style Transfer. In this talk, we describe the integration of deep learning-based tools into our effects pipeline to accomplish this."	https://dl.acm.org/doi/abs/10.1145/3450623.3464652	Mike Navarro, Jacob Rice
Suga': a live virtual dance performance	is a live volumetric dance performance experience presented in Mozilla Hubs' social virtual reality space. The performer appears as a live-streamed 3D video within a photogrammetry scan of the Annaberg Sugar Mill Ruins in the U.S. Virgin Islands, when in fact she is performing from her living room. She traces the point cloud rendering of the mill with her movements as if preparing the space for ritual, recalling events that happened there. Through movement and soundscape, the performer tells the story of her own deep connection and mixed relationship to similar sites as a Black woman growing up in the Caribbean.	https://dl.acm.org/doi/abs/10.1145/3450507.3457436	Valencia James, Thomas Wester, Simon Boas, Holly Newlands, Marin Vesely, Sandrine Malary, Terri Ayanna Wright
Surface multigrid via intrinsic prolongation	This paper introduces a novel geometric multigrid solver for unstructured curved surfaces. Multigrid methods are highly efficient iterative methods for solving systems of linear equations. Despite the success in solving problems defined on structured domains, generalizing multigrid to unstructured curved domains remains a challenging problem. The critical missing ingredient is a prolongation operator to transfer functions across different multigrid levels. We propose a novel method for computing the prolongation for triangulated surfaces based on intrinsic geometry, enabling an efficient geometric multigrid solver for curved surfaces. Our surface multigrid solver achieves better convergence than existing multigrid methods. Compared to direct solvers, our solver is orders of magnitude faster. We evaluate our method on many geometry processing applications and a wide variety of complex shapes with and without boundaries. By simply replacing the direct solver, we upgrade existing algorithms to interactive frame rates, and shift the computational bottleneck away from solving linear systems.	https://dl.acm.org/doi/abs/10.1145/3450626.3459768	Hsueh-Ti Derek Liu, Jiayi Eris Zhang, Mirela Ben-Chen, Alec Jacobson
Sustainable society with a touchless solution using UbiMouse under the pandemic of COVID-19	"This paper introduces a new artificial intelligence software which is capable of controlling devices using fingers in the air. With Ubimouse, touch-panels, restaurant ordering systems, ATM systems, and etc., which are commonly used by various people in public, can be contact-less devices. These touch-less devices, especially under the harsh conditions of COVID-19, are desired to prevent infections mediated by touch devices. Also, these devices cannot be used while wearing gloves due to their touch sensing fault. Thus, in fields using gloves, there is a demand for non-contact device operation. To satisfy these demands, we have developed ""UbiMouse"". This is an AI software that allows you to operate the device by moving your fingers toward the device. In the AIs in UbiMouse, a convolution model and a regression model are used to identify fingers' features from camera footage and to estimates the position of a detected finger, respectively. We demonstrate an operation of UbiMouse without contact. Along with this operation in the air, a mouse cursor is guided to the specified location with high accuracy."	https://dl.acm.org/doi/abs/10.1145/3450550.3470532	Daisuke Akagawa, Junichi Takatsu, Ryoji Otsu, Seiichi Hayashi, Benjamin Vallet
SwarmPlay: A Swarm of Nano-Quadcopters Playing Tic-tac-toe Board Game against a Human	We present a new paradigm of games, i.e. SwarmPlay, where each playing component is presented by an individual drone that has its own mobility and swarm intelligence to win against a human player. The motivation behind the research is to make the games with machines tangible and interactive. Although some research on the robotic players for board games already exists, e.g., chess, the SwarmPlay technology has the potential to offer much more engagement and interaction with a human as it proposes a multi-agent swarm instead of a single interactive robot. The proposed system consists of a robotic swarm, a workstation, a computer vision (CV), and Game Theory-based algorithms. A novel game algorithm was developed to provide a natural game experience to the user. The preliminary user study revealed that participants were highly engaged in the game with drones (69% put a maximum score on the Likert scale) and found it less artificial compared to the regular computer-based systems (77% put maximum score). The affection of the user's game perception from its outcome was analyzed and put under discussion. User study revealed that SwarmPlay has the potential to be implemented in a wider range of games, significantly improving human-drone interactivity.	https://dl.acm.org/doi/abs/10.1145/3450550.3465346	Ekaterina Karmanova, Valerii Serpiva, Stepan Perminov, Roman Ibrahimov, Aleksey Fedoseev, Dzmitry Tsetserukou
Swept volumes via spacetime numerical continuation	Given a solid 3D shape and a trajectory of it over time, we compute its - the union of all points contained within the shape at some moment in time. We consider the representation of the input and output as implicit functions, and lift the problem to 4D spacetime, where we show the problem gains a continuous structure which avoids expensive global searches. We exploit this structure via a continuation method which marches and reconstructs the zero level set of the swept volume, using the temporal dimension to avoid erroneous solutions. We show that, compared to other methods, our approach is not restricted to a limited class of shapes or trajectories, is extremely robust, and its asymptotic complexity is an order lower than standards used in the industry, enabling its use in applications such as modeling, constructive solid geometry, and path planning.	https://dl.acm.org/doi/abs/10.1145/3450626.3459780	Silvia Sellán, Noam Aigerman, Alec Jacobson
Swish: Neural Network Cloth Simulation on Madden NFL 21	This work presents Swish, a real-time machine-learning based cloth simulation technique for games. Swish was used to generate realistic cloth deformation and wrinkles for NFL player jerseys in Madden NFL 21. To our knowledge, this is the first neural cloth simulation featured in a shipped game. This technique allows accurate high-resolution simulation for tight clothing, which is a case where traditional real-time cloth simulations often achieve poor results. We represent cloth detail using both mesh deformations and a database of normal maps, and train a simple neural network to predict cloth shape from the pose of a character's skeleton. We share implementation and performance details that will be useful to other practitioners seeking to introduce machine learning into their real-time character pipelines.	https://dl.acm.org/doi/abs/10.1145/3450623.3464665	Christopher Lewin
Systematically differentiating parametric discontinuities	Emerging research in computer graphics, inverse problems, and machine learning requires us to differentiate and optimize parametric discontinuities. These discontinuities appear in object boundaries, occlusion, contact, and sudden change over time. In many domains, such as rendering and physics simulation, we differentiate the parameters of models that are expressed as integrals over discontinuous functions. Ignoring the discontinuities during differentiation often has a significant impact on the optimization process. Previous approaches either apply specialized hand-derived solutions, smooth out the discontinuities, or rely on incorrect automatic differentiation. We propose a systematic approach to differentiating integrals with discontinuous integrands, by developing a new differentiable programming language. We introduce integration as a language primitive and account for the Dirac delta contribution from differentiating parametric discontinuities in the integrand. We formally define the language semantics and prove the correctness and closure under the differentiation, allowing the generation of gradients and higher-order derivatives. We also build a system, Teg, implementing these semantics. Our approach is widely applicable to a variety of tasks, including image stylization, fitting shader parameters, trajectory optimization, and optimizing physical designs.	https://dl.acm.org/doi/abs/10.1145/3450626.3459775	Sai Praveen Bangaru, Jesse Michel, Kevin Mu, Gilbert Bernstein, Tzu-Mao Li, Jonathan Ragan-Kelley
Take K-12 Students for Global Field Trips by Interactive Droneography	We build an interactive droneography system that emulates in-person field trips, letting students and educators see, learn and interact with remote places by flying drones at home. To guide students from missing directions or losing attention, a visual salience detector and an object recognizer through neural networks are also included.	https://dl.acm.org/doi/abs/10.1145/3450415.3464402	Luke Lu
Taking the Leap: Student Futures in Creative Careers	Industry panelists discuss measures that students can take to prepare for entering creative careers in computer graphics and interactive techniques. In the wake of global pandemic, creative industries have transformed. While certain aspects of hiring and recruitment processes remain unfazed, others have fundamentally changed. Transformed workplace cultures and new technologies present opportunities for alternative and de-habituated career paradigms. Simultaneously, new pathways present unforeseen challenges. Creative industry representatives discuss the general and specific state of affairs within their respective fields and provide insight into changing employment models. Discussion includes advice for educators to help prepare students for a variety of transforming career scenarios, as well as the preparation, training, and attributes students need to enter related fields. Panelists will consider the qualities underlying desirable entry-level applicants in their respective fields and elaborate upon changes in the transition from school to work resulting from the global pandemic. Represented industry segments include animation, interactive/experience design, computer graphics research, and virtual production. Questions considered include how schools and educators can help prepare students for successful transitions into creative careers; what entry-level applicants should have (and should not have) on resumes, portfolios, and demo reels; and what can students do on their own to proactively acquire requisite credentials. Discussion will expose fresh outlooks on the futures of creative fields in computer graphics and interactive techniques.	https://dl.acm.org/doi/abs/10.1145/3450549.3470533	Johannes DeYoung, Brooke Keesling, Rubaiat Habib, Brittany Biggs
Tales from Soda Island: the Neon Jungle	"""Tales from Soda Island"" is a series that tells stories from the world of the independent music collective ""Soda Island."" In this episode, journey through the Neon Jungle as you follow a Tadpolotl on its quest to deliver a package through the twisted depths of the jungle. Made in Quill."	https://dl.acm.org/doi/abs/10.1145/3446367.3452119	Simone Fourgnier, Dan Franke, Peter Ariet, Nick Ladd, Felix Steif, Nick Dias, Joe Mawson
TensorFlow graphics: differentiable computer graphics in tensorflow	Computer graphics is a sub-field of computer science which studies methods for digitally synthesizing and manipulating visual content.	https://dl.acm.org/doi/abs/10.1145/3450508.3464595	Rana Hanocka, Hsueh-Ti Derek Liu
TeraFoils: Design and Rapid Fabrication Techniques for Binary Holographic Structures in the Terahertz Region	In this paper, we introduce TeraFoils, a method for designing and fabricating material-based structures using binary holograms in the terahertz region. We outline the design, fabrication, imaging, and data processing steps for embedding information inside physical objects and exploring a method to create holographic structures with silver-foiled paper. This paper is a sheet on which silver foil is pasted where the ink is printed, using a home-use laser printer and an electric iron. Wave propagation calculations were performed to design a binary-amplitude hologram. Along with the designed pattern, we fabricated silver-foiled binary holograms in the sub-terahertz range (0.1 THz) and confirmed their functions using a two-dimensional THz sensor.	https://dl.acm.org/doi/abs/10.1145/3450618.3469157	Kenta Yamamoto, Kosaku Namikawa, Yoichi Ochiai
Text-Based Motion Synthesis with a Hierarchical Two-Stream RNN	We present a learning-based method for generating animated 3D pose sequences depicting multiple sequential or superimposed actions provided in long, compositional sentences. We propose a hierarchical two-stream sequential model to explore a finer joint-level mapping between natural language sentences and the corresponding 3D pose sequences of the motions. We learn two manifold representations of the motion –- one each for the upper body and the lower body movements. We evaluate our proposed model on the publicly available KIT Motion-Language Dataset containing 3D pose data with human-annotated sentences. Experimental results show that our model advances the state-of-the-art on text-based motion synthesis in objective evaluations by a margin of 50%.	https://dl.acm.org/doi/abs/10.1145/3450618.3469163	Anindita Ghosh, Noshaba Cheema, Cennet Oguz, Christian Theobalt, Philipp Slusallek
The Atmosphere of Raya and the Last Dragon	"The cultures of South-east Asia provided plentiful inspiration for the setting and art direction in Walt Disney Animation Studios' ""Raya and the Last Dragon"". This fantasy adventure required many unique environments ranging from desert landscapes to tropical forests, each describing rich lighting scenarios paired with the appropriate atmospherics. Many departments collaborated to create the extensive amount of atmospherics required by such varied and lush locations. Simultaneously, emphasis was placed on making the atmospheric Lighting workflow more efficient. We focused on improvements to allow Lighting artists more flexibility and control over making complicated atmospheric setups without having to request new assets or assistance from the Effects department on every shot. This in turn would save time and relieve significant production strain."	https://dl.acm.org/doi/abs/10.1145/3450623.3464676	Marc Bryant, Ryan DeYoung, Wei-Feng Wayne Huang, Joe Longson, Noel Villegas
The Hangman at Home: VR	Inspired by the iconic Carl Sandburg poem (1922), this piece explores themes of acknowledgement and participation. It is not about hanging people, but about the awkward intimacy that comes with being human, and the connection between spectator, witness, and accomplice.	https://dl.acm.org/doi/abs/10.1145/3446367.3452333	Michelle Kranot, Uri Kranot
The Right Foot in the Wrong Place: Half-Life Character LocomotionCharacter Locomotion in Half-Life: Alyx	This paper describes the non-player character locomotion system developed for the VR game Half-Life: Alyx. Our solution uses a stride retargeting system, footstep prediction, and a custom motion matching system to animate humanoid and non-humanoid characters as they navigate tight, dense virtual environments in real time.	https://dl.acm.org/doi/abs/10.1145/3450623.3469664	Joe van den Heuvel, James Cunliffe, Eddie Parker
The Tech and Art of Cyberspaces in Cyberpunk 2077	A deep dive into the technology and art behind cyberspace and braindances in Cyberpunk 2077. Braindances are the recorded memories and feelings of individuals, reprojected in the mind of the viewer. To bring this concept into reality, we decided to follow an unconventional approach to rendering environments and characters in real-time. The core visual concept was based around sparse point clouds and glitch effects. Post processes like datamoshing were used to further hide the underlying geometry, aiming for a surreal, out-of-body experience.	https://dl.acm.org/doi/abs/10.1145/3450623.3464662	Peter Ankermann, Oskar Swierad, Krzysztof Krzyscin
The design space of plane elastic curves	Elastic bending of initially flat slender elements allows the realization and economic fabrication of intriguing curved shapes. In this work, we derive an intuitive but rigorous geometric characterization of the design space of plane elastic rods with variable stiffness. It enables designers to determine which shapes are physically viable with active bending by visual inspection alone. Building on these insights, we propose a method for efficiently designing the geometry of a flat elastic rod that realizes a target equilibrium curve, which only requires solving a linear program. We implement this method in an interactive computational design tool that gives feedback about the feasibility of a design, and computes the geometry of the structural elements necessary to realize it within an instant. The tool also offers an iterative optimization routine that improves the fabricability of a model while modifying it as little as possible. In addition, we use our geometric characterization to derive an algorithm for analyzing and recovering the stability of elastic curves that would otherwise snap out of their unstable equilibrium shapes by buckling. We show the efficacy of our approach by designing and manufacturing several physical models that are assembled from flat elements.	https://dl.acm.org/doi/abs/10.1145/3450626.3459800	Christian Hafner, Bernd Bickel
The effect of shape and illumination on material perception: model and applications	Material appearance hinges on material reflectance properties but also surface geometry and illumination. The unlimited number of potential combinations between these factors makes understanding and predicting material appearance a very challenging task. In this work, we collect a large-scale dataset of perceptual ratings of appearance attributes with more than 215,680 responses for 42,120 distinct combinations of material, shape, and illumination. The goal of this dataset is twofold. First, we analyze for the first time the effects of illumination and geometry in material perception across such a large collection of varied appearances. We connect our findings to those of the literature, discussing how previous knowledge generalizes across very diverse materials, shapes, and illuminations. Second, we use the collected dataset to train a deep learning architecture for predicting perceptual attributes that correlate with human judgments. We demonstrate the consistent and robust behavior of our predictor in various challenging scenarios, which, for the first time, enables estimating perceived material attributes from general 2D images. Since our predictor relies on the final appearance in an image, it can compare appearance properties across different geometries and illumination conditions. Finally, we demonstrate several applications that use our predictor, including appearance reproduction using 3D printing, BRDF editing by integrating our predictor in a differentiable renderer, illumination design, or material recommendations for scene design.	https://dl.acm.org/doi/abs/10.1145/3450626.3459813	Ana Serrano, Bin Chen, Chao Wang, Michal Piovarči, Hans-Peter Seidel, Piotr Didyk, Karol Myszkowski
The making of marvel studios' WandaVision, The Falcon and the Winter Soldier, and Loki	Please join Marvel Studios in presenting our first ever episodic streaming series. The teams that worked on WandaVision, The Falcon and the Winter Soldier, and Loki will take SIGGRAPH audiences through their VFX journeys as they discuss some of their shows' most innovative visual effects. WandaVision - Wanda and Vision are two super-powered beings trying to fit in to their ideal suburban lives, but amidst the hijinks, they begin to suspect that everything is not as it seems. Marvel Studios, MARZ, and Rodeo FX discuss developing the various sitcom looks and Wanda's magic. The Falcon and the Winter Soldier - After the events of Avengers: Endgame, Sam Wilson (Falcon) and Bucky Barnes (Winter Soldier) team up to go on a globe-trotting adventure in pursuit of a new foe, testing both their abilities and their patience with one another. Marvel Studios, Weta Digital, and Sony Pictures Imageworks discuss how they took the visual spectacle to new heights with Falcon's flying effects, and created the complex CG environments. Loki - Picking up immediately after Loki steals the Tesseract in Avengers: Endgame, he finds himself called before the Time Variance Authority and given a choice: face deletion from reality as we know it or assist them in catching an even greater threat. Marvel Studios and ILM discuss designing some of the show's most mind-bending effects.	https://dl.acm.org/doi/abs/10.1145/3446368.3452376	Tanissa Schoen, Victoria Tracconi, Tara DeMarco, Ryan Freer, Julien Hery, Eric Leven, Charlie Tait, Chris Waegner, Dan DeLeeuw, Brad Parker, Dave Seager
The shape matching element method: direct animation of curved surface models	We introduce a new method for direct physics-based animation of volumetric curved models, represented using NURBS surfaces. Our technical contribution is the Shape Matching Element Method (SEM). SEM is a completely meshless algorithm, the first to simultaneously be robust to gaps and overlaps in geometry, be compatible with standard constitutive models and time integration schemes, support contact and frictional interactions and to preserve feature correspondence during simulation which enables editable simulated output. We demonstrate the efficacy of our algorithm by producing compelling physics-based animations from a variety of curved input models.	https://dl.acm.org/doi/abs/10.1145/3450626.3459772	Ty Trusty, Honglin Chen, David I. W. Levin
Thin-film smoothed particle hydrodynamics fluid	We propose a particle-based method to simulate thin-film fluid that jointly facilitates aggressive surface deformation and vigorous tangential flows. We build our dynamics model from the surface tension driven Navier-Stokes equation with the dimensionality reduced using the asymptotic lubrication theory and customize a set of differential operators based on the weakly compressible Smoothed Particle Hydrodynamics (SPH) for evolving pointset surfaces. The key insight is that the compressible nature of SPH, which is unfavorable in its typical usage, is helpful in our application to co-evolve the thickness, calculate the surface tension, and enforce the fluid incompressibility on a thin film. In this way, we are able to two-way couple the surface deformation with the in-plane flows in a physically based manner. We can simulate complex vortical swirls, fingering effects due to Rayleigh-Taylor instability, capillary waves, Newton's interference fringes, and the Marangoni effect on liberally deforming surfaces by presenting both realistic visual results and numerical validations. The particle-based nature of our system also enables it to conveniently handle topology changes and codimension transitions, allowing us to marry the thin-film simulation with a wide gamut of 3D phenomena, such as pinch-off of unstable catenoids, dripping under gravity, merging of droplets, as well as bubble rupture.	https://dl.acm.org/doi/abs/10.1145/3450626.3459864	Mengdi Wang, Yitong Deng, Xiangxin Kong, Aditya H. Prasad, Shiying Xiong, Bo Zhu
Time and Memory Efficient Displacement Map Extraction	Displacement maps are used to enhance the final rendered animation at most high-end studios including Blizzard Entertainment. However, commonly available products (Mudbox, Zbrush) that are used to sculpt high resolution models and extract displacements from low resolution counterparts are not conducive for quick iterative workflow that artists normally demand. Here we will summarize the drawbacks in accommodating such commercial products in our pipeline. We then present our custom solution developed using open industry standard libraries like OpenSubDiv (Pixar), OptiX (NVIDIA) and Embree (Intel). We also highlight how we employed frequency analysis (Discrete Cosine Transform) to extract time efficient and memory optimal displacement samples, all of which has objectively improved overall productivity in our workflows involving displacement maps.	https://dl.acm.org/doi/abs/10.1145/3450623.3464672	Vinod Melapudi, Parag Havaldar
To Miss The Ending	Set in a breathtaking visual landscape made of oversized voxels, a dystopian future unravels slowly around you. Set in a future of job automation, political uncertainty, environmental damage and the breakdown of human connection - all of which has led you here, uploading your consciousness to a machine.	https://dl.acm.org/doi/abs/10.1145/3446367.3451997	Anna West, David Callanan
Total relighting: learning to relight portraits for background replacement	We propose a novel system for portrait relighting and background replacement, which maintains high-frequency boundary details and accurately synthesizes the subject's appearance as lit by novel illumination, thereby producing realistic composite images for any desired scene. Our technique includes foreground estimation via alpha matting, relighting, and compositing. We demonstrate that each of these stages can be tackled in a sequential pipeline without the use of priors (e.g. known background or known illumination) and with no specialized acquisition techniques, using only a single RGB portrait image and a novel, target HDR lighting environment as inputs. We train our model using relit portraits of subjects captured in a light stage computational illumination system, which records multiple lighting conditions, high quality geometry, and accurate alpha mattes. To perform realistic relighting for compositing, we introduce a novel per-pixel lighting representation in a deep learning framework, which explicitly models the diffuse and the specular components of appearance, producing relit portraits with convincingly rendered non-Lambertian effects like specular highlights. Multiple experiments and comparisons show the effectiveness of the proposed approach when applied to in-the-wild images.	https://dl.acm.org/doi/abs/10.1145/3450626.3459872	Rohit Pandey, Sergio Orts Escolano, Chloe Legendre, Christian Häne, Sofien Bouaziz, Christoph Rhemann, Paul Debevec, Sean Fanello
Towards Large-Scale Super Resolution Datasets via Learned Downsampling of Ray-Traced Renderings	Delivering high resolution content is a challenge in the film and games industries due to the cost of photorealistic ray-traced rendering. Image upscaling techniques are commonly used to obtain a high resolution result from a low resolution render. Recently, deep learned upscaling has started to make an impact in production settings, synthesizing sharper and more detailed imagery than previous methods. The quality of a super resolution model depends on the size of its dataset, which can be expensive to generate at scale due to the large number of ray-traced pairs of renders required. In this report, we discuss our experiments training an additional neural network to learn the degradation operator, which can be used to rapidly generate low resolution images from existing high resolution renders. Our testing on production scenes shows that super resolution networks trained with a large synthetic dataset produce fewer artifacts and better reconstruction quality than networks trained on a smaller rendered dataset alone, and compare favorably to recent state of the art blind synthetic data techniques.	https://dl.acm.org/doi/abs/10.1145/3450623.3464631	Vaibhav Vavilala, Mark Meyer
Tracing versus freehand for evaluating computer-generated drawings	Non-photorealistic rendering (NPR) and image processing algorithms are widely assumed as a proxy for drawing. However, this assumption is not well assessed due to the difficulty in collecting and registering freehand drawings. Alternatively, tracings are easier to collect and register, but there is no quantitative evaluation of tracing as a proxy for freehand drawing. In this paper, we compare tracing, freehand drawing, and computer-generated drawing approximation (CGDA) to understand their similarities and differences. We collected a dataset of 1,498 tracings and freehand drawings by 110 participants for 100 image prompts. Our drawings are registered to the prompts and include vector-based timestamped strokes collected via stylus input. Comparing tracing and freehand drawing, we found a high degree of similarity in stroke placement and types of strokes used over time. We show that tracing can serve as a viable proxy for freehand drawing because of similar correlations between spatio-temporal stroke features and labeled stroke types. Comparing hand-drawn content and current CGDA output, we found that 60% of drawn pixels corresponded to computer-generated pixels on average. The overlap tended to be commonly drawn content, but people's artistic choices and temporal tendencies remained largely uncaptured. We present an initial analysis to inform new CGDA algorithms and drawing applications, and provide the dataset for use by the community.	https://dl.acm.org/doi/abs/10.1145/3450626.3459819	Zeyu Wang, Sherry Qiu, Nicole Feng, Holly Rushmeier, Leonard McMillan, Julie Dorsey
TransPose: real-time 3D human translation and pose estimation with six inertial sensors	Motion capture is facing some new possibilities brought by the inertial sensing technologies which do not suffer from occlusion or wide-range recordings as vision-based solutions do. However, as the recorded signals are sparse and quite noisy, online performance and global translation estimation turn out to be two key difficulties. In this paper, we present TransPose, a DNN-based approach to perform full motion capture (with both global translations and body poses) from only 6 Inertial Measurement Units (IMUs) at over 90 fps. For body pose estimation, we propose a multi-stage network that estimates leaf-to-full joint positions as intermediate results. This design makes the pose estimation much easier, and thus achieves both better accuracy and lower computation cost. For global translation estimation, we propose a supporting-foot-based method and an RNN-based method to robustly solve for the global translations with a confidence-based fusion technique. Quantitative and qualitative comparisons show that our method outperforms the state-of-the-art learning- and optimization-based methods with a large margin in both accuracy and efficiency. As a purely inertial sensor-based approach, our method is not limited by environmental settings (e.g., fixed cameras), making the capture free from common difficulties such as wide-range motion space and strong occlusion.	https://dl.acm.org/doi/abs/10.1145/3450626.3459786	Xinyu Yi, Yuxiao Zhou, Feng Xu
Transfer matrix based layered materials rendering	A statistical multi-lobe approach was recently introduced in order to efficiently handle layered materials rendering as an alternative to expensive general-purpose approaches. However, this approach poorly supports scattering volumes as the method does not account for back-scattering and resorts to single scattering approximations. In this paper, we address these limitations with an efficient solution based upon a transfer matrix approach which leverages the properties of the Henyey-Greenstein phase function. Under this formalism, each scattering component of the stack is described through a lightweight matrix, layering operations are reduced to simple matrix products and the statistics of each BSDF lobe accounting for multiple scattering effects are obtained through matrix operators. Based on this representation, we leverage the versatility of the transfer matrix approach to efficiently handle forward and backward scattering which occurs in arbitrary layered materials. The resulting model enables the reproduction of a wide range of layered structures embedding scattering volumes of arbitrary depth, in constant computation time and with low variance.	https://dl.acm.org/doi/abs/10.1145/3450626.3459859	Joël Randrianandrasana, Patrick Callet, Laurent Lucas
Transparency Rendering in Cyberpunk 2077	This talk discusses in-detail the transparencies pipeline of Cyberpunk 2077. We present a high-level overview of the system, and then provide details on individual components. Particularly, we discuss our take on decoupled particle lighting (DPL), our distortion approach, and a parallel slab refraction approximation. We also provide performance details on target platforms for these features.	https://dl.acm.org/doi/abs/10.1145/3450623.3464629	Peter Sikachev, Szymon Slega, Kamil Nowakowski, Karol Kowalczyk
Trolls World Tour: Desert Bling	The fantastically realistic environment of Trolls World Tour took a detour into a blistering desert made purely with flecks of glitter. In order to capture the Trolls Glitter Desert experience, we blended the visual expectations of a sand-filled desert with the physical nature of flattened glitter pieces. We found the need to develop mathematical procedurals to integrate with various simulation techniques, and create a hand-drawn keyframe system to choreograph the glitter with 2d artistic control. We built custom USD software with performance increases of almost 10 times native cook times in order to work with the millions of sparkly plastic glitter instances, and integrated it with shaders for our proprietary MoonRay renderer.	https://dl.acm.org/doi/abs/10.1145/3450623.3464657	Youxi Woo, Doug Rizeakos
TryOnGAN: body-aware try-on via layered interpolation	Given a pair of images---target person and garment on another person---we automatically generate the target person in the given garment. Previous methods mostly focused on texture transfer via paired data training, while overlooking body shape deformations, skin color, and seamless blending of garment with the person. This work focuses on those three components, while also not requiring paired data training. We designed a pose conditioned StyleGAN2 architecture with a clothing segmentation branch that is trained on images of people wearing garments. Once trained, we propose a new layered latent space interpolation method that allows us to preserve and synthesize skin color and target body shape while transferring the garment from a different person. We demonstrate results on high resolution 512 × 512 images, and extensively compare to state of the art in try-on on both latent space generated and real images.	https://dl.acm.org/doi/abs/10.1145/3450626.3459884	Kathleen M Lewis, Srivatsan Varadharajan, Ira Kemelmacher-Shlizerman
Unbiased Emission and Scattering Importance Sampling For Heterogeneous Volumes	We present two new distance-sampling methods for production volume path tracing. We extend the null-collision integral formulation to efficiently gather heterogeneous volumetric emission, achieving higher-quality results. Additionally, we propose a tabulation-based approach to importance sample volumetric in-scattering through a spatial guiding data structure. Our methods improve the sampling efficiency for scenarios where low-order heterogeneous scattering dominates, which tends to cause high variance renderings with existing null-collision methods.	https://dl.acm.org/doi/abs/10.1145/3450623.3464644	Wei-Feng Wayne Huang, Peter Kutz, Yining Karl Li, Matt Jen-Yuan Chiang
Unconventional patterns on surfaces	We present a unified method to meshing surfaces with unconventional patterns, both periodic and aperiodic. These patterns, which have so far been studied on the plane, are patterns comprising a small number of tiles, that do not necessarily exhibit translational periodicity. Our method generalizes the de Bruijn multigrid method to the discrete setting, and thus reduces the problem to the computation of -Directional fields on triangle meshes. We work with all cases of directional symmetries that have been little studied, including odd and high We address the properties of such patterns on surfaces and the challenges in their construction, including order-preservation, seamlessness, duality, and singularities. We show how our method allows for the design of original and unconventional meshes that can be applied to architectural, industrial, and recreational design.	https://dl.acm.org/doi/abs/10.1145/3450626.3459933	Merel Meekes, Amir Vaxman
Understand_V.T.S.HAOS	Is there any other way for us to understand the world through Human and AI integration? is an installation that substitutes senses. It helps explore and ponder in the process of cultivation. This work conducts an experiment in which the possibility of the cooperation between natural and artificial algorithms is assessed, and serves as an approach to human enhancement. That is, it investigates how well our brains (natural) work with AI (man-made).	https://dl.acm.org/doi/abs/10.1145/3450507.3457440	Lai Jiun-Ting
Underwater Procedural Vegetation on Pixar’s Luca	On Luca, we extended the procedural vegetation and debris system, called Moss, which has been in use at Pixar since Brave, with capabilities to create lush underwater seascapes. The Moss system was modernized for Onward to be OSL (Open Shading Language) based, enabling artists without C++ expertise to develop new Moss types. For Luca, we added a deformable mesh geometry type for complex underwater vegetation. Additionally we added SeaWind, an OSL-based procedural motion module, to hit the specific art direction of flowing curves in underwater currents. We also improved the pipeline which brings procedural geometry into Houdini for integrating the hero simulation with the procedural motion seamlessly.	https://dl.acm.org/doi/abs/10.1145/3450623.3464671	Marlena Fecho, Brennan Mitchell, Jamie Williams
Unfinished Farewell	"As COVID-19 spreads across the globe and the number of deaths continues to rise, the heartbreaking experiences are being replaced by collective mourning. As German journalist and pacifist Kurt Tukholsky once said: ""The death of one man is a tragedy, the death of millions is a statistic"". When we look back at the help-seeking posts of those who were lost, those who died of unconfirmed COVID-19 testing reports; those who committed suicide out of despair; those whose life-saving medical equipment were being taken away and those who lost their lives due to overwork and infection from their patients... Many of them were not included in the official statistics, and they are likely to be forgotten over time. They were not being treated fairly when they were alive, and they were not being mentioned after they passed away. We spoke to one of those families. One daughter said: ""After this pandemic, who will remember someone such as my mother – she had nowhere to go for medical treatment; she was rejected by the hospital, and she had to die at home?"" This is one of the reasons why we built this online platform. We want to document as many people who have left us because of the pandemic as possible. Our website also includes the help-seeking information these people posted before they passed away. These are the evidences they have left in a particular moment in this pandemic. We hope to provide a space for family members to express their grief and for the public to mourn the dead. Behind every number is a life. ""Unfinished Farewell"" can be viewed at www.farewell.care and www.jiabaoli.org/covid19"	https://dl.acm.org/doi/abs/10.1145/3450623.3464646	Jiabao Li, Lu Wang, Wenying Wu, Laobai Wu, Min Zhu
Unified particle system for multiple-fluid flow and porous material	Porous materials are common in daily life. They include granular material (e.g. sand) that behaves like liquid flow when mixed with fluid and foam material (e.g. sponge) that deforms like solid when interacting with liquid. The underlying physics is further complicated when multiple fluids interact with porous materials involving coupling between rigid and fluid bodies, which may follow different physics models such as the Darcy's law and the multiple-fluid Navier-Stokes equations. We propose a unified particle framework for the simulation of multiple-fluid flows and porous materials. A novel virtual phase concept is introduced to avoid explicit particle state tracking and runtime particle deletion/insertion. Our unified model is flexible and stable to cope with multiple fluid interacting with porous materials, and it can ensure consistent mass and momentum transport over the whole simulation space.	https://dl.acm.org/doi/abs/10.1145/3450626.3459764	Bo Ren, Ben Xu, Chenfeng Li
Unsupervised learning for cuboid shape abstraction via joint segmentation from point clouds	Representing complex 3D objects as simple geometric primitives, known as shape abstraction, is important for geometric modeling, structural analysis, and shape synthesis. In this paper, we propose an unsupervised shape abstraction method to map a point cloud into a compact cuboid representation. We jointly predict cuboid allocation as part segmentation and cuboid shapes and enforce the consistency between the segmentation and shape abstraction for self-learning. For the cuboid abstraction task, we transform the input point cloud into a set of parametric cuboids using a variational auto-encoder network. The segmentation network allocates each point into a cuboid considering the point-cuboid affinity. Without manual annotations of parts in point clouds, we design four novel losses to jointly supervise the two branches in terms of geometric similarity and cuboid compactness. We evaluate our method on multiple shape collections and demonstrate its superiority over existing shape abstraction methods. Moreover, based on our network architecture and learned representations, our approach supports various applications including structured shape generation, shape interpolation, and structural shape clustering.	https://dl.acm.org/doi/abs/10.1145/3450626.3459873	Kaizhi Yang, Xuejin Chen
UsdShade in the Pixar Pipeline	The VFX and animation industry is widely adopting Pixar's USD (Universal Scene Description) format to describe and manipulate scene information throughout production of CG content. A key part to a complete description of a scene is the representation of shading of all the parts, which is the description of materials that will be used to render it. UsdShade is the submodule of USD that is designed to handle material description. UsdShade was developed at Pixar in 2014 during the production of Finding Dory and has been used on all following productions. Since then we have learned a lot and have refined our practices to get the most out of UsdShade. We want to share our best practices and learnings to guide others to great success in using UsdShade in their pipelines.	https://dl.acm.org/doi/abs/10.1145/3450623.3464670	Florian Hecht, Daniel McCoy, Stephen LaVietes, F. Sebastian Grassia
User interfaces for high-dimensional design problems: from theories to implementations	We introduce techniques for effectively performing tasks encompassing or in by the user. Such tasks emerge from applications involving many parameters or high-dimensional latent variables, with examples ranging from image editing, material editing, and shape design, to sound generation, arising in both and those with from machine learning. Mathematically, such a task can be formulated as an , where the user wants to maximize his or her subjective over candidates generated by a model that has for the user to handle. The solution is to bypass direct manipulation in high-dimensional spaces by extracting much , which in turn give rise to We introduce two core techniques for extracting such subspaces: one based on and the other on Bayesian optimization is useful when only point-sampling is possible for the relation between the goodness and the control parameters (thus, the user can treat the system as a black box), while differential subspace search is useful when differential information is further available for the given model. We introduce both and aspects of these techniques, and show applications to image editing, material editing, shape design, and sound generation.	https://dl.acm.org/doi/abs/10.1145/3450508.3464551	Theresa-Marie Rhyne
Using USD in Pixar’s Digital Backlot	At Pixar we have developed a set of tools to resurrect more than 33,000 previously-unusable set & prop models from our old films to be used as a studio-wide resource for previs, set dressing, cameos, automated testing, shader library development test subjects, short film and streaming projects, VR projects, and research. Based on the extensive use of USD [Disney/Pixar 2016], the Digital Backlot has now been used for four released feature films, three feature films still in production, and six completed short-form projects (with several more under development). Our pipeline also ensures that future asset development will continue to build up this library.	https://dl.acm.org/doi/abs/10.1145/3450623.3464654	Eliot K Smyrl
Using isometries for computational design and fabrication	We solve the task of representing free forms by an arrangement of panels that are manufacturable by precise isometric bending of surfaces made from a small number of molds. In fact we manage to solve the paneling task with surfaces of constant Gaussian curvature alone. This includes the case of developable surfaces which exhibit zero curvature. Our computations are based on an existing discrete model of isometric mappings between surfaces which for this occasion has been refined to obtain higher numerical accuracy. Further topics are interesting connections of the paneling problem with the geometry of Killing vector fields, designing and actuating isometries, curved folding in the double-curved case, and quad meshes with rigid faces that are nevertheless flexible.	https://dl.acm.org/doi/abs/10.1145/3450626.3459839	Caigui Jiang, Hui Wang, Victor Ceballos Inza, Felix Dellinger, Florian Rist, Johannes Wallner, Helmut Pottmann
VR Animation Assignment for Students with a Background in Traditional Hand-Drawing Techniques	Media technologies, such as virtual reality (VR), have begun to revolutionize. Consequently, the seamless presentation of media, such as animation, film, and games, has developed remarkably. This integration of advanced media and experiences into the educational environment offers great potential[Mones 2017]. In a similar vein, we believe that such integration leads to the revitalization of the entire industry, which allows students who have a background in traditional hand-drawn methods of expression practice using advanced media and develop their skills. In this submission, we present a drawing expression challenge in 360 degrees of space to students with background in traditional painting. To ensure that this assignment is free of technical hurdles, no game engines or VR painting applications will be used. Only paper, art materials, and common painting and video editing software will be used by the students to complete the assignment. Figure 1 shows the examples of VR animation by students.	https://dl.acm.org/doi/abs/10.1145/3450549.3464415	Nahomi Maki
VR SuperGun: Interfacing 1980s Arcade Hardware with Online Virtual Reality	VR SuperGun is a custom hardware and software prototype allowing play of original arcade platforms through a network connection, reconstituting the material form of the arcade cabinet in digital space. It extends the format of the SuperGun, a device that contains the wiring of an arcade cabinet in consolised form.	https://dl.acm.org/doi/abs/10.1145/3450615.3464526	Kieran Nolan
Vermillion: Oil Painting Simulation In Virtual Reality: A new tool for digital artists offering the analog control of traditional painting with the benefits of a virtual environment.	Digital art has come a long way since the first release of MS Paint. And while artists can already work wonders with the tools at their disposal, there's always been a very distinct barrier between traditional mediums and the digital ones. Instead of brushes on a canvas, a stylus on a screen is used. Instead of mixing paints of different colors and thickness, a color picker and transparency slider are presented. The instinctiveness and versatility of bristles on canvas have been replaced with a selection of discrete tools - draw, blur, smudge,... It's also not possible to make strokes with large gestures, to work on your piece from arm's length, like the old masters did. The typical texture that physical paint has is also lost in drawing programs. Vermillion offers a new tool for digital artists, be they novices who always wanted to try their hand at following along with Bob Ross, or veteran Photoshop users who long for more analog control. It simulates the full oil painting experience. A selection of specialist brushes is offered, each with unique characteristics and their distinct brush pattern. The bristles bend as they are pushed against a surface, soaking up the paint that's on the palette. The paints mix as they would in the real world, not as RGB colors do on a monitor. Paint thinner can be used to control the thickness and flow of the paint. The paint can be pushed, pulled, blurred and blended on the canvas, and shows the relief and pattern of your strokes. The resulting piece can be exported to be presented as a new digital work of art.	https://dl.acm.org/doi/abs/10.1145/3450615.3464542	Thomas van den Berge
Video recoloring via spatial-temporal geometric palettes	Color correction and color grading are important steps in film production. Recent palette-based approaches to image recoloring have shown that a small set of representative colors provide an intuitive set of handles for color adjustment. However, a single, static palette cannot represent the time-varying colors in a video. We introduce a spatial-temporal geometry-based approach to video recoloring. Specifically, its core is a 4D skew polytope with a few vertices that approximately encloses the video pixels in color and time, which implicitly defines time-varying palettes through slicing of the 4D skew polytope at specific time values. Our geometric palette is compact, descriptive, and provides a correspondence between colors throughout the video, including topological changes when colors merge or split. Experiments show that our method produces natural, artifact-free recoloring.	https://dl.acm.org/doi/abs/10.1145/3450626.3459675	Zheng-Jun Du, Kai-Xiang Lei, Kun Xu, Jianchao Tan, Yotam Gingold
View Synthesis In Casually Captured Scenes Using a Cylindrical Neural Radiance Field With Exposure Compensation	We extend Neural Radiance Fields (NeRF) with a cylindrical parameterization that enables rendering photorealistic novel views of 360° outward facing scenes. We further introduce a learned exposure compensation parameter to account for the varying exposure in training images that may occur from casually capturing a scene. We evaluate our method on a variety of 360° casually captured scenes.	https://dl.acm.org/doi/abs/10.1145/3450618.3469147	Wesley Khademi, Jonathan Ventura
Virtual Production for Remote Teaching Modalities: Adapting Sustainable Remote Teaching and Learning Environments by Leveraging Real-time Computer Graphics	Approaches for leveraging real-time graphics, virtual production technologies to bring the visual richness, diversity and fidelity of bespoke teaching venues into the realm of teleconference-based, distanced learning. A variety of readily accessible tools and implementations are presented that dramatically enhance the experience of teaching and learning through common teleconferencing platforms.	https://dl.acm.org/doi/abs/10.1145/3450549.3464412	Nick Jushchyshyn, Sandra Parks
Virtual Reality Live Theatre on No Budget: A Model for Independent Theatrical Productions using Open-Source Social VR	Jettison, along with the entire OnBoardXR festival, is produced and performed live entirely in virtual reality using the open-source Mozilla Hubs platform. These shows took place in a virtual representation of a theater, leveraging the shared conventions of live theatrical performance to simplify the challenge of onboarding the audience: knowing how to behave in a real world theater translates intuitively to behavior in a virtual theater. At the same time, our production process mimicked that of real world theater, with very close parallels in the application of traditional theatrical skills and practices – with the main difference being that our cast and crew were all fully remote. Finally, the Hubs platform allows audiences to view the show on a range of hardware from VR HMDs to tablets and phones. Put together, our process represents a model by which independent theater companies can create productions using familiar techniques and skills, and present it for distributed audiences who don't have dedicated hardware. Ours was an approach of utilizing the latest virtualization technology to allow access to the widest range of audience possible, all from a bare-bones production budget. Unlike other approaches to virtual or online theater, the work of Jettison and its OnBoardXR is an attempt to, as closely as possible, replicate the experience of attending a show in a real world theater – an experience unavailable over the past year. In this talk we will describe our process and learnings.	https://dl.acm.org/doi/abs/10.1145/3450549.3464413	Alex Coulombe, David Gochfeld, Brendan Bradley, Kevin Laibson, Robert Long, Roman Miletitch
Visualization of imaginary stroke movement in painting and calligraphy	"Beholders can feel the imaginary movement from the artist's brushstrokes in visual artworks. This psychological phenomenon has been recorded in the world's art literature, and its physiological basis has been found by neuroaesthetics researchers. However, past practice and research have neither tried to fetch the ""data"" of the imaginary stroke movement from the brain nor re-created artworks in new forms based on it. By drawing lessons from ""copying,"" a common practice in art skill training, we develop two interactive ""painting"" applications which enable the user to draw their perceived stroke movement on reference artworks."	https://dl.acm.org/doi/abs/10.1145/3450507.3457437	Tianqin Zhang, Ruimin Lyu, Zhaolin Yuan
Volumetric appearance stylization with stylizing kernel prediction network	This paper aims to efficiently construct the volume of heterogeneous single-scattering albedo for a given medium that would lead to desired color appearance. We achieve this goal by formulating it as a volumetric style transfer problem in which an input 3D density volume is stylized using color features extracted from a reference 2D image. Unlike existing algorithms that require cumbersome iterative optimizations, our method leverages a feed-forward deep neural network with multiple well-designed modules. At the core of our network is a stylizing kernel predictor (SKP) that extracts multi-scale feature maps from a 2D style image and predicts a handful of stylizing kernels as a highly non-linear combination of the feature maps. Each group of stylizing kernels represents a specific style. A volume autoencoder (VolAE) is designed and jointly learned with the SKP to transform a density volume to an albedo volume based on these stylizing kernels. Since the autoencoder does not encode any style information, it can generate different albedo volumes with a wide range of appearance once training is completed. Additionally, a hybrid multi-scale loss function is used to learn plausible color features and guarantee temporal coherence for time-evolving volumes. Through comprehensive experiments, we validate the effectiveness of our method and show its superiority by comparing against state-of-the-arts. We show that with our method a novice user can easily create a diverse set of realistic translucent effects for 3D models (either static or dynamic), neglecting any cumbersome process of parameter tuning.	https://dl.acm.org/doi/abs/10.1145/3450626.3459799	Jie Guo, Mengtian Li, Zijing Zong, Yuntao Liu, Jingwu He, Yanwen Guo, Ling-Qi Yan
WRAPD: weighted rotation-aware ADMM for parameterization and deformation	Local-global solvers such as ADMM for elastic simulation and geometry optimization struggle to resolve large rotations such as bending and twisting modes, and large distortions in the presence of barrier energies. We propose two improvements to address these challenges. First, we introduce a novel local-global splitting based on the polar decomposition that separates the geometric nonlinearity of rotations from the material nonlinearity of the deformation energy. The resulting ADMM-based algorithm is a combination of an L-BFGS solve in the global step and proximal updates of element stretches in the local step. We also introduce a novel method for dynamic reweighting that is used to adjust element weights at runtime for improved convergence. With both improved rotation handling and element weighting, our algorithm is considerably faster than state-of-the-art approaches for quasi-static simulations. It is also much faster at making early progress in parameterization problems, making it valuable as an initializer to jump-start second-order algorithms.	https://dl.acm.org/doi/abs/10.1145/3450626.3459942	George E. Brown, Rahul Narain
Walking Balance Assessment with Eye-tracking and Spatial Data Visualization	Virtual Reality (VR) based assessment systems can simulate diverse real-life scenarios and help clinicians assess participants' performance under controlled functional contexts. Our previous work demonstrated an assessment paradigm to provide multi-sensory stimuli and cognitive load, and quantify walking balance with obstacle negotiation by motion capture and pressure sensing. However, we need to fill two gaps to make it more clinically relevant: 1. it required offline complex data processing with external statistical analysis software; 2. it utilized motion tracking but overlooked eye movement. Therefore, we present a novel walking balance assessment system with eye tracking to investigate the role of eye movement in walking balance and spatial data visualization to better interpret and understand the experimental data. The spatial visualization includes instantaneous in-situ VR replay for the gaze, head, and feet; and data plots for the outcome measures. The system fills a need to provide eye tracking and intuitive feedback in VR to experimenters, clinicians, and participants in real-time.	https://dl.acm.org/doi/abs/10.1145/3450615.3464533	Zhu Wang, Anat Lubetzky, Ken Perlin
Weakly-supervised contrastive learning in path manifold for Monte Carlo image reconstruction	Image-space auxiliary features such as surface normal have significantly contributed to the recent success of Monte Carlo (MC) reconstruction networks. However, path-space features, another essential piece of light propagation, have not yet been sufficiently explored. Due to the curse of dimensionality, information flow between a regression loss and high-dimensional path-space features is sparse, leading to difficult training and inefficient usage of path-space features in a typical reconstruction framework. This paper introduces a contrastive manifold learning framework to utilize path-space features effectively. The proposed framework employs weakly-supervised learning that converts reference pixel colors to dense pseudo labels for light paths. A convolutional path-embedding network then induces a low-dimensional manifold of paths by iteratively clustering intra-class embeddings, while discriminating inter-class embeddings using gradient descent. The proposed framework facilitates path-space exploration of reconstruction networks by extracting low-dimensional yet meaningful embeddings within the features. We apply our framework to the recent image- and sample-space models and demonstrate considerable improvements, especially on the sample space. The source code is available at https://github.com/Mephisto405/WCMC.	https://dl.acm.org/doi/abs/10.1145/3450626.3459876	In-Young Cho, Yuchi Huo, Sung-Eui Yoon
Weaving The Druun’s Webbing	"The Druun in Walt Disney Animation Studio's ""Raya and the Last Dragon"" is a unique character, both in design and in implementation. Over the course of this film, unique solutions were designed to overcome the technical challenges of having a creature made of both a fluid and a web like structure. In this talk we will present the techniques used to bring one of the Druun's amazing features to life: the webbing."	https://dl.acm.org/doi/abs/10.1145/3450623.3464647	Jacob Benjamin Rice
WhiteStone: A Tangible interactive device for revitalizing Qiang language and culture	"The Qiang is an ancient minority in western China. However, the number of people who can speak the Qiang language is decreasing due to a lack of written text. Although the protection of intangible cultural heritage has been widely discussed, there is still a dearth of interactive design for the Qiang people's language and culture. This research aims to determine the efficacy of tangible interactive games to encourage Qiang people's interest in learning the Qiang language and increase their cultural awareness. To better understand the current state and challenges of Qiang language and culture, we conducted a three-day field investigation in the Qiang villages. Based on the field study's key findings, we created ""WhiteStone,"" a tangible interactive projection device based on the heroic epic of Qiang. This poster examines the design opportunities for tangible interactive games to revitalize the Qiang language and culture."	https://dl.acm.org/doi/abs/10.1145/3450618.3469159	Qin Wu, Rao Xu, Lingze Wu
Why you walk like that: Inferring Body Conditions from Single Gait Cycle	Gait is a key barometer to analyze human body conditions. We propose a personalized gait analysis framework which can diagnose a possible muscularskeletal disorders with a single gait cycle. Our framework built over a gait manifold which reveals the principle kinematic characteristics in the temporal pose sequence. Body parameters such as muscle, skeleton, and joint limits for an arbitrary gait cycle can be approximated by measuring similarity in the small latent space. We present a physical gait simulator to enrich the gait space paired with the body conditions.	https://dl.acm.org/doi/abs/10.1145/3450618.3469162	Sehee Min, Jehee Lee
Wide Angular Range Dynamic Projection Mapping Method Applied to the Projection on a Flying Drone.	In this study, we proposed a method to realize dynamic projection mapping on a target moving at high speed in a wide angular range around the projection equipment using a high-speed gaze control system, and actually implemented and evaluated it. We also combined the proposed system with a teleconferencing system, and conducted an experiment in which a drone was used as an avatar robot for communication with remote locations.	https://dl.acm.org/doi/abs/10.1145/3450618.3469137	Shino Higuchi, Hiromasa Oku
Wig: The Hair Story From Shrek 2 to The Croods: A New Age	This talk presents the features and history of DreamWorks' Wig system, which has been used over the past twenty years on 28 animated feature films and over 2,000 hair setups and growing. The principal philosophy of the system since its inception has been to place control over simulations into the hands of animators. Over time, the system and its related tools have been updated to meet the challenges of evolving technologies and respond to animator needs. With its production proven history, and flexible architecture, the system continues to adapt to recent hair-heavy productions.	https://dl.acm.org/doi/abs/10.1145/3450623.3464667	Megha Davalath, Terran Boylan, Rob O'Neill, Rob Vogt
WireRoom: model-guided explorative design of abstract wire art	We present , a computational framework for the intelligent design of abstract 3D wire art to depict a given 3D model. Our algorithm generates a set of 3D wire shapes from the 3D model with informative, visually pleasing, and concise structures. It is achieved by solving a dynamic travelling salesman problem on the surface of the 3D model with a multi-path expansion approach. We introduce a novel explorative computational design procedure by taking the generated wire shapes as candidates, avoiding manual design of the wire shape structure. We compare our algorithm with a baseline method and conduct a user study to investigate the usability of the framework and the quality of the produced wire shapes. The results of the comparison and user study confirm that our framework is effective for producing informative, visually pleasing, and concise wire shapes.	https://dl.acm.org/doi/abs/10.1145/3450626.3459796	Zhijin Yang, Pengfei Xu, Hongbo Fu, Hui Huang
Wrapped Clothing on Disney’s Raya and the Last Dragon	"This talk outlines novel techniques used to create the complex wrapped clothing on Walt Disney Animation Studios' ""Raya and the Last Dragon"". Inspired by traditional Southeast Asian designs, these wrapped garments are formed by deftly folding long panels of cloth, with little to no reliance on seams to hold the structure. This departure from a standard pattern-based pipeline made the construction and performance of these specialized garments in CG a very challenging task. Using the sampot, dhoti, and bust-wrap garments as production examples, we describe their real-world counterpart designs and construction, discuss what makes them challenging to create in CG, and then outline how we extrapolated their designs and realized them for the stylistic needs and performances of the characters on the film."	https://dl.acm.org/doi/abs/10.1145/3450623.3464659	AVNEET KAUR, JOHANN FRANCOIS COETZEE
